title,pubdate,id,authors,categories,search,abstract,displaydate
"How Well Can LLMs Echo Us? Evaluating AI Chatbots' Role-Play Ability
  with ECHO",2024-04-22 08:00:51+00:00,http://arxiv.org/abs/2404.13957v1,"Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan Wang, Michael R. Lyu",cs.CL,games,"The role-play ability of Large Language Models (LLMs) has emerged as a
popular research direction. However, existing studies focus on imitating
well-known public figures or fictional characters, overlooking the potential
for simulating ordinary individuals. Such an oversight limits the potential for
advancements in digital human clones and non-player characters in video games.
To bridge this gap, we introduce ECHO, an evaluative framework inspired by the
Turing test. This framework engages the acquaintances of the target individuals
to distinguish between human and machine-generated responses. Notably, our
framework focuses on emulating average individuals rather than historical or
fictional figures, presenting a unique advantage to apply the Turing Test. We
evaluated three role-playing LLMs using ECHO, with GPT-3.5 and GPT-4 serving as
foundational models, alongside the online application GPTs from OpenAI. Our
results demonstrate that GPT-4 more effectively deceives human evaluators, and
GPTs achieves a leading success rate of 48.3%. Furthermore, we investigated
whether LLMs could discern between human-generated and machine-generated texts.
While GPT-4 can identify differences, it could not determine which texts were
human-produced. Our code and results of reproducing the role-playing LLMs are
made publicly available via https://github.com/CUHK-ARISE/ECHO.",2024-04-22
"MAP-Elites with Transverse Assessment for Multimodal Problems in
  Creative Domains",2024-03-11 21:50:22+00:00,http://arxiv.org/abs/2403.07182v1,"Marvin Zammit, Antonios Liapis, Georgios N. Yannakakis",cs.NE,games,"The recent advances in language-based generative models have paved the way
for the orchestration of multiple generators of different artefact types (text,
image, audio, etc.) into one system. Presently, many open-source pre-trained
models combine text with other modalities, thus enabling shared vector
embeddings to be compared across different generators. Within this context we
propose a novel approach to handle multimodal creative tasks using Quality
Diversity evolution. Our contribution is a variation of the MAP-Elites
algorithm, MAP-Elites with Transverse Assessment (MEliTA), which is tailored
for multimodal creative tasks and leverages deep learned models that assess
coherence across modalities. MEliTA decouples the artefacts' modalities and
promotes cross-pollination between elites. As a test bed for this algorithm, we
generate text descriptions and cover images for a hypothetical video game and
assign each artefact a unique modality-specific behavioural characteristic.
Results indicate that MEliTA can improve text-to-image mappings within the
solution space, compared to a baseline MAP-Elites algorithm that strictly
treats each image-text pair as one solution. Our approach represents a
significant step forward in multimodal bottom-up orchestration and lays the
groundwork for more complex systems coordinating multimodal creative agents in
the future.",2024-03-11
SyntaxShap: Syntax-aware Explainability Method for Text Generation,2024-02-14 15:45:56+00:00,http://arxiv.org/abs/2402.09259v1,"Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady","cs.CL, cs.AI",games,"To harness the power of large language models in safety-critical domains we
need to ensure the explainability of their predictions. However, despite the
significant attention to model interpretability, there remains an unexplored
domain in explaining sequence-to-sequence tasks using methods tailored for
textual data. This paper introduces SyntaxShap, a local, model-agnostic
explainability method for text generation that takes into consideration the
syntax in the text data. The presented work extends Shapley values to account
for parsing-based syntactic dependencies. Taking a game theoric approach,
SyntaxShap only considers coalitions constraint by the dependency tree. We
adopt a model-based evaluation to compare SyntaxShap and its weighted form to
state-of-the-art explainability methods adapted to text generation tasks, using
diverse metrics including faithfulness, complexity, coherency, and semantic
alignment of the explanations to the model. We show that our syntax-aware
method produces explanations that help build more faithful, coherent, and
interpretable explanations for predictions by autoregressive models.",2024-02-14
Prompt Optimization via Adversarial In-Context Learning,2023-12-05 09:44:45+00:00,http://arxiv.org/abs/2312.02614v1,"Xuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, Junxian He","cs.LG, cs.CL",games,"We propose a new method, Adversarial In-Context Learning (adv-ICL), to
optimize prompt for in-context learning (ICL) by employing one LLM as a
generator, another as a discriminator, and a third as a prompt modifier. As in
traditional adversarial learning, adv-ICL is implemented as a two-player game
between the generator and discriminator, where the generator tries to generate
realistic enough output to fool the discriminator. In each round, given an
input prefixed by task instructions and several exemplars, the generator
produces an output. The discriminator is then tasked with classifying the
generator input-output pair as model-generated or real data. Based on the
discriminator loss, the prompt modifier proposes possible edits to the
generator and discriminator prompts, and the edits that most improve the
adversarial loss are selected. We show that adv-ICL results in significant
improvements over state-of-the-art prompt optimization techniques for both open
and closed-source models on 11 generation and classification tasks including
summarization, arithmetic reasoning, machine translation, data-to-text
generation, and the MMLU and big-bench hard benchmarks. In addition, because
our method uses pre-trained models and updates only prompts rather than model
parameters, it is computationally efficient, easy to extend to any LLM and
task, and effective in low-resource settings.",2023-12-05
"LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language
  Models",2023-11-30 03:59:31+00:00,http://arxiv.org/abs/2311.18232v1,"Marwa Abdulhai, Isadora White, Charlie Snell, Charles Sun, Joey Hong, Yuexiang Zhai, Kelvin Xu, Sergey Levine","cs.CL, cs.AI, cs.LG",games,"Large language models (LLMs) provide excellent text-generation capabilities,
but standard prompting and generation methods generally do not lead to
intentional or goal-directed agents and might necessitate considerable prompt
tuning. This becomes particularly apparent in multi-turn conversations: even
the best current LLMs rarely ask clarifying questions, engage in explicit
information gathering, or take actions now that lead to better decisions after
multiple turns. Reinforcement learning has the potential to leverage the
powerful modeling capabilities of LLMs, as well as their internal
representation of textual interactions, to create capable goal-directed
language agents. This can enable intentional and temporally extended
interactions, such as with humans, through coordinated persuasion and carefully
crafted questions, or in goal-directed play through text games to bring about
desired final outcomes. However, enabling this requires the community to
develop stable and reliable reinforcement learning algorithms that can
effectively train LLMs. Developing such algorithms requires tasks that can
gauge progress on algorithm design, provide accessible and reproducible
evaluations for multi-turn interactions, and cover a range of task properties
and challenges in improving reinforcement learning algorithms. Our paper
introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,
together with an open-source research framework containing a basic toolkit for
getting started on multi-turn RL with offline value-based and policy-based RL
methods. Our benchmark consists of 8 different language tasks, which require
multiple rounds of language interaction and cover a range of tasks in
open-ended dialogue and text games.",2023-11-30
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,games,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
The Consensus Game: Language Model Generation via Equilibrium Search,2023-10-13 14:27:21+00:00,http://arxiv.org/abs/2310.09139v1,"Athul Paul Jacob, Yikang Shen, Gabriele Farina, Jacob Andreas","cs.GT, cs.AI, cs.CL, cs.LG",games,"When applied to question answering and other text generation tasks, language
models (LMs) may be queried generatively (by sampling answers from their output
distribution) or discriminatively (by using them to score or rank a set of
candidate outputs). These procedures sometimes yield very different
predictions. How do we reconcile mutually incompatible scoring procedures to
obtain coherent LM predictions? We introduce a new, a training-free,
game-theoretic procedure for language model decoding. Our approach casts
language model decoding as a regularized imperfect-information sequential
signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks
to communicate an abstract correctness parameter using natural language
sentences to a DISCRIMINATOR. We develop computational procedures for finding
approximate equilibria of this game, resulting in a decoding algorithm we call
EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading
comprehension, commonsense reasoning, mathematical problem-solving, and
dialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,
improves performance over existing LM decoding procedures - on multiple
benchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B
outperforms the much larger LLaMA-65B and PaLM-540B models. These results
highlight the promise of game-theoretic tools for addressing fundamental
challenges of truthfulness and consistency in LMs.",2023-10-13
"Specializing Small Language Models towards Complex Style Transfer via
  Latent Attribute Pre-Training",2023-09-19 21:01:40+00:00,http://arxiv.org/abs/2309.10929v1,"Ruiqi Xu, Yongfeng Huang, Xin Chen, Lin Zhang",cs.CL,games,"In this work, we introduce the concept of complex text style transfer tasks,
and constructed complex text datasets based on two widely applicable scenarios.
Our dataset is the first large-scale data set of its kind, with 700 rephrased
sentences and 1,000 sentences from the game Genshin Impact. While large
language models (LLM) have shown promise in complex text style transfer, they
have drawbacks such as data privacy concerns, network instability, and high
deployment costs. To address these issues, we explore the effectiveness of
small models (less than T5-3B) with implicit style pre-training through
contrastive learning. We also propose a method for automated evaluation of text
generation quality based on alignment with human evaluations using ChatGPT.
Finally, we compare our approach with existing methods and show that our model
achieves state-of-art performances of few-shot text style transfer models.",2023-09-19
"Learning to Generate Equitable Text in Dialogue from Biased Training
  Data",2023-07-10 01:44:13+00:00,http://arxiv.org/abs/2307.04303v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.AI",games,"The ingrained principles of fairness in a dialogue system's decision-making
process and generated responses are crucial for user engagement, satisfaction,
and task achievement. Absence of equitable and inclusive principles can hinder
the formation of common ground, which in turn negatively impacts the overall
performance of the system. For example, misusing pronouns in a user interaction
may cause ambiguity about the intended subject. Yet, there is no comprehensive
study of equitable text generation in dialogue. Aptly, in this work, we use
theories of computational learning to study this problem. We provide formal
definitions of equity in text generation, and further, prove formal connections
between learning human-likeness and learning equity: algorithms for improving
equity ultimately reduce to algorithms for improving human-likeness (on
augmented data). With this insight, we also formulate reasonable conditions
under which text generation algorithms can learn to generate equitable text
without any modifications to the biased training data on which they learn. To
exemplify our theory in practice, we look at a group of algorithms for the
GuessWhat?! visual dialogue game and, using this example, test our theory
empirically. Our theory accurately predicts relative-performance of multiple
algorithms in generating equitable text as measured by both human and automated
evaluation.",2023-07-10
Designing Mixed-Initiative Video Games,2023-07-08 01:45:25+00:00,http://arxiv.org/abs/2307.03877v1,Daijin Yang,"cs.HC, cs.AI, J.5",games,"The development of Artificial Intelligence (AI) enables humans to co-create
content with machines. The unexpectedness of AI-generated content can bring
inspiration and entertainment to users. However, the co-creation interactions
are always designed for content creators and have poor accessibility. To
explore gamification of mixed-initiative co-creation and make human-AI
interactions accessible and fun for players, I prototyped Snake Story, a
mixed-initiative game where players can select AI-generated texts to write a
story of a snake by playing a ""Snake"" like game. A controlled experiment was
conducted to investigate the dynamics of player-AI interactions with and
without the game component in the designed interface. As a result of a study
with 11 players (n=11), I found that players utilized different strategies when
playing with the two versions, game mechanics significantly affected the output
stories, players' creative process, as well as role perceptions, and players
with different backgrounds showed different preferences for the two versions.
Based on these results, I further discussed considerations for mixed-initiative
game design. This work aims to inspire the design of engaging co-creation
experiences.",2023-07-08
"Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement
  Learning",2023-07-05 19:48:03+00:00,http://arxiv.org/abs/2307.02620v1,"Colin Bellinger, Mark Crowley, Isaac Tamblyn","cs.LG, cs.AI, 68T01, I.2.0",games,"Reinforcement learning (RL) has been shown to learn sophisticated control
policies for complex tasks including games, robotics, heating and cooling
systems and text generation. The action-perception cycle in RL, however,
generally assumes that a measurement of the state of the environment is
available at each time step without a cost. In applications such as deep-sea
and planetary robot exploration, materials design and medicine, however, there
can be a high cost associated with measuring, or even approximating, the state
of the environment. In this paper, we survey the recently growing literature
that adopts the perspective that an RL agent might not need, or even want, a
costly measurement at each time step. Within this context, we propose the Deep
Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the
literature and empirically evaluate it on OpenAI gym and Atari Pong
environments. Our results, show that DMSOA learns a better policy with fewer
decision steps and measurements than the considered alternative from the
literature.",2023-07-05
Joint Level Generation and Translation Using Gameplay Videos,2023-06-29 03:46:44+00:00,http://arxiv.org/abs/2306.16662v1,"Negar Mirgati, Matthew Guzdial","cs.CV, cs.LG",games,"Procedural Content Generation via Machine Learning (PCGML) faces a
significant hurdle that sets it apart from other fields, such as image or text
generation, which is limited annotated data. Many existing methods for
procedural level generation via machine learning require a secondary
representation besides level images. However, the current methods for obtaining
such representations are laborious and time-consuming, which contributes to
this problem. In this work, we aim to address this problem by utilizing
gameplay videos of two human-annotated games to develop a novel multi-tail
framework that learns to perform simultaneous level translation and generation.
The translation tail of our framework can convert gameplay video frames to an
equivalent secondary representation, while its generation tail can produce
novel level segments. Evaluation results and comparisons between our framework
and baselines suggest that combining the level generation and translation tasks
can lead to an overall improved performance regarding both tasks. This
represents a possible solution to limited annotated level data, and we
demonstrate the potential for future versions to generalize to unseen games.",2023-06-29
"ByteSized32: A Corpus and Challenge Task for Generating Task-Specific
  World Models Expressed as Text Games",2023-05-24 08:31:30+00:00,http://arxiv.org/abs/2305.14879v1,"Ruoyao Wang, Graham Todd, Eric Yuan, Ziang Xiao, Marc-Alexandre Côté, Peter Jansen","cs.CL, cs.AI",games,"In this work we examine the ability of language models to generate explicit
world models of scientific and common-sense reasoning tasks by framing this as
a problem of generating text-based games. To support this, we introduce
ByteSized32, a corpus of 32 highly-templated text games written in Python
totaling 24k lines of code, each centered around a particular task, and paired
with a set of 16 unseen text game specifications for evaluation. We propose a
suite of automatic and manual metrics for assessing simulation validity,
compliance with task specifications, playability, winnability, and alignment
with the physical world. In a single-shot evaluation of GPT-4 on this
simulation-as-code-generation task, we find it capable of producing runnable
games in 27% of cases, highlighting the difficulty of this challenge task. We
discuss areas of future improvement, including GPT-4's apparent capacity to
perform well at simulating near canonical task solutions, with performance
dropping off as simulations include distractors or deviate from canonical
solutions in the action space.",2023-05-24
"FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured
  Game State Information",2023-05-02 15:36:10+00:00,http://arxiv.org/abs/2305.01528v1,"Andrew Zhu, Karmanya Aggarwal, Alexander Feng, Lara J. Martin, Chris Callison-Burch","cs.CL, cs.AI",games,"Dungeons & Dragons (D&D) is a tabletop roleplaying game with complex natural
language interactions between players and hidden state information. Recent work
has shown that large language models (LLMs) that have access to state
information can generate higher quality game turns than LLMs that use dialog
history alone. However, previous work used game state information that was
heuristically created and was not a true gold standard game state. We present
FIREBALL, a large dataset containing nearly 25,000 unique sessions from real
D\&D gameplay on Discord with true game state info. We recorded game play
sessions of players who used the Avrae bot, which was developed to aid people
in playing D&D online, capturing language, game commands and underlying game
state information. We demonstrate that FIREBALL can improve natural language
generation (NLG) by using Avrae state information, improving both automated
metrics and human judgments of quality. Additionally, we show that LLMs can
generate executable Avrae commands, particularly after finetuning.",2023-05-02
On pitfalls (and advantages) of sophisticated large language models,2023-02-25 11:14:39+00:00,http://arxiv.org/abs/2303.17511v1,Anna Strasser,"cs.CY, cs.AI, cs.CL",games,"Natural language processing based on large language models (LLMs) is a
booming field of AI research. After neural networks have proven to outperform
humans in games and practical domains based on pattern recognition, we might
stand now at a road junction where artificial entities might eventually enter
the realm of human communication. However, this comes with serious risks. Due
to the inherent limitations regarding the reliability of neural networks,
overreliance on LLMs can have disruptive consequences. Since it will be
increasingly difficult to distinguish between human-written and
machine-generated text, one is confronted with new ethical challenges. This
begins with the no longer undoubtedly verifiable human authorship and continues
with various types of fraud, such as a new form of plagiarism. This also
concerns the violation of privacy rights, the possibility of circulating
counterfeits of humans, and, last but not least, it makes a massive spread of
misinformation possible.",2023-02-25
"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based
  Learning",2023-02-08 02:45:21+00:00,http://arxiv.org/abs/2302.03848v1,"Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker",cs.CL,games,"Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.",2023-02-08
"On Realization of Intelligent Decision-Making in the Real World: A
  Foundation Decision Model Perspective",2022-12-24 06:16:45+00:00,http://arxiv.org/abs/2212.12669v1,"Ying Wen, Ziyu Wan, Ming Zhou, Shufang Hou, Zhe Cao, Chenyang Le, Jingxiao Chen, Zheng Tian, Weinan Zhang, Jun Wang","cs.AI, cs.LG",games,"Our situated environment is full of uncertainty and highly dynamic, thus
hindering the widespread adoption of machine-led Intelligent Decision-Making
(IDM) in real world scenarios. This means IDM should have the capability of
continuously learning new skills and efficiently generalizing across wider
applications. IDM benefits from any new approaches and theoretical
breakthroughs that exhibit Artificial General Intelligence (AGI) breaking the
barriers between tasks and applications. Recent research has well-examined
neural architecture, Transformer, as a backbone foundation model and its
generalization to various tasks, including computer vision, natural language
processing, and reinforcement learning. We therefore argue that a foundation
decision model (FDM) can be established by formulating various decision-making
tasks as a sequence decoding task using the Transformer architecture; this
would be a promising solution to advance the applications of IDM in more
complex real world tasks. In this paper, we elaborate on how a foundation
decision model improves the efficiency and generalization of IDM. We also
discuss potential applications of a FDM in multi-agent game AI, production
scheduling, and robotics tasks. Finally, through a case study, we demonstrate
our realization of the FDM, DigitalBrain (DB1) with 1.2 billion parameters,
which achieves human-level performance over 453 tasks, including text
generation, images caption, video games playing, robotic control, and traveling
salesman problems. As a foundation decision model, DB1 would be a baby step
towards more autonomous and efficient real world IDM applications.",2022-12-24
"Synthesis and Evaluation of a Domain-specific Large Data Set for
  Dungeons & Dragons",2022-12-18 12:54:45+00:00,http://arxiv.org/abs/2212.09080v1,"Akila Peiris, Nisansa de Silva","cs.CL, cs.LG",games,"This paper introduces the Forgotten Realms Wiki (FRW) data set and domain
specific natural language generation using FRW along with related analyses.
Forgotten Realms is the de-facto default setting of the popular open ended
tabletop fantasy role playing game, Dungeons & Dragons. The data set was
extracted from the Forgotten Realms Fandom wiki consisting of more than over
45,200 articles. The FRW data set is constituted of 11 sub-data sets in a
number of formats: raw plain text, plain text annotated by article title,
directed link graphs, wiki info-boxes annotated by the wiki article title,
Poincar\'e embedding of first link graph, multiple Word2Vec and Doc2Vec models
of the corpus. This is the first data set of this size for the Dungeons &
Dragons domain. We then present a pairwise similarity comparison benchmark
which utilizes similarity measures. In addition, we perform D&D domain specific
natural language generation using the corpus and evaluate the named entity
classification with respect to the lore of Forgotten Realms.",2022-12-18
Reward Gaming in Conditional Text Generation,2022-11-16 07:10:02+00:00,http://arxiv.org/abs/2211.08714v1,"Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P. Parikh, He He","cs.CL, cs.AI, cs.LG",games,"To align conditional text generation model outputs with desired behaviors,
there has been an increasing focus on training the model using reinforcement
learning (RL) with reward functions learned from human annotations. Under this
framework, we identify three common cases where high rewards are incorrectly
assigned to undesirable patterns: noise-induced spurious correlation, naturally
occurring spurious correlation, and covariate shift. We show that even though
learned metrics achieve high performance on the distribution of the data used
to train the reward function, the undesirable patterns may be amplified during
RL training of the text generation model. While there has been discussion about
reward gaming in the RL or safety community, in this short discussion piece, we
would like to highlight reward gaming in the NLG community using concrete
conditional text generation examples and discuss potential fixes and areas for
future work.",2022-11-16
CLSE: Corpus of Linguistically Significant Entities,2022-11-04 12:56:12+00:00,http://arxiv.org/abs/2211.02423v1,"Aleksandr Chuklin, Justin Zhao, Mihir Kale",cs.CL,games,"One of the biggest challenges of natural language generation (NLG) is the
proper handling of named entities. Named entities are a common source of
grammar mistakes such as wrong prepositions, wrong article handling, or
incorrect entity inflection. Without factoring linguistic representation, such
errors are often underrepresented when evaluating on a small set of arbitrarily
picked argument values, or when translating a dataset from a linguistically
simpler language, like English, to a linguistically complex language, like
Russian. However, for some applications, broadly precise grammatical
correctness is critical -- native speakers may find entity-related grammar
errors silly, jarring, or even offensive.
  To enable the creation of more linguistically diverse NLG datasets, we
release a Corpus of Linguistically Significant Entities (CLSE) annotated by
linguist experts. The corpus includes 34 languages and covers 74 different
semantic types to support various applications from airline ticketing to video
games. To demonstrate one possible use of CLSE, we produce an augmented version
of the Schema-Guided Dialog Dataset, SGD-CLSE. Using the CLSE's entities and a
small number of human translations, we create a linguistically representative
NLG evaluation benchmark in three languages: French (high-resource), Marathi
(low-resource), and Russian (highly inflected language). We establish quality
baselines for neural, template-based, and hybrid NLG systems and discuss the
strengths and weaknesses of each approach.",2022-11-04
"Are Current Decoding Strategies Capable of Facing the Challenges of
  Visual Dialogue?",2022-10-24 07:34:39+00:00,http://arxiv.org/abs/2210.12997v1,"Amit Kumar Chaudhary, Alex J. Lucassen, Ioanna Tsani, Alberto Testoni","cs.CL, cs.CV",games,"Decoding strategies play a crucial role in natural language generation
systems. They are usually designed and evaluated in open-ended text-only tasks,
and it is not clear how different strategies handle the numerous challenges
that goal-oriented multimodal systems face (such as grounding and
informativeness). To answer this question, we compare a wide variety of
different decoding strategies and hyper-parameter configurations in a Visual
Dialogue referential game. Although none of them successfully balance lexical
richness, accuracy in the task, and visual grounding, our in-depth analysis
allows us to highlight the strengths and weaknesses of each decoding strategy.
We believe our findings and suggestions may serve as a starting point for
designing more effective decoding algorithms that handle the challenges of
Visual Dialogue tasks.",2022-10-24
"Towards Pragmatic Production Strategies for Natural Language Generation
  Tasks",2022-10-23 19:30:42+00:00,http://arxiv.org/abs/2210.12828v1,Mario Giulianelli,"cs.CL, cs.AI",games,"This position paper proposes a conceptual framework for the design of Natural
Language Generation (NLG) systems that follow efficient and effective
production strategies in order to achieve complex communicative goals. In this
general framework, efficiency is characterised as the parsimonious regulation
of production and comprehension costs while effectiveness is measured with
respect to task-oriented and contextually grounded communicative goals. We
provide concrete suggestions for the estimation of goals, costs, and utility
via modern statistical methods, demonstrating applications of our framework to
the classic pragmatic task of visually grounded referential games and to
abstractive text summarisation, two popular generation tasks with real-world
applications. In sum, we advocate for the development of NLG systems that learn
to make pragmatic production decisions from experience, by reasoning about
goals, costs, and utility in a human-like way.",2022-10-23
"LEATHER: A Framework for Learning to Generate Human-like Text in
  Dialogue",2022-10-14 13:05:11+00:00,http://arxiv.org/abs/2210.07777v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.LG",games,"Algorithms for text-generation in dialogue can be misguided. For example, in
task-oriented settings, reinforcement learning that optimizes only task-success
can lead to abysmal lexical diversity. We hypothesize this is due to poor
theoretical understanding of the objectives in text-generation and their
relation to the learning process (i.e., model training). To this end, we
propose a new theoretical framework for learning to generate text in dialogue.
Compared to existing theories of learning, our framework allows for analysis of
the multi-faceted goals inherent to text-generation. We use our framework to
develop theoretical guarantees for learners that adapt to unseen data. As an
example, we apply our theory to study data-shift within a cooperative learning
algorithm proposed for the GuessWhat?! visual dialogue game. From this insight,
we propose a new algorithm, and empirically, we demonstrate our proposal
improves both task-success and human-likeness of the generated text. Finally,
we show statistics from our theory are empirically predictive of multiple
qualities of the generated dialogue, suggesting our theory is useful for
model-selection when human evaluations are not available.",2022-10-14
Using Large Language Models to Simulate Multiple Humans,2022-08-18 17:54:49+00:00,http://arxiv.org/abs/2208.10264v3,"Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai","cs.CL, cs.AI, cs.LG",games,"We propose a method for using a large language model, such as GPT-3, to
simulate responses of different humans in a given context. We test our method
by attempting to reproduce well-established economic, psycholinguistic, and
social experiments. The method requires prompt templates for each experiment.
Simulations are run by varying the (hypothetical) subject details, such as
name, and analyzing the text generated by the language model. To validate our
methodology, we use GPT-3 to simulate the Ultimatum Game, garden path
sentences, risk aversion, and the Milgram Shock experiments. In order to
address concerns of exposure to these studies in training data, we also
evaluate simulations on novel variants of these studies. We show that it is
possible to simulate responses of different people and that their responses are
largely consistent with prior human studies from the literature. Using large
language models as simulators offers advantages but also poses risks. Our use
of a language model for simulation is contrasted with anthropomorphic views of
a language model as having its own behavior.",2022-08-18
Mimetic Models: Ethical Implications of AI that Acts Like You,2022-07-19 16:41:36+00:00,http://arxiv.org/abs/2207.09394v1,"Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Solon Barocas, Ashton Anderson","cs.AI, cs.CY",games,"An emerging theme in artificial intelligence research is the creation of
models to simulate the decisions and behavior of specific people, in domains
including game-playing, text generation, and artistic expression. These models
go beyond earlier approaches in the way they are tailored to individuals, and
the way they are designed for interaction rather than simply the reproduction
of fixed, pre-computed behaviors. We refer to these as mimetic models, and in
this paper we develop a framework for characterizing the ethical and social
issues raised by their growing availability. Our framework includes a number of
distinct scenarios for the use of such models, and considers the impacts on a
range of different participants, including the target being modeled, the
operator who deploys the model, and the entities that interact with it.",2022-07-19
Word Play for Playing Othello (Reverses),2022-07-18 17:13:32+00:00,http://arxiv.org/abs/2207.08766v1,"Samantha E. Miller Noever, David Noever",cs.LG,games,"Language models like OpenAI's Generative Pre-Trained Transformers (GPT-2/3)
capture the long-term correlations needed to generate text in a variety of
domains (such as language translators) and recently in gameplay (chess, Go, and
checkers). The present research applies both the larger (GPT-3) and smaller
(GPT-2) language models to explore the complex strategies for the game of
Othello (or Reverses). Given the game rules for rapid reversals of fortune, the
language model not only represents a candidate predictor of the next move based
on previous game moves but also avoids sparse rewards in gameplay. The language
model automatically captures or emulates championship-level strategies. The
fine-tuned GPT-2 model generates Othello games ranging from 13-71% completion,
while the larger GPT-3 model reaches 41% of a complete game. Like previous work
with chess and Go, these language models offer a novel way to generate
plausible game archives, particularly for comparing opening moves across a
larger sample than humanly possible to explore. A primary contribution of these
models magnifies (by two-fold) the previous record for player archives (120,000
human games over 45 years from 1977-2022), thus supplying the research
community with more diverse and original strategies for sampling with other
reinforcement learning techniques.",2022-07-18
Immersive Text Game and Personality Classification,2022-03-20 18:37:03+00:00,http://arxiv.org/abs/2203.10621v1,"Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi","cs.CL, cs.AI, cs.LG",games,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",2022-03-20
"Dynamic population-based meta-learning for multi-agent communication
  with natural language",2021-10-27 07:50:02+00:00,http://arxiv.org/abs/2110.14241v1,"Abhinav Gupta, Marc Lanctot, Angeliki Lazaridou","cs.LG, cs.AI, cs.CL, cs.MA",games,"In this work, our goal is to train agents that can coordinate with seen,
unseen as well as human partners in a multi-agent communication environment
involving natural language. Previous work using a single set of agents has
shown great progress in generalizing to known partners, however it struggles
when coordinating with unfamiliar agents. To mitigate that, recent work
explored the use of population-based approaches, where multiple agents interact
with each other with the goal of learning more generic protocols. These
methods, while able to result in good coordination between unseen partners,
still only achieve so in cases of simple languages, thus failing to adapt to
human partners using natural language. We attribute this to the use of static
populations and instead propose a dynamic population-based meta-learning
approach that builds such a population in an iterative manner. We perform a
holistic evaluation of our method on two different referential games, and show
that our agents outperform all prior work when communicating with seen partners
and humans. Furthermore, we analyze the natural language generation skills of
our agents, where we find that our agents also outperform strong baselines.
Finally, we test the robustness of our agents when communicating with
out-of-population agents and carefully test the importance of each component of
our method through ablation studies.",2021-10-27
Hurdles to Progress in Long-form Question Answering,2021-03-10 20:32:30+00:00,http://arxiv.org/abs/2103.06332v1,"Kalpesh Krishna, Aurko Roy, Mohit Iyyer","cs.CL, cs.LG",games,"The task of long-form question answering (LFQA) involves retrieving documents
relevant to a given question and using them to generate a paragraph-length
answer. While many models have recently been proposed for LFQA, we show in this
paper that the task formulation raises fundamental challenges regarding
evaluation and dataset creation that currently preclude meaningful modeling
progress. To demonstrate these challenges, we first design a new system that
relies on sparse attention and contrastive retriever learning to achieve
state-of-the-art performance on the ELI5 LFQA dataset. While our system tops
the public leaderboard, a detailed analysis reveals several troubling trends:
(1) our system's generated answers are not actually grounded in the documents
that it retrieves; (2) ELI5 contains significant train / test overlap, as at
least 81% of ELI5 validation questions occur in paraphrased form in the
training set; (3) ROUGE-L is not an informative metric of generated answer
quality and can be easily gamed; and (4) human evaluations used for other text
generation tasks are unreliable for LFQA. We provide suggestions to mitigate
each of these issues, which we hope will lead to more rigorous LFQA research
and meaningful progress in the future.",2021-03-10
Deep Learning for General Game Playing with Ludii and Polygames,2021-01-23 19:08:33+00:00,http://arxiv.org/abs/2101.09562v1,"Dennis J. N. J. Soemers, Vegard Mella, Cameron Browne, Olivier Teytaud",cs.AI,games,"Combinations of Monte-Carlo tree search and Deep Neural Networks, trained
through self-play, have produced state-of-the-art results for automated
game-playing in many board games. The training and search algorithms are not
game-specific, but every individual game that these approaches are applied to
still requires domain knowledge for the implementation of the game's rules, and
constructing the neural network's architecture -- in particular the shapes of
its input and output tensors. Ludii is a general game system that already
contains over 500 different games, which can rapidly grow thanks to its
powerful and user-friendly game description language. Polygames is a framework
with training and search algorithms, which has already produced superhuman
players for several board games. This paper describes the implementation of a
bridge between Ludii and Polygames, which enables Polygames to train and
evaluate models for games that are implemented and run through Ludii. We do not
require any game-specific domain knowledge anymore, and instead leverage our
domain knowledge of the Ludii system and its abstract state and move
representations to write functions that can automatically determine the
appropriate shapes for input and output tensors for any game implemented in
Ludii. We describe experimental results for short training runs in a wide
variety of different board games, and discuss several open problems and avenues
for future research.",2021-01-23
Ludii Game Logic Guide,2021-01-06 16:22:37+00:00,http://arxiv.org/abs/2101.02120v1,"Eric Piette, Cameron Browne, Dennis J. N. J. Soemers",cs.AI,games,"This technical report outlines the fundamental workings of the game logic
behind Ludii, a general game system, that can be used to play a wide variety of
games. Ludii is a program developed for the ERC-funded Digital Ludeme Project,
in which mathematical and computational approaches are used to study how games
were played, and spread, throughout history. This report explains how general
game states and equipment are represented in Ludii, and how the rule ludemes
dictating play are implemented behind the scenes, giving some insight into the
core game logic behind the Ludii general game player. This guide is intended to
help game designers using the Ludii game description language to understand it
more completely and make fuller use of its features when describing their
games.",2021-01-06
DORB: Dynamically Optimizing Multiple Rewards with Bandits,2020-11-15 21:57:47+00:00,http://arxiv.org/abs/2011.07635v1,"Ramakanth Pasunuru, Han Guo, Mohit Bansal","cs.CL, cs.AI, cs.LG",games,"Policy gradients-based reinforcement learning has proven to be a promising
approach for directly optimizing non-differentiable evaluation metrics for
language generation tasks. However, optimizing for a specific metric reward
leads to improvements in mostly that metric only, suggesting that the model is
gaming the formulation of that metric in a particular way without often
achieving real qualitative improvements. Hence, it is more beneficial to make
the model optimize multiple diverse metric rewards jointly. While appealing,
this is challenging because one needs to manually decide the importance and
scaling weights of these metric rewards. Further, it is important to consider
using a dynamic combination and curriculum of metric rewards that flexibly
changes over time. Considering the above aspects, in our work, we automate the
optimization of multiple metric rewards simultaneously via a multi-armed bandit
approach (DORB), where at each round, the bandit chooses which metric reward to
optimize next, based on expected arm gains. We use the Exp3 algorithm for
bandits and formulate two approaches for bandit rewards: (1) Single
Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit
(HM-Bandit). We empirically show the effectiveness of our approaches via
various automatic metrics and human evaluation on two important NLG tasks:
question generation and data-to-text generation, including on an unseen-test
transfer setup. Finally, we present interpretable analyses of the learned
bandit curriculum over the optimized rewards.",2020-11-15
Learning Better Representation for Tables by Self-Supervised Tasks,2020-10-15 09:03:38+00:00,http://arxiv.org/abs/2010.07606v1,"Liang Li, Can Ma, Yinliang Yue, Linjun Shou, Dayong Hu",cs.CL,games,"Table-to-text generation aims at automatically generating natural text to
help people to conveniently obtain the important information in tables.
Although neural models for table-to-text have achieved remarkable progress,
some problems still overlooked. The first is that the values recorded in many
tables are mostly numbers in practice. The existing approaches do not do
special treatment for these, and still regard these as words in natural
language text. Secondly, the target texts in training dataset may contain
redundant information or facts do not exist in the input tables. These may give
wrong supervision signals to some methods based on content selection and
planning and auxiliary supervision. To solve these problems, we propose two
self-supervised tasks, Number Ordering and Significance Ordering, to help to
learn better table representation. The former works on the column dimension to
help to incorporate the size property of numbers into table representation. The
latter acts on row dimension and help to learn a significance-aware table
representation. We test our methods on the widely used dataset ROTOWIRE which
consists of NBA game statistic and related news. The experimental results
demonstrate that the model trained together with these two self-supervised
tasks can generate text that contains more salient and well-organized facts,
even without modeling context selection and planning. And we achieve the
state-of-the-art performance on automatic metrics.",2020-10-15
"Discovering Textual Structures: Generative Grammar Induction using
  Template Trees",2020-09-09 19:31:04+00:00,http://arxiv.org/abs/2009.04530v1,"Thomas Winters, Luc De Raedt","cs.CL, cs.AI, 68T50, I.2.7; I.2.6",games,"Natural language generation provides designers with methods for automatically
generating text, e.g. for creating summaries, chatbots and game content. In
practise, text generators are often either learned and hard to interpret, or
created by hand using techniques such as grammars and templates. In this paper,
we introduce a novel grammar induction algorithm for learning interpretable
grammars for generative purposes, called Gitta. We also introduce the novel
notion of template trees to discover latent templates in corpora to derive
these generative grammars. By using existing human-created grammars, we found
that the algorithm can reasonably approximate these grammars using only a few
examples. These results indicate that Gitta could be used to automatically
learn interpretable and easily modifiable grammars, and thus provide a stepping
stone for human-machine co-creation of generative models.",2020-09-09
Navigating Human Language Models with Synthetic Agents,2020-08-10 14:39:53+00:00,http://arxiv.org/abs/2008.04162v7,"Philip Feldman, Antonio Bucchiarone","cs.AI, cs.CL, cs.MA, I.2; I.6; J.4",games,"Modern natural language models such as the GPT-2/GPT-3 contain tremendous
amounts of information about human belief in a consistently testable form. If
these models could be shown to accurately reflect the underlying beliefs of the
human beings that produced the data used to train these models, then such
models become a powerful sociological tool in ways that are distinct from
traditional methods, such as interviews and surveys. In this study, We train a
version of the GPT-2 on a corpora of historical chess games, and then ""launch""
clusters of synthetic agents into the model, using text strings to create
context and orientation. We compare the trajectories contained in the text
generated by the agents/model and compare that to the known ground truth of the
chess board, move legality, and historical patterns of play. We find that the
percentages of moves by piece using the model are substantially similar from
human patterns. We further find that the model creates an accurate latent
representation of the chessboard, and that it is possible to plot trajectories
of legal moves across the board using this knowledge.",2020-08-10
The Go Transformer: Natural Language Modeling for Game Play,2020-07-07 14:37:27+00:00,http://arxiv.org/abs/2007.03500v3,"Matthew Ciolino, David Noever, Josh Kalin","cs.CL, cs.LG",games,"This work applies natural language modeling to generate plausible strategic
moves in the ancient game of Go. We train the Generative Pretrained Transformer
(GPT-2) to mimic the style of Go champions as archived in Smart Game Format
(SGF), which offers a text description of move sequences. The trained model
further generates valid but previously unseen strategies for Go. Because GPT-2
preserves punctuation and spacing, the raw output of the text generator
provides inputs to game visualization and creative patterns, such as the Sabaki
project's game engine using auto-replays. Results demonstrate that language
modeling can capture both the sequencing format of championship Go games and
their strategic formations. Compared to random game boards, the GPT-2
fine-tuning shows efficient opening move sequences favoring corner play over
less advantageous center and side play. Game generation as a language modeling
task offers novel approaches to more than 40 other board games where historical
text annotation provides training data (e.g., Amazons & Connect 4/6).",2020-07-07
Shared Task on Evaluating Accuracy in Natural Language Generation,2020-06-22 13:30:35+00:00,http://arxiv.org/abs/2006.12234v2,"Ehud Reiter, Craig Thomson",cs.CL,games,"We propose a shared task on methodologies and algorithms for evaluating the
accuracy of generated texts. Participants will measure the accuracy of
basketball game summaries produced by NLG systems from basketball box score
data.",2020-06-22
"Graph Constrained Reinforcement Learning for Natural Language Action
  Spaces",2020-01-23 22:33:18+00:00,http://arxiv.org/abs/2001.08837v1,"Prithviraj Ammanabrolu, Matthew Hausknecht","cs.LG, cs.AI, cs.CL, stat.ML",games,"Interactive Fiction games are text-based simulations in which an agent
interacts with the world purely through natural language. They are ideal
environments for studying how to extend reinforcement learning agents to meet
the challenges of natural language understanding, partial observability, and
action generation in combinatorially-large text-based action spaces. We present
KG-A2C, an agent that builds a dynamic knowledge graph while exploring and
generates actions using a template-based action space. We contend that the dual
uses of the knowledge graph to reason about game state and to constrain natural
language generation are the keys to scalable exploration of combinatorially
large natural language actions. Results across a wide variety of IF games show
that KG-A2C outperforms current IF agents despite the exponential increase in
action space size.",2020-01-23
Revisiting Challenges in Data-to-Text Generation with Fact Grounding,2020-01-12 02:31:07+00:00,http://arxiv.org/abs/2001.03830v1,Hongmin Wang,cs.CL,games,"Data-to-text generation models face challenges in ensuring data fidelity by
referring to the correct input source. To inspire studies in this area, Wiseman
et al. (2017) introduced the RotoWire corpus on generating NBA game summaries
from the box- and line-score tables. However, limited attempts have been made
in this direction and the challenges remain. We observe a prominent bottleneck
in the corpus where only about 60% of the summary contents can be grounded to
the boxscore records. Such information deficiency tends to misguide a
conditioned language model to produce unconditioned random facts and thus leads
to factual hallucinations. In this work, we restore the information balance and
revamp this task to focus on fact-grounded data-to-text generation. We
introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),
with 50% more data from the year 2017-19 and enriched input tables, hoping to
attract more research focuses in this direction. Moreover, we achieve improved
data fidelity over the state-of-the-art models by integrating a new form of
table reconstruction as an auxiliary task to boost the generation quality.",2020-01-12
"ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain
  Conversation",2019-10-26 20:18:59+00:00,http://arxiv.org/abs/1910.12129v1,"Juraj Juraska, Kevin K. Bowden, Marilyn Walker",cs.CL,games,"The uptake of deep learning in natural language generation (NLG) led to the
release of both small and relatively large parallel corpora for training neural
models. The existing data-to-text datasets are, however, aimed at task-oriented
dialogue systems, and often thus limited in diversity and versatility. They are
typically crowdsourced, with much of the noise left in them. Moreover, current
neural NLG models do not take full advantage of large training data, and due to
their strong generalizing properties produce sentences that look template-like
regardless. We therefore present a new corpus of 7K samples, which (1) is clean
despite being crowdsourced, (2) has utterances of 9 generalizable and
conversational dialogue act types, making it more suitable for open-domain
dialogue systems, and (3) explores the domain of video games, which is new to
dialogue systems despite having excellent potential for supporting rich
conversations.",2019-10-26
"Table-to-Text Generation with Effective Hierarchical Encoder on Three
  Dimensions (Row, Column and Time)",2019-09-05 10:25:34+00:00,http://arxiv.org/abs/1909.02304v1,"Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu",cs.CL,games,"Although Seq2Seq models for table-to-text generation have achieved remarkable
progress, modeling table representation in one dimension is inadequate. This is
because (1) the table consists of multiple rows and columns, which means that
encoding a table should not depend only on one dimensional sequence or set of
records and (2) most of the tables are time series data (e.g. NBA game data,
stock market data), which means that the description of the current table may
be affected by its historical data. To address aforementioned problems, not
only do we model each table cell considering other records in the same row, we
also enrich table's representation by modeling each table cell in context of
other cells in the same column or with historical (time dimension) data
respectively. In addition, we develop a table cell fusion gate to combine
representations from row, column and time dimension into one dense vector
according to the saliency of each dimension's representation. We evaluated our
methods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both
automatic and human evaluation results demonstrate the effectiveness of our
model with improvement of 2.66 in BLEU over the strong baseline and
outperformance of state-of-the-art model.",2019-09-05
Generating Question-Answer Hierarchies,2019-06-06 14:53:04+00:00,http://arxiv.org/abs/1906.02622v2,"Kalpesh Krishna, Mohit Iyyer",cs.CL,games,"The process of knowledge acquisition can be viewed as a question-answer game
between a student and a teacher in which the student typically starts by asking
broad, open-ended questions before drilling down into specifics (Hintikka,
1981; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a
new way of representing documents. In this paper, we present SQUASH
(Specificity-controlled Question-Answer Hierarchies), a novel and challenging
text generation task that converts an input document into a hierarchy of
question-answer pairs. Users can click on high-level questions (e.g., ""Why did
Frodo leave the Fellowship?"") to reveal related but more specific questions
(e.g., ""Who did Frodo leave with?""). Using a question taxonomy loosely based on
Lehnert (1978), we classify questions in existing reading comprehension
datasets as either ""general"" or ""specific"". We then use these labels as input
to a pipelined system centered around a conditional neural language model. We
extensively evaluate the quality of the generated QA hierarchies through
crowdsourced experiments and report strong empirical results.",2019-06-06
Pragmatically Informative Text Generation,2019-04-02 09:04:57+00:00,http://arxiv.org/abs/1904.01301v2,"Sheng Shen, Daniel Fried, Jacob Andreas, Dan Klein",cs.CL,games,"We improve the informativeness of models for conditional text generation
using techniques from computational pragmatics. These techniques formulate
language production as a game between speakers and listeners, in which a
speaker should generate output text that a listener can use to correctly
identify the original input that the text describes. While such approaches are
widely used in cognitive science and grounded language learning, they have
received less attention for more standard language generation tasks. We
consider two pragmatic modeling methods for text generation: one where
pragmatics is imposed by information preservation, and another where pragmatics
is imposed by explicit modeling of distractors. We find that these methods
improve the performance of strong existing systems for abstractive
summarization and generation from structured meaning representations.",2019-04-02
Automating Direct Speech Variations in Stories and Games,2017-08-30 02:19:39+00:00,http://arxiv.org/abs/1708.09090v1,"Stephanie M. Lukin, James O. Ryan, Marilyn A. Walker",cs.CL,games,"Dialogue authoring in large games requires not only content creation but the
subtlety of its delivery, which can vary from character to character. Manually
authoring this dialogue can be tedious, time-consuming, or even altogether
infeasible. This paper utilizes a rich narrative representation for modeling
dialogue and an expressive natural language generation engine for realizing it,
and expands upon a translation tool that bridges the two. We add functionality
to the translator to allow direct speech to be modeled by the narrative
representation, whereas the original translator supports only narratives told
by a third person narrator. We show that we can perform character substitution
in dialogues. We implement and evaluate a potential application to dialogue
implementation: generating dialogue for games with big, dynamic, or
procedurally-generated open worlds. We present a pilot study on human
perceptions of the personalities of characters using direct speech, assuming
unknown personality types at the time of authoring.",2017-08-30
Deep Reinforcement Learning: An Overview,2017-01-25 11:52:11+00:00,http://arxiv.org/abs/1701.07274v6,Yuxi Li,cs.LG,games,"We give an overview of recent exciting achievements of deep reinforcement
learning (RL). We discuss six core elements, six important mechanisms, and
twelve applications. We start with background of machine learning, deep
learning and reinforcement learning. Next we discuss core RL elements,
including value function, in particular, Deep Q-Network (DQN), policy, reward,
model, planning, and exploration. After that, we discuss important mechanisms
for RL, including attention and memory, unsupervised learning, transfer
learning, multi-agent RL, hierarchical RL, and learning to learn. Then we
discuss various applications of RL, including games, in particular, AlphaGo,
robotics, natural language processing, including dialogue systems, machine
translation, and text generation, computer vision, neural architecture design,
business management, finance, healthcare, Industry 4.0, smart grid, intelligent
transportation systems, and computer systems. We mention topics not reviewed
yet, and list a collection of RL resources. After presenting a brief summary,
we close with discussions.
  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant
update.",2017-01-25
