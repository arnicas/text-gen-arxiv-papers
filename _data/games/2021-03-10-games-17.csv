title,pubdate,id,authors,categories,search,abstract,displaydate
Hurdles to Progress in Long-form Question Answering,2021-03-10 20:32:30+00:00,http://arxiv.org/abs/2103.06332v1,"Kalpesh Krishna, Aurko Roy, Mohit Iyyer","cs.CL, cs.LG",games,"The task of long-form question answering (LFQA) involves retrieving documents
relevant to a given question and using them to generate a paragraph-length
answer. While many models have recently been proposed for LFQA, we show in this
paper that the task formulation raises fundamental challenges regarding
evaluation and dataset creation that currently preclude meaningful modeling
progress. To demonstrate these challenges, we first design a new system that
relies on sparse attention and contrastive retriever learning to achieve
state-of-the-art performance on the ELI5 LFQA dataset. While our system tops
the public leaderboard, a detailed analysis reveals several troubling trends:
(1) our system's generated answers are not actually grounded in the documents
that it retrieves; (2) ELI5 contains significant train / test overlap, as at
least 81% of ELI5 validation questions occur in paraphrased form in the
training set; (3) ROUGE-L is not an informative metric of generated answer
quality and can be easily gamed; and (4) human evaluations used for other text
generation tasks are unreliable for LFQA. We provide suggestions to mitigate
each of these issues, which we hope will lead to more rigorous LFQA research
and meaningful progress in the future.",2021-03-10
Deep Learning for General Game Playing with Ludii and Polygames,2021-01-23 19:08:33+00:00,http://arxiv.org/abs/2101.09562v1,"Dennis J. N. J. Soemers, Vegard Mella, Cameron Browne, Olivier Teytaud",cs.AI,games,"Combinations of Monte-Carlo tree search and Deep Neural Networks, trained
through self-play, have produced state-of-the-art results for automated
game-playing in many board games. The training and search algorithms are not
game-specific, but every individual game that these approaches are applied to
still requires domain knowledge for the implementation of the game's rules, and
constructing the neural network's architecture -- in particular the shapes of
its input and output tensors. Ludii is a general game system that already
contains over 500 different games, which can rapidly grow thanks to its
powerful and user-friendly game description language. Polygames is a framework
with training and search algorithms, which has already produced superhuman
players for several board games. This paper describes the implementation of a
bridge between Ludii and Polygames, which enables Polygames to train and
evaluate models for games that are implemented and run through Ludii. We do not
require any game-specific domain knowledge anymore, and instead leverage our
domain knowledge of the Ludii system and its abstract state and move
representations to write functions that can automatically determine the
appropriate shapes for input and output tensors for any game implemented in
Ludii. We describe experimental results for short training runs in a wide
variety of different board games, and discuss several open problems and avenues
for future research.",2021-01-23
Ludii Game Logic Guide,2021-01-06 16:22:37+00:00,http://arxiv.org/abs/2101.02120v1,"Eric Piette, Cameron Browne, Dennis J. N. J. Soemers",cs.AI,games,"This technical report outlines the fundamental workings of the game logic
behind Ludii, a general game system, that can be used to play a wide variety of
games. Ludii is a program developed for the ERC-funded Digital Ludeme Project,
in which mathematical and computational approaches are used to study how games
were played, and spread, throughout history. This report explains how general
game states and equipment are represented in Ludii, and how the rule ludemes
dictating play are implemented behind the scenes, giving some insight into the
core game logic behind the Ludii general game player. This guide is intended to
help game designers using the Ludii game description language to understand it
more completely and make fuller use of its features when describing their
games.",2021-01-06
DORB: Dynamically Optimizing Multiple Rewards with Bandits,2020-11-15 21:57:47+00:00,http://arxiv.org/abs/2011.07635v1,"Ramakanth Pasunuru, Han Guo, Mohit Bansal","cs.CL, cs.AI, cs.LG",games,"Policy gradients-based reinforcement learning has proven to be a promising
approach for directly optimizing non-differentiable evaluation metrics for
language generation tasks. However, optimizing for a specific metric reward
leads to improvements in mostly that metric only, suggesting that the model is
gaming the formulation of that metric in a particular way without often
achieving real qualitative improvements. Hence, it is more beneficial to make
the model optimize multiple diverse metric rewards jointly. While appealing,
this is challenging because one needs to manually decide the importance and
scaling weights of these metric rewards. Further, it is important to consider
using a dynamic combination and curriculum of metric rewards that flexibly
changes over time. Considering the above aspects, in our work, we automate the
optimization of multiple metric rewards simultaneously via a multi-armed bandit
approach (DORB), where at each round, the bandit chooses which metric reward to
optimize next, based on expected arm gains. We use the Exp3 algorithm for
bandits and formulate two approaches for bandit rewards: (1) Single
Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit
(HM-Bandit). We empirically show the effectiveness of our approaches via
various automatic metrics and human evaluation on two important NLG tasks:
question generation and data-to-text generation, including on an unseen-test
transfer setup. Finally, we present interpretable analyses of the learned
bandit curriculum over the optimized rewards.",2020-11-15
Learning Better Representation for Tables by Self-Supervised Tasks,2020-10-15 09:03:38+00:00,http://arxiv.org/abs/2010.07606v1,"Liang Li, Can Ma, Yinliang Yue, Linjun Shou, Dayong Hu",cs.CL,games,"Table-to-text generation aims at automatically generating natural text to
help people to conveniently obtain the important information in tables.
Although neural models for table-to-text have achieved remarkable progress,
some problems still overlooked. The first is that the values recorded in many
tables are mostly numbers in practice. The existing approaches do not do
special treatment for these, and still regard these as words in natural
language text. Secondly, the target texts in training dataset may contain
redundant information or facts do not exist in the input tables. These may give
wrong supervision signals to some methods based on content selection and
planning and auxiliary supervision. To solve these problems, we propose two
self-supervised tasks, Number Ordering and Significance Ordering, to help to
learn better table representation. The former works on the column dimension to
help to incorporate the size property of numbers into table representation. The
latter acts on row dimension and help to learn a significance-aware table
representation. We test our methods on the widely used dataset ROTOWIRE which
consists of NBA game statistic and related news. The experimental results
demonstrate that the model trained together with these two self-supervised
tasks can generate text that contains more salient and well-organized facts,
even without modeling context selection and planning. And we achieve the
state-of-the-art performance on automatic metrics.",2020-10-15
"Discovering Textual Structures: Generative Grammar Induction using
  Template Trees",2020-09-09 19:31:04+00:00,http://arxiv.org/abs/2009.04530v1,"Thomas Winters, Luc De Raedt","cs.CL, cs.AI, 68T50, I.2.7; I.2.6",games,"Natural language generation provides designers with methods for automatically
generating text, e.g. for creating summaries, chatbots and game content. In
practise, text generators are often either learned and hard to interpret, or
created by hand using techniques such as grammars and templates. In this paper,
we introduce a novel grammar induction algorithm for learning interpretable
grammars for generative purposes, called Gitta. We also introduce the novel
notion of template trees to discover latent templates in corpora to derive
these generative grammars. By using existing human-created grammars, we found
that the algorithm can reasonably approximate these grammars using only a few
examples. These results indicate that Gitta could be used to automatically
learn interpretable and easily modifiable grammars, and thus provide a stepping
stone for human-machine co-creation of generative models.",2020-09-09
Navigating Human Language Models with Synthetic Agents,2020-08-10 14:39:53+00:00,http://arxiv.org/abs/2008.04162v7,"Philip Feldman, Antonio Bucchiarone","cs.AI, cs.CL, cs.MA, I.2; I.6; J.4",games,"Modern natural language models such as the GPT-2/GPT-3 contain tremendous
amounts of information about human belief in a consistently testable form. If
these models could be shown to accurately reflect the underlying beliefs of the
human beings that produced the data used to train these models, then such
models become a powerful sociological tool in ways that are distinct from
traditional methods, such as interviews and surveys. In this study, We train a
version of the GPT-2 on a corpora of historical chess games, and then ""launch""
clusters of synthetic agents into the model, using text strings to create
context and orientation. We compare the trajectories contained in the text
generated by the agents/model and compare that to the known ground truth of the
chess board, move legality, and historical patterns of play. We find that the
percentages of moves by piece using the model are substantially similar from
human patterns. We further find that the model creates an accurate latent
representation of the chessboard, and that it is possible to plot trajectories
of legal moves across the board using this knowledge.",2020-08-10
The Go Transformer: Natural Language Modeling for Game Play,2020-07-07 14:37:27+00:00,http://arxiv.org/abs/2007.03500v3,"Matthew Ciolino, David Noever, Josh Kalin","cs.CL, cs.LG",games,"This work applies natural language modeling to generate plausible strategic
moves in the ancient game of Go. We train the Generative Pretrained Transformer
(GPT-2) to mimic the style of Go champions as archived in Smart Game Format
(SGF), which offers a text description of move sequences. The trained model
further generates valid but previously unseen strategies for Go. Because GPT-2
preserves punctuation and spacing, the raw output of the text generator
provides inputs to game visualization and creative patterns, such as the Sabaki
project's game engine using auto-replays. Results demonstrate that language
modeling can capture both the sequencing format of championship Go games and
their strategic formations. Compared to random game boards, the GPT-2
fine-tuning shows efficient opening move sequences favoring corner play over
less advantageous center and side play. Game generation as a language modeling
task offers novel approaches to more than 40 other board games where historical
text annotation provides training data (e.g., Amazons & Connect 4/6).",2020-07-07
Shared Task on Evaluating Accuracy in Natural Language Generation,2020-06-22 13:30:35+00:00,http://arxiv.org/abs/2006.12234v2,"Ehud Reiter, Craig Thomson",cs.CL,games,"We propose a shared task on methodologies and algorithms for evaluating the
accuracy of generated texts. Participants will measure the accuracy of
basketball game summaries produced by NLG systems from basketball box score
data.",2020-06-22
"Graph Constrained Reinforcement Learning for Natural Language Action
  Spaces",2020-01-23 22:33:18+00:00,http://arxiv.org/abs/2001.08837v1,"Prithviraj Ammanabrolu, Matthew Hausknecht","cs.LG, cs.AI, cs.CL, stat.ML",games,"Interactive Fiction games are text-based simulations in which an agent
interacts with the world purely through natural language. They are ideal
environments for studying how to extend reinforcement learning agents to meet
the challenges of natural language understanding, partial observability, and
action generation in combinatorially-large text-based action spaces. We present
KG-A2C, an agent that builds a dynamic knowledge graph while exploring and
generates actions using a template-based action space. We contend that the dual
uses of the knowledge graph to reason about game state and to constrain natural
language generation are the keys to scalable exploration of combinatorially
large natural language actions. Results across a wide variety of IF games show
that KG-A2C outperforms current IF agents despite the exponential increase in
action space size.",2020-01-23
Revisiting Challenges in Data-to-Text Generation with Fact Grounding,2020-01-12 02:31:07+00:00,http://arxiv.org/abs/2001.03830v1,Hongmin Wang,cs.CL,games,"Data-to-text generation models face challenges in ensuring data fidelity by
referring to the correct input source. To inspire studies in this area, Wiseman
et al. (2017) introduced the RotoWire corpus on generating NBA game summaries
from the box- and line-score tables. However, limited attempts have been made
in this direction and the challenges remain. We observe a prominent bottleneck
in the corpus where only about 60% of the summary contents can be grounded to
the boxscore records. Such information deficiency tends to misguide a
conditioned language model to produce unconditioned random facts and thus leads
to factual hallucinations. In this work, we restore the information balance and
revamp this task to focus on fact-grounded data-to-text generation. We
introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),
with 50% more data from the year 2017-19 and enriched input tables, hoping to
attract more research focuses in this direction. Moreover, we achieve improved
data fidelity over the state-of-the-art models by integrating a new form of
table reconstruction as an auxiliary task to boost the generation quality.",2020-01-12
"ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain
  Conversation",2019-10-26 20:18:59+00:00,http://arxiv.org/abs/1910.12129v1,"Juraj Juraska, Kevin K. Bowden, Marilyn Walker",cs.CL,games,"The uptake of deep learning in natural language generation (NLG) led to the
release of both small and relatively large parallel corpora for training neural
models. The existing data-to-text datasets are, however, aimed at task-oriented
dialogue systems, and often thus limited in diversity and versatility. They are
typically crowdsourced, with much of the noise left in them. Moreover, current
neural NLG models do not take full advantage of large training data, and due to
their strong generalizing properties produce sentences that look template-like
regardless. We therefore present a new corpus of 7K samples, which (1) is clean
despite being crowdsourced, (2) has utterances of 9 generalizable and
conversational dialogue act types, making it more suitable for open-domain
dialogue systems, and (3) explores the domain of video games, which is new to
dialogue systems despite having excellent potential for supporting rich
conversations.",2019-10-26
"Table-to-Text Generation with Effective Hierarchical Encoder on Three
  Dimensions (Row, Column and Time)",2019-09-05 10:25:34+00:00,http://arxiv.org/abs/1909.02304v1,"Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu",cs.CL,games,"Although Seq2Seq models for table-to-text generation have achieved remarkable
progress, modeling table representation in one dimension is inadequate. This is
because (1) the table consists of multiple rows and columns, which means that
encoding a table should not depend only on one dimensional sequence or set of
records and (2) most of the tables are time series data (e.g. NBA game data,
stock market data), which means that the description of the current table may
be affected by its historical data. To address aforementioned problems, not
only do we model each table cell considering other records in the same row, we
also enrich table's representation by modeling each table cell in context of
other cells in the same column or with historical (time dimension) data
respectively. In addition, we develop a table cell fusion gate to combine
representations from row, column and time dimension into one dense vector
according to the saliency of each dimension's representation. We evaluated our
methods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both
automatic and human evaluation results demonstrate the effectiveness of our
model with improvement of 2.66 in BLEU over the strong baseline and
outperformance of state-of-the-art model.",2019-09-05
Generating Question-Answer Hierarchies,2019-06-06 14:53:04+00:00,http://arxiv.org/abs/1906.02622v2,"Kalpesh Krishna, Mohit Iyyer",cs.CL,games,"The process of knowledge acquisition can be viewed as a question-answer game
between a student and a teacher in which the student typically starts by asking
broad, open-ended questions before drilling down into specifics (Hintikka,
1981; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a
new way of representing documents. In this paper, we present SQUASH
(Specificity-controlled Question-Answer Hierarchies), a novel and challenging
text generation task that converts an input document into a hierarchy of
question-answer pairs. Users can click on high-level questions (e.g., ""Why did
Frodo leave the Fellowship?"") to reveal related but more specific questions
(e.g., ""Who did Frodo leave with?""). Using a question taxonomy loosely based on
Lehnert (1978), we classify questions in existing reading comprehension
datasets as either ""general"" or ""specific"". We then use these labels as input
to a pipelined system centered around a conditional neural language model. We
extensively evaluate the quality of the generated QA hierarchies through
crowdsourced experiments and report strong empirical results.",2019-06-06
Pragmatically Informative Text Generation,2019-04-02 09:04:57+00:00,http://arxiv.org/abs/1904.01301v2,"Sheng Shen, Daniel Fried, Jacob Andreas, Dan Klein",cs.CL,games,"We improve the informativeness of models for conditional text generation
using techniques from computational pragmatics. These techniques formulate
language production as a game between speakers and listeners, in which a
speaker should generate output text that a listener can use to correctly
identify the original input that the text describes. While such approaches are
widely used in cognitive science and grounded language learning, they have
received less attention for more standard language generation tasks. We
consider two pragmatic modeling methods for text generation: one where
pragmatics is imposed by information preservation, and another where pragmatics
is imposed by explicit modeling of distractors. We find that these methods
improve the performance of strong existing systems for abstractive
summarization and generation from structured meaning representations.",2019-04-02
Automating Direct Speech Variations in Stories and Games,2017-08-30 02:19:39+00:00,http://arxiv.org/abs/1708.09090v1,"Stephanie M. Lukin, James O. Ryan, Marilyn A. Walker",cs.CL,games,"Dialogue authoring in large games requires not only content creation but the
subtlety of its delivery, which can vary from character to character. Manually
authoring this dialogue can be tedious, time-consuming, or even altogether
infeasible. This paper utilizes a rich narrative representation for modeling
dialogue and an expressive natural language generation engine for realizing it,
and expands upon a translation tool that bridges the two. We add functionality
to the translator to allow direct speech to be modeled by the narrative
representation, whereas the original translator supports only narratives told
by a third person narrator. We show that we can perform character substitution
in dialogues. We implement and evaluate a potential application to dialogue
implementation: generating dialogue for games with big, dynamic, or
procedurally-generated open worlds. We present a pilot study on human
perceptions of the personalities of characters using direct speech, assuming
unknown personality types at the time of authoring.",2017-08-30
Deep Reinforcement Learning: An Overview,2017-01-25 11:52:11+00:00,http://arxiv.org/abs/1701.07274v6,Yuxi Li,cs.LG,games,"We give an overview of recent exciting achievements of deep reinforcement
learning (RL). We discuss six core elements, six important mechanisms, and
twelve applications. We start with background of machine learning, deep
learning and reinforcement learning. Next we discuss core RL elements,
including value function, in particular, Deep Q-Network (DQN), policy, reward,
model, planning, and exploration. After that, we discuss important mechanisms
for RL, including attention and memory, unsupervised learning, transfer
learning, multi-agent RL, hierarchical RL, and learning to learn. Then we
discuss various applications of RL, including games, in particular, AlphaGo,
robotics, natural language processing, including dialogue systems, machine
translation, and text generation, computer vision, neural architecture design,
business management, finance, healthcare, Industry 4.0, smart grid, intelligent
transportation systems, and computer systems. We mention topics not reviewed
yet, and list a collection of RL resources. After presenting a brief summary,
we close with discussions.
  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant
update.",2017-01-25
