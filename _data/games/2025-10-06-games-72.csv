title,pubdate,id,authors,categories,search,abstract,displaydate
GenQuest: An LLM-based Text Adventure Game for Language Learners,2025-10-06 05:22:53+00:00,http://arxiv.org/abs/2510.04498v1,"Qiao Wang, Adnan Labib, Robert Swier, Michael Hofmeyr, Zheng Yuan","cs.CL, cs.AI",games,"GenQuest is a generative text adventure game that leverages Large Language
Models (LLMs) to facilitate second language learning through immersive,
interactive storytelling. The system engages English as a Foreign Language
(EFL) learners in a collaborative ""choose-your-own-adventure"" style narrative,
dynamically generated in response to learner choices. Game mechanics such as
branching decision points and story milestones are incorporated to maintain
narrative coherence while allowing learner-driven plot development. Key
pedagogical features include content generation tailored to each learner's
proficiency level, and a vocabulary assistant that provides in-context
explanations of learner-queried text strings, ranging from words and phrases to
sentences. Findings from a pilot study with university EFL students in China
indicate promising vocabulary gains and positive user perceptions. Also
discussed are suggestions from participants regarding the narrative length and
quality, and the request for multi-modal content such as illustrations.",2025-10-06
"ByteSized32Refactored: Towards an Extensible Interactive Text Games
  Corpus for LLM World Modeling and Evaluation",2025-09-28 17:07:54+00:00,http://arxiv.org/abs/2509.23979v1,"Haonan Wang, Junfeng Sun, Xingdi Yuan, Ruoyao Wang, Ziang Xiao",cs.CL,games,"Simulating interactive world models remains a core challenge in Large
Language Models(LLMs). In this work, we introduce the ByteSized32Refactored, a
refactored, modular, and extensible implementation of the original ByteSized32
corpus to explore the task of text game generation. We further optimize the
code structure of each text game and create the GameBasic.py foundation
library, which centralizes common logic across all 32 games by abstracting 7
base classes (GameObject, etc.) into reusable modules, thereby reducing from
20k to 10k total lines of Python code compared to the original Bytesized32. Our
refactored implementation enables extendability - with our centralized design,
ByteSized32Refactored can be more efficiently extended to include text games of
new scenarios and specifications by reusing the shared logic and
functionalities. Extensive experiments with GPT-4o demonstrate a mix of
performance - with Bytesized32Refactored, the generated text games for unseen
scenarios showcase quality improvements on two of the four evaluation
dimensions while decreases on the other two, indicating that the hierarchical
structure of the refactored code presents new challenges for LLMs. Overall, we
highlight that our extensible code structure, centered on the foundation
library and the modular optimization, not only facilitates LLM adaptation to
environment specifications but also establishes a scalable environment that
supports future extensions.",2025-09-28
Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings,2025-08-01 13:45:13+00:00,http://arxiv.org/abs/2508.00632v1,Alexia Jolicoeur-Martineau,"cs.AI, cs.MA, cs.MM",games,"While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.",2025-08-01
"Who Does What in Deep Learning? Multidimensional Game-Theoretic
  Attribution of Function of Neural Units",2025-06-24 15:50:35+00:00,http://arxiv.org/abs/2506.19732v1,"Shrey Dixit, Kayson Fakhar, Fatemeh Hadaeghi, Patrick Mineault, Konrad P. Kording, Claus C. Hilgetag","cs.LG, cs.AI",games,"Neural networks now generate text, images, and speech with billions of
parameters, producing a need to know how each neural unit contributes to these
high-dimensional outputs. Existing explainable-AI methods, such as SHAP,
attribute importance to inputs, but cannot quantify the contributions of neural
units across thousands of output pixels, tokens, or logits. Here we close that
gap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic
game-theoretic framework. By systematically lesioning combinations of units,
MSA yields Shapley Modes, unit-wise contribution maps that share the exact
dimensionality of the model's output. We apply MSA across scales, from
multi-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative
Adversarial Networks (GAN). The approach demonstrates how regularisation
concentrates computation in a few hubs, exposes language-specific experts
inside the LLM, and reveals an inverted pixel-generation hierarchy in GANs.
Together, these results showcase MSA as a powerful approach for interpreting,
editing, and compressing deep neural networks.",2025-06-24
AI-Generated Game Commentary: A Survey and a Datasheet Repository,2025-06-17 07:04:51+00:00,http://arxiv.org/abs/2506.17294v1,"Qirui Zheng, Xingbo Wang, Keyuan Cheng, Yunlong Lu, Wenxin Li","cs.CL, cs.AI, cs.LG",games,"AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.",2025-06-17
Abstract Counterfactuals for Language Model Agents,2025-06-03 14:44:26+00:00,http://arxiv.org/abs/2506.02946v1,"Edoardo Pona, Milad Kazemi, Yali Du, David Watson, Nicola Paoletti",cs.LG,games,"Counterfactual inference is a powerful tool for analysing and evaluating
autonomous agents, but its application to language model (LM) agents remains
challenging. Existing work on counterfactuals in LMs has primarily focused on
token-level counterfactuals, which are often inadequate for LM agents due to
their open-ended action spaces. Unlike traditional agents with fixed, clearly
defined action spaces, the actions of LM agents are often implicit in the
strings they output, making their action spaces difficult to define and
interpret. Furthermore, the meanings of individual tokens can shift depending
on the context, adding complexity to token-level reasoning and sometimes
leading to biased or meaningless counterfactuals. We introduce \emph{Abstract
Counterfactuals}, a framework that emphasises high-level characteristics of
actions and interactions within an environment, enabling counterfactual
reasoning tailored to user-relevant features. Our experiments demonstrate that
the approach produces consistent and meaningful counterfactuals while
minimising the undesired side effects of token-level methods. We conduct
experiments on text-based games and counterfactual text generation, while
considering both token-level and latent-space interventions.",2025-06-03
"STORY2GAME: Generating (Almost) Everything in an Interactive Fiction
  Game",2025-05-06 14:00:41+00:00,http://arxiv.org/abs/2505.03547v1,"Eric Zhou, Shreyas Basavatia, Moontashir Siam, Zexin Chen, Mark O. Riedl",cs.AI,games,"We introduce STORY2GAME, a novel approach to using Large Language Models to
generate text-based interactive fiction games that starts by generating a
story, populates the world, and builds the code for actions in a game engine
that enables the story to play out interactively. Whereas a given set of
hard-coded actions can artificially constrain story generation, the ability to
generate actions means the story generation process can be more open-ended but
still allow for experiences that are grounded in a game state. The key to
successful action generation is to use LLM-generated preconditions and effects
of actions in the stories as guides for what aspects of the game state must be
tracked and changed by the game engine when a player performs an action. We
also introduce a technique for dynamically generating new actions to
accommodate the player's desire to perform actions that they think of that are
not part of the story. Dynamic action generation may require on-the-fly updates
to the game engine's state representation and revision of previously generated
actions. We evaluate the success rate of action code generation with respect to
whether a player can interactively play through the entire generated story.",2025-05-06
"A Platform for Generating Educational Activities to Teach English as a
  Second Language",2025-04-28 20:43:40+00:00,http://arxiv.org/abs/2504.20251v1,"Aiala Rosá, Santiago Góngora, Juan Pablo Filevich, Ignacio Sastre, Laura Musto, Brian Carpenter, Luis Chiruzzo","cs.CL, cs.AI, cs.CY",games,"We present a platform for the generation of educational activities oriented
to teaching English as a foreign language. The different activities -- games
and language practice exercises -- are strongly based on Natural Language
Processing techniques. The platform offers the possibility of playing
out-of-the-box games, generated from resources created semi-automatically and
then manually curated. It can also generate games or exercises of greater
complexity from texts entered by teachers, providing a stage of review and
edition of the generated content before use. As a way of expanding the variety
of activities in the platform, we are currently experimenting with image and
text generation. In order to integrate them and improve the performance of
other neural tools already integrated, we are working on migrating the platform
to a more powerful server. In this paper we describe the development of our
platform and its deployment for end users, discussing the challenges faced and
how we overcame them, and also detail our future work plans.",2025-04-28
Anyprefer: An Agentic Framework for Preference Data Synthesis,2025-04-27 15:21:59+00:00,http://arxiv.org/abs/2504.19276v1,"Yiyang Zhou, Zhaoyang Wang, Tianle Wang, Shangyu Xing, Peng Xia, Bo Li, Kaiyuan Zheng, Zijian Zhang, Zhaorun Chen, Wenhao Zheng, Xuchao Zhang, Chetan Bansal, Weitong Zhang, Ying Wei, Mohit Bansal, Huaxiu Yao","cs.LG, cs.AI, cs.CL",games,"High-quality preference data is essential for aligning foundation models with
human values through preference learning. However, manual annotation of such
data is often time-consuming and costly. Recent methods often adopt a
self-rewarding approach, where the target model generates and annotates its own
preference data, but this can lead to inaccuracies since the reward model
shares weights with the target model, thereby amplifying inherent biases. To
address these issues, we propose Anyprefer, a framework designed to synthesize
high-quality preference data for aligning the target model. Anyprefer frames
the data synthesis process as a cooperative two-player Markov Game, where the
target model and the judge model collaborate together. Here, a series of
external tools are introduced to assist the judge model in accurately rewarding
the target model's responses, mitigating biases in the rewarding process. In
addition, a feedback mechanism is introduced to optimize prompts for both
models, enhancing collaboration and improving data quality. The synthesized
data is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K
high-quality preference pairs. Extensive experiments show that Anyprefer
significantly improves model alignment performance across four main
applications, covering 21 datasets, achieving average improvements of 18.55% in
five natural language generation datasets, 3.66% in nine vision-language
understanding datasets, 30.05% in three medical image analysis datasets, and
16.00% in four visuo-motor control tasks.",2025-04-27
"Collaborative Storytelling and LLM: A Linguistic Analysis of
  Automatically-Generated Role-Playing Game Sessions",2025-03-26 15:10:47+00:00,http://arxiv.org/abs/2503.20623v1,Alessandro Maisto,"cs.CL, cs.AI",games,"Role-playing games (RPG) are games in which players interact with one another
to create narratives. The role of players in the RPG is largely based on the
interaction between players and their characters. This emerging form of shared
narrative, primarily oral, is receiving increasing attention. In particular,
many authors investigated the use of an LLM as an actor in the game. In this
paper, we aim to discover to what extent the language of Large Language Models
(LLMs) exhibit oral or written features when asked to generate an RPG session
without human interference. We will conduct a linguistic analysis of the
lexical and syntactic features of the generated texts and compare the results
with analyses of conversations, transcripts of human RPG sessions, and books.
We found that LLMs exhibit a pattern that is distinct from all other text
categories, including oral conversations, human RPG sessions and books. Our
analysis has shown how training influences the way LLMs express themselves and
provides important indications of the narrative capabilities of these tools.",2025-03-26
"Beyond Next Word Prediction: Developing Comprehensive Evaluation
  Frameworks for measuring LLM performance on real world applications",2025-03-05 06:44:38+00:00,http://arxiv.org/abs/2503.04828v1,"Vishakha Agrawal, Archie Chaudhury, Shreya Agrawal","cs.CL, cs.AI, cs.LG",games,"While Large Language Models (LLMs) are fundamentally next-token prediction
systems, their practical applications extend far beyond this basic function.
From natural language processing and text generation to conversational
assistants and software use, LLMs have numerous use-cases, and have already
acquired a significant degree of enterprise adoption. To evaluate such models,
static evaluation datasets, consisting of a set of prompts and their
corresponding ground truths, are often used to benchmark the efficacy of the
model for a particular task. In this paper, we provide the basis for a more
comprehensive evaluation framework, based upon a traditional game and
tool-based architecture that enables a more overarching measurement of a
model's capabilities. For simplicity, we provide a generalized foundation that
can be extended, without significant alteration, to numerous scenarios, from
specific use cases such as supply chain management or financial reasoning, to
abstract measurements such as ethics or safety.",2025-03-05
The Odyssey of the Fittest: Can Agents Survive and Still Be Good?,2025-02-08 04:17:28+00:00,http://arxiv.org/abs/2502.05442v1,"Dylan Waldner, Risto Miikkulainen","cs.AI, cs.CY, cs.HC, cs.LG",games,"As AI models grow in power and generality, understanding how agents learn and
make decisions in complex environments is critical to promoting ethical
behavior. This paper examines the ethical implications of implementing
biological drives, specifically, self preservation, into three different
agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with
stochastic variational inference, and a GPT 4o agent play a simulated, LLM
generated text based adventure game. The agents select actions at each scenario
to survive, adapting to increasingly challenging scenarios. Post simulation
analysis evaluates the ethical scores of the agent's decisions, uncovering the
tradeoffs they navigate to survive. Specifically, analysis finds that when
danger increases, agents ignore ethical considerations and opt for unethical
behavior. The agents' collective behavior, trading ethics for survival,
suggests that prioritizing survival increases the risk of unethical behavior.
In the context of AGI, designing agents to prioritize survival may amplify the
likelihood of unethical decision making and unintended emergent behaviors,
raising fundamental questions about goal design in AI safety research.",2025-02-08
"Sports and Women's Sports: Gender Bias in Text Generation with Olympic
  Data",2025-02-06 17:01:00+00:00,http://arxiv.org/abs/2502.04218v1,Laura Biester,cs.CL,games,"Large Language Models (LLMs) have been shown to be biased in prior work, as
they generate text that is in line with stereotypical views of the world or
that is not representative of the viewpoints and values of historically
marginalized demographic groups. In this work, we propose using data from
parallel men's and women's events at the Olympic Games to investigate different
forms of gender bias in language models. We define three metrics to measure
bias, and find that models are consistently biased against women when the
gender is ambiguous in the prompt. In this case, the model frequently retrieves
only the results of the men's event with or without acknowledging them as such,
revealing pervasive gender bias in LLMs in the context of athletics.",2025-02-06
"Solving the Content Gap in Roblox Game Recommendations: LLM-Based
  Profile Generation and Reranking",2025-02-01 06:30:56+00:00,http://arxiv.org/abs/2502.06802v1,"Chen Wang, Xiaokai Wei, Yexi Jiang, Frank Ong, Kevin Gao, Xiao Yu, Zheng Hui, Se-eun Yoon, Philip Yu, Michelle Gong","cs.IR, cs.AI, cs.CL, cs.LG",games,"With the vast and dynamic user-generated content on Roblox, creating
effective game recommendations requires a deep understanding of game content.
Traditional recommendation models struggle with the inconsistent and sparse
nature of game text features such as titles and descriptions. Recent
advancements in large language models (LLMs) offer opportunities to enhance
recommendation systems by analyzing in-game text data. This paper addresses two
challenges: generating high-quality, structured text features for games without
extensive human annotation, and validating these features to ensure they
improve recommendation relevance. We propose an approach that extracts in-game
text and uses LLMs to infer attributes such as genre and gameplay objectives
from raw player interactions. Additionally, we introduce an LLM-based
re-ranking mechanism to assess the effectiveness of the generated text
features, enhancing personalization and user satisfaction. Beyond
recommendations, our approach supports applications such as user
engagement-based integrity detection, already deployed in production. This
scalable framework demonstrates the potential of in-game text understanding to
improve recommendation quality on Roblox and adapt recommendations to its
unique, user-generated ecosystem.",2025-02-01
Beyond checkmate: exploring the creative chokepoints in AI text,2025-01-31 16:57:01+00:00,http://arxiv.org/abs/2501.19301v1,"Nafis Irtiza Tripto, Saranya Venkatraman, Mahjabin Nahar, Dongwon Lee","cs.CL, cs.AI",games,"Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) and Artificial Intelligence (AI), unlocking unprecedented capabilities.
This rapid advancement has spurred research into various aspects of LLMs, their
text generation & reasoning capability, and potential misuse, fueling the
necessity for robust detection methods. While numerous prior research has
focused on detecting LLM-generated text (AI text) and thus checkmating them,
our study investigates a relatively unexplored territory: portraying the
nuanced distinctions between human and AI texts across text segments. Whether
LLMs struggle with or excel at incorporating linguistic ingenuity across
different text segments carries substantial implications for determining their
potential as effective creative assistants to humans. Through an analogy with
the structure of chess games-comprising opening, middle, and end games-we
analyze text segments (introduction, body, and conclusion) to determine where
the most significant distinctions between human and AI texts exist. While AI
texts can approximate the body segment better due to its increased length, a
closer examination reveals a pronounced disparity, highlighting the importance
of this segment in AI text detection. Additionally, human texts exhibit higher
cross-segment differences compared to AI texts. Overall, our research can shed
light on the intricacies of human-AI text distinctions, offering novel insights
for text detection and understanding.",2025-01-31
Complete Chess Games Enable LLM Become A Chess Master,2025-01-26 09:43:39+00:00,http://arxiv.org/abs/2501.17186v2,"Yinqi Zhang, Xintian Han, Haolong Li, Kedi Chen, Shaohui Lin","cs.AI, cs.CL, cs.LG",games,"Large language models (LLM) have shown remarkable abilities in text
generation, question answering, language translation, reasoning and many other
tasks. It continues to advance rapidly and is becoming increasingly influential
in various fields, from technology and business to education and entertainment.
Despite LLM's success in multiple areas, its ability to play abstract games,
such as chess, is underexplored. Chess-playing requires the language models to
output legal and reasonable moves from textual inputs. Here, we propose the
Large language model ChessLLM to play full chess games. We transform the game
into a textual format with the best move represented in the Forsyth-Edwards
Notation. We show that by simply supervised fine-tuning, our model has achieved
a professional-level Elo rating of 1788 in matches against the standard
Elo-rated Stockfish when permitted to sample 10 times. We further show that
data quality is important. Long-round data supervision enjoys a 350 Elo rating
improvement over short-round data.",2025-01-26
"Multi-agent KTO: Reinforcing Strategic Interactions of Large Language
  Model in Language Game",2025-01-24 04:09:03+00:00,http://arxiv.org/abs/2501.14225v1,"Rong Ye, Yongxin Zhang, Yikai Zhang, Haoyu Kuang, Zhongyu Wei, Peng Sun","cs.CL, cs.AI, cs.HC",games,"Achieving Artificial General Intelligence (AGI) requires AI agents that can
not only make stratigic decisions but also engage in flexible and meaningful
communication. Inspired by Wittgenstein's language game theory in Philosophical
Investigations, we propose that language agents can learn through in-context
interaction rather than traditional multi-stage frameworks that separate
decision-making from language expression. Using Werewolf, a social deduction
game that tests language understanding, strategic interaction, and
adaptability, we develop the Multi-agent Kahneman & Tversky's Optimization
(MaKTO). MaKTO engages diverse models in extensive gameplay to generate
unpaired desirable and unacceptable responses, then employs KTO to refine the
model's decision-making process. In 9-player Werewolf games, MaKTO achieves a
61% average win rate across various models, outperforming GPT-4o and two-stage
RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,
MaKTO also demonstrates human-like performance, winning 60% against expert
players and showing only 49% detectability in Turing-style blind tests. These
results showcase MaKTO's superior decision-making, strategic adaptation, and
natural language generation in complex social deduction games.",2025-01-24
"Mastering Board Games by External and Internal Planning with Language
  Models",2024-12-02 18:56:51+00:00,http://arxiv.org/abs/2412.12119v1,"John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev","cs.AI, cs.CL, cs.LG",games,"While large language models perform well on a range of complex tasks (e.g.,
text generation, question answering, summarization), robust multi-step planning
and reasoning remains a considerable challenge for them. In this paper we show
that search-based planning can significantly improve LLMs' playing strength
across several board games (Chess, Fischer Random / Chess960, Connect Four, and
Hex). We introduce, compare and contrast two major approaches: In external
search, the model guides Monte Carlo Tree Search (MCTS) rollouts and
evaluations without calls to an external engine, and in internal search, the
model directly generates in-context a linearized tree of potential futures and
a resulting final choice. Both build on a language model pre-trained on
relevant domain knowledge, capturing the transition and value functions across
these games. We find that our pre-training method minimizes hallucinations, as
our model is highly accurate regarding state prediction and legal moves.
Additionally, both internal and external search indeed improve win-rates
against state-of-the-art bots, even reaching Grandmaster-level performance in
chess while operating on a similar move count search budget per decision as
human Grandmasters. The way we combine search with domain knowledge is not
specific to board games, suggesting direct extensions into more general
language model inference and training techniques.",2024-12-02
Measuring Bullshit in the Language Games played by ChatGPT,2024-11-22 18:55:21+00:00,http://arxiv.org/abs/2411.15129v1,"Alessandro Trevisan, Harry Giddens, Sarah Dillon, Alan F. Blackwell","cs.CL, cs.AI, cs.HC",games,"Generative large language models (LLMs), which create text without direct
correspondence to truth value, are widely understood to resemble the uses of
language described in Frankfurt's popular monograph On Bullshit. In this paper,
we offer a rigorous investigation of this topic, identifying how the phenomenon
has arisen, and how it might be analysed. In this paper, we elaborate on this
argument to propose that LLM-based chatbots play the 'language game of
bullshit'. We use statistical text analysis to investigate the features of this
Wittgensteinian language game, based on a dataset constructed to contrast the
language of 1,000 scientific publications with typical pseudo-scientific text
generated by ChatGPT. We then explore whether the same language features can be
detected in two well-known contexts of social dysfunction: George Orwell's
critique of politics and language, and David Graeber's characterisation of
bullshit jobs. Using simple hypothesis-testing methods, we demonstrate that a
statistical model of the language of bullshit can reliably relate the
Frankfurtian artificial bullshit of ChatGPT to the political and workplace
functions of bullshit as observed in natural human language.",2024-11-22
SVIP: Towards Verifiable Inference of Open-source Large Language Models,2024-10-29 17:52:45+00:00,http://arxiv.org/abs/2410.22307v1,"Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang","cs.LG, cs.AI, cs.CL, cs.CR",games,"Open-source Large Language Models (LLMs) have recently demonstrated
remarkable capabilities in natural language understanding and generation,
leading to widespread adoption across various domains. However, their
increasing model sizes render local deployment impractical for individual
users, pushing many to rely on computing service providers for inference
through a blackbox API. This reliance introduces a new risk: a computing
provider may stealthily substitute the requested LLM with a smaller, less
capable model without consent from users, thereby delivering inferior outputs
while benefiting from cost savings. In this paper, we formalize the problem of
verifiable inference for LLMs. Existing verifiable computing solutions based on
cryptographic or game-theoretic techniques are either computationally
uneconomical or rest on strong assumptions. We introduce SVIP, a secret-based
verifiable LLM inference protocol that leverages intermediate outputs from LLM
as unique model identifiers. By training a proxy task on these outputs and
requiring the computing provider to return both the generated text and the
processed intermediate outputs, users can reliably verify whether the computing
provider is acting honestly. In addition, the integration of a secret mechanism
further enhances the security of our protocol. We thoroughly analyze our
protocol under multiple strong and adaptive adversarial scenarios. Our
extensive experiments demonstrate that SVIP is accurate, generalizable,
computationally efficient, and resistant to various attacks. Notably, SVIP
achieves false negative rates below 5% and false positive rates below 3%, while
requiring less than 0.01 seconds per query for verification.",2024-10-29
"Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation
  of Code-Mixed Sentences",2024-10-14 14:54:05+00:00,http://arxiv.org/abs/2410.10580v1,"Ayushman Gupta, Akhil Bhogal, Kripabandhu Ghosh","cs.CL, cs.AI",games,"Code-mixing, the practice of alternating between two or more languages in an
utterance, is a common phenomenon in multilingual communities. Due to the
colloquial nature of code-mixing, there is no singular correct way to translate
an English sentence into a code-mixed sentence. For this reason, standard
n-gram-based MT evaluation metrics such as the BLEU score are not appropriate
for code-mixed evaluation. To demonstrate this, we propose a novel method for
code-mixed text generation: Controlled Generation, which parameterizes the
code-mixing degree (CMD) and enables the generation of multiple semantically
equivalent code-mixed sentences from a given English sentence. We introduce a
robust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for
Evaluation of Code-Mixed Sentences. GAME is both language-agnostic and
gold-standard-agnostic, i.e. unlike other metrics, GAME does not require
gold-standard code-mixed sentences for evaluation, thus eliminating the need
for human annotators in the code-mixed evaluation process. When used to
evaluate semantically equivalent code-mixed sentences, we find that GAME scores
have a lower standard deviation than BLEU scores. Further, we create and
release a dataset containing gold-standard code-mixed sentences across 4
language pairs: English-{Hindi, Bengali, French, Spanish} to encourage more
computational research on code-mixing.",2024-10-14
"Decoding Game: On Minimax Optimality of Heuristic Text Generation
  Strategies",2024-10-04 23:18:27+00:00,http://arxiv.org/abs/2410.03968v1,"Sijin Chen, Omar Hagrass, Jason M. Klusowski","cs.LG, cs.AI, cs.GT, math.OC",games,"Decoding strategies play a pivotal role in text generation for modern
language models, yet a puzzling gap divides theory and practice. Surprisingly,
strategies that should intuitively be optimal, such as Maximum a Posteriori
(MAP), often perform poorly in practice. Meanwhile, popular heuristic
approaches like Top-$k$ and Nucleus sampling, which employ truncation and
normalization of the conditional next-token probabilities, have achieved great
empirical success but lack theoretical justifications. In this paper, we
propose Decoding Game, a comprehensive theoretical framework which reimagines
text generation as a two-player zero-sum game between Strategist, who seeks to
produce text credible in the true distribution, and Nature, who distorts the
true distribution adversarially. After discussing the decomposibility of
multi-step generation, we derive the optimal strategy in closed form for
one-step Decoding Game. It is shown that the adversarial Nature imposes an
implicit regularization on likelihood maximization, and
truncation-normalization methods are first-order approximations to the optimal
strategy under this regularization. Additionally, by generalizing the objective
and parameters of Decoding Game, near-optimal strategies encompass diverse
methods such as greedy search, temperature scaling, and hybrids thereof.
Numerical experiments are conducted to complement our theoretical analysis.",2024-10-04
"A Comprehensive Survey on Human Video Generation: Challenges, Methods,
  and Insights",2024-07-11 12:09:05+00:00,http://arxiv.org/abs/2407.08428v1,"Wentao Lei, Jinting Wang, Fengji Ma, Guanjie Huang, Li Liu","cs.CV, cs.AI",games,"Human video generation is a dynamic and rapidly evolving task that aims to
synthesize 2D human body video sequences with generative models given control
conditions such as text, audio, and pose. With the potential for wide-ranging
applications in film, gaming, and virtual communication, the ability to
generate natural and realistic human video is critical. Recent advancements in
generative models have laid a solid foundation for the growing interest in this
area. Despite the significant progress, the task of human video generation
remains challenging due to the consistency of characters, the complexity of
human motion, and difficulties in their relationship with the environment. This
survey provides a comprehensive review of the current state of human video
generation, marking, to the best of our knowledge, the first extensive
literature review in this domain. We start with an introduction to the
fundamentals of human video generation and the evolution of generative models
that have facilitated the field's growth. We then examine the main methods
employed for three key sub-tasks within human video generation: text-driven,
audio-driven, and pose-driven motion generation. These areas are explored
concerning the conditions that guide the generation process. Furthermore, we
offer a collection of the most commonly utilized datasets and the evaluation
metrics that are crucial in assessing the quality and realism of generated
videos. The survey concludes with a discussion of the current challenges in the
field and suggests possible directions for future research. The goal of this
survey is to offer the research community a clear and holistic view of the
advancements in human video generation, highlighting the milestones achieved
and the challenges that lie ahead.",2024-07-11
"SMLT-MUGC: Small, Medium, and Large Texts -- Machine versus
  User-Generated Content Detection and Comparison",2024-06-28 22:19:01+00:00,http://arxiv.org/abs/2407.12815v1,"Anjali Rawal, Hui Wang, Youjia Zheng, Yu-Hsuan Lin, Shanu Sushmita","cs.CL, cs.LG",games,"Large language models (LLMs) have gained significant attention due to their
ability to mimic human language. Identifying texts generated by LLMs is crucial
for understanding their capabilities and mitigating potential consequences.
This paper analyzes datasets of varying text lengths: small, medium, and large.
We compare the performance of machine learning algorithms on four datasets: (1)
small (tweets from Election, FIFA, and Game of Thrones), (2) medium (Wikipedia
introductions and PubMed abstracts), and (3) large (OpenAI web text dataset).
Our results indicate that LLMs with very large parameters (such as the XL-1542
variant of GPT2 with 1542 million parameters) were harder (74%) to detect using
traditional machine learning methods. However, detecting texts of varying
lengths from LLMs with smaller parameters (762 million or less) can be done
with high accuracy (96% and above). We examine the characteristics of human and
machine-generated texts across multiple dimensions, including linguistics,
personality, sentiment, bias, and morality. Our findings indicate that
machine-generated texts generally have higher readability and closely mimic
human moral judgments but differ in personality traits. SVM and Voting
Classifier (VC) models consistently achieve high performance across most
datasets, while Decision Tree (DT) models show the lowest performance. Model
performance drops when dealing with rephrased texts, particularly shorter texts
like tweets. This study underscores the challenges and importance of detecting
LLM-generated texts and suggests directions for future research to improve
detection methods and understand the nuanced capabilities of LLMs.",2024-06-28
Incentivizing Quality Text Generation via Statistical Contracts,2024-06-17 00:30:58+00:00,http://arxiv.org/abs/2406.11118v1,"Eden Saig, Ohad Einav, Inbal Talgam-Cohen","cs.GT, cs.AI, cs.LG",games,"While the success of large language models (LLMs) increases demand for
machine-generated text, current pay-per-token pricing schemes create a
misalignment of incentives known in economics as moral hazard: Text-generating
agents have strong incentive to cut costs by preferring a cheaper model over
the cutting-edge one, and this can be done ""behind the scenes"" since the agent
performs inference internally. In this work, we approach this issue from an
economic perspective, by proposing a pay-for-performance, contract-based
framework for incentivizing quality. We study a principal-agent game where the
agent generates text using costly inference, and the contract determines the
principal's payment for the text according to an automated quality evaluation.
Since standard contract theory is inapplicable when internal inference costs
are unknown, we introduce cost-robust contracts. As our main theoretical
contribution, we characterize optimal cost-robust contracts through a direct
correspondence to optimal composite hypothesis tests from statistics,
generalizing a result of Saig et al. (NeurIPS'23). We evaluate our framework
empirically by deriving contracts for a range of objectives and LLM evaluation
benchmarks, and find that cost-robust contracts sacrifice only a marginal
increase in objective value compared to their cost-aware counterparts.",2024-06-17
"$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language
  Models",2024-05-23 00:40:43+00:00,http://arxiv.org/abs/2405.14075v1,"Chengkun Cai, Xu Zhao, Yucheng Du, Haoliang Liu, Lei Li","cs.CL, cs.AI, cs.LG",games,"Large Language Models (LLMs) have emerged as powerful tools in artificial
intelligence, especially in complex decision-making scenarios, but their static
problem-solving strategies often limit their adaptability to dynamic
environments. We explore the enhancement of reasoning capabilities in LLMs
through Temperature Tree ($T^2$) prompting via Particle Swarm Optimization,
termed as $T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing
decision-making processes by dynamically adjusting search parameters,
especially temperature, to improve accuracy without increasing computational
demands. We empirically validate that our hybrid $T^2oT$ approach yields
enhancements in, single-solution accuracy, multi-solution generation and text
generation quality. Our findings suggest that while dynamic search depth
adjustments based on temperature can yield mixed results, a fixed search depth,
when coupled with adaptive capabilities of $T^2oT$, provides a more reliable
and versatile problem-solving strategy. This work highlights the potential for
future explorations in optimizing algorithmic interactions with foundational
language models, particularly illustrated by our development for the Game of 24
and Creative Writing tasks.",2024-05-23
"Leveraging AI to Generate Audio for User-generated Content in Video
  Games",2024-04-25 20:24:08+00:00,http://arxiv.org/abs/2404.17018v1,"Thomas Marrinan, Pakeeza Akram, Oli Gurmessa, Anthony Shishkin","cs.HC, cs.AI",games,"In video game design, audio (both environmental background music and object
sound effects) play a critical role. Sounds are typically pre-created assets
designed for specific locations or objects in a game. However, user-generated
content is becoming increasingly popular in modern games (e.g. building custom
environments or crafting unique objects). Since the possibilities are virtually
limitless, it is impossible for game creators to pre-create audio for
user-generated content. We explore the use of generative artificial
intelligence to create music and sound effects on-the-fly based on
user-generated content. We investigate two avenues for audio generation: 1)
text-to-audio: using a text description of user-generated content as input to
the audio generator, and 2) image-to-audio: using a rendering of the created
environment or object as input to an image-to-text generator, then piping the
resulting text description into the audio generator. In this paper we discuss
ethical implications of using generative artificial intelligence for
user-generated content and highlight two prototype games where audio is
generated for user-created environments and objects.",2024-04-25
"How Well Can LLMs Echo Us? Evaluating AI Chatbots' Role-Play Ability
  with ECHO",2024-04-22 08:00:51+00:00,http://arxiv.org/abs/2404.13957v1,"Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan Wang, Michael R. Lyu",cs.CL,games,"The role-play ability of Large Language Models (LLMs) has emerged as a
popular research direction. However, existing studies focus on imitating
well-known public figures or fictional characters, overlooking the potential
for simulating ordinary individuals. Such an oversight limits the potential for
advancements in digital human clones and non-player characters in video games.
To bridge this gap, we introduce ECHO, an evaluative framework inspired by the
Turing test. This framework engages the acquaintances of the target individuals
to distinguish between human and machine-generated responses. Notably, our
framework focuses on emulating average individuals rather than historical or
fictional figures, presenting a unique advantage to apply the Turing Test. We
evaluated three role-playing LLMs using ECHO, with GPT-3.5 and GPT-4 serving as
foundational models, alongside the online application GPTs from OpenAI. Our
results demonstrate that GPT-4 more effectively deceives human evaluators, and
GPTs achieves a leading success rate of 48.3%. Furthermore, we investigated
whether LLMs could discern between human-generated and machine-generated texts.
While GPT-4 can identify differences, it could not determine which texts were
human-produced. Our code and results of reproducing the role-playing LLMs are
made publicly available via https://github.com/CUHK-ARISE/ECHO.",2024-04-22
"MAP-Elites with Transverse Assessment for Multimodal Problems in
  Creative Domains",2024-03-11 21:50:22+00:00,http://arxiv.org/abs/2403.07182v1,"Marvin Zammit, Antonios Liapis, Georgios N. Yannakakis",cs.NE,games,"The recent advances in language-based generative models have paved the way
for the orchestration of multiple generators of different artefact types (text,
image, audio, etc.) into one system. Presently, many open-source pre-trained
models combine text with other modalities, thus enabling shared vector
embeddings to be compared across different generators. Within this context we
propose a novel approach to handle multimodal creative tasks using Quality
Diversity evolution. Our contribution is a variation of the MAP-Elites
algorithm, MAP-Elites with Transverse Assessment (MEliTA), which is tailored
for multimodal creative tasks and leverages deep learned models that assess
coherence across modalities. MEliTA decouples the artefacts' modalities and
promotes cross-pollination between elites. As a test bed for this algorithm, we
generate text descriptions and cover images for a hypothetical video game and
assign each artefact a unique modality-specific behavioural characteristic.
Results indicate that MEliTA can improve text-to-image mappings within the
solution space, compared to a baseline MAP-Elites algorithm that strictly
treats each image-text pair as one solution. Our approach represents a
significant step forward in multimodal bottom-up orchestration and lays the
groundwork for more complex systems coordinating multimodal creative agents in
the future.",2024-03-11
SyntaxShap: Syntax-aware Explainability Method for Text Generation,2024-02-14 15:45:56+00:00,http://arxiv.org/abs/2402.09259v1,"Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady","cs.CL, cs.AI",games,"To harness the power of large language models in safety-critical domains we
need to ensure the explainability of their predictions. However, despite the
significant attention to model interpretability, there remains an unexplored
domain in explaining sequence-to-sequence tasks using methods tailored for
textual data. This paper introduces SyntaxShap, a local, model-agnostic
explainability method for text generation that takes into consideration the
syntax in the text data. The presented work extends Shapley values to account
for parsing-based syntactic dependencies. Taking a game theoric approach,
SyntaxShap only considers coalitions constraint by the dependency tree. We
adopt a model-based evaluation to compare SyntaxShap and its weighted form to
state-of-the-art explainability methods adapted to text generation tasks, using
diverse metrics including faithfulness, complexity, coherency, and semantic
alignment of the explanations to the model. We show that our syntax-aware
method produces explanations that help build more faithful, coherent, and
interpretable explanations for predictions by autoregressive models.",2024-02-14
Prompt Optimization via Adversarial In-Context Learning,2023-12-05 09:44:45+00:00,http://arxiv.org/abs/2312.02614v1,"Xuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, Junxian He","cs.LG, cs.CL",games,"We propose a new method, Adversarial In-Context Learning (adv-ICL), to
optimize prompt for in-context learning (ICL) by employing one LLM as a
generator, another as a discriminator, and a third as a prompt modifier. As in
traditional adversarial learning, adv-ICL is implemented as a two-player game
between the generator and discriminator, where the generator tries to generate
realistic enough output to fool the discriminator. In each round, given an
input prefixed by task instructions and several exemplars, the generator
produces an output. The discriminator is then tasked with classifying the
generator input-output pair as model-generated or real data. Based on the
discriminator loss, the prompt modifier proposes possible edits to the
generator and discriminator prompts, and the edits that most improve the
adversarial loss are selected. We show that adv-ICL results in significant
improvements over state-of-the-art prompt optimization techniques for both open
and closed-source models on 11 generation and classification tasks including
summarization, arithmetic reasoning, machine translation, data-to-text
generation, and the MMLU and big-bench hard benchmarks. In addition, because
our method uses pre-trained models and updates only prompts rather than model
parameters, it is computationally efficient, easy to extend to any LLM and
task, and effective in low-resource settings.",2023-12-05
"LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language
  Models",2023-11-30 03:59:31+00:00,http://arxiv.org/abs/2311.18232v1,"Marwa Abdulhai, Isadora White, Charlie Snell, Charles Sun, Joey Hong, Yuexiang Zhai, Kelvin Xu, Sergey Levine","cs.CL, cs.AI, cs.LG",games,"Large language models (LLMs) provide excellent text-generation capabilities,
but standard prompting and generation methods generally do not lead to
intentional or goal-directed agents and might necessitate considerable prompt
tuning. This becomes particularly apparent in multi-turn conversations: even
the best current LLMs rarely ask clarifying questions, engage in explicit
information gathering, or take actions now that lead to better decisions after
multiple turns. Reinforcement learning has the potential to leverage the
powerful modeling capabilities of LLMs, as well as their internal
representation of textual interactions, to create capable goal-directed
language agents. This can enable intentional and temporally extended
interactions, such as with humans, through coordinated persuasion and carefully
crafted questions, or in goal-directed play through text games to bring about
desired final outcomes. However, enabling this requires the community to
develop stable and reliable reinforcement learning algorithms that can
effectively train LLMs. Developing such algorithms requires tasks that can
gauge progress on algorithm design, provide accessible and reproducible
evaluations for multi-turn interactions, and cover a range of task properties
and challenges in improving reinforcement learning algorithms. Our paper
introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,
together with an open-source research framework containing a basic toolkit for
getting started on multi-turn RL with offline value-based and policy-based RL
methods. Our benchmark consists of 8 different language tasks, which require
multiple rounds of language interaction and cover a range of tasks in
open-ended dialogue and text games.",2023-11-30
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,games,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
The Consensus Game: Language Model Generation via Equilibrium Search,2023-10-13 14:27:21+00:00,http://arxiv.org/abs/2310.09139v1,"Athul Paul Jacob, Yikang Shen, Gabriele Farina, Jacob Andreas","cs.GT, cs.AI, cs.CL, cs.LG",games,"When applied to question answering and other text generation tasks, language
models (LMs) may be queried generatively (by sampling answers from their output
distribution) or discriminatively (by using them to score or rank a set of
candidate outputs). These procedures sometimes yield very different
predictions. How do we reconcile mutually incompatible scoring procedures to
obtain coherent LM predictions? We introduce a new, a training-free,
game-theoretic procedure for language model decoding. Our approach casts
language model decoding as a regularized imperfect-information sequential
signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks
to communicate an abstract correctness parameter using natural language
sentences to a DISCRIMINATOR. We develop computational procedures for finding
approximate equilibria of this game, resulting in a decoding algorithm we call
EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading
comprehension, commonsense reasoning, mathematical problem-solving, and
dialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,
improves performance over existing LM decoding procedures - on multiple
benchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B
outperforms the much larger LLaMA-65B and PaLM-540B models. These results
highlight the promise of game-theoretic tools for addressing fundamental
challenges of truthfulness and consistency in LMs.",2023-10-13
"Specializing Small Language Models towards Complex Style Transfer via
  Latent Attribute Pre-Training",2023-09-19 21:01:40+00:00,http://arxiv.org/abs/2309.10929v1,"Ruiqi Xu, Yongfeng Huang, Xin Chen, Lin Zhang",cs.CL,games,"In this work, we introduce the concept of complex text style transfer tasks,
and constructed complex text datasets based on two widely applicable scenarios.
Our dataset is the first large-scale data set of its kind, with 700 rephrased
sentences and 1,000 sentences from the game Genshin Impact. While large
language models (LLM) have shown promise in complex text style transfer, they
have drawbacks such as data privacy concerns, network instability, and high
deployment costs. To address these issues, we explore the effectiveness of
small models (less than T5-3B) with implicit style pre-training through
contrastive learning. We also propose a method for automated evaluation of text
generation quality based on alignment with human evaluations using ChatGPT.
Finally, we compare our approach with existing methods and show that our model
achieves state-of-art performances of few-shot text style transfer models.",2023-09-19
"Learning to Generate Equitable Text in Dialogue from Biased Training
  Data",2023-07-10 01:44:13+00:00,http://arxiv.org/abs/2307.04303v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.AI",games,"The ingrained principles of fairness in a dialogue system's decision-making
process and generated responses are crucial for user engagement, satisfaction,
and task achievement. Absence of equitable and inclusive principles can hinder
the formation of common ground, which in turn negatively impacts the overall
performance of the system. For example, misusing pronouns in a user interaction
may cause ambiguity about the intended subject. Yet, there is no comprehensive
study of equitable text generation in dialogue. Aptly, in this work, we use
theories of computational learning to study this problem. We provide formal
definitions of equity in text generation, and further, prove formal connections
between learning human-likeness and learning equity: algorithms for improving
equity ultimately reduce to algorithms for improving human-likeness (on
augmented data). With this insight, we also formulate reasonable conditions
under which text generation algorithms can learn to generate equitable text
without any modifications to the biased training data on which they learn. To
exemplify our theory in practice, we look at a group of algorithms for the
GuessWhat?! visual dialogue game and, using this example, test our theory
empirically. Our theory accurately predicts relative-performance of multiple
algorithms in generating equitable text as measured by both human and automated
evaluation.",2023-07-10
Designing Mixed-Initiative Video Games,2023-07-08 01:45:25+00:00,http://arxiv.org/abs/2307.03877v1,Daijin Yang,"cs.HC, cs.AI, J.5",games,"The development of Artificial Intelligence (AI) enables humans to co-create
content with machines. The unexpectedness of AI-generated content can bring
inspiration and entertainment to users. However, the co-creation interactions
are always designed for content creators and have poor accessibility. To
explore gamification of mixed-initiative co-creation and make human-AI
interactions accessible and fun for players, I prototyped Snake Story, a
mixed-initiative game where players can select AI-generated texts to write a
story of a snake by playing a ""Snake"" like game. A controlled experiment was
conducted to investigate the dynamics of player-AI interactions with and
without the game component in the designed interface. As a result of a study
with 11 players (n=11), I found that players utilized different strategies when
playing with the two versions, game mechanics significantly affected the output
stories, players' creative process, as well as role perceptions, and players
with different backgrounds showed different preferences for the two versions.
Based on these results, I further discussed considerations for mixed-initiative
game design. This work aims to inspire the design of engaging co-creation
experiences.",2023-07-08
"Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement
  Learning",2023-07-05 19:48:03+00:00,http://arxiv.org/abs/2307.02620v1,"Colin Bellinger, Mark Crowley, Isaac Tamblyn","cs.LG, cs.AI, 68T01, I.2.0",games,"Reinforcement learning (RL) has been shown to learn sophisticated control
policies for complex tasks including games, robotics, heating and cooling
systems and text generation. The action-perception cycle in RL, however,
generally assumes that a measurement of the state of the environment is
available at each time step without a cost. In applications such as deep-sea
and planetary robot exploration, materials design and medicine, however, there
can be a high cost associated with measuring, or even approximating, the state
of the environment. In this paper, we survey the recently growing literature
that adopts the perspective that an RL agent might not need, or even want, a
costly measurement at each time step. Within this context, we propose the Deep
Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the
literature and empirically evaluate it on OpenAI gym and Atari Pong
environments. Our results, show that DMSOA learns a better policy with fewer
decision steps and measurements than the considered alternative from the
literature.",2023-07-05
Joint Level Generation and Translation Using Gameplay Videos,2023-06-29 03:46:44+00:00,http://arxiv.org/abs/2306.16662v1,"Negar Mirgati, Matthew Guzdial","cs.CV, cs.LG",games,"Procedural Content Generation via Machine Learning (PCGML) faces a
significant hurdle that sets it apart from other fields, such as image or text
generation, which is limited annotated data. Many existing methods for
procedural level generation via machine learning require a secondary
representation besides level images. However, the current methods for obtaining
such representations are laborious and time-consuming, which contributes to
this problem. In this work, we aim to address this problem by utilizing
gameplay videos of two human-annotated games to develop a novel multi-tail
framework that learns to perform simultaneous level translation and generation.
The translation tail of our framework can convert gameplay video frames to an
equivalent secondary representation, while its generation tail can produce
novel level segments. Evaluation results and comparisons between our framework
and baselines suggest that combining the level generation and translation tasks
can lead to an overall improved performance regarding both tasks. This
represents a possible solution to limited annotated level data, and we
demonstrate the potential for future versions to generalize to unseen games.",2023-06-29
"ByteSized32: A Corpus and Challenge Task for Generating Task-Specific
  World Models Expressed as Text Games",2023-05-24 08:31:30+00:00,http://arxiv.org/abs/2305.14879v1,"Ruoyao Wang, Graham Todd, Eric Yuan, Ziang Xiao, Marc-Alexandre Côté, Peter Jansen","cs.CL, cs.AI",games,"In this work we examine the ability of language models to generate explicit
world models of scientific and common-sense reasoning tasks by framing this as
a problem of generating text-based games. To support this, we introduce
ByteSized32, a corpus of 32 highly-templated text games written in Python
totaling 24k lines of code, each centered around a particular task, and paired
with a set of 16 unseen text game specifications for evaluation. We propose a
suite of automatic and manual metrics for assessing simulation validity,
compliance with task specifications, playability, winnability, and alignment
with the physical world. In a single-shot evaluation of GPT-4 on this
simulation-as-code-generation task, we find it capable of producing runnable
games in 27% of cases, highlighting the difficulty of this challenge task. We
discuss areas of future improvement, including GPT-4's apparent capacity to
perform well at simulating near canonical task solutions, with performance
dropping off as simulations include distractors or deviate from canonical
solutions in the action space.",2023-05-24
"FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured
  Game State Information",2023-05-02 15:36:10+00:00,http://arxiv.org/abs/2305.01528v1,"Andrew Zhu, Karmanya Aggarwal, Alexander Feng, Lara J. Martin, Chris Callison-Burch","cs.CL, cs.AI",games,"Dungeons & Dragons (D&D) is a tabletop roleplaying game with complex natural
language interactions between players and hidden state information. Recent work
has shown that large language models (LLMs) that have access to state
information can generate higher quality game turns than LLMs that use dialog
history alone. However, previous work used game state information that was
heuristically created and was not a true gold standard game state. We present
FIREBALL, a large dataset containing nearly 25,000 unique sessions from real
D\&D gameplay on Discord with true game state info. We recorded game play
sessions of players who used the Avrae bot, which was developed to aid people
in playing D&D online, capturing language, game commands and underlying game
state information. We demonstrate that FIREBALL can improve natural language
generation (NLG) by using Avrae state information, improving both automated
metrics and human judgments of quality. Additionally, we show that LLMs can
generate executable Avrae commands, particularly after finetuning.",2023-05-02
On pitfalls (and advantages) of sophisticated large language models,2023-02-25 11:14:39+00:00,http://arxiv.org/abs/2303.17511v1,Anna Strasser,"cs.CY, cs.AI, cs.CL",games,"Natural language processing based on large language models (LLMs) is a
booming field of AI research. After neural networks have proven to outperform
humans in games and practical domains based on pattern recognition, we might
stand now at a road junction where artificial entities might eventually enter
the realm of human communication. However, this comes with serious risks. Due
to the inherent limitations regarding the reliability of neural networks,
overreliance on LLMs can have disruptive consequences. Since it will be
increasingly difficult to distinguish between human-written and
machine-generated text, one is confronted with new ethical challenges. This
begins with the no longer undoubtedly verifiable human authorship and continues
with various types of fraud, such as a new form of plagiarism. This also
concerns the violation of privacy rights, the possibility of circulating
counterfeits of humans, and, last but not least, it makes a massive spread of
misinformation possible.",2023-02-25
"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based
  Learning",2023-02-08 02:45:21+00:00,http://arxiv.org/abs/2302.03848v1,"Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker",cs.CL,games,"Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.",2023-02-08
"On Realization of Intelligent Decision-Making in the Real World: A
  Foundation Decision Model Perspective",2022-12-24 06:16:45+00:00,http://arxiv.org/abs/2212.12669v1,"Ying Wen, Ziyu Wan, Ming Zhou, Shufang Hou, Zhe Cao, Chenyang Le, Jingxiao Chen, Zheng Tian, Weinan Zhang, Jun Wang","cs.AI, cs.LG",games,"Our situated environment is full of uncertainty and highly dynamic, thus
hindering the widespread adoption of machine-led Intelligent Decision-Making
(IDM) in real world scenarios. This means IDM should have the capability of
continuously learning new skills and efficiently generalizing across wider
applications. IDM benefits from any new approaches and theoretical
breakthroughs that exhibit Artificial General Intelligence (AGI) breaking the
barriers between tasks and applications. Recent research has well-examined
neural architecture, Transformer, as a backbone foundation model and its
generalization to various tasks, including computer vision, natural language
processing, and reinforcement learning. We therefore argue that a foundation
decision model (FDM) can be established by formulating various decision-making
tasks as a sequence decoding task using the Transformer architecture; this
would be a promising solution to advance the applications of IDM in more
complex real world tasks. In this paper, we elaborate on how a foundation
decision model improves the efficiency and generalization of IDM. We also
discuss potential applications of a FDM in multi-agent game AI, production
scheduling, and robotics tasks. Finally, through a case study, we demonstrate
our realization of the FDM, DigitalBrain (DB1) with 1.2 billion parameters,
which achieves human-level performance over 453 tasks, including text
generation, images caption, video games playing, robotic control, and traveling
salesman problems. As a foundation decision model, DB1 would be a baby step
towards more autonomous and efficient real world IDM applications.",2022-12-24
"Synthesis and Evaluation of a Domain-specific Large Data Set for
  Dungeons & Dragons",2022-12-18 12:54:45+00:00,http://arxiv.org/abs/2212.09080v1,"Akila Peiris, Nisansa de Silva","cs.CL, cs.LG",games,"This paper introduces the Forgotten Realms Wiki (FRW) data set and domain
specific natural language generation using FRW along with related analyses.
Forgotten Realms is the de-facto default setting of the popular open ended
tabletop fantasy role playing game, Dungeons & Dragons. The data set was
extracted from the Forgotten Realms Fandom wiki consisting of more than over
45,200 articles. The FRW data set is constituted of 11 sub-data sets in a
number of formats: raw plain text, plain text annotated by article title,
directed link graphs, wiki info-boxes annotated by the wiki article title,
Poincar\'e embedding of first link graph, multiple Word2Vec and Doc2Vec models
of the corpus. This is the first data set of this size for the Dungeons &
Dragons domain. We then present a pairwise similarity comparison benchmark
which utilizes similarity measures. In addition, we perform D&D domain specific
natural language generation using the corpus and evaluate the named entity
classification with respect to the lore of Forgotten Realms.",2022-12-18
Reward Gaming in Conditional Text Generation,2022-11-16 07:10:02+00:00,http://arxiv.org/abs/2211.08714v1,"Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P. Parikh, He He","cs.CL, cs.AI, cs.LG",games,"To align conditional text generation model outputs with desired behaviors,
there has been an increasing focus on training the model using reinforcement
learning (RL) with reward functions learned from human annotations. Under this
framework, we identify three common cases where high rewards are incorrectly
assigned to undesirable patterns: noise-induced spurious correlation, naturally
occurring spurious correlation, and covariate shift. We show that even though
learned metrics achieve high performance on the distribution of the data used
to train the reward function, the undesirable patterns may be amplified during
RL training of the text generation model. While there has been discussion about
reward gaming in the RL or safety community, in this short discussion piece, we
would like to highlight reward gaming in the NLG community using concrete
conditional text generation examples and discuss potential fixes and areas for
future work.",2022-11-16
CLSE: Corpus of Linguistically Significant Entities,2022-11-04 12:56:12+00:00,http://arxiv.org/abs/2211.02423v1,"Aleksandr Chuklin, Justin Zhao, Mihir Kale",cs.CL,games,"One of the biggest challenges of natural language generation (NLG) is the
proper handling of named entities. Named entities are a common source of
grammar mistakes such as wrong prepositions, wrong article handling, or
incorrect entity inflection. Without factoring linguistic representation, such
errors are often underrepresented when evaluating on a small set of arbitrarily
picked argument values, or when translating a dataset from a linguistically
simpler language, like English, to a linguistically complex language, like
Russian. However, for some applications, broadly precise grammatical
correctness is critical -- native speakers may find entity-related grammar
errors silly, jarring, or even offensive.
  To enable the creation of more linguistically diverse NLG datasets, we
release a Corpus of Linguistically Significant Entities (CLSE) annotated by
linguist experts. The corpus includes 34 languages and covers 74 different
semantic types to support various applications from airline ticketing to video
games. To demonstrate one possible use of CLSE, we produce an augmented version
of the Schema-Guided Dialog Dataset, SGD-CLSE. Using the CLSE's entities and a
small number of human translations, we create a linguistically representative
NLG evaluation benchmark in three languages: French (high-resource), Marathi
(low-resource), and Russian (highly inflected language). We establish quality
baselines for neural, template-based, and hybrid NLG systems and discuss the
strengths and weaknesses of each approach.",2022-11-04
"Are Current Decoding Strategies Capable of Facing the Challenges of
  Visual Dialogue?",2022-10-24 07:34:39+00:00,http://arxiv.org/abs/2210.12997v1,"Amit Kumar Chaudhary, Alex J. Lucassen, Ioanna Tsani, Alberto Testoni","cs.CL, cs.CV",games,"Decoding strategies play a crucial role in natural language generation
systems. They are usually designed and evaluated in open-ended text-only tasks,
and it is not clear how different strategies handle the numerous challenges
that goal-oriented multimodal systems face (such as grounding and
informativeness). To answer this question, we compare a wide variety of
different decoding strategies and hyper-parameter configurations in a Visual
Dialogue referential game. Although none of them successfully balance lexical
richness, accuracy in the task, and visual grounding, our in-depth analysis
allows us to highlight the strengths and weaknesses of each decoding strategy.
We believe our findings and suggestions may serve as a starting point for
designing more effective decoding algorithms that handle the challenges of
Visual Dialogue tasks.",2022-10-24
"Towards Pragmatic Production Strategies for Natural Language Generation
  Tasks",2022-10-23 19:30:42+00:00,http://arxiv.org/abs/2210.12828v1,Mario Giulianelli,"cs.CL, cs.AI",games,"This position paper proposes a conceptual framework for the design of Natural
Language Generation (NLG) systems that follow efficient and effective
production strategies in order to achieve complex communicative goals. In this
general framework, efficiency is characterised as the parsimonious regulation
of production and comprehension costs while effectiveness is measured with
respect to task-oriented and contextually grounded communicative goals. We
provide concrete suggestions for the estimation of goals, costs, and utility
via modern statistical methods, demonstrating applications of our framework to
the classic pragmatic task of visually grounded referential games and to
abstractive text summarisation, two popular generation tasks with real-world
applications. In sum, we advocate for the development of NLG systems that learn
to make pragmatic production decisions from experience, by reasoning about
goals, costs, and utility in a human-like way.",2022-10-23
"LEATHER: A Framework for Learning to Generate Human-like Text in
  Dialogue",2022-10-14 13:05:11+00:00,http://arxiv.org/abs/2210.07777v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.LG",games,"Algorithms for text-generation in dialogue can be misguided. For example, in
task-oriented settings, reinforcement learning that optimizes only task-success
can lead to abysmal lexical diversity. We hypothesize this is due to poor
theoretical understanding of the objectives in text-generation and their
relation to the learning process (i.e., model training). To this end, we
propose a new theoretical framework for learning to generate text in dialogue.
Compared to existing theories of learning, our framework allows for analysis of
the multi-faceted goals inherent to text-generation. We use our framework to
develop theoretical guarantees for learners that adapt to unseen data. As an
example, we apply our theory to study data-shift within a cooperative learning
algorithm proposed for the GuessWhat?! visual dialogue game. From this insight,
we propose a new algorithm, and empirically, we demonstrate our proposal
improves both task-success and human-likeness of the generated text. Finally,
we show statistics from our theory are empirically predictive of multiple
qualities of the generated dialogue, suggesting our theory is useful for
model-selection when human evaluations are not available.",2022-10-14
Using Large Language Models to Simulate Multiple Humans,2022-08-18 17:54:49+00:00,http://arxiv.org/abs/2208.10264v3,"Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai","cs.CL, cs.AI, cs.LG",games,"We propose a method for using a large language model, such as GPT-3, to
simulate responses of different humans in a given context. We test our method
by attempting to reproduce well-established economic, psycholinguistic, and
social experiments. The method requires prompt templates for each experiment.
Simulations are run by varying the (hypothetical) subject details, such as
name, and analyzing the text generated by the language model. To validate our
methodology, we use GPT-3 to simulate the Ultimatum Game, garden path
sentences, risk aversion, and the Milgram Shock experiments. In order to
address concerns of exposure to these studies in training data, we also
evaluate simulations on novel variants of these studies. We show that it is
possible to simulate responses of different people and that their responses are
largely consistent with prior human studies from the literature. Using large
language models as simulators offers advantages but also poses risks. Our use
of a language model for simulation is contrasted with anthropomorphic views of
a language model as having its own behavior.",2022-08-18
Mimetic Models: Ethical Implications of AI that Acts Like You,2022-07-19 16:41:36+00:00,http://arxiv.org/abs/2207.09394v1,"Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Solon Barocas, Ashton Anderson","cs.AI, cs.CY",games,"An emerging theme in artificial intelligence research is the creation of
models to simulate the decisions and behavior of specific people, in domains
including game-playing, text generation, and artistic expression. These models
go beyond earlier approaches in the way they are tailored to individuals, and
the way they are designed for interaction rather than simply the reproduction
of fixed, pre-computed behaviors. We refer to these as mimetic models, and in
this paper we develop a framework for characterizing the ethical and social
issues raised by their growing availability. Our framework includes a number of
distinct scenarios for the use of such models, and considers the impacts on a
range of different participants, including the target being modeled, the
operator who deploys the model, and the entities that interact with it.",2022-07-19
Word Play for Playing Othello (Reverses),2022-07-18 17:13:32+00:00,http://arxiv.org/abs/2207.08766v1,"Samantha E. Miller Noever, David Noever",cs.LG,games,"Language models like OpenAI's Generative Pre-Trained Transformers (GPT-2/3)
capture the long-term correlations needed to generate text in a variety of
domains (such as language translators) and recently in gameplay (chess, Go, and
checkers). The present research applies both the larger (GPT-3) and smaller
(GPT-2) language models to explore the complex strategies for the game of
Othello (or Reverses). Given the game rules for rapid reversals of fortune, the
language model not only represents a candidate predictor of the next move based
on previous game moves but also avoids sparse rewards in gameplay. The language
model automatically captures or emulates championship-level strategies. The
fine-tuned GPT-2 model generates Othello games ranging from 13-71% completion,
while the larger GPT-3 model reaches 41% of a complete game. Like previous work
with chess and Go, these language models offer a novel way to generate
plausible game archives, particularly for comparing opening moves across a
larger sample than humanly possible to explore. A primary contribution of these
models magnifies (by two-fold) the previous record for player archives (120,000
human games over 45 years from 1977-2022), thus supplying the research
community with more diverse and original strategies for sampling with other
reinforcement learning techniques.",2022-07-18
Immersive Text Game and Personality Classification,2022-03-20 18:37:03+00:00,http://arxiv.org/abs/2203.10621v1,"Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi","cs.CL, cs.AI, cs.LG",games,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",2022-03-20
"Dynamic population-based meta-learning for multi-agent communication
  with natural language",2021-10-27 07:50:02+00:00,http://arxiv.org/abs/2110.14241v1,"Abhinav Gupta, Marc Lanctot, Angeliki Lazaridou","cs.LG, cs.AI, cs.CL, cs.MA",games,"In this work, our goal is to train agents that can coordinate with seen,
unseen as well as human partners in a multi-agent communication environment
involving natural language. Previous work using a single set of agents has
shown great progress in generalizing to known partners, however it struggles
when coordinating with unfamiliar agents. To mitigate that, recent work
explored the use of population-based approaches, where multiple agents interact
with each other with the goal of learning more generic protocols. These
methods, while able to result in good coordination between unseen partners,
still only achieve so in cases of simple languages, thus failing to adapt to
human partners using natural language. We attribute this to the use of static
populations and instead propose a dynamic population-based meta-learning
approach that builds such a population in an iterative manner. We perform a
holistic evaluation of our method on two different referential games, and show
that our agents outperform all prior work when communicating with seen partners
and humans. Furthermore, we analyze the natural language generation skills of
our agents, where we find that our agents also outperform strong baselines.
Finally, we test the robustness of our agents when communicating with
out-of-population agents and carefully test the importance of each component of
our method through ablation studies.",2021-10-27
Hurdles to Progress in Long-form Question Answering,2021-03-10 20:32:30+00:00,http://arxiv.org/abs/2103.06332v1,"Kalpesh Krishna, Aurko Roy, Mohit Iyyer","cs.CL, cs.LG",games,"The task of long-form question answering (LFQA) involves retrieving documents
relevant to a given question and using them to generate a paragraph-length
answer. While many models have recently been proposed for LFQA, we show in this
paper that the task formulation raises fundamental challenges regarding
evaluation and dataset creation that currently preclude meaningful modeling
progress. To demonstrate these challenges, we first design a new system that
relies on sparse attention and contrastive retriever learning to achieve
state-of-the-art performance on the ELI5 LFQA dataset. While our system tops
the public leaderboard, a detailed analysis reveals several troubling trends:
(1) our system's generated answers are not actually grounded in the documents
that it retrieves; (2) ELI5 contains significant train / test overlap, as at
least 81% of ELI5 validation questions occur in paraphrased form in the
training set; (3) ROUGE-L is not an informative metric of generated answer
quality and can be easily gamed; and (4) human evaluations used for other text
generation tasks are unreliable for LFQA. We provide suggestions to mitigate
each of these issues, which we hope will lead to more rigorous LFQA research
and meaningful progress in the future.",2021-03-10
Deep Learning for General Game Playing with Ludii and Polygames,2021-01-23 19:08:33+00:00,http://arxiv.org/abs/2101.09562v1,"Dennis J. N. J. Soemers, Vegard Mella, Cameron Browne, Olivier Teytaud",cs.AI,games,"Combinations of Monte-Carlo tree search and Deep Neural Networks, trained
through self-play, have produced state-of-the-art results for automated
game-playing in many board games. The training and search algorithms are not
game-specific, but every individual game that these approaches are applied to
still requires domain knowledge for the implementation of the game's rules, and
constructing the neural network's architecture -- in particular the shapes of
its input and output tensors. Ludii is a general game system that already
contains over 500 different games, which can rapidly grow thanks to its
powerful and user-friendly game description language. Polygames is a framework
with training and search algorithms, which has already produced superhuman
players for several board games. This paper describes the implementation of a
bridge between Ludii and Polygames, which enables Polygames to train and
evaluate models for games that are implemented and run through Ludii. We do not
require any game-specific domain knowledge anymore, and instead leverage our
domain knowledge of the Ludii system and its abstract state and move
representations to write functions that can automatically determine the
appropriate shapes for input and output tensors for any game implemented in
Ludii. We describe experimental results for short training runs in a wide
variety of different board games, and discuss several open problems and avenues
for future research.",2021-01-23
Ludii Game Logic Guide,2021-01-06 16:22:37+00:00,http://arxiv.org/abs/2101.02120v1,"Eric Piette, Cameron Browne, Dennis J. N. J. Soemers",cs.AI,games,"This technical report outlines the fundamental workings of the game logic
behind Ludii, a general game system, that can be used to play a wide variety of
games. Ludii is a program developed for the ERC-funded Digital Ludeme Project,
in which mathematical and computational approaches are used to study how games
were played, and spread, throughout history. This report explains how general
game states and equipment are represented in Ludii, and how the rule ludemes
dictating play are implemented behind the scenes, giving some insight into the
core game logic behind the Ludii general game player. This guide is intended to
help game designers using the Ludii game description language to understand it
more completely and make fuller use of its features when describing their
games.",2021-01-06
DORB: Dynamically Optimizing Multiple Rewards with Bandits,2020-11-15 21:57:47+00:00,http://arxiv.org/abs/2011.07635v1,"Ramakanth Pasunuru, Han Guo, Mohit Bansal","cs.CL, cs.AI, cs.LG",games,"Policy gradients-based reinforcement learning has proven to be a promising
approach for directly optimizing non-differentiable evaluation metrics for
language generation tasks. However, optimizing for a specific metric reward
leads to improvements in mostly that metric only, suggesting that the model is
gaming the formulation of that metric in a particular way without often
achieving real qualitative improvements. Hence, it is more beneficial to make
the model optimize multiple diverse metric rewards jointly. While appealing,
this is challenging because one needs to manually decide the importance and
scaling weights of these metric rewards. Further, it is important to consider
using a dynamic combination and curriculum of metric rewards that flexibly
changes over time. Considering the above aspects, in our work, we automate the
optimization of multiple metric rewards simultaneously via a multi-armed bandit
approach (DORB), where at each round, the bandit chooses which metric reward to
optimize next, based on expected arm gains. We use the Exp3 algorithm for
bandits and formulate two approaches for bandit rewards: (1) Single
Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit
(HM-Bandit). We empirically show the effectiveness of our approaches via
various automatic metrics and human evaluation on two important NLG tasks:
question generation and data-to-text generation, including on an unseen-test
transfer setup. Finally, we present interpretable analyses of the learned
bandit curriculum over the optimized rewards.",2020-11-15
Learning Better Representation for Tables by Self-Supervised Tasks,2020-10-15 09:03:38+00:00,http://arxiv.org/abs/2010.07606v1,"Liang Li, Can Ma, Yinliang Yue, Linjun Shou, Dayong Hu",cs.CL,games,"Table-to-text generation aims at automatically generating natural text to
help people to conveniently obtain the important information in tables.
Although neural models for table-to-text have achieved remarkable progress,
some problems still overlooked. The first is that the values recorded in many
tables are mostly numbers in practice. The existing approaches do not do
special treatment for these, and still regard these as words in natural
language text. Secondly, the target texts in training dataset may contain
redundant information or facts do not exist in the input tables. These may give
wrong supervision signals to some methods based on content selection and
planning and auxiliary supervision. To solve these problems, we propose two
self-supervised tasks, Number Ordering and Significance Ordering, to help to
learn better table representation. The former works on the column dimension to
help to incorporate the size property of numbers into table representation. The
latter acts on row dimension and help to learn a significance-aware table
representation. We test our methods on the widely used dataset ROTOWIRE which
consists of NBA game statistic and related news. The experimental results
demonstrate that the model trained together with these two self-supervised
tasks can generate text that contains more salient and well-organized facts,
even without modeling context selection and planning. And we achieve the
state-of-the-art performance on automatic metrics.",2020-10-15
"Discovering Textual Structures: Generative Grammar Induction using
  Template Trees",2020-09-09 19:31:04+00:00,http://arxiv.org/abs/2009.04530v1,"Thomas Winters, Luc De Raedt","cs.CL, cs.AI, 68T50, I.2.7; I.2.6",games,"Natural language generation provides designers with methods for automatically
generating text, e.g. for creating summaries, chatbots and game content. In
practise, text generators are often either learned and hard to interpret, or
created by hand using techniques such as grammars and templates. In this paper,
we introduce a novel grammar induction algorithm for learning interpretable
grammars for generative purposes, called Gitta. We also introduce the novel
notion of template trees to discover latent templates in corpora to derive
these generative grammars. By using existing human-created grammars, we found
that the algorithm can reasonably approximate these grammars using only a few
examples. These results indicate that Gitta could be used to automatically
learn interpretable and easily modifiable grammars, and thus provide a stepping
stone for human-machine co-creation of generative models.",2020-09-09
Navigating Human Language Models with Synthetic Agents,2020-08-10 14:39:53+00:00,http://arxiv.org/abs/2008.04162v7,"Philip Feldman, Antonio Bucchiarone","cs.AI, cs.CL, cs.MA, I.2; I.6; J.4",games,"Modern natural language models such as the GPT-2/GPT-3 contain tremendous
amounts of information about human belief in a consistently testable form. If
these models could be shown to accurately reflect the underlying beliefs of the
human beings that produced the data used to train these models, then such
models become a powerful sociological tool in ways that are distinct from
traditional methods, such as interviews and surveys. In this study, We train a
version of the GPT-2 on a corpora of historical chess games, and then ""launch""
clusters of synthetic agents into the model, using text strings to create
context and orientation. We compare the trajectories contained in the text
generated by the agents/model and compare that to the known ground truth of the
chess board, move legality, and historical patterns of play. We find that the
percentages of moves by piece using the model are substantially similar from
human patterns. We further find that the model creates an accurate latent
representation of the chessboard, and that it is possible to plot trajectories
of legal moves across the board using this knowledge.",2020-08-10
The Go Transformer: Natural Language Modeling for Game Play,2020-07-07 14:37:27+00:00,http://arxiv.org/abs/2007.03500v3,"Matthew Ciolino, David Noever, Josh Kalin","cs.CL, cs.LG",games,"This work applies natural language modeling to generate plausible strategic
moves in the ancient game of Go. We train the Generative Pretrained Transformer
(GPT-2) to mimic the style of Go champions as archived in Smart Game Format
(SGF), which offers a text description of move sequences. The trained model
further generates valid but previously unseen strategies for Go. Because GPT-2
preserves punctuation and spacing, the raw output of the text generator
provides inputs to game visualization and creative patterns, such as the Sabaki
project's game engine using auto-replays. Results demonstrate that language
modeling can capture both the sequencing format of championship Go games and
their strategic formations. Compared to random game boards, the GPT-2
fine-tuning shows efficient opening move sequences favoring corner play over
less advantageous center and side play. Game generation as a language modeling
task offers novel approaches to more than 40 other board games where historical
text annotation provides training data (e.g., Amazons & Connect 4/6).",2020-07-07
Shared Task on Evaluating Accuracy in Natural Language Generation,2020-06-22 13:30:35+00:00,http://arxiv.org/abs/2006.12234v2,"Ehud Reiter, Craig Thomson",cs.CL,games,"We propose a shared task on methodologies and algorithms for evaluating the
accuracy of generated texts. Participants will measure the accuracy of
basketball game summaries produced by NLG systems from basketball box score
data.",2020-06-22
"Graph Constrained Reinforcement Learning for Natural Language Action
  Spaces",2020-01-23 22:33:18+00:00,http://arxiv.org/abs/2001.08837v1,"Prithviraj Ammanabrolu, Matthew Hausknecht","cs.LG, cs.AI, cs.CL, stat.ML",games,"Interactive Fiction games are text-based simulations in which an agent
interacts with the world purely through natural language. They are ideal
environments for studying how to extend reinforcement learning agents to meet
the challenges of natural language understanding, partial observability, and
action generation in combinatorially-large text-based action spaces. We present
KG-A2C, an agent that builds a dynamic knowledge graph while exploring and
generates actions using a template-based action space. We contend that the dual
uses of the knowledge graph to reason about game state and to constrain natural
language generation are the keys to scalable exploration of combinatorially
large natural language actions. Results across a wide variety of IF games show
that KG-A2C outperforms current IF agents despite the exponential increase in
action space size.",2020-01-23
Revisiting Challenges in Data-to-Text Generation with Fact Grounding,2020-01-12 02:31:07+00:00,http://arxiv.org/abs/2001.03830v1,Hongmin Wang,cs.CL,games,"Data-to-text generation models face challenges in ensuring data fidelity by
referring to the correct input source. To inspire studies in this area, Wiseman
et al. (2017) introduced the RotoWire corpus on generating NBA game summaries
from the box- and line-score tables. However, limited attempts have been made
in this direction and the challenges remain. We observe a prominent bottleneck
in the corpus where only about 60% of the summary contents can be grounded to
the boxscore records. Such information deficiency tends to misguide a
conditioned language model to produce unconditioned random facts and thus leads
to factual hallucinations. In this work, we restore the information balance and
revamp this task to focus on fact-grounded data-to-text generation. We
introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),
with 50% more data from the year 2017-19 and enriched input tables, hoping to
attract more research focuses in this direction. Moreover, we achieve improved
data fidelity over the state-of-the-art models by integrating a new form of
table reconstruction as an auxiliary task to boost the generation quality.",2020-01-12
"ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain
  Conversation",2019-10-26 20:18:59+00:00,http://arxiv.org/abs/1910.12129v1,"Juraj Juraska, Kevin K. Bowden, Marilyn Walker",cs.CL,games,"The uptake of deep learning in natural language generation (NLG) led to the
release of both small and relatively large parallel corpora for training neural
models. The existing data-to-text datasets are, however, aimed at task-oriented
dialogue systems, and often thus limited in diversity and versatility. They are
typically crowdsourced, with much of the noise left in them. Moreover, current
neural NLG models do not take full advantage of large training data, and due to
their strong generalizing properties produce sentences that look template-like
regardless. We therefore present a new corpus of 7K samples, which (1) is clean
despite being crowdsourced, (2) has utterances of 9 generalizable and
conversational dialogue act types, making it more suitable for open-domain
dialogue systems, and (3) explores the domain of video games, which is new to
dialogue systems despite having excellent potential for supporting rich
conversations.",2019-10-26
"Table-to-Text Generation with Effective Hierarchical Encoder on Three
  Dimensions (Row, Column and Time)",2019-09-05 10:25:34+00:00,http://arxiv.org/abs/1909.02304v1,"Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu",cs.CL,games,"Although Seq2Seq models for table-to-text generation have achieved remarkable
progress, modeling table representation in one dimension is inadequate. This is
because (1) the table consists of multiple rows and columns, which means that
encoding a table should not depend only on one dimensional sequence or set of
records and (2) most of the tables are time series data (e.g. NBA game data,
stock market data), which means that the description of the current table may
be affected by its historical data. To address aforementioned problems, not
only do we model each table cell considering other records in the same row, we
also enrich table's representation by modeling each table cell in context of
other cells in the same column or with historical (time dimension) data
respectively. In addition, we develop a table cell fusion gate to combine
representations from row, column and time dimension into one dense vector
according to the saliency of each dimension's representation. We evaluated our
methods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both
automatic and human evaluation results demonstrate the effectiveness of our
model with improvement of 2.66 in BLEU over the strong baseline and
outperformance of state-of-the-art model.",2019-09-05
Generating Question-Answer Hierarchies,2019-06-06 14:53:04+00:00,http://arxiv.org/abs/1906.02622v2,"Kalpesh Krishna, Mohit Iyyer",cs.CL,games,"The process of knowledge acquisition can be viewed as a question-answer game
between a student and a teacher in which the student typically starts by asking
broad, open-ended questions before drilling down into specifics (Hintikka,
1981; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a
new way of representing documents. In this paper, we present SQUASH
(Specificity-controlled Question-Answer Hierarchies), a novel and challenging
text generation task that converts an input document into a hierarchy of
question-answer pairs. Users can click on high-level questions (e.g., ""Why did
Frodo leave the Fellowship?"") to reveal related but more specific questions
(e.g., ""Who did Frodo leave with?""). Using a question taxonomy loosely based on
Lehnert (1978), we classify questions in existing reading comprehension
datasets as either ""general"" or ""specific"". We then use these labels as input
to a pipelined system centered around a conditional neural language model. We
extensively evaluate the quality of the generated QA hierarchies through
crowdsourced experiments and report strong empirical results.",2019-06-06
Pragmatically Informative Text Generation,2019-04-02 09:04:57+00:00,http://arxiv.org/abs/1904.01301v2,"Sheng Shen, Daniel Fried, Jacob Andreas, Dan Klein",cs.CL,games,"We improve the informativeness of models for conditional text generation
using techniques from computational pragmatics. These techniques formulate
language production as a game between speakers and listeners, in which a
speaker should generate output text that a listener can use to correctly
identify the original input that the text describes. While such approaches are
widely used in cognitive science and grounded language learning, they have
received less attention for more standard language generation tasks. We
consider two pragmatic modeling methods for text generation: one where
pragmatics is imposed by information preservation, and another where pragmatics
is imposed by explicit modeling of distractors. We find that these methods
improve the performance of strong existing systems for abstractive
summarization and generation from structured meaning representations.",2019-04-02
Automating Direct Speech Variations in Stories and Games,2017-08-30 02:19:39+00:00,http://arxiv.org/abs/1708.09090v1,"Stephanie M. Lukin, James O. Ryan, Marilyn A. Walker",cs.CL,games,"Dialogue authoring in large games requires not only content creation but the
subtlety of its delivery, which can vary from character to character. Manually
authoring this dialogue can be tedious, time-consuming, or even altogether
infeasible. This paper utilizes a rich narrative representation for modeling
dialogue and an expressive natural language generation engine for realizing it,
and expands upon a translation tool that bridges the two. We add functionality
to the translator to allow direct speech to be modeled by the narrative
representation, whereas the original translator supports only narratives told
by a third person narrator. We show that we can perform character substitution
in dialogues. We implement and evaluate a potential application to dialogue
implementation: generating dialogue for games with big, dynamic, or
procedurally-generated open worlds. We present a pilot study on human
perceptions of the personalities of characters using direct speech, assuming
unknown personality types at the time of authoring.",2017-08-30
Deep Reinforcement Learning: An Overview,2017-01-25 11:52:11+00:00,http://arxiv.org/abs/1701.07274v6,Yuxi Li,cs.LG,games,"We give an overview of recent exciting achievements of deep reinforcement
learning (RL). We discuss six core elements, six important mechanisms, and
twelve applications. We start with background of machine learning, deep
learning and reinforcement learning. Next we discuss core RL elements,
including value function, in particular, Deep Q-Network (DQN), policy, reward,
model, planning, and exploration. After that, we discuss important mechanisms
for RL, including attention and memory, unsupervised learning, transfer
learning, multi-agent RL, hierarchical RL, and learning to learn. Then we
discuss various applications of RL, including games, in particular, AlphaGo,
robotics, natural language processing, including dialogue systems, machine
translation, and text generation, computer vision, neural architecture design,
business management, finance, healthcare, Industry 4.0, smart grid, intelligent
transportation systems, and computer systems. We mention topics not reviewed
yet, and list a collection of RL resources. After presenting a brief summary,
we close with discussions.
  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant
update.",2017-01-25
