title,pubdate,id,authors,categories,search,abstract,displaydate
"Search-R1: Training LLMs to Reason and Leverage Search Engines with
  Reinforcement Learning",2025-03-12 16:26:39+00:00,http://arxiv.org/abs/2503.09516v1,"Bowen Jin, Hansi Zeng, Zhenrui Yue, Dong Wang, Hamed Zamani, Jiawei Han","cs.CL, cs.AI, cs.IR",knowledge,"Efficiently acquiring external knowledge and up-to-date information is
essential for effective reasoning and text generation in large language models
(LLMs). Retrieval augmentation and tool-use training approaches where a search
engine is treated as a tool lack complex multi-turn retrieval flexibility or
require large-scale supervised data. Prompting advanced LLMs with reasoning
capabilities during inference to use search engines is not optimal, since the
LLM does not learn how to optimally interact with the search engine. This paper
introduces Search-R1, an extension of the DeepSeek-R1 model where the LLM
learns -- solely through reinforcement learning (RL) -- to autonomously
generate (multiple) search queries during step-by-step reasoning with real-time
retrieval. Search-R1 optimizes LLM rollouts with multi-turn search
interactions, leveraging retrieved token masking for stable RL training and a
simple outcome-based reward function. Experiments on seven question-answering
datasets show that Search-R1 improves performance by 26% (Qwen2.5-7B), 21%
(Qwen2.5-3B), and 10% (LLaMA3.2-3B) over SOTA baselines. This paper further
provides empirical insights into RL optimization methods, LLM choices, and
response length dynamics in retrieval-augmented reasoning. The code and model
checkpoints are available at https://github.com/PeterGriffinJin/Search-R1.",2025-03-12
"Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual
  and Diverse Open-Ended Text Generation",2025-03-11 05:27:28+00:00,http://arxiv.org/abs/2503.08057v1,"Wen Luo, Feifan Song, Wei Li, Guangyue Peng, Shaohang Wei, Houfeng Wang",cs.CL,knowledge,"Large Language Models (LLMs) are increasingly required to generate text that
is both factually accurate and diverse across various open-ended applications.
However, current stochastic decoding methods struggle to balance such
objectives. We introduce Dynamic Focus Decoding (DFD), a novel plug-and-play
stochastic approach that resolves this trade-off without requiring additional
data, knowledge, or models. DFD adaptively adjusts the decoding focus based on
distributional differences across layers, leveraging the modular and
hierarchical nature of factual knowledge within LLMs. This dynamic adjustment
improves factuality in knowledge-intensive decoding steps and promotes
diversity in less knowledge-reliant steps. DFD can be easily integrated with
existing decoding methods, enhancing both factuality and diversity with minimal
computational overhead. Extensive experiments across seven datasets demonstrate
that DFD significantly improves performance, providing a scalable and efficient
solution for open-ended text generation.",2025-03-11
Plume: Scaffolding Text Composition in Dashboards,2025-03-10 16:32:52+00:00,http://arxiv.org/abs/2503.07512v1,"Maxim Lisnic, Vidya Setlur, Nicole Sultanum",cs.HC,knowledge,"Text in dashboards plays multiple critical roles, including providing
context, offering insights, guiding interactions, and summarizing key
information. Despite its importance, most dashboarding tools focus on
visualizations and offer limited support for text authoring. To address this
gap, we developed Plume, a system to help authors craft effective dashboard
text. Through a formative review of exemplar dashboards, we created a typology
of text parameters and articulated the relationship between visual placement
and semantic connections, which informed Plume's design. Plume employs large
language models (LLMs) to generate contextually appropriate content and
provides guidelines for writing clear, readable text. A preliminary evaluation
with 12 dashboard authors explored how assisted text authoring integrates into
workflows, revealing strengths and limitations of LLM-generated text and the
value of our human-in-the-loop approach. Our findings suggest opportunities to
improve dashboard authoring tools by better supporting the diverse roles that
text plays in conveying insights.",2025-03-10
AuthorMist: Evading AI Text Detectors with Reinforcement Learning,2025-03-10 12:41:05+00:00,http://arxiv.org/abs/2503.08716v1,"Isaac David, Arthur Gervais","cs.CR, cs.AI, cs.LG",knowledge,"In the age of powerful AI-generated text, automatic detectors have emerged to
identify machine-written content. This poses a threat to author privacy and
freedom, as text authored with AI assistance may be unfairly flagged. We
propose AuthorMist, a novel reinforcement learning-based system to transform
AI-generated text into human-like writing. AuthorMist leverages a
3-billion-parameter language model as a backbone, fine-tuned with Group
Relative Policy Optimization (GPRO) to paraphrase text in a way that evades AI
detectors.
  Our framework establishes a generic approach where external detector APIs
(GPTZero, WinstonAI, Originality.ai, etc.) serve as reward functions within the
reinforcement learning loop, enabling the model to systematically learn outputs
that these detectors are less likely to classify as AI-generated. This
API-as-reward methodology can be applied broadly to optimize text against any
detector with an accessible interface. Experiments on multiple datasets and
detectors demonstrate that AuthorMist effectively reduces the detectability of
AI-generated text while preserving the original meaning. Our evaluation shows
attack success rates ranging from 78.6% to 96.2% against individual detectors,
significantly outperforming baseline paraphrasing methods. AuthorMist maintains
high semantic similarity (above 0.94) with the original text while successfully
evading detection. These results highlight limitations in current AI text
detection technologies and raise questions about the sustainability of the
detection-evasion arms race.",2025-03-10
"Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic
  Text Rewriting",2025-03-09 21:23:52+00:00,http://arxiv.org/abs/2503.06781v1,"Yufei Li, John Nham, Ganesh Jawahar, Lei Shu, David Uthus, Yun-Hsuan Sung, Chengrun Yang, Itai Rolnick, Yi Qiao, Cong Liu","cs.CL, cs.AI, cs.LG",knowledge,"Generic text rewriting is a prevalent large language model (LLM) application
that covers diverse real-world tasks, such as style transfer, fact correction,
and email editing. These tasks vary in rewriting objectives (e.g., factual
consistency vs. semantic preservation), making it challenging to develop a
unified model that excels across all dimensions. Existing methods often
specialize in either a single task or a specific objective, limiting their
generalizability. In this work, we introduce a generic model proficient in
factuality, stylistic, and conversational rewriting tasks. To simulate
real-world user rewrite requests, we construct a conversational rewrite
dataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw
emails using LLMs. Combined with other popular rewrite datasets, including
LongFact for the factuality rewrite task and RewriteLM for the stylistic
rewrite task, this forms a broad benchmark for training and evaluating generic
rewrite models. To align with task-specific objectives, we propose Dr Genre, a
Decoupled-reward learning framework for Generic rewriting, that utilizes
objective-oriented reward models with a task-specific weighting. Evaluation
shows that \approach delivers higher-quality rewrites across all targeted
tasks, improving objectives including instruction following (agreement),
internal consistency (coherence), and minimal unnecessary edits (conciseness).",2025-03-09
"Text-Speech Language Models with Improved Cross-Modal Transfer by
  Aligning Abstraction Levels",2025-03-08 13:28:50+00:00,http://arxiv.org/abs/2503.06211v1,"Santiago Cuervo, Adel Moumen, Yanis Labrak, Sameer Khurana, Antoine Laurent, Mickael Rouvier, Ricard Marxer","cs.CL, cs.AI, eess.AS",knowledge,"Text-Speech Language Models (TSLMs) -- language models trained to jointly
process and generate text and speech -- aim to enable cross-modal knowledge
transfer to overcome the scaling limitations of unimodal speech LMs. The
predominant approach to TSLM training expands the vocabulary of a pre-trained
text LM by appending new embeddings and linear projections for speech, followed
by fine-tuning on speech data. We hypothesize that this method limits
cross-modal transfer by neglecting feature compositionality, preventing
text-learned functions from being fully leveraged at appropriate abstraction
levels. To address this, we propose augmenting vocabulary expansion with
modules that better align abstraction levels across layers. Our models,
\textsc{SmolTolk}, rival or surpass state-of-the-art TSLMs trained with orders
of magnitude more compute. Representation analyses and improved multimodal
performance suggest our method enhances cross-modal transfer.",2025-03-08
Personalized Text Generation with Contrastive Activation Steering,2025-03-07 08:07:15+00:00,http://arxiv.org/abs/2503.05213v1,"Jinghao Zhang, Yuting Liu, Wenjie Wang, Qiang Liu, Shu Wu, Liang Wang, Tat-Seng Chua",cs.CL,knowledge,"Personalized text generation aims to infer users' writing style preferences
from their historical texts and generate outputs that faithfully reflect these
stylistic characteristics. Existing solutions primarily adopt two paradigms:
retrieval-augmented generation (RAG) and parameter-efficient fine-tuning
(PEFT). While these approaches have advanced the field, they suffer from two
critical limitations: (1) the entanglement of content semantics and stylistic
patterns in historical texts impedes accurate modeling of user-specific writing
preferences; and (2) scalability challenges arising from both RAG's inference
latency by retrieval operations and PEFT's parameter storage requirements for
per user model. To overcome these limitations, we propose StyleVector, a
training-free framework that disentangles and represents personalized writing
style as a vector in LLM's activation space, enabling style-steered generation
during inference without requiring costly retrieval or parameter storage.
Comprehensive experiments demonstrate that our framework achieves a significant
8% relative improvement in personalized generation while reducing storage
requirements by 1700 times over PEFT method.",2025-03-07
"Guiding LLMs to Generate High-Fidelity and High-Quality Counterfactual
  Explanations for Text Classification",2025-03-06 14:15:07+00:00,http://arxiv.org/abs/2503.04463v1,"Van Bach Nguyen, Christin Seifert, Jörg Schlötterer",cs.CL,knowledge,"The need for interpretability in deep learning has driven interest in
counterfactual explanations, which identify minimal changes to an instance that
change a model's prediction. Current counterfactual (CF) generation methods
require task-specific fine-tuning and produce low-quality text. Large Language
Models (LLMs), though effective for high-quality text generation, struggle with
label-flipping counterfactuals (i.e., counterfactuals that change the
prediction) without fine-tuning. We introduce two simple classifier-guided
approaches to support counterfactual generation by LLMs, eliminating the need
for fine-tuning while preserving the strengths of LLMs. Despite their
simplicity, our methods outperform state-of-the-art counterfactual generation
methods and are effective across different LLMs, highlighting the benefits of
guiding counterfactual generation by LLMs with classifier information. We
further show that data augmentation by our generated CFs can improve a
classifier's robustness. Our analysis reveals a critical issue in
counterfactual generation by LLMs: LLMs rely on parametric knowledge rather
than faithfully following the classifier.",2025-03-06
"TPC: Cross-Temporal Prediction Connection for Vision-Language Model
  Hallucination Reduction",2025-03-06 14:11:00+00:00,http://arxiv.org/abs/2503.04457v1,"Chao Wang, Weiwei Fu, Yang Zhou","cs.CV, cs.AI",knowledge,"Vision-language models (VLMs) have achieved remarkable advancements,
capitalizing on the impressive capabilities of large language models (LLMs)
across diverse tasks. Despite this, a critical challenge known as hallucination
occurs when models overconfidently describe objects or attributes absent from
the image, a problem exacerbated by the tendency of VLMs to rely on linguistic
priors. This limitation reduces model reliability in high-stakes applications.
In this work, we have observed the characteristic of logits' continuity
consistency enhancement and introduced a straightforward and efficient method,
Cross-Temporal Prediction Connection (TPC), designed to enhance the semantic
consistency of logits by connecting them temporally across timesteps. TPC
amplifies information flow and improves coherence, effectively reducing
hallucination. Extensive experiments show that TPC surpasses existing
representatives, delivering superior performance in both accuracy and
efficiency while maintaining robustness in open-ended text generation tasks.",2025-03-06
"Tgea: An error-annotated dataset and benchmark tasks for text generation
  from pretrained language models",2025-03-06 09:14:02+00:00,http://arxiv.org/abs/2503.04232v1,"Jie He, Bo Peng, Yi Liao, Qun Liu, Deyi Xiong",cs.CL,knowledge,"In order to deeply understand the capability of pretrained language models in
text generation and conduct a diagnostic evaluation, we propose TGEA, an
error-annotated dataset with multiple benchmark tasks for text generation from
pretrained language models (PLMs). We use carefully selected prompt words to
guide GPT-2 to generate candidate sentences, from which we select 47K for error
annotation. Crowdsourced workers manually check each of these sentences and
detect 12k erroneous sentences. We create an error taxonomy to cover 24 types
of errors occurring in these erroneous sentences according to the nature of
errors with respect to linguistics and knowledge (eg, common sense). For each
erroneous span in PLM-generated sentences, we also detect another span that is
closely associated with it. Each error is hence manually labeled with
comprehensive annotations, including the span of the error, the associated
span, minimal correction to the error, the type of the error, and rationale
behind the error. Apart from the fully annotated dataset, we also present a
detailed description of the data collection procedure, statistics and analysis
of the dataset. This is the first dataset with comprehensive annotations for
PLM-generated texts, which facilitates the diagnostic evaluation of PLM-based
text generation. Furthermore, we use TGEA as a benchmark dataset and propose a
series of automatic diagnosis tasks, including error detection, error type
classification, associated span detection, error rationale generation, to
further promote future study on the automatic error detection and correction on
texts generated by pretrained language models.",2025-03-06
"Explanation based In-Context Demonstrations Retrieval for Multilingual
  Grammatical Error Correction",2025-02-12 15:41:43+00:00,http://arxiv.org/abs/2502.08507v1,"Wei Li, Wen Luo, Guangyue Peng, Houfeng Wang",cs.CL,knowledge,"Grammatical error correction (GEC) aims to correct grammatical, spelling, and
semantic errors in natural language text. With the growing of large language
models (LLMs), direct text generation has gradually become the focus of the GEC
methods, and few-shot in-context learning presents a cost-effective solution.
However, selecting effective in-context examples remains challenging, as the
similarity between input texts does not necessarily correspond to similar
grammatical error patterns. In this paper, we propose a novel retrieval method
based on natural language grammatical error explanations (GEE) to address this
issue. Our method retrieves suitable few-shot demonstrations by matching the
GEE of the test input with that of pre-constructed database samples, where
explanations for erroneous samples are generated by LLMs. We conducted
multilingual GEC few-shot experiments on both major open-source and
closed-source LLMs. Experiments across five languages show that our method
outperforms existing semantic and BM25-based retrieval techniques, without
requiring additional training or language adaptation. This also suggests that
matching error patterns is key to selecting examples.",2025-02-12
"Bridging LLM-Generated Code and Requirements: Reverse Generation
  technique and SBC Metric for Developer Insights",2025-02-11 01:12:11+00:00,http://arxiv.org/abs/2502.07835v1,Ahilan Ayyachamy Nadar Ponnusamy,"cs.SE, cs.AI",knowledge,"The rise of Large Language Models (LLMs) in software engineering,
particularly in code generation, has garnered significant attention. However,
assessing the quality of AI-generated code remains a challenge due to the
inherent complexity of programming tasks and the lack of robust evaluation
metrics that align well with human judgment. Traditional token-based metrics
such as BLEU and ROUGE, while commonly used in natural language processing,
exhibit weak correlations with human assessments in code intelligence and
verification tasks. Furthermore, these metrics are primarily research focused
and are not designed for seamless integration into the software development
lifecycle, limiting their practical utility for developers seeking to improve
code quality and security.
  AI-assisted coding has been shown to be more beneficial for senior
developers, as they possess the expertise to critically evaluate the generated
code for correctness, completeness, and compliance. In contrast, junior
developers may struggle to identify hallucinations, missing functionality, or
incorrect logic in AI-generated code. To bridge this gap, This paper introduces
a novel scoring mechanism called the SBC score, which is based on a reverse
generation technique that leverages the natural language generation
capabilities of LLMs. Unlike direct code analysis, our approach reconstructs
system requirements from AI-generated code and compares them with the original
specifications to quantify accuracy. The SBC score combines semantic
similarity, BLEU, and completeness analysis, providing actionable insights to
developers by highlighting missing features and hallucinations. Our code and
datasets are available on GitHub",2025-02-11
"Latent Convergence Modulation in Large Language Models: A Novel Approach
  to Iterative Contextual Realignment",2025-02-10 09:46:33+00:00,http://arxiv.org/abs/2502.06302v1,"Patricia Porretta, Sylvester Pakenham, Huxley Ainsworth, Gregory Chatten, Godfrey Allerton, Simon Hollingsworth, Vance Periwinkle",cs.CL,knowledge,"Token prediction stability remains a challenge in autoregressive generative
models, where minor variations in early inference steps often lead to
significant semantic drift over extended sequences. A structured modulation
mechanism was introduced to regulate hidden state transitions, ensuring that
latent representation trajectories remain aligned with prior contextual
dependencies while preserving generative flexibility. The modulation framework
was designed to function within transformer-based architectures, dynamically
constraining representation evolution without imposing external memory
dependencies or extensive architectural modifications. Empirical evaluations
demonstrated that structured latent adjustments contributed to reductions in
perplexity fluctuations, entropy variance, and lexical instability, improving
coherence in long-form text generation. Gradient propagation stability was
further analyzed, revealing that the modulation process led to smoother
optimization pathways, mitigating erratic fluctuations in weight updates across
successive inference steps. The computational efficiency of the modulation
process was assessed, showing that its integration within transformer-based
architectures introduced only marginal overhead while maintaining compatibility
with existing optimization frameworks. The structured modulation constraints
also influenced syntactic variation, preventing excessive repetition while
maintaining balanced sentence length distributions. Comparative evaluations
against baseline models reinforced the role of controlled latent state
evolution in improving pronoun resolution, logical consistency, and contextual
alignment across autoregressive text generation tasks.",2025-02-10
"Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge
  in Software Engineering",2025-02-10 06:49:29+00:00,http://arxiv.org/abs/2502.06193v1,"Ruiqi Wang, Jiyu Guo, Cuiyun Gao, Guodong Fan, Chun Yong Chong, Xin Xia","cs.SE, cs.AI",knowledge,"Recently, large language models (LLMs) have been deployed to tackle various
software engineering (SE) tasks like code generation, significantly advancing
the automation of SE tasks. However, assessing the quality of these
LLM-generated code and text remains challenging. The commonly used Pass@k
metric necessitates extensive unit tests and configured environments, demands a
high labor cost, and is not suitable for evaluating LLM-generated text.
Conventional metrics like BLEU, which measure only lexical rather than semantic
similarity, have also come under scrutiny. In response, a new trend has emerged
to employ LLMs for automated evaluation, known as LLM-as-a-judge. These
LLM-as-a-judge methods are claimed to better mimic human assessment than
conventional metrics without relying on high-quality reference answers.
Nevertheless, their exact human alignment in SE tasks remains unexplored. In
this paper, we empirically explore LLM-as-a-judge methods for evaluating SE
tasks, focusing on their alignment with human judgments. We select seven
LLM-as-a-judge methods that utilize general-purpose LLMs, alongside two LLMs
specifically fine-tuned for evaluation. After generating and manually scoring
LLM responses on three recent SE datasets of code translation, code generation,
and code summarization, we then prompt these methods to evaluate each response.
Finally, we compare the scores generated by these methods with human
evaluation. The results indicate that output-based methods reach the highest
Pearson correlation of 81.32 and 68.51 with human scores in code translation
and generation, achieving near-human evaluation, noticeably outperforming
ChrF++, one of the best conventional metrics, at 34.23 and 64.92. Such
output-based methods prompt LLMs to output judgments directly, and exhibit more
balanced score distributions that resemble human score patterns. Finally, we
provide...",2025-02-10
"Structural Perturbation in Large Language Model Representations through
  Recursive Symbolic Regeneration",2025-02-09 07:00:10+00:00,http://arxiv.org/abs/2502.05794v1,"Kathlyn Eaglewood, Tobias Featherington, Dorian Mayfair, Sylvester Grimshaw, James Pettigrew",cs.CL,knowledge,"Symbolic perturbations offer a novel approach for influencing neural
representations without requiring direct modification of model parameters. The
recursive regeneration of symbolic structures introduces structured variations
in latent embeddings, leading to controlled shifts in attention dynamics and
lexical diversity across sequential generations. A comparative analysis with
conventional fine-tuning techniques reveals that structural modifications at
the symbolic level induce distinct variations in contextual sensitivity while
maintaining overall model fluency and coherence. Shifts in attention weight
distributions highlight the role of symbolic modifications in adjusting token
dependencies, influencing response variability, and refining long-form text
generation. Experimental findings suggest that symbolic perturbations can
enhance adaptability in domain-specific applications, allowing modifications in
model behavior without retraining. Evaluations of semantic drift indicate that
recursive regeneration alters long-range token dependencies, affecting topic
coherence across extended text sequences. Results from lexical variability
assessments further support the conclusion that symbolic-level modifications
introduce interpretable variations in generated responses, potentially enabling
more controlled stylistic adjustments in automated text generation.",2025-02-09
"AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features
  toward Generating Attractive Ad Texts",2025-02-07 05:39:55+00:00,http://arxiv.org/abs/2502.04674v2,"Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura","cs.CL, cs.AI",knowledge,"Effective linguistic choices that attract potential customers play crucial
roles in advertising success. This study aims to explore the linguistic
features of ad texts that influence human preferences. Although the creation of
attractive ad texts is an active area of research, progress in understanding
the specific linguistic features that affect attractiveness is hindered by
several obstacles. First, human preferences are complex and influenced by
multiple factors, including their content, such as brand names, and their
linguistic styles, making analysis challenging. Second, publicly available ad
text datasets that include human preferences are lacking, such as ad
performance metrics and human feedback, which reflect people's interests. To
address these problems, we present AdParaphrase, a paraphrase dataset that
contains human preferences for pairs of ad texts that are semantically
equivalent but differ in terms of wording and style. This dataset allows for
preference analysis that focuses on the differences in linguistic features. Our
analysis revealed that ad texts preferred by human judges have higher fluency,
longer length, more nouns, and use of bracket symbols. Furthermore, we
demonstrate that an ad text-generation model that considers these findings
significantly improves the attractiveness of a given text. The dataset is
publicly available at: https://github.com/CyberAgentAILab/AdParaphrase.",2025-02-07
"Experiments with Large Language Models on Retrieval-Augmented Generation
  for Closed-Source Simulation Software",2025-02-06 09:48:04+00:00,http://arxiv.org/abs/2502.03916v1,"Andreas Baumann, Peter Eberhard","cs.CL, cs.AI",knowledge,"Large Language Models (LLMs) are increasingly helpful in text generation,
even writing code in programming languages based on user prompts written in
natural language. They are even applied to generate simulation models for
multibody systems from natural language. Research results suggest that LLMs
surpass the mere replication of existing code examples, where some LLMs have
been trained on an open-source multibody simulation code. However, for
closed-source simulation software, such results are not to be expected as their
ideas and concepts might differ from other publicly available ones. LLMs can
hallucinate for knowledge-intensive tasks, such as model creation, which can
lead to wrong responses. This is especially the case for the LLM unknown
closed-source simulation software. The same applies to other internal knowledge
kept private to protect intellectual property or data privacy. The
Retrieval-Augmented Generation (RAG) approach might yield a solution for these
knowledge-intensive tasks. This paper explores the application of RAG to
closed-source simulation software and presents first experiments. After a brief
introduction to LLMs, the RAG approach, and the simulation method applied by
the close-source simulation software, several examples are provided to test
LLMs' knowledge of the simulation software and the creation of simulation
models using two RAG systems. The examples show promising results indicating
the benefits of applying RAG systems to closed-source simulation software,
helping to access their knowledge. Nevertheless, they also reveal gaps in the
applied information and open questions for further research.",2025-02-06
"Context-Preserving Gradient Modulation for Large Language Models: A
  Novel Approach to Semantic Consistency in Long-Form Text Generation",2025-02-05 22:13:06+00:00,http://arxiv.org/abs/2502.03643v1,"Nirola Kobanov, Edmund Weatherstone, Zachary Vanderpoel, Orlando Wetherby",cs.CL,knowledge,"Maintaining semantic consistency over extended text sequences remains a
fundamental challenge in long-form text generation, where conventional training
methodologies often struggle to prevent contextual drift and coherence
degradation. A novel gradient modulation approach is introduced, designed to
adjust parameter updates dynamically in response to contextual relevance,
ensuring that generated text remains aligned with prior discourse. By
integrating a modulation function that selectively amplifies or attenuates
gradients based on learned contextual dependencies, the proposed method
enhances the stability of model-generated narratives without imposing
significant computational overhead. Comparative evaluations against baseline
models reveal improvements in coherence, contextual retention, and long-range
dependency tracking, demonstrating the effectiveness of modifying the learning
process at the gradient level. The results indicate that sentence structure
variability and lexical diversity benefit from this approach, mitigating
repetitive phrasing and improving adaptability across diverse linguistic
contexts. Statistical validation of coherence metrics further substantiates the
observed enhancements, with a significant reduction in inconsistencies emerging
as a direct consequence of the modulation mechanism. Computational efficiency
assessments confirm that the framework achieves these gains without requiring
substantial modifications to the underlying architecture, ensuring
compatibility with existing optimization workflows.",2025-02-05
"Structured Token Retention and Computational Memory Paths in Large
  Language Models",2025-02-05 11:59:22+00:00,http://arxiv.org/abs/2502.03102v1,"Jonathan Delena, Augustin Moreau, Dominic Ravensdale, Frederick Chatterton",cs.CL,knowledge,"Memory retention mechanisms play a central role in determining the efficiency
of computational architectures designed for processing extended sequences.
Conventional methods for token management often impose fixed retention
thresholds or rely on uniform attention weight distributions, leading to
inefficient memory utilization and premature information loss in extended
sequence modeling. Structured Token Retention (STR) introduces a probabilistic
selection framework that dynamically adjusts token persistence based on
contextual significance, ensuring that computational resources are allocated to
semantically relevant elements. Computational Memory Paths (CMP) extend this
framework through hierarchical memory allocation, refining retention efficiency
through structured reallocation of token embeddings. Comparative assessments
against baseline models demonstrate that STR and CMP improve token survival
rates across long input sequences while reducing cumulative error propagation
across processing layers. Experimental results further indicate reductions in
computational overhead, improving inference speed without degrading contextual
coherence. Token distribution analyses reveal that structured memory allocation
prevents excessive redundancy in attention weight calculations, optimizing
information retrieval efficiency in large-scale generative architectures. The
integration of STR and CMP into an open-source model illustrates the
adaptability of structured memory retention methodologies, highlighting their
applicability in generative text processing, long-context comprehension, and
scalable sequence modeling.",2025-02-05
"Analyze Feature Flow to Enhance Interpretation and Steering in Language
  Models",2025-02-05 09:39:34+00:00,http://arxiv.org/abs/2502.03032v2,"Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov","cs.LG, cs.CL",knowledge,"We introduce a new approach to systematically map features discovered by
sparse autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.",2025-02-05
"Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and
  Retrieval-Augmented Generation",2025-02-04 16:33:25+00:00,http://arxiv.org/abs/2502.02464v2,"Abdelrahman Abdallah, Bhawna Piryani, Jamshid Mozafari, Mohammed Ali, Adam Jatowt","cs.IR, cs.CL",knowledge,"Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical
components of modern natural language processing (NLP) applications in
information retrieval, question answering, and knowledge-based text generation.
However, existing solutions are often fragmented, lacking a unified framework
that easily integrates these essential processes. The absence of a standardized
implementation, coupled with the complexity of retrieval and re-ranking
workflows, makes it challenging for researchers to compare and evaluate
different approaches in a consistent environment. While existing toolkits such
as Rerankers and RankLLM provide general-purpose reranking pipelines, they
often lack the flexibility required for fine-grained experimentation and
benchmarking. In response to these challenges, we introduce \textbf{Rankify}, a
powerful and modular open-source toolkit designed to unify retrieval,
re-ranking, and RAG within a cohesive framework. Rankify supports a wide range
of retrieval techniques, including dense and sparse retrievers, while
incorporating state-of-the-art re-ranking models to enhance retrieval quality.
Additionally, Rankify includes a collection of pre-retrieved datasets to
facilitate benchmarking, available at Huggingface
(https://huggingface.co/datasets/abdoelsayed/reranking-datasets). To encourage
adoption and ease of integration, we provide comprehensive documentation
(http://rankify.readthedocs.io/), an open-source implementation on
GitHub(https://github.com/DataScienceUIBK/rankify), and a PyPI package for
effortless installation(https://pypi.org/project/rankify/). By providing a
unified and lightweight framework, Rankify allows researchers and practitioners
to advance retrieval and re-ranking methodologies while ensuring consistency,
scalability, and ease of use.",2025-02-04
"Gradient-Regularized Latent Space Modulation in Large Language Models
  for Structured Contextual Synthesis",2025-02-04 03:43:52+00:00,http://arxiv.org/abs/2502.01979v1,"Derek Yotheringhay, Beatrix Nightingale, Maximilian Featherstone, Edmund Worthington, Hugo Ashdown",cs.CL,knowledge,"Generating structured textual content requires mechanisms that enforce
coherence, stability, and adherence to predefined constraints while maintaining
semantic fidelity. Conventional approaches often rely on rule-based heuristics
or fine-tuning strategies that lack flexibility and generalizability across
diverse tasks. The incorporation of Gradient-Regularized Latent Space
Modulation (GRLSM) introduces a novel paradigm for guiding text generation
through the application of structured constraints within the latent space. The
integration of gradient-based regularization mitigates abrupt variations in
latent representations, ensuring a smoother encoding process that enhances
structural consistency and logical progression within generated sequences.
Comparative evaluations demonstrate that latent space modulation leads to a
reduction in perplexity, increased coherence scores, and improved structural
alignment across multiple domains. Stability assessments further indicate that
the imposition of spectral norm constraints facilitates more controlled
variations in generated text, preserving semantic consistency under input
perturbations. Empirical results confirm that structured latent space
constraints not only refine the organization of generated outputs but also
enhance interpretability through more predictable and reliable synthesis
patterns. Performance metrics illustrate that the GRLSM framework substantially
reduces structural inconsistencies while preserving the generative flexibility
inherent in neural models.",2025-02-04
"Latent Lexical Projection in Large Language Models: A Novel Approach to
  Implicit Representation Refinement",2025-02-03 23:18:53+00:00,http://arxiv.org/abs/2502.01882v1,"Ziad Shaker, Brendan Ashdown, Hugo Fitzalan, Alistair Heathcote, Jocasta Huntington",cs.CL,knowledge,"Generating semantically coherent text requires a robust internal
representation of linguistic structures, which traditional embedding techniques
often fail to capture adequately. A novel approach, Latent Lexical Projection
(LLP), is introduced to refine lexical representations through a structured
transformation into a latent space, thereby enhancing the alignment between
input embeddings and their contextual meanings. The method integrates an
optimized projection mechanism within an existing language model architecture,
enabling more accurate token selection while maintaining syntactic integrity.
Evaluations across multiple benchmarks indicate a reduction in perplexity and
an increase in BLEU scores, suggesting improvements in predictive accuracy and
fluency. The analysis of lexical diversity reveals a more varied vocabulary in
generated text, addressing common issues of redundancy and repetitive phrase
structures. Further assessments of entropy distributions demonstrate a decline
in uncertainty during decoding, reflecting enhanced confidence in word
selection. Additionally, long-range dependency retention exhibits measurable
gains, with increased classification accuracy at extended token distances.
Computational efficiency remains within manageable constraints, despite the
added projection mechanism, highlighting the practicality of LLP for
integration into existing architectures.",2025-02-03
M+: Extending MemoryLLM with Scalable Long-Term Memory,2025-02-01 23:13:10+00:00,http://arxiv.org/abs/2502.00592v1,"Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio Feris, Zexue He",cs.CL,knowledge,"Equipping large language models (LLMs) with latent-space memory has attracted
increasing attention as they can extend the context window of existing language
models. However, retaining information from the distant past remains a
challenge. For example, MemoryLLM (Wang et al., 2024a), as a representative
work with latent-space memory, compresses past information into hidden states
across all layers, forming a memory pool of 1B parameters. While effective for
sequence lengths up to 16k tokens, it struggles to retain knowledge beyond 20k
tokens. In this work, we address this limitation by introducing M+, a
memory-augmented model based on MemoryLLM that significantly enhances long-term
information retention. M+ integrates a long-term memory mechanism with a
co-trained retriever, dynamically retrieving relevant information during text
generation. We evaluate M+ on diverse benchmarks, including long-context
understanding and knowledge retention tasks. Experimental results show that M+
significantly outperforms MemoryLLM and recent strong baselines, extending
knowledge retention from under 20k to over 160k tokens with similar GPU memory
overhead.",2025-02-01
"A Comprehensive Framework for Semantic Similarity Analysis of Human and
  AI-Generated Text Using Transformer Architectures and Ensemble Techniques",2025-01-24 07:07:37+00:00,http://arxiv.org/abs/2501.14288v2,"Lifu Gao, Ziwei Liu, Qi Zhang","cs.CL, cs.AI",knowledge,"The rapid advancement of large language models (LLMs) has made detecting
AI-generated text an increasingly critical challenge. Traditional methods often
fail to capture the nuanced semantic differences between human and
machine-generated content. We therefore propose a novel approach based on
semantic similarity analysis, leveraging a multi-layered architecture that
combines a pre-trained DeBERTa-v3-large model, Bi-directional LSTMs, and linear
attention pooling to capture both local and global semantic patterns. To
enhance performance, we employ advanced input and output augmentation
techniques such as sector-level context integration and wide output
configurations. These techniques enable the model to learn more discriminative
features and generalize across diverse domains. Experimental results show that
this approach works better than traditional methods, proving its usefulness for
AI-generated text detection and other text comparison tasks.",2025-01-24
"BiMarker: Enhancing Text Watermark Detection for Large Language Models
  with Bipolar Watermarks",2025-01-21 14:32:50+00:00,http://arxiv.org/abs/2501.12174v4,Zhuang Li,cs.LG,knowledge,"The rapid growth of Large Language Models (LLMs) raises concerns about
distinguishing AI-generated text from human content. Existing watermarking
techniques, like \kgw, struggle with low watermark strength and stringent
false-positive requirements. Our analysis reveals that current methods rely on
coarse estimates of non-watermarked text, limiting watermark detectability. To
address this, we propose Bipolar Watermark (\tool), which splits generated text
into positive and negative poles, enhancing detection without requiring
additional computational resources or knowledge of the prompt. Theoretical
analysis and experimental results demonstrate \tool's effectiveness and
compatibility with existing optimization techniques, providing a new
optimization dimension for watermarking in LLM-generated content.",2025-01-21
"Reasoning-Enhanced Self-Training for Long-Form Personalized Text
  Generation",2025-01-07 22:29:08+00:00,http://arxiv.org/abs/2501.04167v1,"Alireza Salemi, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Weize Kong, Tao Chen, Zhuowan Li, Michael Bendersky, Hamed Zamani","cs.CL, cs.AI, cs.IR",knowledge,"Personalized text generation requires a unique ability of large language
models (LLMs) to learn from context that they often do not encounter during
their standard training. One way to encourage LLMs to better use personalized
context for generating outputs that better align with the user's expectations
is to instruct them to reason over the user's past preferences, background
knowledge, or writing style. To achieve this, we propose Reasoning-Enhanced
Self-Training for Personalized Text Generation (REST-PG), a framework that
trains LLMs to reason over personal data during response generation. REST-PG
first generates reasoning paths to train the LLM's reasoning abilities and then
employs Expectation-Maximization Reinforced Self-Training to iteratively train
the LLM based on its own high-reward outputs. We evaluate REST-PG on the
LongLaMP benchmark, consisting of four diverse personalized long-form text
generation tasks. Our experiments demonstrate that REST-PG achieves significant
improvements over state-of-the-art baselines, with an average relative
performance gain of 14.5% on the benchmark.",2025-01-07
"Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual
  Information in Long-form Text Generation",2025-01-07 05:43:23+00:00,http://arxiv.org/abs/2501.03545v1,"Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani",cs.CL,knowledge,"This paper presents ICAT, an evaluation framework for measuring coverage of
diverse factual information in long-form text generation. ICAT breaks down a
long output text into a list of atomic claims and not only verifies each claim
through retrieval from a (reliable) knowledge source, but also computes the
alignment between the atomic factual claims and various aspects expected to be
presented in the output. We study three implementations of the ICAT framework,
each with a different assumption on the availability of aspects and alignment
method. By adopting data from the diversification task in the TREC Web Track
and the ClueWeb corpus, we evaluate the ICAT framework. We demonstrate strong
correlation with human judgments and provide comprehensive evaluation across
multiple state-of-the-art LLMs. Our framework further offers interpretable and
fine-grained analysis of diversity and coverage. Its modular design allows for
easy adaptation to different domains and datasets, making it a valuable tool
for evaluating the qualitative aspects of long-form responses produced by LLMs.",2025-01-07
Map2Text: New Content Generation from Low-Dimensional Visualizations,2024-12-24 20:16:13+00:00,http://arxiv.org/abs/2412.18673v1,"Xingjian Zhang, Ziyang Xiong, Shixuan Liu, Yutong Xie, Tolga Ergen, Dongsub Shim, Hua Xu, Honglak Lee, Qiaozhu Me","cs.AI, cs.HC",knowledge,"Low-dimensional visualizations, or ""projection maps"" of datasets, are widely
used across scientific research and creative industries as effective tools for
interpreting large-scale and complex information. These visualizations not only
support understanding existing knowledge spaces but are often used implicitly
to guide exploration into unknown areas. While powerful methods like TSNE or
UMAP can create such visual maps, there is currently no systematic way to
leverage them for generating new content. To bridge this gap, we introduce
Map2Text, a novel task that translates spatial coordinates within
low-dimensional visualizations into new, coherent, and accurately aligned
textual content. This allows users to explore and navigate undiscovered
information embedded in these spatial layouts interactively and intuitively. To
evaluate the performance of Map2Text methods, we propose Atometric, an
evaluation metric that provides a granular assessment of logical coherence and
alignment of the atomic statements in the generated texts. Experiments
conducted across various datasets demonstrate the versatility of Map2Text in
generating scientific research hypotheses, crafting synthetic personas, and
devising strategies for testing large language models. Our findings highlight
the potential of Map2Text to unlock new pathways for interacting with and
navigating large-scale textual datasets, offering a novel framework for
spatially guided content generation and discovery.",2024-12-24
"The HalluRAG Dataset: Detecting Closed-Domain Hallucinations in RAG
  Applications Using an LLM's Internal States",2024-12-22 15:08:24+00:00,http://arxiv.org/abs/2412.17056v1,"Fabian Ridder, Malte Schilling","cs.CL, cs.LG",knowledge,"Detecting hallucinations in large language models (LLMs) is critical for
enhancing their reliability and trustworthiness. Most research focuses on
hallucinations as deviations from information seen during training. However,
the opaque nature of an LLM's parametric knowledge complicates the
understanding of why generated texts appear ungrounded: The LLM might not have
picked up the necessary knowledge from large and often inaccessible datasets,
or the information might have been changed or contradicted during further
training. Our focus is on hallucinations involving information not used in
training, which we determine by using recency to ensure the information emerged
after a cut-off date. This study investigates these hallucinations by detecting
them at sentence level using different internal states of various LLMs. We
present HalluRAG, a dataset designed to train classifiers on these
hallucinations. Depending on the model and quantization, MLPs trained on
HalluRAG detect hallucinations with test accuracies ranging up to 75 %, with
Mistral-7B-Instruct-v0.1 achieving the highest test accuracies. Our results
show that IAVs detect hallucinations as effectively as CEVs and reveal that
answerable and unanswerable prompts are encoded differently as separate
classifiers for these categories improved accuracy. However, HalluRAG showed
some limited generalizability, advocating for more diversity in datasets on
hallucinations.",2024-12-22
GraphAgent: Agentic Graph Language Assistant,2024-12-22 14:13:32+00:00,http://arxiv.org/abs/2412.17029v1,"Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang",cs.AI,knowledge,"Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.",2024-12-22
EMPRA: Embedding Perturbation Rank Attack against Neural Ranking Models,2024-12-20 22:36:19+00:00,http://arxiv.org/abs/2412.16382v1,"Amin Bigdeli, Negar Arabzadeh, Ebrahim Bagheri, Charles L. A. Clarke",cs.IR,knowledge,"Recent research has shown that neural information retrieval techniques may be
susceptible to adversarial attacks. Adversarial attacks seek to manipulate the
ranking of documents, with the intention of exposing users to targeted content.
In this paper, we introduce the Embedding Perturbation Rank Attack (EMPRA)
method, a novel approach designed to perform adversarial attacks on black-box
Neural Ranking Models (NRMs). EMPRA manipulates sentence-level embeddings,
guiding them towards pertinent context related to the query while preserving
semantic integrity. This process generates adversarial texts that seamlessly
integrate with the original content and remain imperceptible to humans. Our
extensive evaluation conducted on the widely-used MS MARCO V1 passage
collection demonstrate the effectiveness of EMPRA against a wide range of
state-of-the-art baselines in promoting a specific set of target documents
within a given ranked results. Specifically, EMPRA successfully achieves a
re-ranking of almost 96% of target documents originally ranked between 51-100
to rank within the top 10. Furthermore, EMPRA does not depend on surrogate
models for adversarial text generation, enhancing its robustness against
different NRMs in realistic settings.",2024-12-20
Qwen2.5 Technical Report,2024-12-19 17:56:09+00:00,http://arxiv.org/abs/2412.15115v1,"Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu",cs.CL,knowledge,"In this report, we introduce Qwen2.5, a comprehensive series of large
language models (LLMs) designed to meet diverse needs. Compared to previous
iterations, Qwen 2.5 has been significantly improved during both the
pre-training and post-training stages. In terms of pre-training, we have scaled
the high-quality pre-training datasets from the previous 7 trillion tokens to
18 trillion tokens. This provides a strong foundation for common sense, expert
knowledge, and reasoning capabilities. In terms of post-training, we implement
intricate supervised finetuning with over 1 million samples, as well as
multistage reinforcement learning. Post-training techniques enhance human
preference, and notably improve long text generation, structural data analysis,
and instruction following. To handle diverse and varied use cases effectively,
we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base
and instruction-tuned models, with quantized versions available. In addition,
for hosted solutions, the proprietary models currently include two
mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both
available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier
performance on a wide range of benchmarks evaluating language understanding,
reasoning, mathematics, coding, human preference alignment, etc. Specifically,
the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and
proprietary models and demonstrates competitive performance to the
state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5
times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness
while performing competitively against GPT-4o-mini and GPT-4o respectively.
Additionally, as the foundation, Qwen2.5 models have been instrumental in
training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and
multimodal models.",2024-12-19
Why language models collapse when trained on recursively generated text,2024-12-19 14:11:15+00:00,http://arxiv.org/abs/2412.14872v1,"Lecheng Wang, Xianjie Shi, Ge Li, Jia Li, Yihong Dong, Xuanming Zhang, Wenpin Jiao, Hong Mei",cs.CL,knowledge,"Language models (LMs) have been widely used to generate text on the Internet.
The generated text is often collected into the training corpus of the next
generations of LMs. Previous work has experimentally found that LMs collapse
when trained on recursively generated text. This paper contributes to existing
knowledge from two aspects. We present a theoretical proof of LM collapse. Our
proof reveals the cause of LM collapse and proves that all auto-regressive LMs
will definitely collapse. We present a new finding: the performance of LMs
gradually declines when trained on recursively generated text until they
perform no better than a randomly initialized LM. The trained LMs produce large
amounts of repetitive text and perform poorly across a wide range of natural
language tasks. The above proof and new findings deepen our understanding of LM
collapse and offer valuable insights that may inspire new training techniques
to mitigate this threat.",2024-12-19
"Extending LLMs to New Languages: A Case Study of Llama and Persian
  Adaptation",2024-12-17 23:18:06+00:00,http://arxiv.org/abs/2412.13375v1,"Samin Mahdizadeh Sani, Pouya Sadeghi, Thuy-Trang Vu, Yadollah Yaghoobzadeh, Gholamreza Haffari",cs.CL,knowledge,"Large language models (LLMs) have made great progress in classification and
text generation tasks. However, they are mainly trained on English data and
often struggle with low-resource languages. In this study, we explore adding a
new language, i.e., Persian, to Llama (a model with a limited understanding of
Persian) using parameter-efficient fine-tuning. We employ a multi-stage
approach involving pretraining on monolingual Persian data, aligning
representations through bilingual pretraining and instruction datasets, and
instruction-tuning with task-specific datasets. We evaluate the model's
performance at each stage on generation and classification tasks. Our findings
suggest that incorporating the Persian language, through bilingual data
alignment, can enhance classification accuracy for Persian tasks, with no
adverse impact and sometimes even improvements on English tasks. Additionally,
the results highlight the model's initial strength as a critical factor when
working with limited training data, with cross-lingual alignment offering
minimal benefits for the low-resource language. Knowledge transfer from English
to Persian has a marginal effect, primarily benefiting simple classification
tasks.",2024-12-17
"Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental
  Health",2024-12-17 15:01:07+00:00,http://arxiv.org/abs/2412.12981v1,"Vivek Kumar, Eirini Ntoutsi, Pushpraj Singh Rajawat, Giacomo Medda, Diego Reforgiato Recupero",cs.CL,knowledge,"Large language models (LLMs) have shown promising capabilities in healthcare
analysis but face several challenges like hallucinations, parroting, and bias
manifestation. These challenges are exacerbated in complex, sensitive, and
low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an
expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by
generating in-context conversational dialogues leveraging LLMs, particularly
ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues
and tailored information, taking into account therapy style (empathy,
reflection), contextual relevance, and false semantic change. Subsequently, the
dialogues are annotated by experts, strictly adhering to the Motivational
Interviewing Skills Code (MISC), focusing on both the psychological and
linguistic dimensions of MI dialogues. We comprehensively evaluate the
IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding
of domain intricacies by modeling novel classification tasks employing several
classical machine learning and current state-of-the-art transformer approaches.
Finally, we discuss the effects of progressive prompting strategies and the
impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our
contributions provide the MI community with not only a comprehensive dataset
but also valuable insights for using LLMs in empathetic text generation for
conversational therapy in supervised settings.",2024-12-17
Graph-Guided Textual Explanation Generation Framework,2024-12-16 19:35:55+00:00,http://arxiv.org/abs/2412.12318v1,"Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael Färber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein",cs.CL,knowledge,"Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned the faithfulness of NLEs, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations -- input fragments identified as critical
for the model's predictions -- exhibit measurable faithfulness, which has been
incrementally improved through existing research. Building on this foundation,
we propose G-Tex, a Graph-Guided Textual Explanation Generation framework
designed to enhance the faithfulness of NLEs by leveraging highlight
explanations. Specifically, highlight explanations are extracted as highly
faithful cues representing the model's reasoning and are subsequently encoded
through a graph neural network layer, which explicitly guides the NLE
generation process. This alignment ensures that the generated explanations
closely reflect the model's underlying reasoning. Experiments on T5 and BART
using three reasoning datasets show that G-Tex improves NLE faithfulness by up
to 17.59% compared to baseline methods. Additionally, G-Tex generates NLEs with
greater semantic and lexical similarity to human-written ones. Human
evaluations show that G-Tex can decrease redundant content and enhance the
overall quality of NLEs. As our work introduces a novel method for explicitly
guiding NLE generation to improve faithfulness, we hope it will serve as a
stepping stone for addressing additional criteria for NLE and generated text
overall.",2024-12-16
"LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse
  Input Contexts",2024-12-16 17:29:51+00:00,http://arxiv.org/abs/2412.12001v1,"Zhuhao Wang, Yihua Sun, Zihan Li, Xuan Yang, Fang Chen, Hongen Liao","cs.CL, cs.CV",knowledge,"Drafting radiology reports is a complex task requiring flexibility, where
radiologists tail content to available information and particular clinical
demands. However, most current radiology report generation (RRG) models are
constrained to a fixed task paradigm, such as predicting the full ``finding''
section from a single image, inherently involving a mismatch between inputs and
outputs. The trained models lack the flexibility for diverse inputs and could
generate harmful, input-agnostic hallucinations. To bridge the gap between
current RRG models and the clinical demands in practice, we first develop a
data generation pipeline to create a new MIMIC-RG4 dataset, which considers
four common radiology report drafting scenarios and has perfectly corresponded
input and output. Secondly, we propose a novel large language model (LLM) based
RRG framework, namely LLM-RG4, which utilizes LLM's flexible
instruction-following capabilities and extensive general knowledge. We further
develop an adaptive token fusion module that offers flexibility to handle
diverse scenarios with different input combinations, while minimizing the
additional computational burden associated with increased input volumes.
Besides, we propose a token-level loss weighting strategy to direct the model's
attention towards positive and uncertain descriptions. Experimental results
demonstrate that LLM-RG4 achieves state-of-the-art performance in both clinical
efficiency and natural language generation on the MIMIC-RG4 and MIMIC-CXR
datasets. We quantitatively demonstrate that our model has minimal
input-agnostic hallucinations, whereas current open-source models commonly
suffer from this problem.",2024-12-16
DART: An AIGT Detector using AMR of Rephrased Text,2024-12-16 07:51:09+00:00,http://arxiv.org/abs/2412.11517v1,"Hyeonchu Park, Byungjun Kim, Bugeun Kim","cs.CL, cs.AI",knowledge,"As large language models (LLMs) generate more human-like texts, concerns
about the side effects of AI-generated texts (AIGT) have grown. So, researchers
have developed methods for detecting AIGT. However, two challenges remain.
First, the performance on detecting black-box LLMs is low, because existing
models have focused on syntactic features. Second, most AIGT detectors have
been tested on a single-candidate setting, which assumes that we know the
origin of an AIGT and may deviate from the real-world scenario. To resolve
these challenges, we propose DART, which consists of four steps: rephrasing,
semantic parsing, scoring, and multiclass classification. We conducted several
experiments to test the performance of DART by following previous work. The
experimental result shows that DART can discriminate multiple black-box LLMs
without using syntactic features and knowing the origin of AIGT.",2024-12-16
AD-LLM: Benchmarking Large Language Models for Anomaly Detection,2024-12-15 10:22:14+00:00,http://arxiv.org/abs/2412.11142v1,"Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao","cs.CL, cs.AI",knowledge,"Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.",2024-12-15
"TSCheater: Generating High-Quality Tibetan Adversarial Texts via Visual
  Similarity",2024-12-03 10:57:19+00:00,http://arxiv.org/abs/2412.02371v3,"Xi Cao, Quzong Gesang, Yuan Sun, Nuo Qun, Tashi Nyima","cs.CL, cs.CR",knowledge,"Language models based on deep neural networks are vulnerable to textual
adversarial attacks. While rich-resource languages like English are receiving
focused attention, Tibetan, a cross-border language, is gradually being studied
due to its abundant ancient literature and critical language strategy.
Currently, there are several Tibetan adversarial text generation methods, but
they do not fully consider the textual features of Tibetan script and
overestimate the quality of generated adversarial texts. To address this issue,
we propose a novel Tibetan adversarial text generation method called TSCheater,
which considers the characteristic of Tibetan encoding and the feature that
visually similar syllables have similar semantics. This method can also be
transferred to other abugidas, such as Devanagari script. We utilize a
self-constructed Tibetan syllable visual similarity database called TSVSDB to
generate substitution candidates and adopt a greedy algorithm-based scoring
mechanism to determine substitution order. After that, we conduct the method on
eight victim language models. Experimentally, TSCheater outperforms existing
methods in attack effectiveness, perturbation magnitude, semantic similarity,
visual similarity, and human acceptance. Finally, we construct the first
Tibetan adversarial robustness evaluation benchmark called AdvTS, which is
generated by existing methods and proofread by humans.",2024-12-03
Can LLMs be Good Graph Judger for Knowledge Graph Construction?,2024-11-26 12:46:57+00:00,http://arxiv.org/abs/2411.17388v1,"Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang","cs.CL, cs.AI",knowledge,"In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.",2024-11-26
"Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning
  Small Language Models",2024-11-25 23:37:48+00:00,http://arxiv.org/abs/2411.16991v1,"Yao Fu, Yin Yu, Xiaotian Han, Runchao Li, Xianxuan Long, Haotian Yu, Pan Li",cs.CL,knowledge,"Knowledge distillation (KD) has become a widely adopted approach for
compressing large language models (LLMs) to reduce computational costs and
memory footprints. However, the availability of complex teacher models is a
prerequisite for running most KD pipelines. Thus, the traditional KD procedure
can be unachievable or budget-unfriendly, particularly when relying on
commercial LLMs like GPT4. In this regard, Self-distillation (SelfD) emerges as
an advisable alternative, enabling student models to learn without teachers'
guidance. Nonetheless, existing SelfD approaches for LMs often involve
architectural modifications, assuming the models are open-source, which may not
always be practical. In this work, we introduce a model-agnostic and
task-agnostic method named dynamic SelfD from the previous minibatch (DynSDPB),
which realizes current iterations' distillation from the last ones' generated
logits. Additionally, to address prediction inaccuracies during the early
iterations, we dynamically adjust the distillation influence and temperature
values to enhance the adaptability of fine-tuning. Furthermore, DynSDPB is a
novel fine-tuning policy that facilitates the seamless integration of existing
self-correction and self-training techniques for small language models (SLMs)
because they all require updating SLMs' parameters. We demonstrate the superior
performance of DynSDPB on both encoder-only LMs (e.g., BERT model families) and
decoder-only LMs (e.g., LLaMA model families), validating its effectiveness
across natural language understanding (NLU) and natural language generation
(NLG) benchmarks.",2024-11-25
"MolMetaLM: a Physicochemical Knowledge-Guided Molecular Meta Language
  Model",2024-11-23 09:27:38+00:00,http://arxiv.org/abs/2411.15500v1,"Yifan Wu, Min Zeng, Yang Li, Yang Zhang, Min Li","cs.ET, cs.CL",knowledge,"Most current molecular language models transfer the masked language model or
image-text generation model from natural language processing to molecular
field. However, molecules are not solely characterized by atom/bond symbols;
they encapsulate important physical/chemical properties. Moreover, normal
language models bring grammar rules that are irrelevant for understanding
molecules. In this study, we propose a novel physicochemical knowledge-guided
molecular meta language framework MolMetaLM. We design a molecule-specialized
meta language paradigm, formatted as multiple <S,P,O> (subject, predicate,
object) knowledge triples sharing the same S (i.e., molecule) to enhance
learning the semantic relationships between physicochemical knowledge and
molecules. By introducing different molecular knowledge and noises, the meta
language paradigm generates tens of thousands of pretraining tasks. By
recovering the token/sequence/order-level noises, MolMetaLM exhibits
proficiency in large-scale benchmark evaluations involving property prediction,
molecule generation, conformation inference, and molecular optimization.
Through MolMetaLM, we offer a new insight for designing language models.",2024-11-23
"Benchmarking Multimodal Models for Ukrainian Language Understanding
  Across Academic and Cultural Domains",2024-11-22 00:37:49+00:00,http://arxiv.org/abs/2411.14647v1,"Yurii Paniv, Artur Kiulian, Dmytro Chaplynskyi, Mykola Khandoga, Anton Polishko, Tetiana Bas, Guillermo Gabrielli",cs.CL,knowledge,"While the evaluation of multimodal English-centric models is an active area
of research with numerous benchmarks, there is a profound lack of benchmarks or
evaluation suites for low- and mid-resource languages. We introduce ZNO-Vision,
a comprehensive multimodal Ukrainian-centric benchmark derived from
standardized university entrance examination (ZNO). The benchmark consists of
over 4,300 expert-crafted questions spanning 12 academic disciplines, including
mathematics, physics, chemistry, and humanities. We evaluated the performance
of both open-source models and API providers, finding that only a handful of
models performed above baseline. Alongside the new benchmark, we performed the
first evaluation study of multimodal text generation for the Ukrainian
language: we measured caption generation quality on the Multi30K-UK dataset,
translated the VQA benchmark into Ukrainian, and measured performance
degradation relative to original English versions. Lastly, we tested a few
models from a cultural perspective on knowledge of national cuisine. We believe
our work will advance multimodal generation capabilities for the Ukrainian
language and our approach could be useful for other low-resource languages.",2024-11-22
"Knowledge Graphs, Large Language Models, and Hallucinations: An NLP
  Perspective",2024-11-21 16:09:05+00:00,http://arxiv.org/abs/2411.14258v1,"Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose","cs.CL, cs.AI, 68-02, I.2.7",knowledge,"Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.",2024-11-21
"Robust Detection of Watermarks for Large Language Models Under Human
  Edits",2024-11-21 06:06:04+00:00,http://arxiv.org/abs/2411.13868v1,"Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su","cs.LG, cs.CL, math.ST, stat.ME, stat.ML, stat.TH",knowledge,"Watermarking has offered an effective approach to distinguishing text
generated by large language models (LLMs) from human-written text. However, the
pervasive presence of human edits on LLM-generated text dilutes watermark
signals, thereby significantly degrading detection performance of existing
methods. In this paper, by modeling human edits through mixture model
detection, we introduce a new method in the form of a truncated goodness-of-fit
test for detecting watermarked text under human edits, which we refer to as
Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection
of the Gumbel-max watermark in a certain asymptotic regime of substantial text
modifications and vanishing watermark signals. Importantly, Tr-GoF achieves
this optimality \textit{adaptively} as it does not require precise knowledge of
human edit levels or probabilistic specifications of the LLMs, in contrast to
the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover,
we establish that the Tr-GoF test attains the highest detection efficiency rate
in a certain regime of moderate text modifications. In stark contrast, we show
that sum-based detection rules, as employed by existing methods, fail to
achieve optimal robustness in both regimes because the additive nature of their
statistics is less resilient to edit-induced noise. Finally, we demonstrate the
competitive and sometimes superior empirical performance of the Tr-GoF test on
both synthetic data and open-source LLMs in the OPT and LLaMA families.",2024-11-21
"From Text to Pose to Image: Improving Diffusion Model Control and
  Quality",2024-11-19 21:34:50+00:00,http://arxiv.org/abs/2411.12872v2,"Clément Bonnet, Ariel N. Lee, Franck Wertel, Antoine Tamano, Tanguy Cizain, Pablo Ducru","cs.CV, cs.AI, cs.LG",knowledge,"In the last two years, text-to-image diffusion models have become extremely
popular. As their quality and usage increase, a major concern has been the need
for better output control. In addition to prompt engineering, one effective
method to improve the controllability of diffusion models has been to condition
them on additional modalities such as image style, depth map, or keypoints.
This forms the basis of ControlNets or Adapters. When attempting to apply these
methods to control human poses in outputs of text-to-image diffusion models,
two main challenges have arisen. The first challenge is generating poses
following a wide range of semantic text descriptions, for which previous
methods involved searching for a pose within a dataset of (caption, pose)
pairs. The second challenge is conditioning image generation on a specified
pose while keeping both high aesthetic and high pose fidelity. In this article,
we fix these two main issues by introducing a text-to-pose (T2P) generative
model alongside a new sampling algorithm, and a new pose adapter that
incorporates more pose keypoints for higher pose fidelity. Together, these two
new state-of-the-art models enable, for the first time, a generative
text-to-pose-to-image framework for higher pose control in diffusion models. We
release all models and the code used for the experiments at
https://github.com/clement-bonnet/text-to-pose.",2024-11-19
"A Combined Encoder and Transformer Approach for Coherent and
  High-Quality Text Generation",2024-11-19 01:41:56+00:00,http://arxiv.org/abs/2411.12157v1,"Jiajing Chen, Shuo Wang, Zhen Qi, Zhenhong Zhang, Chihang Wang, Hongye Zheng",cs.CL,knowledge,"This research introduces a novel text generation model that combines BERT's
semantic interpretation strengths with GPT-4's generative capabilities,
establishing a high standard in generating coherent, contextually accurate
language. Through the combined architecture, the model enhances semantic depth
and maintains smooth, human-like text flow, overcoming limitations seen in
prior models. Experimental benchmarks reveal that BERT-GPT-4 surpasses
traditional models, including GPT-3, T5, BART, Transformer-XL, and CTRL, in key
metrics like Perplexity and BLEU, showcasing its superior natural language
generation performance. By fully utilizing contextual information, this hybrid
model generates text that is not only logically coherent but also aligns
closely with human language patterns, providing an advanced solution for text
generation tasks. This research highlights the potential of integrating
semantic understanding with advanced generative models, contributing new
insights for NLP, and setting a foundation for broader applications of
large-scale generative architectures in areas such as automated writing,
question-answer systems, and adaptive conversational agents.",2024-11-19
"FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large
  and Small Language Models",2024-11-18 16:34:58+00:00,http://arxiv.org/abs/2411.11707v1,"Tao Fan, Yan Kang, Guoqiang Ma, Lixin Fan, Kai Chen, Qiang Yang","cs.CL, cs.AI",knowledge,"By adapting Large Language Models (LLMs) to domain-specific tasks or
enriching them with domain-specific knowledge, we can fully harness the
capabilities of LLMs. Nonetheless, a gap persists in achieving simultaneous
mutual enhancement between the server's LLM and the downstream clients' Small
Language Models (SLMs). To address this, we propose FedCoLLM, a novel and
parameter-efficient federated framework designed for co-tuning LLMs and SLMs.
This approach is aimed at adaptively transferring server-side LLMs knowledge to
clients' SLMs while simultaneously enriching the LLMs with domain insights from
the clients. To accomplish this, FedCoLLM utilizes lightweight adapters in
conjunction with SLMs, facilitating knowledge exchange between server and
clients in a manner that respects data privacy while also minimizing
computational and communication overhead. Our evaluation of FedCoLLM, utilizing
various public LLMs and SLMs across a range of NLP text generation tasks,
reveals that the performance of clients' SLMs experiences notable improvements
with the assistance of the LLMs. Simultaneously, the LLMs enhanced via FedCoLLM
achieves comparable performance to that obtained through direct fine-tuning on
clients' data.",2024-11-18
"CROW: Eliminating Backdoors from Large Language Models via Internal
  Consistency Regularization",2024-11-18 07:52:12+00:00,http://arxiv.org/abs/2411.12768v1,"Nay Myat Min, Long H. Pham, Yige Li, Jun Sun","cs.CL, cs.AI, cs.LG",knowledge,"Recent studies reveal that Large Language Models (LLMs) are susceptible to
backdoor attacks, where adversaries embed hidden triggers that manipulate model
responses. Existing backdoor defense methods are primarily designed for vision
or classification tasks, and are thus ineffective for text generation tasks,
leaving LLMs vulnerable. We introduce Internal Consistency Regularization
(CROW), a novel defense using consistency regularization finetuning to address
layer-wise inconsistencies caused by backdoor triggers. CROW leverages the
intuition that clean models exhibit smooth, consistent transitions in hidden
representations across layers, whereas backdoored models show noticeable
fluctuation when triggered. By enforcing internal consistency through
adversarial perturbations and regularization, CROW neutralizes backdoor effects
without requiring clean reference models or prior trigger knowledge, relying
only on a small set of clean data. This makes it practical for deployment
across various LLM architectures. Experimental results demonstrate that CROW
consistently achieves a significant reductions in attack success rates across
diverse backdoor strategies and tasks, including negative sentiment, targeted
refusal, and code injection, on models such as Llama-2 (7B, 13B), CodeLlama
(7B, 13B) and Mistral-7B, while preserving the model's generative capabilities.",2024-11-18
SEFD: Semantic-Enhanced Framework for Detecting LLM-Generated Text,2024-11-17 20:13:30+00:00,http://arxiv.org/abs/2411.12764v1,"Weiqing He, Bojian Hou, Tianqi Shang, Davoud Ataee Tarzanagh, Qi Long, Li Shen","cs.CL, cs.AI, cs.IR",knowledge,"The widespread adoption of large language models (LLMs) has created an urgent
need for robust tools to detect LLM-generated text, especially in light of
\textit{paraphrasing} techniques that often evade existing detection methods.
To address this challenge, we present a novel semantic-enhanced framework for
detecting LLM-generated text (SEFD) that leverages a retrieval-based mechanism
to fully utilize text semantics. Our framework improves upon existing detection
methods by systematically integrating retrieval-based techniques with
traditional detectors, employing a carefully curated retrieval mechanism that
strikes a balance between comprehensive coverage and computational efficiency.
We showcase the effectiveness of our approach in sequential text scenarios
common in real-world applications, such as online forums and Q\&A platforms.
Through comprehensive experiments across various LLM-generated texts and
detection methods, we demonstrate that our framework substantially enhances
detection accuracy in paraphrasing scenarios while maintaining robustness for
standard LLM-generated content.",2024-11-17
LLM Hallucination Reasoning with Zero-shot Knowledge Test,2024-11-14 18:55:26+00:00,http://arxiv.org/abs/2411.09689v1,"Seongmin Lee, Hsiang Hsu, Chun-Fu Chen","cs.AI, cs.CL",knowledge,"LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing
detection methods rely on external knowledge, LLM fine-tuning, or
hallucination-labeled datasets, and they do not distinguish between different
types of hallucinations, which are crucial for improving detection performance.
We introduce a new task, Hallucination Reasoning, which classifies
LLM-generated text into one of three categories: aligned, misaligned, and
fabricated. Our novel zero-shot method assesses whether LLM has enough
knowledge about a given prompt and text. Our experiments conducted on new
datasets demonstrate the effectiveness of our method in hallucination reasoning
and underscore its importance for enhancing detection performance.",2024-11-14
LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models,2024-11-14 17:08:23+00:00,http://arxiv.org/abs/2411.09595v1,"Zhengyi Wang, Jonathan Lorraine, Yikai Wang, Hang Su, Jun Zhu, Sanja Fidler, Xiaohui Zeng","cs.LG, cs.AI, cs.CL, cs.CV, 68T05, I.3.5; I.2.10; I.2.6",knowledge,"This work explores expanding the capabilities of large language models (LLMs)
pretrained on text to generate 3D meshes within a unified model. This offers
key advantages of (1) leveraging spatial knowledge already embedded in LLMs,
derived from textual sources like 3D tutorials, and (2) enabling conversational
3D generation and mesh understanding. A primary challenge is effectively
tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.
To address this, we introduce LLaMA-Mesh, a novel approach that represents the
vertex coordinates and face definitions of 3D meshes as plain text, allowing
direct integration with LLMs without expanding the vocabulary. We construct a
supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate
3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs
as required, and (3) understand and interpret 3D meshes. Our work is the first
to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge
for 3D mesh generation in a text-based format, effectively unifying the 3D and
text modalities. LLaMA-Mesh achieves mesh generation quality on par with models
trained from scratch while maintaining strong text generation performance.",2024-11-14
Asterisk*: Keep it Simple,2024-11-08 16:42:33+00:00,http://arxiv.org/abs/2411.05691v1,Andrew Semenov,"cs.CL, cs.AI",knowledge,"This paper describes Asterisk, a compact GPT-based model for generating text
embeddings. The model uses a minimalist architecture with two layers, two
attention heads, and 256 embedding dimensions. By applying knowledge
distillation from larger pretrained models, we explore the trade-offs between
model size and performance while minimizing computational and memory
requirements. The model is primarily evaluated and optimized for classification
tasks, with experimental results showing its moderate performance in zero-shot
classification across various downstream applications. With additional
configuration, the model performance can approach or even surpass that of
larger architectures on specific classification tasks.",2024-11-08
Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking,2024-11-08 07:05:06+00:00,http://arxiv.org/abs/2411.05375v1,"Mubashara Akhtar, Michael Schlichtkrull, Andreas Vlachos","cs.CL, cs.AI, cs.IR, cs.LG",knowledge,"Current automated fact-checking (AFC) approaches commonly evaluate evidence
either implicitly via the predicted verdicts or by comparing retrieved evidence
with a predefined closed knowledge source, such as Wikipedia. However, these
methods suffer from limitations, resulting from their reliance on evaluation
metrics developed for different purposes and constraints imposed by closed
knowledge sources. Recent advances in natural language generation (NLG)
evaluation offer new possibilities for evidence assessment. In this work, we
introduce Ev2R, an evaluation framework for AFC that comprises three types of
approaches for evidence evaluation: reference-based, proxy-reference, and
reference-less. We evaluate their effectiveness through agreement with human
ratings and adversarial tests, and demonstrate that prompt-based scorers,
particularly those leveraging LLMs and reference evidence, outperform
traditional evaluation approaches.",2024-11-08
"PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology
  Report Generation",2024-11-07 19:06:17+00:00,http://arxiv.org/abs/2411.05085v1,"Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores Sánchez-Valverde, Lara Jaques-Pérez, Lourdes Pérez-Rodríguez, Kenji Takeda, José María Salinas, Javier Alvarez-Valle, Joaquín Galant Herrero, Antonio Pertusa","cs.AI, cs.CL, cs.CV",knowledge,"Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/",2024-11-07
GASE: Generatively Augmented Sentence Encoding,2024-11-07 17:53:47+00:00,http://arxiv.org/abs/2411.04914v1,"Manuel Frank, Haithem Afli",cs.CL,knowledge,"We propose an approach to enhance sentence embeddings by applying generative
text models for data augmentation at inference time. Unlike conventional data
augmentation that utilises synthetic training data, our approach does not
require access to model parameters or the computational resources typically
required for fine-tuning state-of-the-art models. Generatively Augmented
Sentence Encoding uses diverse linguistic synthetic variants of input texts
generated by paraphrasing, summarising, or extracting keywords, followed by
pooling the original and synthetic embeddings. Experimental results on the
Massive Text Embedding Benchmark for Semantic Textual Similarity (STS)
demonstrate performance improvements across a range of embedding models using
different generative models for augmentation. We find that generative
augmentation leads to larger performance improvements for embedding models with
lower baseline performance. These findings suggest that integrating generative
augmentation at inference time adds semantic diversity and can enhance the
robustness and generalizability of sentence embeddings for embedding models.
Our results show that the degree to which generative augmentation can improve
STS performance depends not only on the embedding model but also on the
dataset. From a broader perspective, the approach allows trading training for
inference compute.",2024-11-07
"VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and
  Benchmark Models",2024-11-07 16:06:00+00:00,http://arxiv.org/abs/2411.04825v1,"Ming Cheng, Jiaying Gong, Chenhan Yuan, William A. Ingram, Edward Fox, Hoda Eldardiry","cs.CL, cs.DL, cs.LG",knowledge,"Existing text simplification or paraphrase datasets mainly focus on
sentence-level text generation in a general domain. These datasets are
typically developed without using domain knowledge. In this paper, we release a
novel dataset, VTechAGP, which is the first academic-to-general-audience text
paraphrase dataset consisting of 4,938 document-level these and dissertation
academic and general-audience abstract pairs from 8 colleges authored over 25
years. We also propose a novel dynamic soft prompt generative language model,
DSPT5. For training, we leverage a contrastive-generative loss function to
learn the keyword vectors in the dynamic prompt. For inference, we adopt a
crowd-sampling decoding strategy at both semantic and structural levels to
further select the best output candidate. We evaluate DSPT5 and various
state-of-the-art large language models (LLMs) from multiple perspectives.
Results demonstrate that the SOTA LLMs does not provide satisfactory outcomes,
while the lightweight DSPT5 can achieve competitive results. To the best of our
knowledge, we are the first to build a benchmark dataset and solutions for
academic-to-general-audience text paraphrase dataset.",2024-11-07
"RAGulator: Lightweight Out-of-Context Detectors for Grounded Text
  Generation",2024-11-06 13:51:42+00:00,http://arxiv.org/abs/2411.03920v1,"Ian Poey, Jiajun Liu, Qishuai Zhong, Adrien Chenailler",cs.CL,knowledge,"Real-time detection of out-of-context LLM outputs is crucial for enterprises
looking to safely adopt RAG applications. In this work, we train lightweight
models to discriminate LLM-generated text that is semantically out-of-context
from retrieved text documents. We preprocess a combination of summarisation and
semantic textual similarity datasets to construct training data using minimal
resources. We find that DeBERTa is not only the best-performing model under
this pipeline, but it is also fast and does not require additional text
preprocessing or feature engineering. While emerging work demonstrates that
generative LLMs can also be fine-tuned and used in complex data pipelines to
achieve state-of-the-art performance, we note that speed and resource limits
are important considerations for on-premise deployment.",2024-11-06
"Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge
  Reasoning and Text Generation",2024-11-06 00:23:55+00:00,http://arxiv.org/abs/2411.03572v1,"Yuxin Dong, Shuo Wang, Hongye Zheng, Jiajing Chen, Zhenhong Zhang, Chihang Wang",cs.IR,knowledge,"This study aims to optimize the existing retrieval-augmented generation model
(RAG) by introducing a graph structure to improve the performance of the model
in dealing with complex knowledge reasoning tasks. The traditional RAG model
has the problem of insufficient processing efficiency when facing complex graph
structure information (such as knowledge graphs, hierarchical relationships,
etc.), which affects the quality and consistency of the generated results. This
study proposes a scheme to process graph structure data by combining graph
neural network (GNN), so that the model can capture the complex relationship
between entities, thereby improving the knowledge consistency and reasoning
ability of the generated text. The experiment used the Natural Questions (NQ)
dataset and compared it with multiple existing generation models. The results
show that the graph-based RAG model proposed in this paper is superior to the
traditional generation model in terms of quality, knowledge consistency, and
reasoning ability, especially when dealing with tasks that require
multi-dimensional reasoning. Through the combination of the enhancement of the
retrieval module and the graph neural network, the model in this study can
better handle complex knowledge background information and has broad potential
value in multiple practical application scenarios.",2024-11-06
"Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document
  Relation Extraction with Graph-of-Thoughts Reasoning",2024-11-05 07:12:36+00:00,http://arxiv.org/abs/2411.02864v1,"Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu","cs.CL, cs.AI, cs.IR",knowledge,"Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug"" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
""ensemble-play"", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.",2024-11-05
"A Comprehensive Survey of Small Language Models in the Era of Large
  Language Models: Techniques, Enhancements, Applications, Collaboration with
  LLMs, and Trustworthiness",2024-11-04 04:43:01+00:00,http://arxiv.org/abs/2411.03350v1,"Fali Wang, Zhiwei Zhang, Xianren Zhang, Zongyu Wu, Tzuhao Mo, Qiuhao Lu, Wanjing Wang, Rui Li, Junjie Xu, Xianfeng Tang, Qi He, Yao Ma, Ming Huang, Suhang Wang","cs.CL, cs.AI, cs.LG, 68T50 (Primary) 68T07 (Secondary), I.2.7",knowledge,"Large language models (LLM) have demonstrated emergent abilities in text
generation, question answering, and reasoning, facilitating various tasks and
domains. Despite their proficiency in various tasks, LLMs like LaPM 540B and
Llama-3.1 405B face limitations due to large parameter sizes and computational
demands, often requiring cloud API use which raises privacy concerns, limits
real-time applications on edge devices, and increases fine-tuning costs.
Additionally, LLMs often underperform in specialized domains such as healthcare
and law due to insufficient domain-specific knowledge, necessitating
specialized models. Therefore, Small Language Models (SLMs) are increasingly
favored for their low inference latency, cost-effectiveness, efficient
development, and easy customization and adaptability. These models are
particularly well-suited for resource-limited environments and domain knowledge
acquisition, addressing LLMs' challenges and proving ideal for applications
that require localized data handling for privacy, minimal inference latency for
efficiency, and domain knowledge acquisition through lightweight fine-tuning.
The rising demand for SLMs has spurred extensive research and development.
However, a comprehensive survey investigating issues related to the definition,
acquisition, application, enhancement, and reliability of SLM remains lacking,
prompting us to conduct a detailed survey on these topics. The definition of
SLMs varies widely, thus to standardize, we propose defining SLMs by their
capability to perform specialized tasks and suitability for
resource-constrained settings, setting boundaries based on the minimal size for
emergent abilities and the maximum size sustainable under resource constraints.
For other aspects, we provide a taxonomy of relevant models/methods and develop
general frameworks for each category to enhance and utilize SLMs effectively.",2024-11-04
"E2E-AFG: An End-to-End Model with Adaptive Filtering for
  Retrieval-Augmented Generation",2024-11-01 08:02:09+00:00,http://arxiv.org/abs/2411.00437v1,"Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan","cs.CL, cs.AI",knowledge,"Retrieval-augmented generation methods often neglect the quality of content
retrieved from external knowledge bases, resulting in irrelevant information or
potential misinformation that negatively affects the generation results of
large language models. In this paper, we propose an end-to-end model with
adaptive filtering for retrieval-augmented generation (E2E-AFG), which
integrates answer existence judgment and text generation into a single
end-to-end framework. This enables the model to focus more effectively on
relevant content while reducing the influence of irrelevant information and
generating accurate answers. We evaluate E2E-AFG on six representative
knowledge-intensive language datasets, and the results show that it
consistently outperforms baseline models across all tasks, demonstrating the
effectiveness and robustness of the proposed approach.",2024-11-01
"Enhancing Authorship Attribution through Embedding Fusion: A Novel
  Approach with Masked and Encoder-Decoder Language Models",2024-11-01 07:18:27+00:00,http://arxiv.org/abs/2411.00411v1,"Arjun Ramesh Kaushik, Sunil Rufus R P, Nalini Ratha","cs.CL, cs.LG",knowledge,"The increasing prevalence of AI-generated content alongside human-written
text underscores the need for reliable discrimination methods. To address this
challenge, we propose a novel framework with textual embeddings from
Pre-trained Language Models (PLMs) to distinguish AI-generated and
human-authored text. Our approach utilizes Embedding Fusion to integrate
semantic information from multiple Language Models, harnessing their
complementary strengths to enhance performance. Through extensive evaluation
across publicly available diverse datasets, our proposed approach demonstrates
strong performance, achieving classification accuracy greater than 96% and a
Matthews Correlation Coefficient (MCC) greater than 0.93. This evaluation is
conducted on a balanced dataset of texts generated from five well-known Large
Language Models (LLMs), highlighting the effectiveness and robustness of our
novel methodology.",2024-11-01
Language Models can Self-Lengthen to Generate Long Texts,2024-10-31 13:47:10+00:00,http://arxiv.org/abs/2410.23933v1,"Shanghaoran Quan, Tianyi Tang, Bowen Yu, An Yang, Dayiheng Liu, Bofei Gao, Jianhong Tu, Yichang Zhang, Jingren Zhou, Junyang Lin",cs.CL,knowledge,"Recent advancements in Large Language Models (LLMs) have significantly
enhanced their ability to process long contexts, yet a notable gap remains in
generating long, aligned outputs. This limitation stems from a training gap
where pre-training lacks effective instructions for long-text generation, and
post-training data primarily consists of short query-response pairs. Current
approaches, such as instruction backtranslation and behavior imitation, face
challenges including data quality, copyright issues, and constraints on
proprietary model usage. In this paper, we introduce an innovative iterative
training framework called Self-Lengthen that leverages only the intrinsic
knowledge and skills of LLMs without the need for auxiliary data or proprietary
models. The framework consists of two roles: the Generator and the Extender.
The Generator produces the initial response, which is then split and expanded
by the Extender. This process results in a new, longer response, which is used
to train both the Generator and the Extender iteratively. Through this process,
the models are progressively trained to handle increasingly longer responses.
Experiments on benchmarks and human evaluations show that Self-Lengthen
outperforms existing methods in long-text generation, when applied to top
open-source LLMs such as Qwen2 and LLaMA3. Our code is publicly available at
https://github.com/QwenLM/Self-Lengthen.",2024-10-31
Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment,2024-10-30 20:28:10+00:00,http://arxiv.org/abs/2410.23437v1,"Arihan Yadav, Alan McMillan","cs.LG, cs.CL, cs.IR, H.3.3; I.2.7; I.2.6",knowledge,"Retrieval-Augmented Generation (RAG) systems enhance text generation by
incorporating external knowledge but often struggle when retrieving context
across different text modalities due to semantic gaps. We introduce a
generalized projection-based method, inspired by adapter modules in transfer
learning, that efficiently bridges these gaps between various text types, such
as programming code and pseudocode, or English and French sentences. Our
approach emphasizes speed, accuracy, and data efficiency, requiring minimal
resources for training and inference. By aligning embeddings from heterogeneous
text modalities into a unified space through a lightweight projection network,
our model significantly outperforms traditional retrieval methods like the
Okapi BM25 algorithm and models like Dense Passage Retrieval (DPR), while
approaching the accuracy of Sentence Transformers. Extensive evaluations
demonstrate the effectiveness and generalizability of our method across
different tasks, highlighting its potential for real-time, resource-constrained
applications.",2024-10-30
"Parameter-Efficient Fine-Tuning in Large Models: A Survey of
  Methodologies",2024-10-24 13:58:59+00:00,http://arxiv.org/abs/2410.19878v2,"Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang","cs.CL, cs.AI, cs.LG",knowledge,"The large models, as predicted by scaling raw forecasts, have made
groundbreaking progress in many fields, particularly in natural language
generation tasks, where they have approached or even surpassed human levels.
However, the unprecedented scale of their parameters brings significant
computational and storage costs. These large models require substantial
computational resources and GPU memory to operate. When adapting large models
to specific downstream tasks, their massive parameter scale poses a significant
challenge in fine-tuning on hardware platforms with limited computational power
and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)
offers a practical solution by efficiently adjusting the parameters of large
pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts
the parameters of pre-trained large models to adapt to specific tasks or
domains, minimizing the introduction of additional parameters and the
computational resources required. This review mainly introduces the preliminary
knowledge of PEFT, the core ideas and principles of various PEFT algorithms,
the applications of PEFT, and potential future research directions. By reading
this review, we believe that interested parties can quickly grasp the PEFT
methodology, thereby accelerating its development and innovation.",2024-10-24
"Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent
  Simulation",2024-10-13 12:57:08+00:00,http://arxiv.org/abs/2410.09824v3,"Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding",cs.CL,knowledge,"Graph generation is a fundamental task that has been extensively studied in
social, technological, and scientific analysis. For modeling the dynamic graph
evolution process, traditional rule-based methods struggle to capture community
structures within graphs, while deep learning methods only focus on fitting
training graphs. This limits existing graph generators to producing graphs that
adhere to predefined rules or closely resemble training datasets, achieving
poor performance in dynamic graph generation. Given that graphs are abstract
representations arising from pairwise interactions in human activities, a
realistic simulation of human-wise interaction could provide deeper insights
into the graph evolution mechanism. With the increasing recognition of large
language models (LLMs) in simulating human behavior, we introduce
GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic
graph generation. Without training or fine-tuning process of LLM, our framework
effectively replicates seven macro-level structural characteristics in
established network science theories while surpassing existing baselines in
graph expansion tasks by 31\% on specific evaluation metrics. Through node
classification task, we validate GAG effectively preserves characteristics of
real-world network for node-wise textual features in generated text-rich graph.
Furthermore, by incorporating parallel acceleration, GAG supports generating
graphs with up to nearly 100,000 nodes or 10 million edges through large-scale
LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code
is available at https://anonymous.4open.science/r/GraphAgent-2206.",2024-10-13
"Enhancing elusive clues in knowledge learning by contrasting attention
  of language models",2024-09-26 15:30:54+00:00,http://arxiv.org/abs/2409.17954v1,"Jian Gao, Xiao Zhang, Ji Wu, Miao Li",cs.AI,knowledge,"Causal language models acquire vast amount of knowledge from general text
corpus during pretraining, but the efficiency of knowledge learning is known to
be unsatisfactory, especially when learning from knowledge-dense and
small-sized corpora. The deficiency can come from long-distance dependencies
which are hard to capture by language models, and overfitting to co-occurrence
patterns and distracting clues in the training text. To address these issues,
the paper proposes a method to enhance knowledge learning during language model
pretraining, by enhancing elusive but important clues in text discovered by the
language model themselves. We found that larger language models pay more
attention to non-obvious but important clues, which are often overlooked by
smaller language models. Therefore, we can identify these clues by contrasting
the attention weights of large and small language models. We use the identified
clues as a guide to perform token-dropout data augmentation on the training
text, and observed a significant boost in both small and large models'
performance in fact memorization. This shows that the behavior contrast between
more and less-performant language models contains important clues for knowledge
learning, and it can be ``amplified"" for a straight-forward improvement in
knowledge learning efficiency.",2024-09-26
"Zero- and Few-shot Named Entity Recognition and Text Expansion in
  Medication Prescriptions using ChatGPT",2024-09-26 09:49:27+00:00,http://arxiv.org/abs/2409.17683v1,"Natthanaphop Isaradech, Andrea Riedel, Wachiranun Sirikul, Markus Kreuzthaler, Stefan Schulz","cs.CL, cs.AI",knowledge,"Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.",2024-09-26
Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness,2024-09-25 13:18:57+00:00,http://arxiv.org/abs/2409.16914v1,"Shixuan Ma, Quan Wang",cs.CL,knowledge,"The increasing capability and widespread usage of large language models
(LLMs) highlight the desirability of automatic detection of LLM-generated text.
Zero-shot detectors, due to their training-free nature, have received
considerable attention and notable success. In this paper, we identify a new
feature, token cohesiveness, that is useful for zero-shot detection, and we
demonstrate that LLM-generated text tends to exhibit higher token cohesiveness
than human-written text. Based on this observation, we devise TOCSIN, a generic
dual-channel detection paradigm that uses token cohesiveness as a plug-and-play
module to improve existing zero-shot detectors. To calculate token
cohesiveness, TOCSIN only requires a few rounds of random token deletion and
semantic difference measurement, making it particularly suitable for a
practical black-box setting where the source model used for generation is not
accessible. Extensive experiments with four state-of-the-art base detectors on
various datasets, source models, and evaluation settings demonstrate the
effectiveness and generality of the proposed approach. Code available at:
\url{https://github.com/Shixuan-Ma/TOCSIN}.",2024-09-25
"Probing Omissions and Distortions in Transformer-based RDF-to-Text
  Models",2024-09-25 07:54:16+00:00,http://arxiv.org/abs/2409.16707v1,"Juliette Faille, Albert Gatt, Claire Gardent",cs.CL,knowledge,"In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.",2024-09-25
"ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI
  Detection for Text Origination",2024-09-22 01:13:22+00:00,http://arxiv.org/abs/2409.14285v1,"Navid Ayoobi, Lily Knab, Wen Cheng, David Pantoja, Hamidreza Alikhani, Sylvain Flamant, Jin Kim, Arjun Mukherjee","cs.CL, cs.AI",knowledge,"While large language models (LLMs) exhibit significant utility across various
domains, they simultaneously are susceptible to exploitation for unethical
purposes, including academic misconduct and dissemination of misinformation.
Consequently, AI-generated text detection systems have emerged as a
countermeasure. However, these detection mechanisms demonstrate vulnerability
to evasion techniques and lack robustness against textual manipulations. This
paper introduces back-translation as a novel technique for evading detection,
underscoring the need to enhance the robustness of current detection systems.
The proposed method involves translating AI-generated text through multiple
languages before back-translating to English. We present a model that combines
these back-translated texts to produce a manipulated version of the original
AI-generated text. Our findings demonstrate that the manipulated text retains
the original semantics while significantly reducing the true positive rate
(TPR) of existing detection methods. We evaluate this technique on nine AI
detectors, including six open-source and three proprietary systems, revealing
their susceptibility to back-translation manipulation. In response to the
identified shortcomings of existing AI text detectors, we present a
countermeasure to improve the robustness against this form of manipulation. Our
results indicate that the TPR of the proposed method declines by only 1.85%
after back-translation manipulation. Furthermore, we build a large dataset of
720k texts using eight different LLMs. Our dataset contains both human-authored
and LLM-generated texts in various domains and writing styles to assess the
performance of our method and existing detectors. This dataset is publicly
shared for the benefit of the research community.",2024-09-22
"Beyond Accuracy Optimization: Computer Vision Losses for Large Language
  Model Fine-Tuning",2024-09-20 16:46:17+00:00,http://arxiv.org/abs/2409.13641v1,"Daniele Rege Cambrin, Giuseppe Gallipoli, Irene Benedetto, Luca Cagliero, Paolo Garza","cs.CL, cs.CV",knowledge,"Large Language Models (LLMs) have demonstrated impressive performance across
various tasks. However, current training approaches combine standard
cross-entropy loss with extensive data, human feedback, or ad hoc methods to
enhance performance. These solutions are often not scalable or feasible due to
their associated costs, complexity, or resource requirements. This study
investigates the use of established semantic segmentation loss functions in
natural language generation to create a versatile, practical, and scalable
solution for fine-tuning different architectures. We evaluate their
effectiveness in solving Math Word Problems and question answering across
different models of varying sizes. For the analyzed tasks, we found that the
traditional Cross-Entropy loss represents a sub-optimal choice, while models
trained to minimize alternative (task-dependent) losses, such as Focal or
Lov\'asz, achieve a mean improvement of +42% on exact match without requiring
additional data or human feedback. These findings suggest a promising pathway
for more efficient and accessible training processes.",2024-09-20
"Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative
  Systems",2024-09-20 06:21:03+00:00,http://arxiv.org/abs/2409.13252v1,Andrea Colombo,"cs.DB, cs.AI",knowledge,"Knowledge Graphs (KGs) have been used to organize large datasets into
structured, interconnected information, enhancing data analytics across various
fields. In the legislative context, one potential natural application of KGs is
modeling the intricate set of interconnections that link laws and their
articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has
opened new opportunities in legal applications, such as text generation and
document drafting. Despite their potential, the use of LLMs in legislative
contexts is critical since it requires the absence of hallucinations and
reliance on up-to-date information, as new laws are published on a daily basis.
  This work investigates how Legislative Knowledge Graphs and LLMs can
synergize and support legislative processes. We address three key questions:
the benefits of using KGs for legislative systems, how LLM can support
legislative activities by ensuring an accurate output, and how we can allow
non-technical users to use such technologies in their activities. To this aim,
we develop Legis AI Platform, an interactive platform focused on Italian
legislation that enhances the possibility of conducting legislative analysis
and that aims to support lawmaking activities.",2024-09-20
"A Multiple-Fill-in-the-Blank Exam Approach for Enhancing Zero-Resource
  Hallucination Detection in Large Language Models",2024-09-20 04:34:30+00:00,http://arxiv.org/abs/2409.17173v1,"Satoshi Munakata, Taku Fukui, Takao Mohri","cs.CL, cs.AI, 68T50, F.2.2; I.2.7",knowledge,"Large language models (LLMs) often fabricate a hallucinatory text. Several
methods have been developed to detect such text by semantically comparing it
with the multiple versions probabilistically regenerated. However, a
significant issue is that if the storyline of each regenerated text changes,
the generated texts become incomparable, which worsen detection accuracy. In
this paper, we propose a hallucination detection method that incorporates a
multiple-fill-in-the-blank exam approach to address this storyline-changing
issue. First, our method creates a multiple-fill-in-the-blank exam by masking
multiple objects from the original text. Second, prompts an LLM to repeatedly
answer this exam. This approach ensures that the storylines of the exam answers
align with the original ones. Finally, quantifies the degree of hallucination
for each original sentence by scoring the exam answers, considering the
potential for \emph{hallucination snowballing} within the original text itself.
Experimental results show that our method alone not only outperforms existing
methods, but also achieves clearer state-of-the-art performance in the
ensembles with existing methods.",2024-09-20
"THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation
  in Large Language Models",2024-09-17 16:55:25+00:00,http://arxiv.org/abs/2409.11353v1,"Mengfei Liang, Archish Arun, Zekun Wu, Cristian Munoz, Jonathan Lutch, Emre Kazim, Adriano Koshiyama, Philip Treleaven",cs.CL,knowledge,"Hallucination, the generation of factually incorrect content, is a growing
challenge in Large Language Models (LLMs). Existing detection and mitigation
methods are often isolated and insufficient for domain-specific needs, lacking
a standardized pipeline. This paper introduces THaMES (Tool for Hallucination
Mitigations and EvaluationS), an integrated framework and library addressing
this gap. THaMES offers an end-to-end solution for evaluating and mitigating
hallucinations in LLMs, featuring automated test set generation, multifaceted
benchmarking, and adaptable mitigation strategies. It automates test set
creation from any corpus, ensuring high data quality, diversity, and
cost-efficiency through techniques like batch processing, weighted sampling,
and counterfactual validation. THaMES assesses a model's ability to detect and
reduce hallucinations across various tasks, including text generation and
binary classification, applying optimal mitigation strategies like In-Context
Learning (ICL), Retrieval Augmented Generation (RAG), and Parameter-Efficient
Fine-tuning (PEFT). Evaluations of state-of-the-art LLMs using a knowledge base
of academic papers, political news, and Wikipedia reveal that commercial models
like GPT-4o benefit more from RAG than ICL, while open-weight models like
Llama-3.1-8B-Instruct and Mistral-Nemo gain more from ICL. Additionally, PEFT
significantly enhances the performance of Llama-3.1-8B-Instruct in both
evaluation tasks.",2024-09-17
"Zero-resource Hallucination Detection for Text Generation via
  Graph-based Contextual Knowledge Triples Modeling",2024-09-17 15:38:36+00:00,http://arxiv.org/abs/2409.11283v3,"Xinyue Fang, Zhen Huang, Zhiliang Tian, Minghui Fang, Ziyi Pan, Quntian Fang, Zhihua Wen, Hengyue Pan, Dongsheng Li","cs.CL, cs.AI",knowledge,"LLMs obtain remarkable performance but suffer from hallucinations. Most
research on detecting hallucination focuses on the questions with short and
concrete correct answers that are easy to check the faithfulness. Hallucination
detections for text generation with open-ended answers are more challenging.
Some researchers use external knowledge to detect hallucinations in generated
texts, but external resources for specific scenarios are hard to access. Recent
studies on detecting hallucinations in long text without external resources
conduct consistency comparison among multiple sampled outputs. To handle long
texts, researchers split long texts into multiple facts and individually
compare the consistency of each pairs of facts. However, these methods (1)
hardly achieve alignment among multiple facts; (2) overlook dependencies
between multiple contextual facts. In this paper, we propose a graph-based
context-aware (GCA) hallucination detection for text generations, which aligns
knowledge facts and considers the dependencies between contextual knowledge
triples in consistency comparison. Particularly, to align multiple facts, we
conduct a triple-oriented response segmentation to extract multiple knowledge
triples. To model dependencies among contextual knowledge triple (facts), we
construct contextual triple into a graph and enhance triples' interactions via
message passing and aggregating via RGCN. To avoid the omission of knowledge
triples in long text, we conduct a LLM-based reverse verification via
reconstructing the knowledge triples. Experiments show that our model enhances
hallucination detection and excels all baselines.",2024-09-17
"MGSA: Multi-Granularity Graph Structure Attention for Knowledge
  Graph-to-Text Generation",2024-09-16 14:01:03+00:00,http://arxiv.org/abs/2409.10294v2,"Shanshan Wang, Chun Zhang, Ning Zhang","cs.CL, cs.AI",knowledge,"The Knowledge Graph-to-Text Generation task aims to convert structured
knowledge graphs into coherent and human-readable natural language text. Recent
efforts in this field have focused on enhancing pre-trained language models
(PLMs) by incorporating graph structure information to capture the intricate
structure details of knowledge graphs. However, most of these approaches tend
to capture only single-granularity structure information, concentrating either
on the relationships between entities within the original graph or on the
relationships between words within the same entity or across different
entities. This narrow focus results in a significant limitation: models that
concentrate solely on entity-level structure fail to capture the nuanced
semantic relationships between words, while those that focus only on word-level
structure overlook the broader relationships between original entire entities.
To overcome these limitations, this paper introduces the Multi-granularity
Graph Structure Attention (MGSA), which is based on PLMs. The encoder of the
model architecture features an entity-level structure encoding module, a
word-level structure encoding module, and an aggregation module that
synthesizes information from both structure. This multi-granularity structure
encoding approach allows the model to simultaneously capture both entity-level
and word-level structure information, providing a more comprehensive
understanding of the knowledge graph's structure information, thereby
significantly improving the quality of the generated text. We conducted
extensive evaluations of the MGSA model using two widely recognized KG-to-Text
Generation benchmark datasets, WebNLG and EventNarrative, where it consistently
outperformed models that rely solely on single-granularity structure
information, demonstrating the effectiveness of our approach.",2024-09-16
Spatio-Temporal Context Prompting for Zero-Shot Action Detection,2024-08-28 17:59:05+00:00,http://arxiv.org/abs/2408.15996v2,"Wei-Jhe Huang, Min-Hung Chen, Shang-Hong Lai","cs.CV, cs.AI",knowledge,"Spatio-temporal action detection encompasses the tasks of localizing and
classifying individual actions within a video. Recent works aim to enhance this
process by incorporating interaction modeling, which captures the relationship
between people and their surrounding context. However, these approaches have
primarily focused on fully-supervised learning, and the current limitation lies
in the lack of generalization capability to recognize unseen action categories.
In this paper, we aim to adapt the pretrained image-language models to detect
unseen actions. To this end, we propose a method which can effectively leverage
the rich knowledge of visual-language models to perform Person-Context
Interaction. Meanwhile, our Context Prompting module will utilize contextual
information to prompt labels, thereby enhancing the generation of more
representative text features. Moreover, to address the challenge of recognizing
distinct actions by multiple people at the same timestamp, we design the
Interest Token Spotting mechanism which employs pretrained visual knowledge to
find each person's interest context tokens, and then these tokens will be used
for prompting to generate text features tailored to each individual. To
evaluate the ability to detect unseen actions, we propose a comprehensive
benchmark on J-HMDB, UCF101-24, and AVA datasets. The experiments show that our
method achieves superior results compared to previous approaches and can be
further extended to multi-action videos, bringing it closer to real-world
applications. The code and data can be found in
https://webber2933.github.io/ST-CLIP-project-page.",2024-08-28
DIAGen: Diverse Image Augmentation with Generative Models,2024-08-26 19:09:13+00:00,http://arxiv.org/abs/2408.14584v1,"Tobias Lingenberg, Markus Reuter, Gopika Sudhakaran, Dominik Gojny, Stefan Roth, Simone Schaub-Meyer","cs.CV, cs.AI",knowledge,"Simple data augmentation techniques, such as rotations and flips, are widely
used to enhance the generalization power of computer vision models. However,
these techniques often fail to modify high-level semantic attributes of a
class. To address this limitation, researchers have explored generative
augmentation methods like the recently proposed DA-Fusion. Despite some
progress, the variations are still largely limited to textural changes, thus
falling short on aspects like varied viewpoints, environment, weather
conditions, or even class-level semantic attributes (eg, variations in a dog's
breed). To overcome this challenge, we propose DIAGen, building upon DA-Fusion.
First, we apply Gaussian noise to the embeddings of an object learned with
Textual Inversion to diversify generations using a pre-trained diffusion
model's knowledge. Second, we exploit the general knowledge of a text-to-text
generative model to guide the image generation of the diffusion model with
varied class-specific prompts. Finally, we introduce a weighting mechanism to
mitigate the impact of poorly generated samples. Experimental results across
various datasets show that DIAGen not only enhances semantic diversity but also
improves the performance of subsequent classifiers. The advantages of DIAGen
over standard augmentations and the DA-Fusion baseline are particularly
pronounced with out-of-distribution samples.",2024-08-26
"Biomedical Large Languages Models Seem not to be Superior to Generalist
  Models on Unseen Medical Data",2024-08-25 13:36:22+00:00,http://arxiv.org/abs/2408.13833v1,"Felix J. Dorfner, Amin Dada, Felix Busch, Marcus R. Makowski, Tianyu Han, Daniel Truhn, Jens Kleesiek, Madhumita Sushil, Jacqueline Lammert, Lisa C. Adams, Keno K. Bressem",cs.CL,knowledge,"Large language models (LLMs) have shown potential in biomedical applications,
leading to efforts to fine-tune them on domain-specific data. However, the
effectiveness of this approach remains unclear. This study evaluates the
performance of biomedically fine-tuned LLMs against their general-purpose
counterparts on a variety of clinical tasks. We evaluated their performance on
clinical case challenges from the New England Journal of Medicine (NEJM) and
the Journal of the American Medical Association (JAMA) and on several clinical
tasks (e.g., information extraction, document summarization, and clinical
coding). Using benchmarks specifically chosen to be likely outside the
fine-tuning datasets of biomedical models, we found that biomedical LLMs mostly
perform inferior to their general-purpose counterparts, especially on tasks not
focused on medical knowledge. While larger models showed similar performance on
case tasks (e.g., OpenBioLLM-70B: 66.4% vs. Llama-3-70B-Instruct: 65% on JAMA
cases), smaller biomedical models showed more pronounced underperformance
(e.g., OpenBioLLM-8B: 30% vs. Llama-3-8B-Instruct: 64.3% on NEJM cases).
Similar trends were observed across the CLUE (Clinical Language Understanding
Evaluation) benchmark tasks, with general-purpose models often performing
better on text generation, question answering, and coding tasks. Our results
suggest that fine-tuning LLMs to biomedical data may not provide the expected
benefits and may potentially lead to reduced performance, challenging
prevailing assumptions about domain-specific adaptation of LLMs and
highlighting the need for more rigorous evaluation frameworks in healthcare AI.
Alternative approaches, such as retrieval-augmented generation, may be more
effective in enhancing the biomedical capabilities of LLMs without compromising
their general knowledge.",2024-08-25
"MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders
  Synthesized via Neuro-Symbolic LLM Agents",2024-08-22 05:59:47+00:00,http://arxiv.org/abs/2408.12142v1,"Congchi Yin, Feng Li, Shu Zhang, Zike Wang, Jun Shao, Piji Li, Jianhua Chen, Xun Jiang","cs.CL, cs.AI",knowledge,"The clinical diagnosis of most mental disorders primarily relies on the
conversations between psychiatrist and patient. The creation of such diagnostic
conversation datasets is promising to boost the AI mental healthcare community.
However, directly collecting the conversations in real diagnosis scenarios is
near impossible due to stringent privacy and ethical considerations. To address
this issue, we seek to synthesize diagnostic conversation by exploiting
anonymous patient cases that are easier to access. Specifically, we design a
neuro-symbolic multi-agent framework for synthesizing the diagnostic
conversation of mental disorders with large language models. It takes patient
case as input and is capable of generating multiple diverse conversations with
one single patient case. The framework basically involves the interaction
between a doctor agent and a patient agent, and achieves text generation under
symbolic control via a dynamic diagnosis tree from a tool agent. By applying
the proposed framework, we develop the largest Chinese mental disorders
diagnosis dataset MDD-5k, which is built upon 1000 cleaned real patient cases
by cooperating with a pioneering psychiatric hospital, and contains 5000
high-quality long conversations with diagnosis results as labels. To the best
of our knowledge, it's also the first labelled Chinese mental disorders
diagnosis dataset. Human evaluation demonstrates the proposed MDD-5k dataset
successfully simulates human-like diagnostic process of mental disorders. The
dataset and code will become publicly accessible in
https://github.com/lemonsis/MDD-5k.",2024-08-22
Analysis of Plan-based Retrieval for Grounded Text Generation,2024-08-20 02:19:35+00:00,http://arxiv.org/abs/2408.10490v1,"Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat, Andrew McCallum, Manzil Zaheer","cs.CL, cs.IR",knowledge,"In text generation, hallucinations refer to the generation of seemingly
coherent text that contradicts established knowledge. One compelling hypothesis
is that hallucinations occur when a language model is given a generation task
outside its parametric knowledge (due to rarity, recency, domain, etc.). A
common strategy to address this limitation is to infuse the language models
with retrieval mechanisms, providing the model with relevant knowledge for the
task. In this paper, we leverage the planning capabilities of instruction-tuned
LLMs and analyze how planning can be used to guide retrieval to further reduce
the frequency of hallucinations. We empirically evaluate several variations of
our proposed approach on long-form text generation tasks. By improving the
coverage of relevant facts, plan-guided retrieval and generation can produce
more informative responses while providing a higher rate of attribution to
source documents.",2024-08-20
"DELIA: Diversity-Enhanced Learning for Instruction Adaptation in Large
  Language Models",2024-08-19 17:56:06+00:00,http://arxiv.org/abs/2408.10841v1,"Yuanhao Zeng, Fei Ren, Xinpeng Zhou, Yihang Wang, Yingxia Shao","cs.AI, cs.CL",knowledge,"Although instruction tuning is widely used to adjust behavior in Large
Language Models (LLMs), extensive empirical evidence and research indicates
that it is primarily a process where the model fits to specific task formats,
rather than acquiring new knowledge or capabilities. We propose that this
limitation stems from biased features learned during instruction tuning, which
differ from ideal task-specfic features, leading to learn less underlying
semantics in downstream tasks. However, ideal features are unknown and
incalculable, constraining past work to rely on prior knowledge to assist
reasoning or training, which limits LLMs' capabilities to the developers'
abilities, rather than data-driven scalable learning. In our paper, through our
novel data synthesis method, DELIA (Diversity-Enhanced Learning for Instruction
Adaptation), we leverage the buffering effect of extensive diverse data in LLMs
training to transform biased features in instruction tuning into approximations
of ideal features, without explicit prior ideal features. Experiments show
DELIA's better performance compared to common instruction tuning and other
baselines. It outperforms common instruction tuning by 17.07%-33.41% on
Icelandic-English translation bleurt score (WMT-21 dataset, gemma-7b-it) and
improves accuracy by 36.1% on formatted text generation (Llama2-7b-chat).
Notably, among knowledge injection methods we've known, DELIA uniquely align
the internal representations of new special tokens with their prior semantics.",2024-08-19
"SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From
  Pre-Trained Foundation Models",2024-08-19 17:32:15+00:00,http://arxiv.org/abs/2408.10174v2,"Anke Tang, Li Shen, Yong Luo, Shuai Xie, Han Hu, Lefei Zhang, Bo Du, Dacheng Tao","cs.LG, cs.AI",knowledge,"Deep model training on extensive datasets is increasingly becoming
cost-prohibitive, prompting the widespread adoption of deep model fusion
techniques to leverage knowledge from pre-existing models. From simple weight
averaging to more sophisticated methods like AdaMerging, model fusion
effectively improves model performance and accelerates the development of new
models. However, potential interference between parameters of individual models
and the lack of interpretability in the fusion progress remain significant
challenges. Existing methods often try to resolve the parameter interference
issue by evaluating attributes of parameters, such as their magnitude or sign,
or by parameter pruning. In this study, we begin by examining the fine-tuning
of linear layers through the lens of subspace analysis and explicitly define
parameter interference as an optimization problem to shed light on this
subject. Subsequently, we introduce an innovative approach to model fusion
called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which
allows for the upscaling of source models into an MoE model without extra data
or further training. Our approach relies on the observation that fine-tuning
mostly keeps the important parts from the pre-training, but it uses less
significant or unused areas to adapt to new tasks. Also, the issue of parameter
interference, which is intrinsically intractable in the original parameter
space, can be managed by expanding the dimensions. We conduct extensive
experiments across diverse scenarios, such as image classification and text
generation tasks, using full fine-tuning and LoRA fine-tuning, and we apply our
method to large language models (CLIP models, Flan-T5 models, and Mistral-7B
models), highlighting the adaptability and scalability of SMILE. Code is
available at https://github.com/tanganke/fusion_bench",2024-08-19
Rhyme-aware Chinese lyric generator based on GPT,2024-08-19 16:17:20+00:00,http://arxiv.org/abs/2408.10130v1,"Yixiao Yuan, Yangchen Huang, Yu Ma, Xinjin Li, Zhenglin Li, Yiming Shi, Huapeng Zhou","cs.CL, cs.AI",knowledge,"Neural language representation models such as GPT, pre-trained on large-scale
corpora, can effectively capture rich semantic patterns from plain text and be
fine-tuned to consistently improve natural language generation performance.
However, existing pre-trained language models used to generate lyrics rarely
consider rhyme information, which is crucial in lyrics. Using a pre-trained
model directly results in poor performance. To enhance the rhyming quality of
generated lyrics, we incorporate integrated rhyme information into our model,
thereby improving lyric generation performance.",2024-08-19
"LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial
  Description",2024-08-09 09:22:40+00:00,http://arxiv.org/abs/2408.04957v3,"Yizhang Jin, Jian Li, Jiangning Zhang, Jianlong Hu, Zhenye Gan, Xin Tan, Yong Liu, Yabiao Wang, Chengjie Wang, Lizhuang Ma","cs.CV, cs.AI",knowledge,"Visual Spatial Description (VSD) aims to generate texts that describe the
spatial relationships between objects within images. Traditional visual spatial
relationship classification (VSRC) methods typically output the spatial
relationship between two objects in an image, often neglecting world knowledge
and lacking general language capabilities. In this paper, we propose a Large
Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD,
which is designed for the classification, description, and open-ended
description of visual spatial relationships. Specifically, the model first
constructs a VSD instruction-following dataset using given figure-caption pairs
for the three tasks. It then employs LoRA to fine-tune a Large Language and
Vision Assistant for VSD, which has 13 billion parameters and supports
high-resolution images. Finally, a large language model (Qwen-2) is used to
refine the generated sentences, enhancing their diversity and accuracy.
LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can
follow open-ended instructions to assist with inquiries about object
relationships in images.",2024-08-09
Cool-Fusion: Fuse Large Language Models without Training,2024-07-29 09:02:19+00:00,http://arxiv.org/abs/2407.19807v1,"Cong Liu, Xiaojun Quan, Yan Pan, Liang Lin, Weigang Wu, Xu Chen",cs.CL,knowledge,"We focus on the problem of fusing two or more heterogeneous large language
models (LLMs) to facilitate their complementary strengths. One of the
challenges on model fusion is high computational load, i.e. to fine-tune or to
align vocabularies via combinatorial optimization. To this end, we propose
\emph{Cool-Fusion}, a simple yet effective approach that fuses the knowledge of
heterogeneous source LLMs to leverage their complementary strengths.
\emph{Cool-Fusion} is the first method that does not require any type of
training like the ensemble approaches. But unlike ensemble methods, it is
applicable to any set of source LLMs that have different vocabularies. The
basic idea is to have each source LLM individually generate tokens until the
tokens can be decoded into a text segment that ends at word boundaries common
to all source LLMs. Then, the source LLMs jointly rerank the generated text
segment and select the best one, which is the fused text generation in one
step. Extensive experiments are conducted across a variety of benchmark
datasets. On \emph{GSM8K}, \emph{Cool-Fusion} increases accuracy from three
strong source LLMs by a significant 8\%-17.8\%.",2024-07-29
Positive Text Reframing under Multi-strategy Optimization,2024-07-25 10:58:42+00:00,http://arxiv.org/abs/2407.17940v2,"Shutong Jia, Biwei Cao, Qingqing Gao, Jiuxin Cao, Bo Liu","cs.CL, cs.AI",knowledge,"Differing from sentiment transfer, positive reframing seeks to substitute
negative perspectives with positive expressions while preserving the original
meaning. With the emergence of pre-trained language models (PLMs), it is
possible to achieve acceptable results by fine-tuning PLMs. Nevertheless,
generating fluent, diverse and task-constrained reframing text remains a
significant challenge. To tackle this issue, a \textbf{m}ulti-\textbf{s}trategy
\textbf{o}ptimization \textbf{f}ramework (MSOF) is proposed in this paper.
Starting from the objective of positive reframing, we first design positive
sentiment reward and content preservation reward to encourage the model to
transform the negative expressions of the original text while ensuring the
integrity and consistency of the semantics. Then, different decoding
optimization approaches are introduced to improve the quality of text
generation. Finally, based on the modeling formula of positive reframing, we
propose a multi-dimensional re-ranking method that further selects candidate
sentences from three dimensions: strategy consistency, text similarity and
fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate
our framework achieves significant improvements on unconstrained and controlled
positive reframing tasks.",2024-07-25
"The Power of Combining Data and Knowledge: GPT-4o is an Effective
  Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of
  Lung Cancer",2024-07-25 09:42:24+00:00,http://arxiv.org/abs/2407.17900v2,"Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu","cs.CL, cs.LG",knowledge,"Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.765 and an AP value of 0.415 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.",2024-07-25
"Are Large Language Models Possible to Conduct Cognitive Behavioral
  Therapy?",2024-07-25 03:01:47+00:00,http://arxiv.org/abs/2407.17730v1,"Hao Shen, Zihan Li, Minqiang Yang, Minghui Ni, Yongfeng Tao, Zhengyang Yu, Weihao Zheng, Chen Xu, Bin Hu",cs.CL,knowledge,"In contemporary society, the issue of psychological health has become
increasingly prominent, characterized by the diversification, complexity, and
universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently
the most influential and clinically effective psychological treatment method
with no side effects, has limited coverage and poor quality in most countries.
In recent years, researches on the recognition and intervention of emotional
disorders using large language models (LLMs) have been validated, providing new
possibilities for psychological assistance therapy. However, are LLMs truly
possible to conduct cognitive behavioral therapy? Many concerns have been
raised by mental health experts regarding the use of LLMs for therapy. Seeking
to answer this question, we collected real CBT corpus from online video
websites, designed and conducted a targeted automatic evaluation framework
involving the evaluation of emotion tendency of generated text, structured
dialogue pattern and proactive inquiry ability. For emotion tendency, we
calculate the emotion tendency score of the CBT dialogue text generated by each
model. For structured dialogue pattern, we use a diverse range of automatic
evaluation metrics to compare speaking style, the ability to maintain
consistency of topic and the use of technology in CBT between different models
. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning
Ability) metric. We also evaluated the CBT ability of the LLM after integrating
a CBT knowledge base to explore the help of introducing additional knowledge to
enhance the model's CBT counseling ability. Four LLM variants with excellent
performance on natural language processing are evaluated, and the experimental
result shows the great potential of LLMs in psychological counseling realm,
especially after combining with other technological means.",2024-07-25
"Generative artificial intelligence in dentistry: Current approaches and
  future challenges",2024-07-24 03:33:47+00:00,http://arxiv.org/abs/2407.17532v1,"Fabián Villena, Claudia Véliz, Rosario García-Huidobro, Sebastián Aguayo",cs.CL,knowledge,"Artificial intelligence (AI) has become a commodity for people because of the
advent of generative AI (GenAI) models that bridge the usability gap of AI by
providing a natural language interface to interact with complex models. These
GenAI models range from text generation - such as two-way chat systems - to the
generation of image or video from textual descriptions input by a user. These
advancements in AI have impacted Dentistry in multiple aspects. In dental
education, the student now has the opportunity to solve a plethora of questions
by only prompting a GenAI model and have the answer in a matter of seconds.
GenAI models can help us deliver better patient healthcare by helping
practitioners gather knowledge quickly and efficiently. Finally, GenAI can also
be used in dental research, where the applications range from new drug
discovery to assistance in academic writing. In this review, we first define
GenAI models and describe their multiple generation modalities; then, we
explain and discuss their current and potential applications in Dentistry; and
finally, we describe the challenges these new technologies impose in our area.",2024-07-24
"Robust Privacy Amidst Innovation with Large Language Models Through a
  Critical Assessment of the Risks",2024-07-23 04:20:14+00:00,http://arxiv.org/abs/2407.16166v1,"Yao-Shun Chuang, Atiquer Rahman Sarkar, Noman Mohammed, Xiaoqian Jiang",cs.CL,knowledge,"This study examines integrating EHRs and NLP with large language models
(LLMs) to improve healthcare data management and patient care. It focuses on
using advanced models to create secure, HIPAA-compliant synthetic patient notes
for biomedical research. The study used de-identified and re-identified MIMIC
III datasets with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic notes.
Text generation employed templates and keyword extraction for contextually
relevant notes, with one-shot generation for comparison. Privacy assessment
checked PHI occurrence, while text utility was tested using an ICD-9 coding
task. Text quality was evaluated with ROUGE and cosine similarity metrics to
measure semantic similarity with source notes. Analysis of PHI occurrence and
text utility via the ICD-9 coding task showed that the keyword-based method had
low risk and good performance. One-shot generation showed the highest PHI
exposure and PHI co-occurrence, especially in geographic location and date
categories. The Normalized One-shot method achieved the highest classification
accuracy. Privacy analysis revealed a critical balance between data utility and
privacy protection, influencing future data use and sharing. Re-identified data
consistently outperformed de-identified data. This study demonstrates the
effectiveness of keyword-based methods in generating privacy-protecting
synthetic clinical notes that retain data usability, potentially transforming
clinical data-sharing practices. The superior performance of re-identified over
de-identified data suggests a shift towards methods that enhance utility and
privacy by using dummy PHIs to perplex privacy attacks.",2024-07-23
"Finetuning Generative Large Language Models with Discrimination
  Instructions for Knowledge Graph Completion",2024-07-23 02:25:01+00:00,http://arxiv.org/abs/2407.16127v1,"Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu","cs.CL, cs.AI",knowledge,"Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.",2024-07-23
"Intelligent Artistic Typography: A Comprehensive Review of Artistic Text
  Design and Generation",2024-07-20 06:45:09+00:00,http://arxiv.org/abs/2407.14774v1,"Yuhang Bai, Zichuan Huang, Wenshuo Gao, Shuai Yang, Jiaying Liu","cs.CV, cs.AI, cs.GR",knowledge,"Artistic text generation aims to amplify the aesthetic qualities of text
while maintaining readability. It can make the text more attractive and better
convey its expression, thus enjoying a wide range of application scenarios such
as social media display, consumer electronics, fashion, and graphic design.
Artistic text generation includes artistic text stylization and semantic
typography. Artistic text stylization concentrates on the text effect overlaid
upon the text, such as shadows, outlines, colors, glows, and textures. By
comparison, semantic typography focuses on the deformation of the characters to
strengthen their visual representation by mimicking the semantic understanding
within the text. This overview paper provides an introduction to both artistic
text stylization and semantic typography, including the taxonomy, the key ideas
of representative methods, and the applications in static and dynamic artistic
text generation. Furthermore, the dataset and evaluation metrics are
introduced, and the future directions of artistic text generation are
discussed. A comprehensive list of artistic text generation models studied in
this review is available at
https://github.com/williamyang1991/Awesome-Artistic-Typography/.",2024-07-20
Check-Eval: A Checklist-based Approach for Evaluating Text Quality,2024-07-19 17:14:16+00:00,http://arxiv.org/abs/2407.14467v1,"Jayr Pereira, Roberto Lotufo","cs.CL, cs.AI",knowledge,"Evaluating the quality of text generated by large language models (LLMs)
remains a significant challenge. Traditional metrics often fail to align well
with human judgments, particularly in tasks requiring creativity and nuance. In
this paper, we propose Check-Eval, a novel evaluation framework leveraging LLMs
to assess the quality of generated text through a checklist-based approach.
Check-Eval can be employed as both a reference-free and reference-dependent
evaluation method, providing a structured and interpretable assessment of text
quality. The framework consists of two main stages: checklist generation and
checklist evaluation. We validate Check-Eval on two benchmark datasets:
Portuguese Legal Semantic Textual Similarity and SummEval. Our results
demonstrate that Check-Eval achieves higher correlations with human judgments
compared to existing metrics, such as G-Eval and GPTScore, underscoring its
potential as a more reliable and effective evaluation framework for natural
language generation tasks. The code for our experiments is available at
https://anonymous.4open.science/r/check-eval-0DB4.",2024-07-19
"From Instruction to Insight: Exploring the Functional and Semantic Roles
  of Text in Interactive Dashboards",2024-07-19 16:48:00+00:00,http://arxiv.org/abs/2407.14451v1,"Nicole Sultanum, Vidya Setlur",cs.HC,knowledge,"There is increased interest in the interplay between text and visuals in the
field of data visualization. However, this attention has predominantly been on
the use of text in standalone visualizations or augmenting text stories
supported by a series of independent views. In this paper, we shift from the
traditional focus on single-chart annotations to characterize the nuanced but
crucial communication role of text in the complex environment of interactive
dashboards. Through a survey and analysis of 190 dashboards in the wild, plus
13 expert interview sessions with experienced dashboard authors, we highlight
the distinctive nature of text as an integral component of the dashboard
experience, while delving into the categories, semantic levels, and functional
roles of text, and exploring how these text elements are coalesced by dashboard
authors to guide and inform dashboard users.
  Our contributions are: 1) we distill qualitative and quantitative findings
from our studies to characterize current practices of text use in dashboards,
including a categorization of text-based components and design patterns; 2) we
leverage current practices and existing literature to propose, discuss, and
validate recommended practices for text in dashboards, embodied as 12
heuristics that underscore the semantic and functional role of text in offering
navigational cues, contextualizing data insights, supporting reading order,
etc; 3) we reflect on our findings to identify gaps and propose opportunities
for data visualization researchers to push the boundaries on text usage for
dashboards, from authoring support and interactivity to text generation and
content personalization.
  Our research underscores the significance of elevating text as a first-class
citizen in data visualization, and the need to support the inclusion of textual
components and their interactive affordances in dashboard design.",2024-07-19
"KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with
  Large Language Models",2024-07-19 12:13:08+00:00,http://arxiv.org/abs/2407.14239v1,"Kemou Jiang, Xuan Cai, Zhiyong Cui, Aoyong Li, Yilong Ren, Haiyang Yu, Hao Yang, Daocheng Fu, Licheng Wen, Pinlong Cai",cs.AI,knowledge,"Large language models (LLMs) as autonomous agents offer a novel avenue for
tackling real-world challenges through a knowledge-driven manner. These
LLM-enhanced methodologies excel in generalization and interpretability.
However, the complexity of driving tasks often necessitates the collaboration
of multiple, heterogeneous agents, underscoring the need for such LLM-driven
agents to engage in cooperative knowledge sharing and cognitive synergy.
Despite the promise of LLMs, current applications predominantly center around
single agent scenarios. To broaden the horizons of knowledge-driven strategies
and bolster the generalization capabilities of autonomous agents, we propose
the KoMA framework consisting of multi-agent interaction, multi-step planning,
shared-memory, and ranking-based reflection modules to enhance multi-agents'
decision-making in complex driving scenarios. Based on the framework's
generated text descriptions of driving scenarios, the multi-agent interaction
module enables LLM agents to analyze and infer the intentions of surrounding
vehicles, akin to human cognition. The multi-step planning module enables LLM
agents to analyze and obtain final action decisions layer by layer to ensure
consistent goals for short-term action decisions. The shared memory module can
accumulate collective experience to make superior decisions, and the
ranking-based reflection module can evaluate and improve agent behavior with
the aim of enhancing driving safety and efficiency. The KoMA framework not only
enhances the robustness and adaptability of autonomous driving agents but also
significantly elevates their generalization capabilities across diverse
scenarios. Empirical results demonstrate the superiority of our approach over
traditional methods, particularly in its ability to handle complex,
unpredictable driving environments without extensive retraining.",2024-07-19
"Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by
  Direct Preference Optimization",2024-07-19 03:12:10+00:00,http://arxiv.org/abs/2407.14000v1,"Md Sultan Al Nahian, Ramakanth Kavuluru","cs.IR, cs.CL, cs.LG",knowledge,"Extractive question answering over clinical text is a crucial need to help
deal with the deluge of clinical text generated in hospitals. While encoder
models (e.g., BERT) have been popular for this reading comprehension task,
recently encoder-decoder models (e.g., T5) are on the rise. There is also the
emergence of preference optimization techniques to align decoder-only LLMs with
human preferences. In this paper, we combine encoder-decoder models with the
direct preference optimization (DPO) method to improve over prior state of the
art for the RadQA radiology question answering task by 12-15 F1 points. To the
best of our knowledge, this effort is the first to show that DPO method also
works for reading comprehension via novel heuristics to generate preference
data without human inputs.",2024-07-19
BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs,2024-07-14 15:17:02+00:00,http://arxiv.org/abs/2407.10241v2,"Zhiting Fan, Ruizhe Chen, Ruiling Xu, Zuozhu Liu",cs.CL,knowledge,"Evaluating the bias in Large Language Models (LLMs) becomes increasingly
crucial with their rapid development. However, existing evaluation methods rely
on fixed-form outputs and cannot adapt to the flexible open-text generation
scenarios of LLMs (e.g., sentence completion and question answering). To
address this, we introduce BiasAlert, a plug-and-play tool designed to detect
social bias in open-text generations of LLMs. BiasAlert integrates external
human knowledge with inherent reasoning capabilities to detect bias reliably.
Extensive experiments demonstrate that BiasAlert significantly outperforms
existing state-of-the-art methods like GPT4-as-A-Judge in detecting bias.
Furthermore, through application studies, we demonstrate the utility of
BiasAlert in reliable LLM bias evaluation and bias mitigation across various
scenarios. Model and code will be publicly released.",2024-07-14
"Is Contrasting All You Need? Contrastive Learning for the Detection and
  Attribution of AI-generated Text",2024-07-12 15:44:56+00:00,http://arxiv.org/abs/2407.09364v1,"Lucio La Cava, Davide Costa, Andrea Tagarelli","cs.CL, cs.AI, cs.CY, cs.HC, physics.soc-ph",knowledge,"The significant progress in the development of Large Language Models has
contributed to blurring the distinction between human and AI-generated text.
The increasing pervasiveness of AI-generated text and the difficulty in
detecting it poses new challenges for our society. In this paper, we tackle the
problem of detecting and attributing AI-generated text by proposing WhosAI, a
triplet-network contrastive learning framework designed to predict whether a
given input text has been generated by humans or AI and to unveil the
authorship of the text. Unlike most existing approaches, our proposed framework
is conceived to learn semantic similarity representations from multiple
generators at once, thus equally handling both detection and attribution tasks.
Furthermore, WhosAI is model-agnostic and scalable to the release of new AI
text-generation models by incorporating their generated instances into the
embedding space learned by our framework. Experimental results on the
TuringBench benchmark of 200K news articles show that our proposed framework
achieves outstanding results in both the Turing Test and Authorship Attribution
tasks, outperforming all the methods listed in the TuringBench benchmark
leaderboards.",2024-07-12
"Who Writes the Review, Human or AI?",2024-05-30 17:38:44+00:00,http://arxiv.org/abs/2405.20285v1,"Panagiotis C. Theocharopoulos, Spiros V. Georgakopoulos, Sotiris K. Tasoulis, Vassilis P. Plagianakos",cs.CL,knowledge,"With the increasing use of Artificial Intelligence in Natural Language
Processing, concerns have been raised regarding the detection of AI-generated
text in various domains. This study aims to investigate this issue by proposing
a methodology to accurately distinguish AI-generated and human-written book
reviews. Our approach utilizes transfer learning, enabling the model to
identify generated text across different topics while improving its ability to
detect variations in writing style and vocabulary. To evaluate the
effectiveness of the proposed methodology, we developed a dataset consisting of
real book reviews and AI-generated reviews using the recently proposed Vicuna
open-source language model. The experimental results demonstrate that it is
feasible to detect the original source of text, achieving an accuracy rate of
96.86%. Our efforts are oriented toward the exploration of the capabilities and
limitations of Large Language Models in the context of text identification.
Expanding our knowledge in these aspects will be valuable for effectively
navigating similar models in the future and ensuring the integrity and
authenticity of human-generated content.",2024-05-30
"Kernel Language Entropy: Fine-grained Uncertainty Quantification for
  LLMs from Semantic Similarities",2024-05-30 12:42:05+00:00,http://arxiv.org/abs/2405.20003v1,"Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen","cs.LG, cs.AI, cs.CL",knowledge,"Uncertainty quantification in Large Language Models (LLMs) is crucial for
applications where safety and reliability are important. In particular,
uncertainty can be used to improve the trustworthiness of LLMs by detecting
factually incorrect model responses, commonly called hallucinations.
Critically, one should seek to capture the model's semantic uncertainty, i.e.,
the uncertainty over the meanings of LLM outputs, rather than uncertainty over
lexical or syntactic variations that do not affect answer correctness. To
address this problem, we propose Kernel Language Entropy (KLE), a novel method
for uncertainty estimation in white- and black-box LLMs. KLE defines positive
semidefinite unit trace kernels to encode the semantic similarities of LLM
outputs and quantifies uncertainty using the von Neumann entropy. It considers
pairwise semantic dependencies between answers (or semantic clusters),
providing more fine-grained uncertainty estimates than previous methods based
on hard clustering of answers. We theoretically prove that KLE generalizes the
previous state-of-the-art method called semantic entropy and empirically
demonstrate that it improves uncertainty quantification performance across
multiple natural language generation datasets and LLM architectures.",2024-05-30
Large Language Model Watermark Stealing With Mixed Integer Programming,2024-05-30 04:11:17+00:00,http://arxiv.org/abs/2405.19677v1,"Zhaoxi Zhang, Xiaomei Zhang, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shengshan Hu, Asif Gill, Shirui Pan","cs.CR, cs.AI",knowledge,"The Large Language Model (LLM) watermark is a newly emerging technique that
shows promise in addressing concerns surrounding LLM copyright, monitoring
AI-generated text, and preventing its misuse. The LLM watermark scheme commonly
includes generating secret keys to partition the vocabulary into green and red
lists, applying a perturbation to the logits of tokens in the green list to
increase their sampling likelihood, thus facilitating watermark detection to
identify AI-generated text if the proportion of green tokens exceeds a
threshold. However, recent research indicates that watermarking methods using
numerous keys are susceptible to removal attacks, such as token editing,
synonym substitution, and paraphrasing, with robustness declining as the number
of keys increases. Therefore, the state-of-the-art watermark schemes that
employ fewer or single keys have been demonstrated to be more robust against
text editing and paraphrasing. In this paper, we propose a novel green list
stealing attack against the state-of-the-art LLM watermark scheme and
systematically examine its vulnerability to this attack. We formalize the
attack as a mixed integer programming problem with constraints. We evaluate our
attack under a comprehensive threat model, including an extreme scenario where
the attacker has no prior knowledge, lacks access to the watermark detector
API, and possesses no information about the LLM's parameter settings or
watermark injection/detection scheme. Extensive experiments on LLMs, such as
OPT and LLaMA, demonstrate that our attack can successfully steal the green
list and remove the watermark across all settings.",2024-05-30
"WRDScore: New Metric for Evaluation of Natural Language Generation
  Models",2024-05-29 16:00:46+00:00,http://arxiv.org/abs/2405.19220v1,Ravil Mussabayev,"cs.CL, cs.AI",knowledge,"The problem of natural language generation, and, more specifically, method
name prediction, faces significant difficulties when proposed models need to be
evaluated on test data. Such a metric would need to consider the versatility
with which a single method can be named, with respect to both semantics and
syntax. Measuring the direct overlap between the predicted and reference (true)
sequences will not be able to capture these subtleties. Other existing
embedding based metrics either do not measure precision and recall or impose
strict unrealistic assumptions on both sequences. To address these issues, we
propose a new metric that, on the one hand, is very simple and lightweight,
and, on the other hand, is able to calculate precision and recall without
resorting to any assumptions while obtaining good performance with respect to
the human judgement.",2024-05-29
"MetaToken: Detecting Hallucination in Image Descriptions by Meta
  Classification",2024-05-29 15:28:42+00:00,http://arxiv.org/abs/2405.19186v1,"Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk","cs.CV, cs.CL, cs.LG, I.4",knowledge,"Large Vision Language Models (LVLMs) have shown remarkable capabilities in
multimodal tasks like visual question answering or image captioning. However,
inconsistencies between the visual information and the generated text, a
phenomenon referred to as hallucinations, remain an unsolved problem with
regard to the trustworthiness of LVLMs. To address this problem, recent works
proposed to incorporate computationally costly Large (Vision) Language Models
in order to detect hallucinations on a sentence- or subsentence-level. In this
work, we introduce MetaToken, a lightweight binary classifier to detect
hallucinations on the token-level at negligible cost. Based on a statistical
analysis, we reveal key factors of hallucinations in LVLMs which have been
overseen in previous works. MetaToken can be applied to any open-source LVLM
without any knowledge about ground truth data providing a reliable detection of
hallucinations. We evaluate our method on four state-of-the-art LVLMs
demonstrating the effectiveness of our approach.",2024-05-29
Alt4Blind: A User Interface to Simplify Charts Alt-Text Creation,2024-05-29 14:19:57+00:00,http://arxiv.org/abs/2405.19111v1,"Omar Moured, Shahid Ali Farooqui, Karin Muller, Sharifeh Fadaeijouybari, Thorsten Schwarz, Mohammed Javed, Rainer Stiefelhagen","cs.CV, cs.HC",knowledge,"Alternative Texts (Alt-Text) for chart images are essential for making
graphics accessible to people with blindness and visual impairments.
Traditionally, Alt-Text is manually written by authors but often encounters
issues such as oversimplification or complication. Recent trends have seen the
use of AI for Alt-Text generation. However, existing models are susceptible to
producing inaccurate or misleading information. We address this challenge by
retrieving high-quality alt-texts from similar chart images, serving as a
reference for the user when creating alt-texts. Our three contributions are as
follows: (1) we introduce a new benchmark comprising 5,000 real images with
semantically labeled high-quality Alt-Texts, collected from Human Computer
Interaction venues. (2) We developed a deep learning-based model to rank and
retrieve similar chart images that share the same visual and textual semantics.
(3) We designed a user interface (UI) to facilitate the alt-text creation
process. Our preliminary interviews and investigations highlight the usability
of our UI. For the dataset and further details, please refer to our project
page: https://moured.github.io/alt4blind/.",2024-05-29
"LMO-DP: Optimizing the Randomization Mechanism for Differentially
  Private Fine-Tuning (Large) Language Models",2024-05-29 05:32:50+00:00,http://arxiv.org/abs/2405.18776v1,"Qin Yang, Meisam Mohammad, Han Wang, Ali Payani, Ashish Kundu, Kai Shu, Yan Yan, Yuan Hong","cs.CR, cs.CL, cs.LG",knowledge,"Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants
have been proposed to ensure rigorous privacy for fine-tuning large-scale
pre-trained language models. However, they rely heavily on the Gaussian
mechanism, which may overly perturb the gradients and degrade the accuracy,
especially in stronger privacy regimes (e.g., the privacy budget $\epsilon <
3$). To address such limitations, we propose a novel Language Model-based
Optimal Differential Privacy (LMO-DP) mechanism, which takes the first step to
enable the tight composition of accurately fine-tuning (large) language models
with a sub-optimal DP mechanism, even in strong privacy regimes (e.g., $0.1\leq
\epsilon<3$). Furthermore, we propose a novel offline optimal noise search
method to efficiently derive the sub-optimal DP that significantly reduces the
noise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters)
on the SST-2 dataset can achieve an accuracy of 92.20% (given $\epsilon=0.3$,
$\delta=10^{-10}$) by drastically outperforming the Gaussian mechanism (e.g.,
$\sim 50\%$ for small $\epsilon$ and $\delta$). We also draw similar findings
on the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP
is also the first solution to accurately fine-tune Llama-2 with strong
differential privacy guarantees. The code will be released soon and available
upon request.",2024-05-29
Augmenting Textual Generation via Topology Aware Retrieval,2024-05-27 19:02:18+00:00,http://arxiv.org/abs/2405.17602v1,"Yu Wang, Nedim Lipka, Ruiyi Zhang, Alexa Siu, Yuying Zhao, Bo Ni, Xin Wang, Ryan Rossi, Tyler Derr",cs.IR,knowledge,"Despite the impressive advancements of Large Language Models (LLMs) in
generating text, they are often limited by the knowledge contained in the input
and prone to producing inaccurate or hallucinated content. To tackle these
issues, Retrieval-augmented Generation (RAG) is employed as an effective
strategy to enhance the available knowledge base and anchor the responses in
reality by pulling additional texts from external databases. In real-world
applications, texts are often linked through entities within a graph, such as
citations in academic papers or comments in social networks. This paper
exploits these topological relationships to guide the retrieval process in RAG.
Specifically, we explore two kinds of topological connections: proximity-based,
focusing on closely connected nodes, and role-based, which looks at nodes
sharing similar subgraph structures. Our empirical research confirms their
relevance to text relationships, leading us to develop a Topology-aware
Retrieval-augmented Generation framework. This framework includes a retrieval
module that selects texts based on their topological relationships and an
aggregation module that integrates these texts into prompts to stimulate LLMs
for text generation. We have curated established text-attributed networks and
conducted comprehensive experiments to validate the effectiveness of this
framework, demonstrating its potential to enhance RAG with topological
awareness.",2024-05-27
A Library for Automatic Natural Language Generation of Spanish Texts,2024-05-27 15:44:06+00:00,http://arxiv.org/abs/2405.17280v1,"Silvia García-Méndez, Milagros Fernández-Gavilanes, Enrique Costa-Montenegro, Jonathan Juncal-Martínez, F. Javier González-Castaño",cs.CL,knowledge,"In this article we present a novel system for natural language generation
(NLG) of Spanish sentences from a minimum set of meaningful words (such as
nouns, verbs and adjectives) which, unlike other state-of-the-art solutions,
performs the NLG task in a fully automatic way, exploiting both knowledge-based
and statistical approaches. Relying on its linguistic knowledge of vocabulary
and grammar, the system is able to generate complete, coherent and correctly
spelled sentences from the main word sets presented by the user. The system,
which was designed to be integrable, portable and efficient, can be easily
adapted to other languages by design and can feasibly be integrated in a wide
range of digital devices. During its development we also created a
supplementary lexicon for Spanish, aLexiS, with wide coverage and high
precision, as well as syntactic trees from a freely available definite-clause
grammar. The resulting NLG library has been evaluated both automatically and
manually (annotation). The system can potentially be used in different
application domains such as augmentative communication and automatic generation
of administrative reports or news.",2024-05-27
On the Noise Robustness of In-Context Learning for Text Generation,2024-05-27 15:22:58+00:00,http://arxiv.org/abs/2405.17264v1,"Hongfu Gao, Feipeng Zhang, Wenyu Jiang, Jun Shu, Feng Zheng, Hongxin Wei","cs.CL, cs.LG",knowledge,"Large language models (LLMs) have shown impressive performance on downstream
tasks by in-context learning (ICL), which heavily relies on the quality of
demonstrations selected from a large set of annotated examples. Recent works
claim that in-context learning is robust to noisy demonstrations in text
classification. In this work, we show that, on text generation tasks, noisy
annotations significantly hurt the performance of in-context learning. To
circumvent the issue, we propose a simple and effective approach called Local
Perplexity Ranking (LPR), which replaces the ""noisy"" candidates with their
nearest neighbors that are more likely to be clean. Our method is motivated by
analyzing the perplexity deviation caused by noisy labels and decomposing
perplexity into inherent perplexity and matching perplexity. Our key idea
behind LPR is thus to decouple the matching perplexity by performing the
ranking among the neighbors in semantic space. Our approach can prevent the
selected demonstrations from including mismatched input-label pairs while
preserving the effectiveness of the original selection methods. Extensive
experiments demonstrate the effectiveness of LPR, improving the EM score by up
to 18.75 on common benchmarks with noisy annotations.",2024-05-27
"ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with
  LLM-Enhanced Cardiological Text",2024-05-26 06:45:39+00:00,http://arxiv.org/abs/2405.19366v1,"Han Yu, Peikun Guo, Akane Sano","eess.SP, cs.AI",knowledge,"The utilization of deep learning on electrocardiogram (ECG) analysis has
brought the advanced accuracy and efficiency of cardiac healthcare diagnostics.
By leveraging the capabilities of deep learning in semantic understanding,
especially in feature extraction and representation learning, this study
introduces a new multimodal contrastive pretaining framework that aims to
improve the quality and robustness of learned representations of 12-lead ECG
signals. Our framework comprises two key components, including Cardio Query
Assistant (CQA) and ECG Semantics Integrator(ESI). CQA integrates a
retrieval-augmented generation (RAG) pipeline to leverage large language models
(LLMs) and external medical knowledge to generate detailed textual descriptions
of ECGs. The generated text is enriched with information about demographics and
waveform patterns. ESI integrates both contrastive and captioning loss to
pretrain ECG encoders for enhanced representations. We validate our approach
through various downstream tasks, including arrhythmia detection and ECG-based
subject identification. Our experimental results demonstrate substantial
improvements over strong baselines in these tasks. These baselines encompass
supervised and self-supervised learning methods, as well as prior multimodal
pretraining approaches.",2024-05-26
Certifiably Robust RAG against Retrieval Corruption,2024-05-24 13:44:25+00:00,http://arxiv.org/abs/2405.15556v1,"Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal","cs.LG, cs.CL, cs.CR",knowledge,"Retrieval-augmented generation (RAG) has been shown vulnerable to retrieval
corruption attacks: an attacker can inject malicious passages into retrieval
results to induce inaccurate responses. In this paper, we propose RobustRAG as
the first defense framework against retrieval corruption attacks. The key
insight of RobustRAG is an isolate-then-aggregate strategy: we get LLM
responses from each passage in isolation and then securely aggregate these
isolated responses. To instantiate RobustRAG, we design keyword-based and
decoding-based algorithms for securely aggregating unstructured text responses.
Notably, RobustRAG can achieve certifiable robustness: we can formally prove
and certify that, for certain queries, RobustRAG can always return accurate
responses, even when the attacker has full knowledge of our defense and can
arbitrarily inject a small number of malicious passages. We evaluate RobustRAG
on open-domain QA and long-form text generation datasets and demonstrate its
effectiveness and generalizability across various tasks and datasets.",2024-05-24
Linearly Controlled Language Generation with Performative Guarantees,2024-05-24 11:30:44+00:00,http://arxiv.org/abs/2405.15454v1,"Emily Cheng, Marco Baroni, Carmen Amo Alonso","cs.CL, cs.SY, eess.SY",knowledge,"The increasing prevalence of Large Language Models (LMs) in critical
applications highlights the need for controlled language generation strategies
that are not only computationally efficient but that also enjoy performance
guarantees. To achieve this, we use a common model of concept semantics as
linearly represented in an LM's latent space. In particular, we take the view
that natural language generation traces a trajectory in this continuous
semantic space, realized by the language model's hidden activations. This view
permits a control-theoretic treatment of text generation in latent space, in
which we propose a lightweight, gradient-free intervention that dynamically
steers trajectories away from regions corresponding to undesired meanings.
Crucially, we show that this intervention, which we compute in closed form, is
guaranteed (in probability) to steer the output into the allowed region.
Finally, we demonstrate on a toxicity avoidance objective that the intervention
steers language away from undesired content while maintaining text quality.",2024-05-24
"Evaluating Consistency and Reasoning Capabilities of Large Language
  Models",2024-04-25 10:03:14+00:00,http://arxiv.org/abs/2404.16478v1,"Yash Saxena, Sarthak Chopra, Arunendra Mani Tripathi","cs.CL, cs.AI",knowledge,"Large Language Models (LLMs) are extensively used today across various
sectors, including academia, research, business, and finance, for tasks such as
text generation, summarization, and translation. Despite their widespread
adoption, these models often produce incorrect and misleading information,
exhibiting a tendency to hallucinate. This behavior can be attributed to
several factors, with consistency and reasoning capabilities being significant
contributors. LLMs frequently lack the ability to generate explanations and
engage in coherent reasoning, leading to inaccurate responses. Moreover, they
exhibit inconsistencies in their outputs. This paper aims to evaluate and
compare the consistency and reasoning capabilities of both public and
proprietary LLMs. The experiments utilize the Boolq dataset as the ground
truth, comprising questions, answers, and corresponding explanations. Queries
from the dataset are presented as prompts to the LLMs, and the generated
responses are evaluated against the ground truth answers. Additionally,
explanations are generated to assess the models' reasoning abilities.
Consistency is evaluated by repeatedly presenting the same query to the models
and observing for variations in their responses. For measuring reasoning
capabilities, the generated explanations are compared to the ground truth
explanations using metrics such as BERT, BLEU, and F-1 scores. The findings
reveal that proprietary models generally outperform public models in terms of
both consistency and reasoning capabilities. However, even when presented with
basic general knowledge questions, none of the models achieved a score of 90\%
in both consistency and reasoning. This study underscores the direct
correlation between consistency and reasoning abilities in LLMs and highlights
the inherent reasoning challenges present in current language models.",2024-04-25
"Semantic Routing for Enhanced Performance of LLM-Assisted Intent-Based
  5G Core Network Management and Orchestration",2024-04-24 13:34:20+00:00,http://arxiv.org/abs/2404.15869v1,"Dimitrios Michael Manias, Ali Chouman, Abdallah Shami","cs.NI, cs.AI",knowledge,"Large language models (LLMs) are rapidly emerging in Artificial Intelligence
(AI) applications, especially in the fields of natural language processing and
generative AI. Not limited to text generation applications, these models
inherently possess the opportunity to leverage prompt engineering, where the
inputs of such models can be appropriately structured to articulate a model's
purpose explicitly. A prominent example of this is intent-based networking, an
emerging approach for automating and maintaining network operations and
management. This paper presents semantic routing to achieve enhanced
performance in LLM-assisted intent-based management and orchestration of 5G
core networks. This work establishes an end-to-end intent extraction framework
and presents a diverse dataset of sample user intents accompanied by a thorough
analysis of the effects of encoders and quantization on overall system
performance. The results show that using a semantic router improves the
accuracy and efficiency of the LLM deployment compared to stand-alone LLMs with
prompting architectures.",2024-04-24
"Visual Delta Generator with Large Multi-modal Models for Semi-supervised
  Composed Image Retrieval",2024-04-23 21:00:22+00:00,http://arxiv.org/abs/2404.15516v1,"Young Kyun Jang, Donghyun Kim, Zihang Meng, Dat Huynh, Ser-Nam Lim","cs.CV, cs.AI",knowledge,"Composed Image Retrieval (CIR) is a task that retrieves images similar to a
query, based on a provided textual modification. Current techniques rely on
supervised learning for CIR models using labeled triplets of the reference
image, text, target image. These specific triplets are not as commonly
available as simple image-text pairs, limiting the widespread use of CIR and
its scalability. On the other hand, zero-shot CIR can be relatively easily
trained with image-caption pairs without considering the image-to-image
relation, but this approach tends to yield lower accuracy. We propose a new
semi-supervised CIR approach where we search for a reference and its related
target images in auxiliary data and learn our large language model-based Visual
Delta Generator (VDG) to generate text describing the visual difference (i.e.,
visual delta) between the two. VDG, equipped with fluent language knowledge and
being model agnostic, can generate pseudo triplets to boost the performance of
CIR models. Our approach significantly improves the existing supervised
learning approaches and achieves state-of-the-art results on the CIR
benchmarks.",2024-04-23
"LLM-Personalize: Aligning LLM Planners with Human Preferences via
  Reinforced Self-Training for Housekeeping Robots",2024-04-22 15:35:33+00:00,http://arxiv.org/abs/2404.14285v1,"Dongge Han, Trevor McInroe, Adam Jelley, Stefano V. Albrecht, Peter Bell, Amos Storkey","cs.RO, cs.AI",knowledge,"Large language models (LLMs) have shown significant potential for robotics
applications, particularly task planning, by harnessing their language
comprehension and text generation capabilities. However, in applications such
as household robotics, a critical gap remains in the personalization of these
models to individual user preferences. We introduce LLM-Personalize, a novel
framework with an optimization pipeline designed to personalize LLM planners
for household robotics. Our LLM-Personalize framework features an LLM planner
that performs iterative planning in multi-room, partially-observable household
scenarios, making use of a scene graph constructed with local observations. The
generated plan consists of a sequence of high-level actions which are
subsequently executed by a controller. Central to our approach is the
optimization pipeline, which combines imitation learning and iterative
self-training to personalize the LLM planner. In particular, the imitation
learning phase performs initial LLM alignment from demonstrations, and
bootstraps the model to facilitate effective iterative self-training, which
further explores and aligns the model to user preferences. We evaluate
LLM-Personalize on Housekeep, a challenging simulated real-world 3D benchmark
for household rearrangements, and show that LLM-Personalize achieves more than
a 30 percent increase in success rate over existing LLM planners, showcasing
significantly improved alignment with human preferences. Project page:
https://donggehan.github.io/projectllmpersonalize/.",2024-04-22
Context-Enhanced Language Models for Generating Multi-Paper Citations,2024-04-22 04:30:36+00:00,http://arxiv.org/abs/2404.13865v1,"Avinash Anand, Kritarth Prasad, Ujjwal Goel, Mohit Gupta, Naman Lal, Astha Verma, Rajiv Ratn Shah",cs.CL,knowledge,"Citation text plays a pivotal role in elucidating the connection between
scientific documents, demanding an in-depth comprehension of the cited paper.
Constructing citations is often time-consuming, requiring researchers to delve
into extensive literature and grapple with articulating relevant content. To
address this challenge, the field of citation text generation (CTG) has
emerged. However, while earlier methods have primarily centered on creating
single-sentence citations, practical scenarios frequently necessitate citing
multiple papers within a single paragraph. To bridge this gap, we propose a
method that leverages Large Language Models (LLMs) to generate multi-citation
sentences. Our approach involves a single source paper and a collection of
target papers, culminating in a coherent paragraph containing multi-sentence
citation text. Furthermore, we introduce a curated dataset named MCG-S2ORC,
composed of English-language academic research papers in Computer Science,
showcasing multiple citation instances. In our experiments, we evaluate three
LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this
endeavor. Additionally, we exhibit enhanced performance by integrating
knowledge graphs from target papers into the prompts for generating citation
text. This research underscores the potential of harnessing LLMs for citation
generation, opening a compelling avenue for exploring the intricate connections
between scientific documents.",2024-04-22
Filtered Direct Preference Optimization,2024-04-22 03:05:19+00:00,http://arxiv.org/abs/2404.13846v2,"Tetsuro Morimura, Mitsuki Sakamoto, Yuu Jinnai, Kenshi Abe, Kaito Ariu","cs.LG, cs.AI, cs.CL",knowledge,"Reinforcement learning from human feedback (RLHF) plays a crucial role in
aligning language models with human preferences. While the significance of
dataset quality is generally recognized, explicit investigations into its
impact within the RLHF framework, to our knowledge, have been limited. This
paper addresses the issue of text quality within the preference dataset by
focusing on Direct Preference Optimization (DPO), an increasingly adopted
reward-model-free RLHF method. We confirm that text quality significantly
influences the performance of models optimized with DPO more than those
optimized with reward-model-based RLHF. Building on this new insight, we
propose an extension of DPO, termed filtered direct preference optimization
(fDPO). fDPO uses a trained reward model to monitor the quality of texts within
the preference dataset during DPO training. Samples of lower quality are
discarded based on comparisons with texts generated by the model being
optimized, resulting in a more accurate dataset. Experimental results
demonstrate that fDPO enhances the final model performance. Our code is
available at https://github.com/CyberAgentAILab/filtered-dpo.",2024-04-22
"Parameter Efficient Diverse Paraphrase Generation Using Sequence-Level
  Knowledge Distillation",2024-04-19 02:59:09+00:00,http://arxiv.org/abs/2404.12596v1,"Lasal Jayawardena, Prasan Yapa","cs.CL, cs.AI, cs.LG",knowledge,"Over the past year, the field of Natural Language Generation (NLG) has
experienced an exponential surge, largely due to the introduction of Large
Language Models (LLMs). These models have exhibited the most effective
performance in a range of domains within the Natural Language Processing and
Generation domains. However, their application in domain-specific tasks, such
as paraphrasing, presents significant challenges. The extensive number of
parameters makes them difficult to operate on commercial hardware, and they
require substantial time for inference, leading to high costs in a production
setting. In this study, we tackle these obstacles by employing LLMs to develop
three distinct models for the paraphrasing field, applying a method referred to
as sequence-level knowledge distillation. These distilled models are capable of
maintaining the quality of paraphrases generated by the LLM. They demonstrate
faster inference times and the ability to generate diverse paraphrases of
comparable quality. A notable characteristic of these models is their ability
to exhibit syntactic diversity while also preserving lexical diversity,
features previously uncommon due to existing data quality issues in datasets
and not typically observed in neural-based approaches. Human evaluation of our
models shows that there is only a 4% drop in performance compared to the LLM
teacher model used in the distillation process, despite being 1000 times
smaller. This research provides a significant contribution to the NLG field,
offering a more efficient and cost-effective solution for paraphrasing tasks.",2024-04-19
"Incubating Text Classifiers Following User Instruction with Nothing but
  LLM",2024-04-16 19:53:35+00:00,http://arxiv.org/abs/2404.10877v1,"Letian Peng, Jingbo Shang",cs.CL,knowledge,"In this paper, we aim to generate text classification data given arbitrary
class definitions (i.e., user instruction), so one can train a small text
classifier without any human annotation or raw corpus. Compared with pioneer
attempts, our proposed Incubator is the first framework that can handle
complicated and even mutually dependent classes (e.g., ""TED Talk given by
Educator"" and ""Other""). Specifically, Incubator is an LLM firstly tuned on the
instruction-to-data mappings that we obtained from classification datasets and
descriptions on HuggingFace together with in-context augmentation by GPT-4. We
then refine Incubator by learning on the cluster centers of semantic textual
embeddings to emphasize the uniformity and semantic diversity in generations.
We compare Incubator on various classification tasks with strong baselines such
as direct LLM-based inference and training data generation by prompt
engineering. Experiments show Incubator is able to (1) perform well on
traditional benchmarks, (2) take label dependency and user preference into
consideration, and (3) enable logical text mining by incubating multiple
classifiers.",2024-04-16
"LaDiC: Are Diffusion Models Really Inferior to Autoregressive
  Counterparts for Image-to-Text Generation?",2024-04-16 17:47:16+00:00,http://arxiv.org/abs/2404.10763v1,"Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun","cs.AI, cs.CL, cs.CV",knowledge,"Diffusion models have exhibited remarkable capabilities in text-to-image
generation. However, their performance in image-to-text generation,
specifically image captioning, has lagged behind Auto-Regressive (AR) models,
casting doubt on their applicability for such tasks. In this work, we revisit
diffusion models, highlighting their capacity for holistic context modeling and
parallel decoding. With these benefits, diffusion models can alleviate the
inherent limitations of AR methods, including their slow inference speed, error
propagation, and unidirectional constraints. Furthermore, we identify the prior
underperformance of diffusion models stemming from the absence of an effective
latent space for image-text alignment, and the discrepancy between continuous
diffusion processes and discrete textual data. In response, we introduce a
novel architecture, LaDiC, which utilizes a split BERT to create a dedicated
latent space for captions and integrates a regularization module to manage
varying text lengths. Our framework also includes a diffuser for semantic
image-to-text conversion and a Back&Refine technique to enhance token
interactivity during inference. LaDiC achieves state-of-the-art performance for
diffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2
CIDEr, demonstrating exceptional performance without pre-training or ancillary
modules. This indicates strong competitiveness with AR models, revealing the
previously untapped potential of diffusion models in image-to-text generation.",2024-04-16
Generative Text Steganography with Large Language Model,2024-04-16 02:19:28+00:00,http://arxiv.org/abs/2404.10229v1,"Jiaxuan Wu, Zhengxian Wu, Yiming Xue, Juan Wen, Wanli Peng",cs.CL,knowledge,"Recent advances in large language models (LLMs) have blurred the boundary of
high-quality text generation between humans and machines, which is favorable
for generative text steganography. While, current advanced steganographic
mapping is not suitable for LLMs since most users are restricted to accessing
only the black-box API or user interface of the LLMs, thereby lacking access to
the training vocabulary and its sampling probabilities. In this paper, we
explore a black-box generative text steganographic method based on the user
interfaces of large language models, which is called LLM-Stega. The main goal
of LLM-Stega is that the secure covert communication between Alice (sender) and
Bob (receiver) is conducted by using the user interfaces of LLMs. Specifically,
We first construct a keyword set and design a new encrypted steganographic
mapping to embed secret messages. Furthermore, to guarantee accurate extraction
of secret messages and rich semantics of generated stego texts, an optimization
mechanism based on reject sampling is proposed. Comprehensive experiments
demonstrate that the proposed LLM-Stega outperforms current state-of-the-art
methods.",2024-04-16
"Gaining More Insight into Neural Semantic Parsing with Challenging
  Benchmarks",2024-04-12 09:48:58+00:00,http://arxiv.org/abs/2404.08354v2,"Xiao Zhang, Chunliu Wang, Rik van Noord, Johan Bos",cs.CL,knowledge,"The Parallel Meaning Bank (PMB) serves as a corpus for semantic processing
with a focus on semantic parsing and text generation. Currently, we witness an
excellent performance of neural parsers and generators on the PMB. This might
suggest that such semantic processing tasks have by and large been solved. We
argue that this is not the case and that performance scores from the past on
the PMB are inflated by non-optimal data splits and test sets that are too
easy. In response, we introduce several changes. First, instead of the prior
random split, we propose a more systematic splitting approach to improve the
reliability of the standard test data. Second, except for the standard test
set, we also propose two challenge sets: one with longer texts including
discourse structure, and one that addresses compositional generalization. We
evaluate five neural models for semantic parsing and meaning-to-text
generation. Our results show that model performance declines (in some cases
dramatically) on the challenge sets, revealing the limitations of neural models
when confronting such challenges.",2024-04-12
"Adapting LLMs for Efficient Context Processing through Soft Prompt
  Compression",2024-04-07 15:44:20+00:00,http://arxiv.org/abs/2404.04997v2,"Cangqing Wang, Yutian Yang, Ruisi Li, Dan Sun, Ruicong Cai, Yuzhu Zhang, Chengqian Fu, Lillian Floyd","cs.LG, cs.AI, cs.CL",knowledge,"The rapid advancement of Large Language Models (LLMs) has inaugurated a
transformative epoch in natural language processing, fostering unprecedented
proficiency in text generation, comprehension, and contextual scrutiny.
Nevertheless, effectively handling extensive contexts, crucial for myriad
applications, poses a formidable obstacle owing to the intrinsic constraints of
the models' context window sizes and the computational burdens entailed by
their operations. This investigation presents an innovative framework that
strategically tailors LLMs for streamlined context processing by harnessing the
synergies among natural language summarization, soft prompt compression, and
augmented utility preservation mechanisms. Our methodology, dubbed
SoftPromptComp, amalgamates natural language prompts extracted from
summarization methodologies with dynamically generated soft prompts to forge a
concise yet semantically robust depiction of protracted contexts. This
depiction undergoes further refinement via a weighting mechanism optimizing
information retention and utility for subsequent tasks. We substantiate that
our framework markedly diminishes computational overhead and enhances LLMs'
efficacy across various benchmarks, while upholding or even augmenting the
caliber of the produced content. By amalgamating soft prompt compression with
sophisticated summarization, SoftPromptComp confronts the dual challenges of
managing lengthy contexts and ensuring model scalability. Our findings point
towards a propitious trajectory for augmenting LLMs' applicability and
efficiency, rendering them more versatile and pragmatic for real-world
applications. This research enriches the ongoing discourse on optimizing
language models, providing insights into the potency of soft prompts and
summarization techniques as pivotal instruments for the forthcoming generation
of NLP solutions.",2024-04-07
ToXCL: A Unified Framework for Toxic Speech Detection and Explanation,2024-03-25 12:21:38+00:00,http://arxiv.org/abs/2403.16685v1,"Nhat M. Hoang, Xuan Long Do, Duc Anh Do, Duc Anh Vu, Luu Anh Tuan","cs.CL, cs.CY",knowledge,"The proliferation of online toxic speech is a pertinent problem posing
threats to demographic groups. While explicit toxic speech contains offensive
lexical signals, implicit one consists of coded or indirect language.
Therefore, it is crucial for models not only to detect implicit toxic speech
but also to explain its toxicity. This draws a unique need for unified
frameworks that can effectively detect and explain implicit toxic speech. Prior
works mainly formulated the task of toxic speech detection and explanation as a
text generation problem. Nonetheless, models trained using this strategy can be
prone to suffer from the consequent error propagation problem. Moreover, our
experiments reveal that the detection results of such models are much lower
than those that focus only on the detection task. To bridge these gaps, we
introduce ToXCL, a unified framework for the detection and explanation of
implicit toxic speech. Our model consists of three modules: a (i) Target Group
Generator to generate the targeted demographic group(s) of a given post; an
(ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit
toxic speech and is boosted by a (iii) Teacher Classifier via knowledge
distillation, and the decoder generates the necessary explanation. ToXCL
achieves new state-of-the-art effectiveness, and outperforms baselines
significantly.",2024-03-25
"Evidence-Driven Retrieval Augmented Response Generation for Online
  Misinformation",2024-03-22 05:05:45+00:00,http://arxiv.org/abs/2403.14952v1,"Zhenrui Yue, Huimin Zeng, Yimeng Lu, Lanyu Shang, Yang Zhang, Dong Wang","cs.CL, cs.AI",knowledge,"The proliferation of online misinformation has posed significant threats to
public interest. While numerous online users actively participate in the combat
against misinformation, many of such responses can be characterized by the lack
of politeness and supporting facts. As a solution, text generation approaches
are proposed to automatically produce counter-misinformation responses.
Nevertheless, existing methods are often trained end-to-end without leveraging
external knowledge, resulting in subpar text quality and excessively repetitive
responses. In this paper, we propose retrieval augmented response generation
for online misinformation (RARG), which collects supporting evidence from
scientific sources and generates counter-misinformation responses based on the
evidences. In particular, our RARG consists of two stages: (1) evidence
collection, where we design a retrieval pipeline to retrieve and rerank
evidence documents using a database comprising over 1M academic articles; (2)
response generation, in which we align large language models (LLMs) to generate
evidence-based responses via reinforcement learning from human feedback (RLHF).
We propose a reward function to maximize the utilization of the retrieved
evidence while maintaining the quality of the generated text, which yields
polite and factual responses that clearly refutes misinformation. To
demonstrate the effectiveness of our method, we study the case of COVID-19 and
perform extensive experiments with both in- and cross-domain datasets, where
RARG consistently outperforms baselines by generating high-quality
counter-misinformation responses.",2024-03-22
A Closer Look at Claim Decomposition,2024-03-18 16:03:45+00:00,http://arxiv.org/abs/2403.11903v1,"Miriam Wanner, Seth Ebner, Zhengping Jiang, Mark Dredze, Benjamin Van Durme",cs.CL,knowledge,"As generated text becomes more commonplace, it is increasingly important to
evaluate how well-supported such text is by external knowledge sources. Many
approaches for evaluating textual support rely on some method for decomposing
text into its individual subclaims which are scored against a trusted
reference. We investigate how various methods of claim decomposition --
especially LLM-based methods -- affect the result of an evaluation approach
such as the recently proposed FActScore, finding that it is sensitive to the
decomposition method used. This sensitivity arises because such metrics
attribute overall textual support to the model that generated the text even
though error can also come from the metric's decomposition step. To measure
decomposition quality, we introduce an adaptation of FActScore, which we call
DecompScore. We then propose an LLM-based approach to generating decompositions
inspired by Bertrand Russell's theory of logical atomism and neo-Davidsonian
semantics and demonstrate its improved decomposition quality over previous
methods.",2024-03-18
"GPT-4 as Evaluator: Evaluating Large Language Models on Pest Management
  in Agriculture",2024-03-18 15:08:01+00:00,http://arxiv.org/abs/2403.11858v1,"Shanglong Yang, Zhipeng Yuan, Shunbao Li, Ruoling Peng, Kang Liu, Po Yang",cs.CL,knowledge,"In the rapidly evolving field of artificial intelligence (AI), the
application of large language models (LLMs) in agriculture, particularly in
pest management, remains nascent. We aimed to prove the feasibility by
evaluating the content of the pest management advice generated by LLMs,
including the Generative Pre-trained Transformer (GPT) series from OpenAI and
the FLAN series from Google. Considering the context-specific properties of
agricultural advice, automatically measuring or quantifying the quality of text
generated by LLMs becomes a significant challenge. We proposed an innovative
approach, using GPT-4 as an evaluator, to score the generated content on
Coherence, Logical Consistency, Fluency, Relevance, Comprehensibility, and
Exhaustiveness. Additionally, we integrated an expert system based on crop
threshold data as a baseline to obtain scores for Factual Accuracy on whether
pests found in crop fields should take management action. Each model's score
was weighted by percentage to obtain a final score. The results showed that
GPT-3.4 and GPT-4 outperform the FLAN models in most evaluation categories.
Furthermore, the use of instruction-based prompting containing domain-specific
knowledge proved the feasibility of LLMs as an effective tool in agriculture,
with an accuracy rate of 72%, demonstrating LLMs' effectiveness in providing
pest management suggestions.",2024-03-18
Embedded Named Entity Recognition using Probing Classifiers,2024-03-18 12:58:16+00:00,http://arxiv.org/abs/2403.11747v1,"Nicholas Popovič, Michael Färber",cs.CL,knowledge,"Extracting semantic information from generated text is a useful tool for
applications such as automated fact checking or retrieval augmented generation.
Currently, this requires either separate models during inference, which
increases computational cost, or destructive fine-tuning of the language model.
Instead, we propose directly embedding information extraction capabilities into
pre-trained language models using probing classifiers, enabling efficient
simultaneous text generation and information extraction. For this, we introduce
an approach called EMBER and show that it enables named entity recognition in
decoder-only language models without fine-tuning them and while incurring
minimal additional computational cost at inference time. Specifically, our
experiments using GPT-2 show that EMBER maintains high token generation rates
during streaming text generation, with only a negligible decrease in speed of
around 1% compared to a 43.64% slowdown measured for a baseline using a
separate NER model. Code and data are available at
https://github.com/nicpopovic/EMBER.",2024-03-18
"Reinforcement Learning with Token-level Feedback for Controllable Text
  Generation",2024-03-18 08:18:37+00:00,http://arxiv.org/abs/2403.11558v1,"Wendi Li, Wei Wei, Kaihe Xu, Wenfeng Xie, Dangyang Chen, Yu Cheng","cs.CL, cs.AI",knowledge,"To meet the requirements of real-world applications, it is essential to
control generations of large language models (LLMs). Prior research has tried
to introduce reinforcement learning (RL) into controllable text generation
while most existing methods suffer from overfitting issues (finetuning-based
methods) or semantic collapse (post-processing methods). However, current RL
methods are generally guided by coarse-grained (sentence/paragraph-level)
feedback, which may lead to suboptimal performance owing to semantic twists or
progressions within sentences. To tackle that, we propose a novel reinforcement
learning algorithm named TOLE which formulates TOken-LEvel rewards for
controllable text generation, and employs a ""first-quantize-then-noise""
paradigm to enhance the robustness of the RL algorithm.Furthermore, TOLE can be
flexibly extended to multiple constraints with little computational expense.
Experimental results show that our algorithm can achieve superior performance
on both single-attribute and multi-attribute control tasks. We have released
our codes at https://github.com/WindyLee0822/CTG",2024-03-18
"ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate
  Professional and Non-Professional Styled Text",2024-03-14 06:49:16+00:00,http://arxiv.org/abs/2403.09131v2,"Chang Zong, Yuyan Chen, Weiming Lu, Jian Shao, Yueting Zhuang","cs.CL, cs.AI, 68T50, I.2.7",knowledge,"Large Language Models (LLMs) have demonstrated efficacy in various linguistic
applications, including text summarization and controlled text generation.
However, studies into their capacity of switching between styles via
fine-tuning remain underexplored. This study concentrates on textual
professionalism and introduces a novel methodology, named ProSwitch, which
equips a language model with the ability to produce both professional and
non-professional responses through knowledge-guided instruction tuning.
ProSwitch unfolds across three phases: data preparation for gathering domain
knowledge and training corpus; instruction tuning for optimizing language
models with multiple levels of instruction formats; and comprehensive
evaluation for assessing the professionalism discrimination and reference-based
quality of generated text. Comparative analysis of ProSwitch against both
general and specialized language models reveals that our approach outperforms
baselines in switching between professional and non-professional text
generation.",2024-03-14
"Truth-Aware Context Selection: Mitigating the Hallucinations of Large
  Language Models Being Misled by Untruthful Contexts",2024-03-12 11:40:44+00:00,http://arxiv.org/abs/2403.07556v1,"Tian Yu, Shaolei Zhang, Yang Feng",cs.CL,knowledge,"Although large language models (LLMs) have demonstrated impressive text
generation capabilities, they are easily misled by the untruthful context
provided by users or knowledge argumentation tools, thereby producing
hallucinations. To alleviate the LLMs from being misled by untruthful
information and take advantage of knowledge argumentation, we propose
Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful
context from the inputs. TACS begins by performing truth detection on the input
context, leveraging the parameterized knowledge within the LLM. Subsequently,
it constructs a corresponding attention mask based on the truthfulness of each
position, selecting the truthful context and discarding the untruthful context.
Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate,
to further study the LLMs' ability to accept truthful information and resist
untruthful information. Experimental results show that TACS can effectively
filter information in context and significantly improve the overall quality of
LLMs' responses when presented with misleading information.",2024-03-12
Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs,2024-03-12 08:13:52+00:00,http://arxiv.org/abs/2403.07398v1,"Tianqing Fang, Zeming Chen, Yangqiu Song, Antoine Bosselut","cs.CL, cs.AI",knowledge,"Event commonsense reasoning requires the ability to reason about the
relationship between events, as well as infer implicit context underlying that
relationship. However, data scarcity makes it challenging for language models
to learn to generate commonsense inferences for contexts and questions
involving interactions between complex events. To address this demand, we
present COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop
logical queries (e.g., the joint effect or cause of both event A and B, or the
effect of the effect of event C) from an existing commonsense knowledge graph
(CSKG), and verbalizing them using handcrafted rules and large language models
into multiple-choice and text generation questions. Our experiments show that
language models trained on COM2 exhibit significant improvements in complex
reasoning ability, resulting in enhanced zero-shot performance in both
in-domain and out-of-domain tasks for question answering and generative
commonsense reasoning, without expensive human annotations.",2024-03-12
"Premonition: Using Generative Models to Preempt Future Data Changes in
  Continual Learning",2024-03-12 06:29:54+00:00,http://arxiv.org/abs/2403.07356v1,"Mark D. McDonnell, Dong Gong, Ehsan Abbasnejad, Anton van den Hengel","cs.CV, cs.LG",knowledge,"Continual learning requires a model to adapt to ongoing changes in the data
distribution, and often to the set of tasks to be performed. It is rare,
however, that the data and task changes are completely unpredictable. Given a
description of an overarching goal or data theme, which we call a realm, humans
can often guess what concepts are associated with it. We show here that the
combination of a large language model and an image generation model can
similarly provide useful premonitions as to how a continual learning challenge
might develop over time. We use the large language model to generate text
descriptions of semantically related classes that might potentially appear in
the data stream in future. These descriptions are then rendered using Stable
Diffusion to generate new labelled image samples. The resulting synthetic
dataset is employed for supervised pre-training, but is discarded prior to
commencing continual learning, along with the pre-training classification head.
We find that the backbone of our pre-trained networks can learn representations
useful for the downstream continual learning problem, thus becoming a valuable
input to any existing continual learning method. Although there are
complexities arising from the domain gap between real and synthetic images, we
show that pre-training models in this manner improves multiple Class Incremenal
Learning (CIL) methods on fine-grained image classification benchmarks.
Supporting code can be found at https://github.com/cl-premonition/premonition.",2024-03-12
"Monitoring AI-Modified Content at Scale: A Case Study on the Impact of
  ChatGPT on AI Conference Peer Reviews",2024-03-11 21:51:39+00:00,http://arxiv.org/abs/2403.07183v1,"Weixin Liang, Zachary Izzo, Yaohui Zhang, Haley Lepp, Hancheng Cao, Xuandong Zhao, Lingjiao Chen, Haotian Ye, Sheng Liu, Zhi Huang, Daniel A. McFarland, James Y. Zou","cs.CL, cs.AI, cs.LG, cs.SI, I.2.7",knowledge,"We present an approach for estimating the fraction of text in a large corpus
which is likely to be substantially modified or produced by a large language
model (LLM). Our maximum likelihood model leverages expert-written and
AI-generated reference texts to accurately and efficiently examine real-world
LLM-use at the corpus level. We apply this approach to a case study of
scientific peer review in AI conferences that took place after the release of
ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest
that between 6.5% and 16.9% of text submitted as peer reviews to these
conferences could have been substantially modified by LLMs, i.e. beyond
spell-checking or minor writing updates. The circumstances in which generated
text occurs offer insight into user behavior: the estimated fraction of
LLM-generated text is higher in reviews which report lower confidence, were
submitted close to the deadline, and from reviewers who are less likely to
respond to author rebuttals. We also observe corpus-level trends in generated
text which may be too subtle to detect at the individual level, and discuss the
implications of such trends on peer review. We call for future
interdisciplinary work to examine how LLM use is changing our information and
knowledge practices.",2024-03-11
One Category One Prompt: Dataset Distillation using Diffusion Models,2024-03-11 20:23:59+00:00,http://arxiv.org/abs/2403.07142v1,"Ali Abbasi, Ashkan Shahbazi, Hamed Pirsiavash, Soheil Kolouri","cs.CV, cs.CL, cs.LG",knowledge,"The extensive amounts of data required for training deep neural networks pose
significant challenges on storage and transmission fronts. Dataset distillation
has emerged as a promising technique to condense the information of massive
datasets into a much smaller yet representative set of synthetic samples.
However, traditional dataset distillation approaches often struggle to scale
effectively with high-resolution images and more complex architectures due to
the limitations in bi-level optimization. Recently, several works have proposed
exploiting knowledge distillation with decoupled optimization schemes to scale
up dataset distillation. Although these methods effectively address the
scalability issue, they rely on extensive image augmentations requiring the
storage of soft labels for augmented images. In this paper, we introduce
Dataset Distillation using Diffusion Models (D3M) as a novel paradigm for
dataset distillation, leveraging recent advancements in generative
text-to-image foundation models. Our approach utilizes textual inversion, a
technique for fine-tuning text-to-image generative models, to create concise
and informative representations for large datasets. By employing these learned
text prompts, we can efficiently store and infer new samples for introducing
data variability within a fixed memory budget. We show the effectiveness of our
method through extensive experiments across various computer vision benchmark
datasets with different memory budgets.",2024-03-11
Narrating Causal Graphs with Large Language Models,2024-03-11 19:19:59+00:00,http://arxiv.org/abs/2403.07118v1,"Atharva Phatak, Vijay K. Mago, Ameeta Agrawal, Aravind Inbasekaran, Philippe J. Giabbanelli",cs.CL,knowledge,"The use of generative AI to create text descriptions from graphs has mostly
focused on knowledge graphs, which connect concepts using facts. In this work
we explore the capability of large pretrained language models to generate text
from causal graphs, where salient concepts are represented as nodes and
causality is represented via directed, typed edges. The causal reasoning
encoded in these graphs can support applications as diverse as healthcare or
marketing. Using two publicly available causal graph datasets, we empirically
investigate the performance of four GPT-3 models under various settings. Our
results indicate that while causal text descriptions improve with training
data, compared to fact-based graphs, they are harder to generate under
zero-shot settings. Results further suggest that users of generative AI can
deploy future applications faster since similar performances are obtained when
training a model with only a few examples as compared to fine-tuning via a
large curated dataset.",2024-03-11
"Evolving Knowledge Distillation with Large Language Models and Active
  Learning",2024-03-11 03:55:24+00:00,http://arxiv.org/abs/2403.06414v1,"Chengyuan Liu, Yangyang Kang, Fubang Zhao, Kun Kuang, Zhuoren Jiang, Changlong Sun, Fei Wu",cs.CL,knowledge,"Large language models (LLMs) have demonstrated remarkable capabilities across
various NLP tasks. However, their computational costs are prohibitively high.
To address this issue, previous research has attempted to distill the knowledge
of LLMs into smaller models by generating annotated data. Nonetheless, these
works have mainly focused on the direct use of LLMs for text generation and
labeling, without fully exploring their potential to comprehend the target task
and acquire valuable knowledge. In this paper, we propose EvoKD: Evolving
Knowledge Distillation, which leverages the concept of active learning to
interactively enhance the process of data generation using large language
models, simultaneously improving the task capabilities of small domain model
(student model). Different from previous work, we actively analyze the student
model's weaknesses, and then synthesize labeled samples based on the analysis.
In addition, we provide iterative feedback to the LLMs regarding the student
model's performance to continuously construct diversified and challenging
samples. Experiments and analysis on different NLP tasks, namely, text
classification and named entity recognition show the effectiveness of EvoKD.",2024-03-11
"Know Your Audience: The benefits and pitfalls of generating plain
  language summaries beyond the ""general"" audience",2024-03-08 01:27:24+00:00,http://arxiv.org/abs/2403.04979v1,"Tal August, Kyle Lo, Noah A. Smith, Katharina Reinecke",cs.HC,knowledge,"Language models (LMs) show promise as tools for communicating science to the
general public by simplifying and summarizing complex language. Because models
can be prompted to generate text for a specific audience (e.g.,
college-educated adults), LMs might be used to create multiple versions of
plain language summaries for people with different familiarities of scientific
topics. However, it is not clear what the benefits and pitfalls of adaptive
plain language are. When is simplifying necessary, what are the costs in doing
so, and do these costs differ for readers with different background knowledge?
Through three within-subjects studies in which we surface summaries for
different envisioned audiences to participants of different backgrounds, we
found that while simpler text led to the best reading experience for readers
with little to no familiarity in a topic, high familiarity readers tended to
ignore certain details in overly plain summaries (e.g., study limitations). Our
work provides methods and guidance on ways of adapting plain language summaries
beyond the single ""general"" audience.",2024-03-08
"KnowledgeVIS: Interpreting Language Models by Comparing
  Fill-in-the-Blank Prompts",2024-03-07 18:56:31+00:00,http://arxiv.org/abs/2403.04758v1,"Adam Coscia, Alex Endert","cs.HC, cs.AI, cs.CY, cs.LG",knowledge,"Recent growth in the popularity of large language models has led to their
increased usage for summarizing, predicting, and generating text, making it
vital to help researchers and engineers understand how and why they work. We
present KnowledgeVis, a human-in-the-loop visual analytics system for
interpreting language models using fill-in-the-blank sentences as prompts. By
comparing predictions between sentences, KnowledgeVis reveals learned
associations that intuitively connect what language models learn during
training to natural language tasks downstream, helping users create and test
multiple prompt variations, analyze predicted words using a novel semantic
clustering technique, and discover insights using interactive visualizations.
Collectively, these visualizations help users identify the likelihood and
uniqueness of individual predictions, compare sets of predictions between
prompts, and summarize patterns and relationships between predictions across
all prompts. We demonstrate the capabilities of KnowledgeVis with feedback from
six NLP experts as well as three different use cases: (1) probing biomedical
knowledge in two domain-adapted models; and (2) evaluating harmful identity
stereotypes and (3) discovering facts and relationships between three
general-purpose models.",2024-03-07
"Fact-Checking the Output of Large Language Models via Token-Level
  Uncertainty Quantification",2024-03-07 17:44:17+00:00,http://arxiv.org/abs/2403.04696v1,"Ekaterina Fadeeva, Aleksandr Rubashevskii, Artem Shelmanov, Sergey Petrakov, Haonan Li, Hamdy Mubarak, Evgenii Tsymbalov, Gleb Kuzmin, Alexander Panchenko, Timothy Baldwin, Preslav Nakov, Maxim Panov","cs.CL, cs.AI, cs.LG",knowledge,"Large language models (LLMs) are notorious for hallucinating, i.e., producing
erroneous claims in their output. Such hallucinations can be dangerous, as
occasional factual inaccuracies in the generated text might be obscured by the
rest of the output being generally factual, making it extremely hard for the
users to spot them. Current services that leverage LLMs usually do not provide
any means for detecting unreliable generations. Here, we aim to bridge this
gap. In particular, we propose a novel fact-checking and hallucination
detection pipeline based on token-level uncertainty quantification. Uncertainty
scores leverage information encapsulated in the output of a neural network or
its layers to detect unreliable predictions, and we show that they can be used
to fact-check the atomic claims in the LLM output. Moreover, we present a novel
token-level uncertainty quantification method that removes the impact of
uncertainty about what claim to generate on the current step and what surface
form to use. Our method Claim Conditioned Probability (CCP) measures only the
uncertainty of particular claim value expressed by the model. Experiments on
the task of biography generation demonstrate strong improvements for CCP
compared to the baselines for six different LLMs and three languages. Human
evaluation reveals that the fact-checking pipeline based on uncertainty
quantification is competitive with a fact-checking tool that leverages external
knowledge.",2024-03-07
Enhancing Court View Generation with Knowledge Injection and Guidance,2024-03-07 09:51:11+00:00,http://arxiv.org/abs/2403.04366v1,"Ang Li, Yiquan Wu, Yifei Liu, Fei Wu, Ming Cai, Kun Kuang",cs.AI,knowledge,"Court View Generation (CVG) is a challenging task in the field of Legal
Artificial Intelligence (LegalAI), which aims to generate court views based on
the plaintiff claims and the fact descriptions. While Pretrained Language
Models (PLMs) have showcased their prowess in natural language generation,
their application to the complex, knowledge-intensive domain of CVG often
reveals inherent limitations. In this paper, we present a novel approach, named
Knowledge Injection and Guidance (KIG), designed to bolster CVG using PLMs. To
efficiently incorporate domain knowledge during the training stage, we
introduce a knowledge-injected prompt encoder for prompt tuning, thereby
reducing computational overhead. Moreover, to further enhance the model's
ability to utilize domain knowledge, we employ a generating navigator, which
dynamically guides the text generation process in the inference stage without
altering the model's architecture, making it readily transferable.
Comprehensive experiments on real-world data demonstrate the effectiveness of
our approach compared to several established baselines, especially in the
responsivity of claims, where it outperforms the best baseline by 11.87%.",2024-03-07
Advancing Biomedical Text Mining with Community Challenges,2024-03-07 06:52:51+00:00,http://arxiv.org/abs/2403.04261v1,"Hui Zong, Rongrong Wu, Jiaxue Cha, Erman Wu, Jiakun Li, Liang Tao, Zuofeng Li, Buzhou Tang, Bairong Shen","cs.AI, cs.CL, cs.LG",knowledge,"The field of biomedical research has witnessed a significant increase in the
accumulation of vast amounts of textual data from various sources such as
scientific literatures, electronic health records, clinical trial reports, and
social media. However, manually processing and analyzing these extensive and
complex resources is time-consuming and inefficient. To address this challenge,
biomedical text mining, also known as biomedical natural language processing,
has garnered great attention. Community challenge evaluation competitions have
played an important role in promoting technology innovation and
interdisciplinary collaboration in biomedical text mining research. These
challenges provide platforms for researchers to develop state-of-the-art
solutions for data mining and information processing in biomedical research. In
this article, we review the recent advances in community challenges specific to
Chinese biomedical text mining. Firstly, we collect the information of these
evaluation tasks, such as data sources and task types. Secondly, we conduct
systematic summary and comparative analysis, including named entity
recognition, entity normalization, attribute extraction, relation extraction,
event extraction, text classification, text similarity, knowledge graph
construction, question answering, text generation, and large language model
evaluation. Then, we summarize the potential clinical applications of these
community challenge tasks from translational informatics perspective. Finally,
we discuss the contributions and limitations of these community challenges,
while highlighting future directions in the era of large language models.",2024-03-07
"Quantifying Contamination in Evaluating Code Generation Capabilities of
  Language Models",2024-03-06 21:45:35+00:00,http://arxiv.org/abs/2403.04811v1,"Martin Riddell, Ansong Ni, Arman Cohan","cs.SE, cs.CL, cs.LG",knowledge,"While large language models have achieved remarkable performance on various
code generation benchmarks, there have been growing concerns regarding
potential contamination of these benchmarks as they may be leaked into
pretraining and finetuning data. While recent work has investigated
contamination in natural language generation and understanding tasks, there has
been less extensive research into how data contamination impacts the evaluation
of code generation, which is critical for understanding the robustness and
reliability of LLMs in programming contexts. In this work, we perform a
comprehensive study of data contamination of popular code generation
benchmarks, and precisely quantify their overlap with pretraining corpus
through both surface-level and semantic-level matching. In our experiments, we
show that there are substantial overlap between popular code generation
benchmarks and open training corpus, and models perform significantly better on
the subset of the benchmarks where similar solutions are seen during training.
We also conduct extensive analysis on the factors that affects model
memorization and generalization, such as model size, problem difficulty, and
question length. We release all resulting files from our matching pipeline for
future research.",2024-03-06
"DECIDER: A Rule-Controllable Decoding Strategy for Language Generation
  by Imitating Dual-System Cognitive Theory",2024-03-04 11:49:08+00:00,http://arxiv.org/abs/2403.01954v1,"Chen Xu, Tian Lan, Changlong Yu, Wei Wang, Jun Gao, Yu Ji, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu","cs.CL, cs.AI, cs.LO",knowledge,"Lexicon-based constrained decoding approaches aim to control the meaning or
style of the generated text through certain target concepts. Existing
approaches over-focus the targets themselves, leading to a lack of high-level
reasoning about how to achieve them. However, human usually tackles tasks by
following certain rules that not only focuses on the targets but also on
semantically relevant concepts that induce the occurrence of targets. In this
work, we present DECIDER, a rule-controllable decoding strategy for constrained
language generation inspired by dual-system cognitive theory. Specifically, in
DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner
that takes high-level rules as input. Then, the DECIDER allows rule signals to
flow into the PLM at each decoding step. Extensive experimental results
demonstrate that DECIDER can effectively follow given rules to guide generation
direction toward the targets in a more human-like manner.",2024-03-04
"Direct Alignment of Draft Model for Speculative Decoding with
  Chat-Fine-Tuned LLMs",2024-02-29 19:55:06+00:00,http://arxiv.org/abs/2403.00858v3,"Raghavv Goel, Mukul Gagrani, Wonseok Jeon, Junyoung Park, Mingu Lee, Christopher Lott","cs.LG, cs.AI, cs.CL",knowledge,"Text generation with Large Language Models (LLMs) is known to be memory bound
due to the combination of their auto-regressive nature, huge parameter counts,
and limited memory bandwidths, often resulting in low token rates. Speculative
decoding has been proposed as a solution for LLM inference acceleration.
However, since draft models are often unavailable in the modern open-source LLM
families, e.g., for Llama 2 7B, training a high-quality draft model is required
to enable inference acceleration via speculative decoding. In this paper, we
propose a simple draft model training framework for direct alignment to
chat-capable target models. With the proposed framework, we train Llama 2 Chat
Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of
the original size. Our training framework only consists of pretraining,
distillation dataset generation, and finetuning with knowledge distillation,
with no additional alignment procedure. For the finetuning step, we use
instruction-response pairs generated by target model for distillation in
plausible data distribution, and propose a new Total Variation Distance++
(TVD++) loss that incorporates variance reduction techniques inspired from the
policy gradient method in reinforcement learning. Our empirical results show
that Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3
block efficiency and 2.4$\times$ speed-up relative to autoregressive decoding
on various tasks with no further task-specific fine-tuning.",2024-02-29
"Token-Specific Watermarking with Enhanced Detectability and Semantic
  Coherence for Large Language Models",2024-02-28 05:43:22+00:00,http://arxiv.org/abs/2402.18059v2,"Mingjia Huo, Sai Ashish Somayajula, Youwei Liang, Ruisi Zhang, Farinaz Koushanfar, Pengtao Xie","cs.LG, cs.CL, cs.CR",knowledge,"Large language models generate high-quality responses with potential
misinformation, underscoring the need for regulation by distinguishing
AI-generated and human-written texts. Watermarking is pivotal in this context,
which involves embedding hidden markers in texts during the LLM inference
phase, which is imperceptible to humans. Current watermarking algorithms,
however, face the challenge of achieving both the detectability of inserted
watermarks and the semantic integrity of generated texts, where enhancing one
aspect often undermines the other. To overcome this, we introduce a novel
multi-objective optimization (MOO) approach for watermarking that utilizes
lightweight networks to generate token-specific watermarking logits and
splitting ratios. By leveraging MOO to optimize for both detection and semantic
objective functions, our method simultaneously achieves detectability and
semantic integrity. Experimental results show that our method outperforms
current watermarking techniques in enhancing the detectability of texts
generated by LLMs while maintaining their semantic coherence. Our code is
available at https://github.com/mignonjia/TS_watermark.",2024-02-28
"CounterCurate: Enhancing Physical and Semantic Visio-Linguistic
  Compositional Reasoning via Counterfactual Examples",2024-02-20 18:59:55+00:00,http://arxiv.org/abs/2402.13254v2,"Jianrui Zhang, Mu Cai, Tengyang Xie, Yong Jae Lee","cs.CV, cs.AI, cs.CL, cs.LG",knowledge,"We propose CounterCurate, a framework to comprehensively improve the
visio-linguistic compositional reasoning capability for both contrastive and
generative multimodal models. In particular, we identify two critical
under-explored problems: the neglect of the physically grounded reasoning
(counting and position understanding) and the potential of using highly capable
text and image generation models for semantic counterfactual fine-tuning. Our
work pioneers an approach that addresses these gaps. We first spotlight the
near-chance performance of multimodal models like CLIP and LLaVA in physically
grounded compositional reasoning. We then apply simple data augmentation using
grounded image generation model GLIGEN to generate fine-tuning data, resulting
in significant performance improvements: +33% and +37% for CLIP and LLaVA,
respectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we
exploit the capabilities of high-performing text generation and image
generation models, specifically GPT-4V and DALLE-3, to curate challenging
semantic counterfactuals, thereby further enhancing compositional reasoning
capabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms
GPT-4V.",2024-02-20
Adaptive Text Watermark for Large Language Models,2024-01-25 03:57:12+00:00,http://arxiv.org/abs/2401.13927v1,"Yepeng Liu, Yuheng Bu",cs.CL,knowledge,"The advancement of Large Language Models (LLMs) has led to increasing
concerns about the misuse of AI-generated text, and watermarking for
LLM-generated text has emerged as a potential solution. However, it is
challenging to generate high-quality watermarked text while maintaining strong
security, robustness, and the ability to detect watermarks without prior
knowledge of the prompt or model. This paper proposes an adaptive watermarking
strategy to address this problem. To improve the text quality and maintain
robustness, we adaptively add watermarking to token distributions with high
entropy measured using an auxiliary model and keep the low entropy token
distributions untouched. For the sake of security and to further minimize the
watermark's impact on text quality, instead of using a fixed green/red list
generated from a random secret key, which can be vulnerable to decryption and
forgery, we adaptively scale up the output logits in proportion based on the
semantic embedding of previously generated text using a well designed semantic
mapping model. Our experiments involving various LLMs demonstrate that our
approach achieves comparable robustness performance to existing watermark
methods. Additionally, the text generated by our method has perplexity
comparable to that of \emph{un-watermarked} LLMs while maintaining security
even under various attacks.",2024-01-25
"Consistency Guided Knowledge Retrieval and Denoising in LLMs for
  Zero-shot Document-level Relation Triplet Extraction",2024-01-24 17:04:28+00:00,http://arxiv.org/abs/2401.13598v1,"Qi Sun, Kun Huang, Xiaocui Yang, Rong Tong, Kun Zhang, Soujanya Poria",cs.CL,knowledge,"Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in
information systems that aims to simultaneously extract entities with semantic
relations from a document. Existing methods heavily rely on a substantial
amount of fully labeled data. However, collecting and annotating data for newly
emerging relations is time-consuming and labor-intensive. Recent advanced Large
Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text
generation capabilities, inspiring us to explore an alternative approach for
obtaining auto-labeled documents with new relations. In this paper, we propose
a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework,
which generates labeled data by retrieval and denoising knowledge from LLMs,
called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide
ChatGPT to generate labeled long-text data step by step. To improve the quality
of synthetic data, we propose a denoising strategy based on the consistency of
cross-document knowledge. Leveraging our denoised synthetic data, we proceed to
fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.
We perform experiments for both zero-shot document-level relation and triplet
extraction on two public datasets. The experimental results illustrate that our
GenRDK framework outperforms strong baselines.",2024-01-24
Fine-grained Contract NER using instruction based model,2024-01-24 16:05:03+00:00,http://arxiv.org/abs/2401.13545v1,"Hiranmai Sri Adibhatla, Pavan Baswani, Manish Shrivastava",cs.IR,knowledge,"Lately, instruction-based techniques have made significant strides in
improving performance in few-shot learning scenarios. They achieve this by
bridging the gap between pre-trained language models and fine-tuning for
specific downstream tasks. Despite these advancements, the performance of Large
Language Models (LLMs) in information extraction tasks like Named Entity
Recognition (NER), using prompts or instructions, still falls short of
supervised baselines. The reason for this performance gap can be attributed to
the fundamental disparity between NER and LLMs. NER is inherently a sequence
labeling task, where the model must assign entity-type labels to individual
tokens within a sentence. In contrast, LLMs are designed as a text generation
task. This distinction between semantic labeling and text generation leads to
subpar performance. In this paper, we transform the NER task into a
text-generation task that can be readily adapted by LLMs. This involves
enhancing source sentences with task-specific instructions and answer choices,
allowing for the identification of entities and their types within natural
language. We harness the strength of LLMs by integrating supervised learning
within them. The goal of this combined strategy is to boost the performance of
LLMs in extraction tasks like NER while simultaneously addressing hallucination
issues often observed in LLM-generated content. A novel corpus Contract NER
comprising seven frequently observed contract categories, encompassing named
entities associated with 18 distinct legal entity types is released along with
our baseline models. Our models and dataset are available to the community for
future research * .",2024-01-24
"MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion,
  ASR Error Detection, and ASR Error Correction",2024-01-24 06:55:55+00:00,http://arxiv.org/abs/2401.13260v1,"Jiajun He, Xiaohan Shi, Xingfeng Li, Tomoki Toda","cs.CL, cs.MM, cs.SD, eess.AS",knowledge,"The prevalent approach in speech emotion recognition (SER) involves
integrating both audio and textual information to comprehensively identify the
speaker's emotion, with the text generally obtained through automatic speech
recognition (ASR). An essential issue of this approach is that ASR errors from
the text modality can worsen the performance of SER. Previous studies have
proposed using an auxiliary ASR error detection task to adaptively assign
weights of each word in ASR hypotheses. However, this approach has limited
improvement potential because it does not address the coherence of semantic
information in the text. Additionally, the inherent heterogeneity of different
modalities leads to distribution gaps between their representations, making
their fusion challenging. Therefore, in this paper, we incorporate two
auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to
enhance the semantic coherence of ASR text, and further introduce a novel
multi-modal fusion (MF) method to learn shared representations across
modalities. We refer to our method as MF-AED-AEC. Experimental results indicate
that MF-AED-AEC significantly outperforms the baseline model by a margin of
4.1\%.",2024-01-24
IndiText Boost: Text Augmentation for Low Resource India Languages,2024-01-23 20:54:40+00:00,http://arxiv.org/abs/2401.13085v1,"Onkar Litake, Niraj Yagnik, Shreyas Labhsetwar","cs.CL, cs.AI, cs.LG",knowledge,"Text Augmentation is an important task for low-resource languages. It helps
deal with the problem of data scarcity. A data augmentation strategy is used to
deal with the problem of data scarcity. Through the years, much work has been
done on data augmentation for the English language. In contrast, very less work
has been done on Indian languages. This is contrary to the fact that data
augmentation is used to deal with data scarcity. In this work, we focus on
implementing techniques like Easy Data Augmentation, Back Translation,
Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for
text classification on different languages. We focus on 6 Indian languages
namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to
our knowledge, no such work exists for text augmentation on Indian languages.
We carry out binary as well as multi-class text classification to make our
results more comparable. We get surprising results as basic data augmentation
techniques surpass LLMs.",2024-01-23
Unsupervised Learning of Graph from Recipes,2024-01-22 16:25:47+00:00,http://arxiv.org/abs/2401.12088v1,"Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller",cs.CL,knowledge,"Cooking recipes are one of the most readily available kinds of procedural
text. They consist of natural language instructions that can be challenging to
interpret. In this paper, we propose a model to identify relevant information
from recipes and generate a graph to represent the sequence of actions in the
recipe. In contrast with other approaches, we use an unsupervised approach. We
iteratively learn the graph structure and the parameters of a $\mathsf{GNN}$
encoding the texts (text-to-graph) one sequence at a time while providing the
supervision by decoding the graph into text (graph-to-text) and comparing the
generated text to the input. We evaluate the approach by comparing the
identified entities with annotated datasets, comparing the difference between
the input and output texts, and comparing our generated graphs with those
generated by state of the art methods.",2024-01-22
"With Greater Text Comes Greater Necessity: Inference-Time Training Helps
  Long Text Generation",2024-01-21 14:28:41+00:00,http://arxiv.org/abs/2401.11504v1,"Y. Wang, D. Ma, D. Cai","cs.CL, cs.AI",knowledge,"Long text generation, such as novel writing or discourse-level translation
with extremely long contexts, presents significant challenges to current
language models. Existing methods mainly focus on extending the model's context
window through strategies like length extrapolation. However, these approaches
demand substantial hardware resources during the training and/or inference
phases. Our proposed method, Temp-Lora, introduces an alternative concept.
Instead of relying on the KV cache to store all context information, Temp-Lora
embeds this information directly into the model's parameters. In the process of
long text generation, we use a temporary Lora module, progressively trained
with text generated previously. This approach not only efficiently preserves
contextual knowledge but also prevents any permanent alteration to the model's
parameters given that the module is discarded post-generation. Extensive
experiments on the PG19 language modeling benchmark and the GuoFeng
discourse-level translation benchmark validate the effectiveness of Temp-Lora.
Our results show that: 1) Temp-Lora substantially enhances generation quality
for long texts, as indicated by a 13.2% decrease in perplexity on a subset of
PG19, and a 29.6% decrease in perplexity along with a 53.2% increase in BLEU
score on GuoFeng, 2) Temp-Lora is compatible with and enhances most existing
long text generation methods, and 3) Temp-Lora can greatly reduce computational
costs by shortening the context window. While ensuring a slight improvement in
generation quality (a decrease of 3.8% in PPL), it enables a reduction of 70.5%
in the FLOPs required for inference and a 51.5% decrease in latency.",2024-01-21
"Large Language Models for Scientific Information Extraction: An
  Empirical Study for Virology",2024-01-18 15:04:55+00:00,http://arxiv.org/abs/2401.10040v1,"Mahsa Shamsabadi, Jennifer D'Souza, Sören Auer","cs.CL, cs.AI, cs.DL, cs.IT, math.IT",knowledge,"In this paper, we champion the use of structured and semantic content
representation of discourse-based scholarly communication, inspired by tools
like Wikipedia infoboxes or structured Amazon product descriptions. These
representations provide users with a concise overview, aiding scientists in
navigating the dense academic landscape. Our novel automated approach leverages
the robust text generation capabilities of LLMs to produce structured scholarly
contribution summaries, offering both a practical solution and insights into
LLMs' emergent abilities.
  For LLMs, the prime focus is on improving their general intelligence as
conversational agents. We argue that these models can also be applied
effectively in information extraction (IE), specifically in complex IE tasks
within terse domains like Science. This paradigm shift replaces the traditional
modular, pipelined machine learning approach with a simpler objective expressed
through instructions. Our results show that finetuned FLAN-T5 with 1000x fewer
parameters than the state-of-the-art GPT-davinci is competitive for the task.",2024-01-18
"Evolutionary Computation in the Era of Large Language Model: Survey and
  Roadmap",2024-01-18 14:58:17+00:00,http://arxiv.org/abs/2401.10034v1,"Xingyu Wu, Sheng-hao Wu, Jibin Wu, Liang Feng, Kay Chen Tan","cs.NE, cs.AI, cs.CL",knowledge,"Large Language Models (LLMs), built upon Transformer-based architectures with
massive pretraining on diverse data, have not only revolutionized natural
language processing but also extended their prowess to various domains, marking
a significant stride towards artificial general intelligence. The interplay
between LLMs and Evolutionary Algorithms (EAs), despite differing in objectives
and methodologies, reveals intriguing parallels, especially in their shared
optimization nature, black-box characteristics, and proficiency in handling
complex problems. Meanwhile, EA can not only provide an optimization framework
for LLM's further enhancement under black-box settings but also empower LLM
with flexible global search and iterative mechanism in applications. On the
other hand, LLM's abundant domain knowledge enables EA to perform smarter
searches, while its text processing capability assist in deploying EA across
various tasks. Based on their complementary advantages, this paper presents a
comprehensive review and forward-looking roadmap, categorizing their mutual
inspiration into LLM-enhanced evolutionary optimization and EA-enhanced LLM.
Some integrated synergy methods are further introduced to exemplify the
amalgamation of LLMs and EAs in various application scenarios, including neural
architecture search, code generation, software engineering, and text
generation. As the first comprehensive review specifically focused on the EA
research in the era of LLMs, this paper provides a foundational stepping stone
for understanding and harnessing the collaborative potential of LLMs and EAs.
By presenting a comprehensive review, categorization, and critical analysis, we
contribute to the ongoing discourse on the cross-disciplinary study of these
two powerful paradigms. The identified challenges and future directions offer
guidance to unlock the full potential of this innovative collaboration.",2024-01-18
"Contrastive Perplexity for Controlled Generation: An Application in
  Detoxifying Large Language Models",2024-01-16 16:49:39+00:00,http://arxiv.org/abs/2401.08491v2,"Tassilo Klein, Moin Nabi","cs.CL, cs.LG",knowledge,"The generation of undesirable and factually incorrect content of large
language models poses a significant challenge and remains largely an unsolved
issue. This paper studies the integration of a contrastive learning objective
for fine-tuning LLMs for implicit knowledge editing and controlled text
generation. Optimizing the training objective entails aligning text
perplexities in a contrastive fashion. To facilitate training the model in a
self-supervised fashion, we leverage an off-the-shelf LLM for training data
generation. We showcase applicability in the domain of detoxification. Herein,
the proposed approach leads to a significant decrease in the generation of
toxic content while preserving general utility for downstream tasks such as
commonsense reasoning and reading comprehension. The proposed approach is
conceptually simple but empirically powerful.",2024-01-16
LLMs for Test Input Generation for Semantic Caches,2024-01-16 06:16:33+00:00,http://arxiv.org/abs/2401.08138v1,"Zafaryab Rasool, Scott Barnett, David Willie, Stefanus Kurniawan, Sherwin Balugo, Srikanth Thudumu, Mohamed Abdelrazek","cs.SE, cs.AI",knowledge,"Large language models (LLMs) enable state-of-the-art semantic capabilities to
be added to software systems such as semantic search of unstructured documents
and text generation. However, these models are computationally expensive. At
scale, the cost of serving thousands of users increases massively affecting
also user experience. To address this problem, semantic caches are used to
check for answers to similar queries (that may have been phrased differently)
without hitting the LLM service. Due to the nature of these semantic cache
techniques that rely on query embeddings, there is a high chance of errors
impacting user confidence in the system. Adopting semantic cache techniques
usually requires testing the effectiveness of a semantic cache (accurate cache
hits and misses) which requires a labelled test set of similar queries and
responses which is often unavailable. In this paper, we present VaryGen, an
approach for using LLMs for test input generation that produces similar
questions from unstructured text documents. Our novel approach uses the
reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise
subtle variations to queries, and 3) evaluate the synthesised test dataset. We
evaluated our approach in the domain of a student question and answer system by
qualitatively analysing 100 generated queries and result pairs, and conducting
an empirical case study with an open source semantic cache. Our results show
that query pairs satisfy human expectations of similarity and our generated
data demonstrates failure cases of a semantic cache. Additionally, we also
evaluate our approach on Qasper dataset. This work is an important first step
into test input generation for semantic applications and presents
considerations for practitioners when calibrating a semantic cache.",2024-01-16
"Leveraging External Knowledge Resources to Enable Domain-Specific
  Comprehension",2024-01-15 21:43:46+00:00,http://arxiv.org/abs/2401.07977v1,"Saptarshi Sengupta, Connor Heaton, Prasenjit Mitra, Soumalya Sarkar",cs.CL,knowledge,"Machine Reading Comprehension (MRC) has been a long-standing problem in NLP
and, with the recent introduction of the BERT family of transformer based
language models, it has come a long way to getting solved. Unfortunately,
however, when BERT variants trained on general text corpora are applied to
domain-specific text, their performance inevitably degrades on account of the
domain shift i.e. genre/subject matter discrepancy between the training and
downstream application data. Knowledge graphs act as reservoirs for either open
or closed domain information and prior studies have shown that they can be used
to improve the performance of general-purpose transformers in domain-specific
applications. Building on existing work, we introduce a method using
Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings
extracted from knowledge graphs with the embeddings spaces of pre-trained
language models (LMs). We fuse the aligned embeddings with open-domain LMs BERT
and RoBERTa, and fine-tune them for two MRC tasks namely span detection
(COVID-QA) and multiple-choice questions (PubMedQA). On the COVID-QA dataset,
we see that our approach allows these models to perform similar to their
domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match
(EM) metric. With regards to PubMedQA, we observe an overall improvement in
accuracy while the F1 stays relatively the same over the domain-specific
models.",2024-01-15
"Automating Knowledge Acquisition for Content-Centric Cognitive Agents
  Using LLMs",2023-12-27 02:31:51+00:00,http://arxiv.org/abs/2312.16378v1,"Sanjay Oruganti, Sergei Nirenburg, Jesse English, Marjorie McShane","cs.CL, cs.AI",knowledge,"The paper describes a system that uses large language model (LLM) technology
to support the automatic learning of new entries in an intelligent agent's
semantic lexicon. The process is bootstrapped by an existing non-toy lexicon
and a natural language generator that converts formal, ontologically-grounded
representations of meaning into natural language sentences. The learning method
involves a sequence of LLM requests and includes an automatic quality control
step. To date, this learning method has been applied to learning multiword
expressions whose meanings are equivalent to those of transitive verbs in the
agent's lexicon. The experiment demonstrates the benefits of a hybrid learning
architecture that integrates knowledge-based methods and resources with both
traditional data analytics and LLMs.",2023-12-27
"Zur Darstellung eines mehrstufigen Prototypbegriffs in der
  multilingualen automatischen Sprachgenerierung: vom Korpus über word
  embeddings bis hin zum automatischen Wörterbuch",2023-12-26 19:39:25+00:00,http://arxiv.org/abs/2312.16311v1,María José Domínguez Vázquez,cs.CL,knowledge,"The multilingual dictionary of noun valency Portlex is considered to be the
trigger for the creation of the automatic language generators Xera and
Combinatoria, whose development and use is presented in this paper. Both
prototypes are used for the automatic generation of nominal phrases with their
mono- and bi-argumental valence slots, which could be used, among others, as
dictionary examples or as integrated components of future autonomous
E-Learning-Tools. As samples for new types of automatic valency dictionaries
including user interaction, we consider the language generators as we know them
today. In the specific methodological procedure for the development of the
language generators, the syntactic-semantic description of the noun slots turns
out to be the main focus from a syntagmatic and paradigmatic point of view.
Along with factors such as representativeness, grammatical correctness,
semantic coherence, frequency and the variety of lexical candidates, as well as
semantic classes and argument structures, which are fixed components of both
resources, a concept of a multi-sided prototype stands out. The combined
application of this prototype concept as well as of word embeddings together
with techniques from the field of automatic natural language processing and
generation (NLP and NLG) opens up a new way for the future development of
automatically generated plurilingual valency dictionaries. All things
considered, the paper depicts the language generators both from the point of
view of their development as well as from that of the users. The focus lies on
the role of the prototype concept within the development of the resources.",2023-12-26
Making Large Language Models A Better Foundation For Dense Retrieval,2023-12-24 15:10:35+00:00,http://arxiv.org/abs/2312.15503v1,"Chaofan Li, Zheng Liu, Shitao Xiao, Yingxia Shao",cs.CL,knowledge,"Dense retrieval needs to learn discriminative text embeddings to represent
the semantic relationship between query and document. It may benefit from the
using of large language models (LLMs), given LLMs' strong capability on
semantic understanding. However, the LLMs are pre-trained by text generation
tasks, whose working pattern is completely different from representing texts as
embeddings. As a result, it is imperative to study how to adapt LLMs properly
so that they can be effectively initialized as the backbone encoder for dense
retrieval.
  In this paper, we propose a novel approach, called LLaRA (LLM adapted for
dense RetrievAl), which works as a post-hoc adaptation of LLM for the dense
retrieval application. LLaRA consists of two pretext tasks: EBAE
(Embedding-Based Auto-Encoding) and EBAR (Embedding-Based Auto-Regression),
where the text embeddings from LLM are used to reconstruct the tokens for the
input sentence and predict the tokens for the next sentence, respectively.
LLaRA turns out to be simple, lightweight, and highly effective. It is applied
to adapt LLaMA-2-7B (base) on the Wikipedia corpus, where it substantially
improves the model's fine-tuned performances on a variety of dense retrieval
benchmarks, like MSMARCO and BEIR. Our model and code will be made publicly
available at BGE repository.",2023-12-24
Exploiting Novel GPT-4 APIs,2023-12-21 21:22:41+00:00,http://arxiv.org/abs/2312.14302v1,"Kellin Pelrine, Mohammad Taufeeque, Michał Zając, Euan McLean, Adam Gleave","cs.CR, cs.AI, cs.CL, cs.LG, I.2.7",knowledge,"Language model attacks typically assume one of two extreme threat models:
full white-box access to model weights, or black-box access limited to a text
generation API. However, real-world APIs are often more flexible than just text
generation: these APIs expose ``gray-box'' access leading to new threat
vectors. To explore this, we red-team three new functionalities exposed in the
GPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that
fine-tuning a model on as few as 15 harmful examples or 100 benign examples can
remove core safeguards from GPT-4, enabling a range of harmful outputs.
Furthermore, we find that GPT-4 Assistants readily divulge the function call
schema and can be made to execute arbitrary function calls. Finally, we find
that knowledge retrieval can be hijacked by injecting instructions into
retrieval documents. These vulnerabilities highlight that any additions to the
functionality exposed by an API can create new vulnerabilities.",2023-12-21
"LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent
  Sentence Spaces",2023-12-20 17:25:23+00:00,http://arxiv.org/abs/2312.13208v1,"Yingji Zhang, Danilo S. Carvalho, Ian Pratt-Hartmann, André Freitas",cs.CL,knowledge,"Deep generative neural networks, such as Variational AutoEncoders (VAEs),
offer an opportunity to better understand and control language models from the
perspective of sentence-level latent spaces. To combine the controllability of
VAE latent spaces with the state-of-the-art performance of recent large
language models (LLMs), we present in this work LlaMaVAE, which combines
expressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE
architecture, aiming to provide better text generation control to LLMs. In
addition, to conditionally guide the VAE generation, we investigate a new
approach based on flow-based invertible neural networks (INNs) named Invertible
CVAE. Experimental results reveal that LlaMaVAE can outperform the previous
state-of-the-art VAE language model, Optimus, across various tasks, including
language modelling, semantic textual similarity and definition modelling.
Qualitative analysis on interpolation and traversal experiments also indicates
an increased degree of semantic clustering and geometric consistency, which
enables better generation control.",2023-12-20
Can ChatGPT be Your Personal Medical Assistant?,2023-12-19 09:54:27+00:00,http://arxiv.org/abs/2312.12006v1,"Md. Rafiul Biswas, Ashhadul Islam, Zubair Shah, Wajdi Zaghouani, Samir Brahim Belhaouari","cs.CL, cs.SI",knowledge,"The advanced large language model (LLM) ChatGPT has shown its potential in
different domains and remains unbeaten due to its characteristics compared to
other LLMs. This study aims to evaluate the potential of using a fine-tuned
ChatGPT model as a personal medical assistant in the Arabic language. To do so,
this study uses publicly available online questions and answering datasets in
Arabic language. There are almost 430K questions and answers for 20
disease-specific categories. GPT-3.5-turbo model was fine-tuned with a portion
of this dataset. The performance of this fine-tuned model was evaluated through
automated and human evaluation. The automated evaluations include perplexity,
coherence, similarity, and token count. Native Arabic speakers with medical
knowledge evaluated the generated text by calculating relevance, accuracy,
precision, logic, and originality. The overall result shows that ChatGPT has a
bright future in medical assistance.",2023-12-19
"External Knowledge Augmented Polyphone Disambiguation Using Large
  Language Model",2023-12-19 08:00:10+00:00,http://arxiv.org/abs/2312.11920v1,Chen Li,cs.CL,knowledge,"One of the key issues in Mandarin Chinese text-to-speech (TTS) systems is
polyphone disambiguation when doing grapheme-to-phoneme (G2P) conversion. In
this paper, we introduce a novel method to solve the problem as a generation
task. Following the trending research of large language models (LLM) and prompt
learning, the proposed method consists of three modules. Retrieval module
incorporates external knowledge which is a multi-level semantic dictionary of
Chinese polyphonic characters to format the sentence into a prompt. Generation
module adopts the decoder-only Transformer architecture to induce the target
text. Postprocess module corrects the generated text into a valid result if
needed. Experimental results show that our method outperforms the existing
methods on a public dataset called CPP. We also empirically study the impacts
of different templates of the prompt, different sizes of training data, and
whether to incorporate external knowledge.",2023-12-19
Deep dive into language traits of AI-generated Abstracts,2023-12-17 06:03:33+00:00,http://arxiv.org/abs/2312.10617v1,"Vikas Kumar, Amisha Bharti, Devanshu Verma, Vasudha Bhatnagar","cs.CL, cs.LG",knowledge,"Generative language models, such as ChatGPT, have garnered attention for
their ability to generate human-like writing in various fields, including
academic research. The rapid proliferation of generated texts has bolstered the
need for automatic identification to uphold transparency and trust in the
information. However, these generated texts closely resemble human writing and
often have subtle differences in the grammatical structure, tones, and
patterns, which makes systematic scrutinization challenging. In this work, we
attempt to detect the Abstracts generated by ChatGPT, which are much shorter in
length and bounded. We extract the texts semantic and lexical properties and
observe that traditional machine learning models can confidently detect these
Abstracts.",2023-12-17
"A Soft Contrastive Learning-based Prompt Model for Few-shot Sentiment
  Analysis",2023-12-16 15:17:28+00:00,http://arxiv.org/abs/2312.10479v1,"Jingyi Zhou, Jie Zhou, Jiabao Zhao, Siyin Wang, Haijun Shan, Gui Tao, Qi Zhang, Xuanjing Huang",cs.CL,knowledge,"Few-shot text classification has attracted great interest in both academia
and industry due to the lack of labeled data in many fields. Different from
general text classification (e.g., topic classification), few-shot sentiment
classification is more challenging because the semantic distances among the
classes are more subtle. For instance, the semantic distances between the
sentiment labels in a positive or negative polarity (e.g., ``love"" and ``joy"",
``remorse"" and ``sadness"") are close, while the distances are large for the
sentiment labels in two opposite polarities (e.g., ``love"" and ``sadness""). To
address this problem, we propose a Soft Contrastive learning-based Prompt
(\texttt{SCP}) model for few-shot sentiment analysis. First, we design a
sentiment-aware chain of thought prompt module to guide the model to predict
the sentiment from coarse grain to fine grain via a series of intermediate
reasoning steps. Then, we propose a soft contrastive learning algorithm to take
the correlation of the labels into account. A series of experiments on several
sentiment analysis datasets show the great advantages of \texttt{SCP} by
comparing it with SOTA baselines (e.g., ChatGPT).",2023-12-16
CoAScore: Chain-of-Aspects Prompting for NLG Evaluation,2023-12-16 06:57:20+00:00,http://arxiv.org/abs/2312.10355v1,"Peiyuan Gong, Jiaxin Mao",cs.CL,knowledge,"Recently, natural language generation (NLG) evaluation has shifted from a
single-aspect to a multi-aspect paradigm, allowing for a more accurate
assessment. Large language models (LLMs) achieve superior performance on
various NLG evaluation tasks. However, current work often employs the LLM to
independently evaluate different aspects, which largely ignores the rich
correlation between various aspects. To fill this research gap, in this work,
we propose an NLG evaluation metric called CoAScore. Powered by LLMs, the
CoAScore utilizes multi-aspect knowledge through a CoA
(\textbf{C}hain-\textbf{o}f-\textbf{A}spects) prompting framework when
assessing the quality of a certain aspect. Specifically, for a given aspect to
evaluate, we first prompt the LLM to generate a chain of aspects that are
relevant to the target aspect and could be useful for the evaluation. We then
collect evaluation scores for each generated aspect, and finally, leverage the
knowledge of these aspects to improve the evaluation of the target aspect. We
evaluate CoAScore across five NLG evaluation tasks (e.g., summarization, dialog
response generation, etc) and nine aspects (e.g., overall quality, relevance,
coherence, etc). Our experimental findings highlight that, in comparison to
individual aspect evaluation, CoAScore exhibits a higher correlation with human
judgments. This improvement significantly outperforms existing unsupervised
evaluation metrics, whether for assessing overall quality or other aspects. We
also conducted extensive ablation studies to validate the effectiveness of the
three stages within the CoAScore framework and conducted case studies to show
how the LLM performs in these stages. Our code and scripts are available.",2023-12-16
GSQA: An End-to-End Model for Generative Spoken Question Answering,2023-12-15 13:33:18+00:00,http://arxiv.org/abs/2312.09781v1,"Min-Han Shih, Ho-Lam Chung, Yu-Chi Pai, Ming-Hao Hsu, Guan-Ting Lin, Shang-Wen Li, Hung-yi Lee","cs.CL, cs.AI",knowledge,"In recent advancements in spoken question answering (QA), end-to-end models
have made significant strides. However, previous research has primarily focused
on extractive span selection. While this extractive-based approach is effective
when answers are present directly within the input, it falls short in
addressing abstractive questions, where answers are not directly extracted but
inferred from the given information. To bridge this gap, we introduce the first
end-to-end Generative Spoken Question Answering (GSQA) model that empowers the
system to engage in abstractive reasoning. The challenge in training our GSQA
model lies in the absence of a spoken abstractive QA dataset. We propose using
text models for initialization and leveraging the extractive QA dataset to
transfer knowledge from the text generative model to the spoken generative
model. Experimental results indicate that our model surpasses the previous
extractive model by 3% on extractive QA datasets. Furthermore, the GSQA model
has only been fine-tuned on the spoken extractive QA dataset. Despite not
having seen any spoken abstractive QA data, it can still closely match the
performance of the cascade model. In conclusion, our GSQA model shows the
potential to generalize to a broad spectrum of questions, thus further
expanding spoken question answering capabilities of abstractive QA. Our code is
available at
\href{https://voidful.github.io/GSQA}{https://voidful.github.io/GSQA}",2023-12-15
"Extending Context Window of Large Language Models via Semantic
  Compression",2023-12-15 07:04:33+00:00,http://arxiv.org/abs/2312.09571v1,"Weizhi Fei, Xueyan Niu, Pingyi Zhou, Lu Hou, Bo Bai, Lei Deng, Wei Han","cs.CL, cs.IT, math.IT",knowledge,"Transformer-based Large Language Models (LLMs) often impose limitations on
the length of the text input to ensure the generation of fluent and relevant
responses. This constraint restricts their applicability in scenarios involving
long texts. We propose a novel semantic compression method that enables
generalization to texts that are 6-8 times longer, without incurring
significant computational costs or requiring fine-tuning. Our proposed
framework draws inspiration from source coding in information theory and
employs a pre-trained model to reduce the semantic redundancy of long inputs
before passing them to the LLMs for downstream tasks. Experimental results
demonstrate that our method effectively extends the context window of LLMs
across a range of tasks including question answering, summarization, few-shot
learning, and information retrieval. Furthermore, the proposed semantic
compression method exhibits consistent fluency in text generation while
reducing the associated computational overhead.",2023-12-15
"Towards Verifiable Text Generation with Evolving Memory and
  Self-Reflection",2023-12-14 16:10:56+00:00,http://arxiv.org/abs/2312.09075v1,"Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin",cs.CL,knowledge,"Large Language Models (LLMs) face several challenges, including the tendency
to produce incorrect outputs, known as hallucination. An effective solution is
verifiable text generation, which prompts LLMs to generate content with
citations for accuracy verification. However, verifiable text generation is
non-trivial due to the focus-shifting phenomenon, the dilemma between the
precision and scope in document retrieval, and the intricate reasoning required
to discern the relationship between the claim and citations. In this paper, we
present VTG, an innovative approach for Verifiable Text Generation with
evolving memory and self-reflection. VTG maintains evolving long short-term
memory to retain both valuable documents and up-to-date documents. Active
retrieval and diverse query generation are utilized to enhance both the
precision and scope of the retrieved documents. Furthermore, VTG features a
two-tier verifier and an evidence finder, enabling rethinking and reflection on
the relationship between the claim and citations. We conduct extensive
experiments on five datasets across three knowledge-intensive tasks and the
results reveal that VTG significantly outperforms existing baselines.",2023-12-14
Towards Optimal Statistical Watermarking,2023-12-13 06:57:00+00:00,http://arxiv.org/abs/2312.07930v1,"Baihe Huang, Banghua Zhu, Hanlin Zhu, Jason D. Lee, Jiantao Jiao, Michael I. Jordan","cs.LG, cs.CL, cs.CR, cs.IT, math.IT, stat.ML",knowledge,"We study statistical watermarking by formulating it as a hypothesis testing
problem, a general framework which subsumes all previous statistical
watermarking methods. Key to our formulation is a coupling of the output tokens
and the rejection region, realized by pseudo-random generators in practice,
that allows non-trivial trade-off between the Type I error and Type II error.
We characterize the Uniformly Most Powerful (UMP) watermark in this context. In
the most common scenario where the output is a sequence of $n$ tokens, we
establish matching upper and lower bounds on the number of i.i.d. tokens
required to guarantee small Type I and Type II errors. Our rate scales as
$\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$
and thus greatly improves the $O(h^{-2})$ rate in the previous works. For
scenarios where the detector lacks knowledge of the model's distribution, we
introduce the concept of model-agnostic watermarking and establish the minimax
bounds for the resultant increase in Type II error. Moreover, we formulate the
robust watermarking problem where user is allowed to perform a class of
perturbation on the generated texts, and characterize the optimal type II error
of robust UMP tests via a linear programming problem. To the best of our
knowledge, this is the first systematic statistical treatment on the
watermarking problem with near-optimal rates in the i.i.d. setting, and might
be of interest for future works.",2023-12-13
"Leveraging Generative Language Models for Weakly Supervised Sentence
  Component Analysis in Video-Language Joint Learning",2023-12-10 02:03:51+00:00,http://arxiv.org/abs/2312.06699v1,"Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Rahul Pratap Singh, Bishmoy Paul, Ali Dabouei, Min Xu","cs.CV, cs.LG",knowledge,"A thorough comprehension of textual data is a fundamental element in
multi-modal video analysis tasks. However, recent works have shown that the
current models do not achieve a comprehensive understanding of the textual data
during the training for the target downstream tasks. Orthogonal to the previous
approaches to this limitation, we postulate that understanding the significance
of the sentence components according to the target task can potentially enhance
the performance of the models. Hence, we utilize the knowledge of a pre-trained
large language model (LLM) to generate text samples from the original ones,
targeting specific sentence components. We propose a weakly supervised
importance estimation module to compute the relative importance of the
components and utilize them to improve different video-language tasks. Through
rigorous quantitative analysis, our proposed method exhibits significant
improvement across several video-language tasks. In particular, our approach
notably enhances video-text retrieval by a relative improvement of 8.3\% in
video-to-text and 1.4\% in text-to-video retrieval over the baselines, in terms
of R@1. Additionally, in video moment retrieval, average mAP shows a relative
improvement ranging from 2.0\% to 13.7 \% across different baselines.",2023-12-10
"An Attention-Based Denoising Framework for Personality Detection in
  Social Media Texts",2023-11-16 14:56:09+00:00,http://arxiv.org/abs/2311.09945v1,"Qirui Tang, Wenkang Jiang, Yihua Du, Lei Lin","cs.CY, cs.CL",knowledge,"In social media networks, users produce a large amount of text content
anytime, providing researchers with a valuable approach to digging for
personality-related information. Personality detection based on user-generated
texts is a universal method that can be used to build user portraits. The
presence of noise in social media texts hinders personality detection. However,
previous studies have not fully addressed this challenge. Inspired by the
scanning reading technique, we propose an attention-based information
extraction mechanism (AIEM) for long texts, which is applied to quickly locate
valuable pieces of information, and focus more attention on the deep semantics
of key pieces. Then, we provide a novel attention-based denoising framework
(ADF) for personality detection tasks and achieve state-of-the-art performance
on two commonly used datasets. Notably, we obtain an average accuracy
improvement of 10.2% on the gold standard Twitter-Myers-Briggs Type Indicator
(Twitter-MBTI) dataset. We made our code publicly available on GitHub. We shed
light on how AIEM works to magnify personality-related signals.",2023-11-16
X-Mark: Towards Lossless Watermarking Through Lexical Redundancy,2023-11-16 11:58:31+00:00,http://arxiv.org/abs/2311.09832v1,"Liang Chen, Yatao Bian, Yang Deng, Shuaiyi Li, Bingzhe Wu, Peilin Zhao, Kam-fai Wong",cs.CL,knowledge,"Text watermarking has emerged as an important technique for detecting
machine-generated text. However, existing methods can severely degrade text
quality due to arbitrary vocabulary partitioning, which disrupts the language
model's expressiveness and impedes textual coherence. To mitigate this, we
introduce XMark, a novel approach that capitalizes on text redundancy within
the lexical space. Specifically, XMark incorporates a mutually exclusive rule
for synonyms during the language model decoding process, thereby integrating
prior knowledge into vocabulary partitioning and preserving the capabilities of
language generation. We present theoretical analyses and empirical evidence
demonstrating that XMark substantially enhances text generation fluency while
maintaining watermark detectability. Furthermore, we investigate watermarking's
impact on the emergent abilities of large language models, including zero-shot
and few-shot knowledge recall, logical reasoning, and instruction following.
Our comprehensive experiments confirm that XMark consistently outperforms
existing methods in retaining these crucial capabilities of LLMs.",2023-11-16
"The Curious Decline of Linguistic Diversity: Training Language Models on
  Synthetic Text",2023-11-16 11:31:50+00:00,http://arxiv.org/abs/2311.09807v1,"Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, Chloé Clavel",cs.CL,knowledge,"This study investigates the consequences of training large language models
(LLMs) on synthetic data generated by their predecessors, an increasingly
prevalent practice aimed at addressing the limited supply of human-generated
training data. Diverging from the usual emphasis on performance metrics, we
focus on the impact of this training methodology on linguistic diversity,
especially when conducted recursively over time. To assess this, we developed a
set of novel metrics targeting lexical, syntactic, and semantic diversity,
applying them in recursive fine-tuning experiments across various natural
language generation tasks. Our findings reveal a marked decrease in the
diversity of the models' outputs through successive iterations. This trend
underscores the potential risks of training LLMs on predecessor-generated text,
particularly concerning the preservation of linguistic richness. Our study
highlights the need for careful consideration of the long-term effects of such
training approaches on the linguistic capabilities of LLMs.",2023-11-16
"Improving the Generation Quality of Watermarked Large Language Models
  via Word Importance Scoring",2023-11-16 08:36:00+00:00,http://arxiv.org/abs/2311.09668v1,"Yuhang Li, Yihan Wang, Zhouxing Shi, Cho-Jui Hsieh","cs.CL, cs.CR, cs.LG",knowledge,"The strong general capabilities of Large Language Models (LLMs) bring
potential ethical risks if they are unrestrictedly accessible to malicious
users. Token-level watermarking inserts watermarks in the generated texts by
altering the token probability distributions with a private random number
generator seeded by its prefix tokens. However, this watermarking algorithm
alters the logits during generation, which can lead to a downgraded text
quality if it chooses to promote tokens that are less relevant given the input.
In this work, we propose to improve the quality of texts generated by a
watermarked language model by Watermarking with Importance Scoring (WIS). At
each generation step, we estimate the importance of the token to generate, and
prevent it from being impacted by watermarking if it is important for the
semantic correctness of the output. We further propose three methods to predict
importance scoring, including a perturbation-based method and two model-based
methods. Empirical experiments show that our method can generate texts with
better quality with comparable level of detection rate.",2023-11-16
"Think While You Write: Hypothesis Verification Promotes Faithful
  Knowledge-to-Text Generation",2023-11-16 00:13:19+00:00,http://arxiv.org/abs/2311.09467v1,"Yifu Qiu, Varun Embar, Shay B. Cohen, Benjamin Han","cs.CL, cs.AI",knowledge,"Neural knowledge-to-text generation models often struggle to faithfully
generate descriptions for the input facts: they may produce hallucinations that
contradict the given facts, or describe facts not present in the input. To
reduce hallucinations, we propose a novel decoding method, TWEAK (Think While
Effectively Articulating Knowledge). TWEAK treats the generated sequences at
each decoding step and its future sequences as hypotheses, and ranks each
generation candidate based on how well their corresponding hypotheses support
the input facts using a Hypothesis Verification Model (HVM). We first
demonstrate the effectiveness of TWEAK by using a Natural Language Inference
(NLI) model as the HVM and report improved faithfulness with minimal impact on
the quality. We then replace the NLI model with our task-specific HVM trained
with a first-of-a-kind dataset, FATE (Fact-Aligned Textual Entailment), which
pairs input facts with their faithful and hallucinated descriptions with the
hallucinated spans marked. The new HVM improves the faithfulness and the
quality further and runs faster. Overall the best TWEAK variants improve on
average 2.22/7.17 points on faithfulness measured by FactKB over WebNLG and
TekGen/GenWiki, respectively, with only 0.14/0.32 points degradation on quality
measured by BERTScore over the same datasets. Since TWEAK is a decoding-only
approach, it can be integrated with any neural generative model without
retraining.",2023-11-16
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,knowledge,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
REST: Retrieval-Based Speculative Decoding,2023-11-14 15:43:47+00:00,http://arxiv.org/abs/2311.08252v1,"Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D Lee, Di He","cs.CL, cs.AI, cs.IR, cs.LG",knowledge,"We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm
designed to speed up language model generation. The key insight driving the
development of REST is the observation that the process of text generation
often includes certain common phases and patterns. Unlike previous methods that
rely on a draft language model for speculative decoding, REST harnesses the
power of retrieval to generate draft tokens. This method draws from the
reservoir of existing knowledge, retrieving and employing relevant tokens based
on the current context. Its plug-and-play nature allows for seamless
integration and acceleration of any language models, all without necessitating
additional training. When benchmarked on 7B and 13B language models in a
single-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on
code or text generation. The code of REST is available at
https://github.com/FasterDecoding/REST.",2023-11-14
"RECALL: A Benchmark for LLMs Robustness against External Counterfactual
  Knowledge",2023-11-14 13:24:19+00:00,http://arxiv.org/abs/2311.08147v1,"Yi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun","cs.CL, cs.AI",knowledge,"LLMs and AI chatbots have improved people's efficiency in various fields.
However, the necessary knowledge for answering the question may be beyond the
models' knowledge boundaries. To mitigate this issue, many researchers try to
introduce external knowledge, such as knowledge graphs and Internet contents,
into LLMs for up-to-date information. However, the external information from
the Internet may include counterfactual information that will confuse the model
and lead to an incorrect response. Thus there is a pressing need for LLMs to
possess the ability to distinguish reliable information from external
knowledge. Therefore, to evaluate the ability of LLMs to discern the
reliability of external knowledge, we create a benchmark from existing
knowledge bases. Our benchmark consists of two tasks, Question Answering and
Text Generation, and for each task, we provide models with a context containing
counterfactual information. Evaluation results show that existing LLMs are
susceptible to interference from unreliable external knowledge with
counterfactual information, and simple intervention methods make limited
contributions to the alleviation of this issue.",2023-11-14
Insights into Classifying and Mitigating LLMs' Hallucinations,2023-11-14 12:30:28+00:00,http://arxiv.org/abs/2311.08117v1,"Alessandro Bruno, Pier Luigi Mazzeo, Aladine Chetouani, Marouane Tliba, Mohamed Amine Kerkouri",cs.CL,knowledge,"The widespread adoption of large language models (LLMs) across diverse AI
applications is proof of the outstanding achievements obtained in several
tasks, such as text mining, text generation, and question answering. However,
LLMs are not exempt from drawbacks. One of the most concerning aspects regards
the emerging problematic phenomena known as ""Hallucinations"". They manifest in
text generation systems, particularly in question-answering systems reliant on
LLMs, potentially resulting in false or misleading information propagation.
This paper delves into the underlying causes of AI hallucination and elucidates
its significance in artificial intelligence. In particular, Hallucination
classification is tackled over several tasks (Machine Translation, Question and
Answer, Dialog Systems, Summarisation Systems, Knowledge Graph with LLMs, and
Visual Question Answer). Additionally, we explore potential strategies to
mitigate hallucinations, aiming to enhance the overall reliability of LLMs. Our
research addresses this critical issue within the HeReFaNMi (Health-Related
Fake News Mitigation) project, generously supported by NGI Search, dedicated to
combating Health-Related Fake News dissemination on the Internet. This
endeavour represents a concerted effort to safeguard the integrity of
information dissemination in an age of evolving AI technologies.",2023-11-14
LLatrieval: LLM-Verified Retrieval for Verifiable Generation,2023-11-14 01:38:02+00:00,http://arxiv.org/abs/2311.07838v1,"Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu","cs.CL, cs.AI, cs.IR",knowledge,"Verifiable generation aims to let the large language model (LLM) generate
text with corresponding supporting documents, which enables the user to
flexibly verify the answer and makes it more trustworthy. Its evaluation not
only measures the correctness of the answer, but also the answer's
verifiability, i.e., how well the answer is supported by the corresponding
documents. In typical, verifiable generation adopts the retrieval-read
pipeline, which is divided into two stages: 1) retrieve relevant documents of
the question. 2) according to the documents, generate the corresponding answer.
Since the retrieved documents can supplement knowledge for the LLM to generate
the answer and serve as evidence, the retrieval stage is essential for the
correctness and verifiability of the answer. However, the widely used
retrievers become the bottleneck of the entire pipeline and limit the overall
performance. They often have fewer parameters than the large language model and
have not been proven to scale well to the size of LLMs. Since the LLM passively
receives the retrieval result, if the retriever does not correctly find the
supporting documents, the LLM can not generate the correct and verifiable
answer, which overshadows the LLM's remarkable abilities. In this paper, we
propose LLatrieval (Large Language Model Verified Retrieval), where the LLM
updates the retrieval result until it verifies that the retrieved documents can
support answering the question. Thus, the LLM can iteratively provide feedback
to retrieval and facilitate the retrieval result to sufficiently support
verifiable generation. Experimental results show that our method significantly
outperforms extensive baselines and achieves new state-of-the-art results.",2023-11-14
"AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language
  Models Denoising",2023-11-13 19:36:54+00:00,http://arxiv.org/abs/2311.07700v1,"Zhen Guo, Shangdi Yu","cs.CL, cs.AI, cs.LG",knowledge,"Large language models (LLMs) have opened up enormous opportunities while
simultaneously posing ethical dilemmas. One of the major concerns is their
ability to create text that closely mimics human writing, which can lead to
potential misuse, such as academic misconduct, disinformation, and fraud. To
address this problem, we present AuthentiGPT, an efficient classifier that
distinguishes between machine-generated and human-written texts. Under the
assumption that human-written text resides outside the distribution of
machine-generated text, AuthentiGPT leverages a black-box LLM to denoise input
text with artificially added noise, and then semantically compares the denoised
text with the original to determine if the content is machine-generated. With
only one trainable parameter, AuthentiGPT eliminates the need for a large
training dataset, watermarking the LLM's output, or computing the
log-likelihood. Importantly, the detection capability of AuthentiGPT can be
easily adapted to any generative language model. With a 0.918 AUROC score on a
domain-specific dataset, AuthentiGPT demonstrates its effectiveness over other
commercial algorithms, highlighting its potential for detecting
machine-generated text in academic settings.",2023-11-13
"Controlled Text Generation for Black-box Language Models via Score-based
  Progressive Editor",2023-11-13 16:03:23+00:00,http://arxiv.org/abs/2311.07430v1,"Sangwon Yu, Changmin Lee, Hojin Lee, Sungroh Yoon",cs.CL,knowledge,"Despite recent progress in language models, generating constrained text for
specific domains remains a challenge, particularly when utilizing black-box
models that lack domain-specific knowledge. In this paper, we introduce ScoPE
(Score-based Progressive Editor) generation, a novel approach for controlled
text generation for black-box language models. We employ ScoPE to facilitate
text generation in the target domain by integrating it with language models
through a cascading approach. Trained to enhance the target domain score of the
edited text, ScoPE progressively edits intermediate output discrete tokens to
align with the target attributes throughout the auto-regressive generation
process of the language model. This iterative process guides subsequent steps
to produce desired output texts for the target domain. Our experimental results
on diverse controlled generations demonstrate that ScoPE effectively
facilitates controlled text generation for black-box language models in both
in-domain and out-of-domain conditions, which is challenging for existing
methods.",2023-11-13
"TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for
  Human-Aligned LLMs",2023-11-09 13:58:59+00:00,http://arxiv.org/abs/2311.05374v1,"Shuyi Xie, Wenlin Yao, Yong Dai, Shaobo Wang, Donlin Zhou, Lifeng Jin, Xinhua Feng, Pengzhi Wei, Yujie Lin, Zhichao Hu, Dong Yu, Zhengyou Zhang, Jing Nie, Yuhong Liu","cs.CL, cs.AI",knowledge,"Large language models (LLMs) have shown impressive capabilities across
various natural language tasks. However, evaluating their alignment with human
preferences remains a challenge. To this end, we propose a comprehensive human
evaluation framework to assess LLMs' proficiency in following instructions on
diverse real-world tasks. We construct a hierarchical task tree encompassing 7
major areas covering over 200 categories and over 800 tasks, which covers
diverse capabilities such as question answering, reasoning, multiturn dialogue,
and text generation, to evaluate LLMs in a comprehensive and in-depth manner.
We also design detailed evaluation standards and processes to facilitate
consistent, unbiased judgments from human evaluators. A test set of over 3,000
instances is released, spanning different difficulty levels and knowledge
domains. Our work provides a standardized methodology to evaluate human
alignment in LLMs for both English and Chinese. We also analyze the feasibility
of automating parts of evaluation with a strong LLM (GPT-4). Our framework
supports a thorough assessment of LLMs as they are integrated into real-world
applications. We have made publicly available the task tree, TencentLLMEval
dataset, and evaluation methodology which have been demonstrated as effective
in assessing the performance of Tencent Hunyuan LLMs. By doing so, we aim to
facilitate the benchmarking of advances in the development of safe and
human-aligned LLMs.",2023-11-09
Aspects of human memory and Large Language Models,2023-11-07 09:39:12+00:00,http://arxiv.org/abs/2311.03839v2,Romuald A. Janik,"cs.CL, cs.AI, cs.LG, q-bio.NC",knowledge,"Large Language Models (LLMs) are huge artificial neural networks which
primarily serve to generate text, but also provide a very sophisticated
probabilistic model of language use. Since generating a semantically consistent
text requires a form of effective memory, we investigate the memory properties
of LLMs and find surprising similarities with key characteristics of human
memory. We argue that the human-like memory properties of the Large Language
Model do not follow automatically from the LLM architecture but are rather
learned from the statistics of the training textual data. These results
strongly suggest that the biological features of human memory leave an imprint
on the way that we structure our textual narratives.",2023-11-07
Automatic Logical Forms improve fidelity in Table-to-Text generation,2023-10-26 10:00:24+00:00,http://arxiv.org/abs/2310.17279v1,"Iñigo Alonso, Eneko Agirre",cs.CL,knowledge,"Table-to-text systems generate natural language statements from structured
data like tables. While end-to-end techniques suffer from low factual
correctness (fidelity), a previous study reported gains when using manual
logical forms (LF) that represent the selected content and the semantics of the
target text. Given the manual step, it was not clear whether automatic LFs
would be effective, or whether the improvement came from content selection
alone. We present TlT which, given a table and a selection of the content,
first produces LFs and then the textual statement. We show for the first time
that automatic LFs improve quality, with an increase in fidelity of 30 points
over a comparable system not using LFs. Our experiments allow to quantify the
remaining challenges for high factual correctness, with automatic selection of
content coming first, followed by better Logic-to-Text generation and, to a
lesser extent, better Table-to-Logic parsing.",2023-10-26
Knowledge Editing for Large Language Models: A Survey,2023-10-24 22:18:13+00:00,http://arxiv.org/abs/2310.16218v2,"Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, Jundong Li","cs.CL, cs.AI",knowledge,"Large language models (LLMs) have recently transformed both the academic and
industrial landscapes due to their remarkable capacity to understand, analyze,
and generate texts based on their vast knowledge and reasoning ability.
Nevertheless, one major drawback of LLMs is their substantial computational
cost for pre-training due to their unprecedented amounts of parameters. The
disadvantage is exacerbated when new knowledge frequently needs to be
introduced into the pre-trained model. Therefore, it is imperative to develop
effective and efficient techniques to update pre-trained LLMs. Traditional
methods encode new knowledge in pre-trained LLMs through direct fine-tuning.
However, naively re-training LLMs can be computationally intensive and risks
degenerating valuable pre-trained knowledge irrelevant to the update in the
model. Recently, Knowledge-based Model Editing (KME) has attracted increasing
attention, which aims to precisely modify the LLMs to incorporate specific
knowledge, without negatively influencing other irrelevant knowledge. In this
survey, we aim to provide a comprehensive and in-depth overview of recent
advances in the field of KME. We first introduce a general formulation of KME
to encompass different KME strategies. Afterward, we provide an innovative
taxonomy of KME techniques based on how the new knowledge is introduced into
pre-trained LLMs, and investigate existing KME strategies while analyzing key
insights, advantages, and limitations of methods from each category. Moreover,
representative metrics, datasets, and applications of KME are introduced
accordingly. Finally, we provide an in-depth analysis regarding the
practicality and remaining challenges of KME and suggest promising research
directions for further advancement in this field.",2023-10-24
"Woodpecker: Hallucination Correction for Multimodal Large Language
  Models",2023-10-24 17:58:07+00:00,http://arxiv.org/abs/2310.16045v1,"Shukang Yin, Chaoyou Fu, Sirui Zhao, Tong Xu, Hao Wang, Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, Enhong Chen","cs.CV, cs.AI, cs.CL, cs.LG",knowledge,"Hallucination is a big shadow hanging over the rapidly evolving Multimodal
Large Language Models (MLLMs), referring to the phenomenon that the generated
text is inconsistent with the image content. In order to mitigate
hallucinations, existing studies mainly resort to an instruction-tuning manner
that requires retraining the models with specific data. In this paper, we pave
a different way, introducing a training-free method named Woodpecker. Like a
woodpecker heals trees, it picks out and corrects hallucinations from the
generated text. Concretely, Woodpecker consists of five stages: key concept
extraction, question formulation, visual knowledge validation, visual claim
generation, and hallucination correction. Implemented in a post-remedy manner,
Woodpecker can easily serve different MLLMs, while being interpretable by
accessing intermediate outputs of the five stages. We evaluate Woodpecker both
quantitatively and qualitatively and show the huge potential of this new
paradigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement
in accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released
at https://github.com/BradyFU/Woodpecker.",2023-10-24
Enhancing Biomedical Lay Summarisation with External Knowledge Graphs,2023-10-24 10:25:21+00:00,http://arxiv.org/abs/2310.15702v1,"Tomas Goldsack, Zhihao Zhang, Chen Tang, Carolina Scarton, Chenghua Lin",cs.CL,knowledge,"Previous approaches for automatic lay summarisation are exclusively reliant
on the source article that, given it is written for a technical audience (e.g.,
researchers), is unlikely to explicitly define all technical concepts or state
all of the background information that is relevant for a lay audience. We
address this issue by augmenting eLife, an existing biomedical lay
summarisation dataset, with article-specific knowledge graphs, each containing
detailed information on relevant biomedical concepts. Using both automatic and
human evaluations, we systematically investigate the effectiveness of three
different approaches for incorporating knowledge graphs within lay
summarisation models, with each method targeting a distinct area of the
encoder-decoder model architecture. Our results confirm that integrating
graph-based domain knowledge can significantly benefit lay summarisation by
substantially increasing the readability of generated text and improving the
explanation of technical concepts.",2023-10-24
"Let the Pretrained Language Models ""Imagine"" for Short Texts Topic
  Modeling",2023-10-24 00:23:30+00:00,http://arxiv.org/abs/2310.15420v1,"Pritom Saha Akash, Jie Huang, Kevin Chen-Chuan Chang",cs.CL,knowledge,"Topic models are one of the compelling methods for discovering latent
semantics in a document collection. However, it assumes that a document has
sufficient co-occurrence information to be effective. However, in short texts,
co-occurrence information is minimal, which results in feature sparsity in
document representation. Therefore, existing topic models (probabilistic or
neural) mostly fail to mine patterns from them to generate coherent topics. In
this paper, we take a new approach to short-text topic modeling to address the
data-sparsity issue by extending short text into longer sequences using
existing pre-trained language models (PLMs). Besides, we provide a simple
solution extending a neural topic model to reduce the effect of noisy
out-of-topics text generation from PLMs. We observe that our model can
substantially improve the performance of short-text topic modeling. Extensive
experiments on multiple real-world datasets under extreme data sparsity
scenarios show that our models can generate high-quality topics outperforming
state-of-the-art models.",2023-10-24
"Towards Possibilities & Impossibilities of AI-generated Text Detection:
  A Survey",2023-10-23 18:11:32+00:00,http://arxiv.org/abs/2310.15264v1,"Soumya Suvra Ghosal, Souradip Chakraborty, Jonas Geiping, Furong Huang, Dinesh Manocha, Amrit Singh Bedi","cs.CL, cs.AI",knowledge,"Large Language Models (LLMs) have revolutionized the domain of natural
language processing (NLP) with remarkable capabilities of generating human-like
text responses. However, despite these advancements, several works in the
existing literature have raised serious concerns about the potential misuse of
LLMs such as spreading misinformation, generating fake news, plagiarism in
academia, and contaminating the web. To address these concerns, a consensus
among the research community is to develop algorithmic solutions to detect
AI-generated text. The basic idea is that whenever we can tell if the given
text is either written by a human or an AI, we can utilize this information to
address the above-mentioned concerns. To that end, a plethora of detection
frameworks have been proposed, highlighting the possibilities of AI-generated
text detection. But in parallel to the development of detection frameworks,
researchers have also concentrated on designing strategies to elude detection,
i.e., focusing on the impossibilities of AI-generated text detection. This is a
crucial step in order to make sure the detection frameworks are robust enough
and it is not too easy to fool a detector. Despite the huge interest and the
flurry of research in this domain, the community currently lacks a
comprehensive analysis of recent developments. In this survey, we aim to
provide a concise categorization and overview of current work encompassing both
the prospects and the limitations of AI-generated text detection. To enrich the
collective knowledge, we engage in an exhaustive discussion on critical and
challenging open questions related to ongoing research on AI-generated text
detection.",2023-10-23
"Fidelity-Enriched Contrastive Search: Reconciling the
  Faithfulness-Diversity Trade-Off in Text Generation",2023-10-23 14:27:45+00:00,http://arxiv.org/abs/2310.14981v1,"Wei-Lin Chen, Cheng-Kuang Wu, Hsin-Hsi Chen, Chung-Chi Chen",cs.CL,knowledge,"In this paper, we address the hallucination problem commonly found in natural
language generation tasks. Language models often generate fluent and convincing
content but can lack consistency with the provided source, resulting in
potential inaccuracies. We propose a new decoding method called
Fidelity-Enriched Contrastive Search (FECS), which augments the contrastive
search framework with context-aware regularization terms. FECS promotes tokens
that are semantically similar to the provided source while penalizing
repetitiveness in the generated text. We demonstrate its effectiveness across
two tasks prone to hallucination: abstractive summarization and dialogue
generation. Results show that FECS consistently enhances faithfulness across
various language model sizes while maintaining output diversity comparable to
well-performing decoding algorithms.",2023-10-23
"HateRephrase: Zero- and Few-Shot Reduction of Hate Intensity in Online
  Posts using Large Language Models",2023-10-21 12:18:29+00:00,http://arxiv.org/abs/2310.13985v1,"Vibhor Agarwal, Yu Chen, Nishanth Sastry",cs.CL,knowledge,"Hate speech has become pervasive in today's digital age. Although there has
been considerable research to detect hate speech or generate counter speech to
combat hateful views, these approaches still cannot completely eliminate the
potential harmful societal consequences of hate speech -- hate speech, even
when detected, can often not be taken down or is often not taken down enough;
and hate speech unfortunately spreads quickly, often much faster than any
generated counter speech.
  This paper investigates a relatively new yet simple and effective approach of
suggesting a rephrasing of potential hate speech content even before the post
is made. We show that Large Language Models (LLMs) perform well on this task,
outperforming state-of-the-art baselines such as BART-Detox. We develop 4
different prompts based on task description, hate definition, few-shot
demonstrations and chain-of-thoughts for comprehensive experiments and conduct
experiments on open-source LLMs such as LLaMA-1, LLaMA-2 chat, Vicuna as well
as OpenAI's GPT-3.5. We propose various evaluation metrics to measure the
efficacy of the generated text and ensure the generated text has reduced hate
intensity without drastically changing the semantic meaning of the original
text.
  We find that LLMs with a few-shot demonstrations prompt work the best in
generating acceptable hate-rephrased text with semantic meaning similar to the
original text. Overall, we find that GPT-3.5 outperforms the baseline and
open-source models for all the different kinds of prompts. We also perform
human evaluations and interestingly, find that the rephrasings generated by
GPT-3.5 outperform even the human-generated ground-truth rephrasings in the
dataset. We also conduct detailed ablation studies to investigate why LLMs work
satisfactorily on this task and conduct a failure analysis to understand the
gaps.",2023-10-21
"Automatic Unit Test Data Generation and Actor-Critic Reinforcement
  Learning for Code Synthesis",2023-10-20 17:13:16+00:00,http://arxiv.org/abs/2310.13669v1,"Philip John Gorinski, Matthieu Zimmer, Gerasimos Lampouras, Derrick Goh Xin Deik, Ignacio Iacobacci","cs.LG, cs.AI, cs.CL, cs.PL",knowledge,"The advent of large pre-trained language models in the domain of Code
Synthesis has shown remarkable performance on various benchmarks, treating the
problem of Code Generation in a fashion similar to Natural Language Generation,
trained with a Language Modelling (LM) objective. In addition, the property of
programming language code being precisely evaluable with respect to its
semantics -- through the use of Unit Tests to check its functional correctness
-- lends itself to using Reinforcement Learning (RL) as a further training
paradigm. Previous work has shown that RL can be applied as such to improve
models' coding capabilities; however, such RL-based methods rely on a reward
signal based on defined Unit Tests, which are much harder to obtain compared to
the huge crawled code datasets used in LM objectives. In this work, we present
a novel approach to automatically obtain data consisting of function signatures
and associated Unit Tests, suitable for RL training of Code Synthesis models.
We also introduce a straightforward, simple yet effective Actor-Critic RL
training scheme and show that it, in conjunction with automatically generated
training data, leads to improvement of a pre-trained code language model's
performance by up to 9.9% improvement over the original underlying code
synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or
CodeRL.",2023-10-20
Knowledge-Augmented Language Model Verification,2023-10-19 15:40:00+00:00,http://arxiv.org/abs/2310.12836v1,"Jinheon Baek, Soyeong Jeong, Minki Kang, Jong C. Park, Sung Ju Hwang","cs.CL, cs.LG",knowledge,"Recent Language Models (LMs) have shown impressive capabilities in generating
texts with the knowledge internalized in parameters. Yet, LMs often generate
the factually incorrect responses to the given queries, since their knowledge
may be inaccurate, incomplete, and outdated. To address this problem, previous
works propose to augment LMs with the knowledge retrieved from an external
knowledge source. However, such approaches often show suboptimal text
generation performance due to two reasons: 1) the model may fail to retrieve
the knowledge relevant to the given query, or 2) the model may not faithfully
reflect the retrieved knowledge in the generated text. To overcome these, we
propose to verify the output and the knowledge of the knowledge-augmented LMs
with a separate verifier, which is a small LM that is trained to detect those
two types of errors through instruction-finetuning. Then, when the verifier
recognizes an error, we can rectify it by either retrieving new knowledge or
generating new text. Further, we use an ensemble of the outputs from different
instructions with a single verifier to enhance the reliability of the
verification processes. We validate the effectiveness of the proposed
verification steps on multiple question answering benchmarks, whose results
show that the proposed verifier effectively identifies retrieval and generation
errors, allowing LMs to provide more factually correct outputs. Our code is
available at https://github.com/JinheonBaek/KALMV.",2023-10-19
"MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and
  Uni-Modal Adapter",2023-10-19 14:52:58+00:00,http://arxiv.org/abs/2310.12798v1,"Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, Tat-Seng Chua","cs.CL, cs.MM",knowledge,"Language Models (LMs) have demonstrated impressive molecule understanding
ability on various 1D text-related tasks. However, they inherently lack 2D
graph perception - a critical ability of human professionals in comprehending
molecules' topological structures. To bridge this gap, we propose MolCA:
Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal
Adapter. MolCA enables an LM (e.g., Galactica) to understand both text- and
graph-based molecular contents via the cross-modal projector. Specifically, the
cross-modal projector is implemented as a Q-Former to connect a graph encoder's
representation space and an LM's text space. Further, MolCA employs a uni-modal
adapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks.
Unlike previous studies that couple an LM with a graph encoder via cross-modal
contrastive learning, MolCA retains the LM's ability of open-ended text
generation and augments it with 2D graph information. To showcase its
effectiveness, we extensively benchmark MolCA on tasks of molecule captioning,
IUPAC name prediction, and molecule-text retrieval, on which MolCA
significantly outperforms the baselines. Our codes and checkpoints can be found
at https://github.com/acharkq/MolCA.",2023-10-19
"GraphextQA: A Benchmark for Evaluating Graph-Enhanced Large Language
  Models",2023-10-12 16:46:58+00:00,http://arxiv.org/abs/2310.08487v1,"Yuanchun Shen, Ruotong Liao, Zhen Han, Yunpu Ma, Volker Tresp",cs.CL,knowledge,"While multi-modal models have successfully integrated information from image,
video, and audio modalities, integrating graph modality into large language
models (LLMs) remains unexplored. This discrepancy largely stems from the
inherent divergence between structured graph data and unstructured text data.
Incorporating graph knowledge provides a reliable source of information,
enabling potential solutions to address issues in text generation, e.g.,
hallucination, and lack of domain knowledge. To evaluate the integration of
graph knowledge into language models, a dedicated dataset is needed. However,
there is currently no benchmark dataset specifically designed for multimodal
graph-language models. To address this gap, we propose GraphextQA, a question
answering dataset with paired subgraphs, retrieved from Wikidata, to facilitate
the evaluation and future development of graph-language models. Additionally,
we introduce a baseline model called CrossGNN, which conditions answer
generation on the paired graphs by cross-attending question-aware graph
features at decoding. The proposed dataset is designed to evaluate
graph-language models' ability to understand graphs and make use of it for
answer generation. We perform experiments with language-only models and the
proposed graph-language model to validate the usefulness of the paired graphs
and to demonstrate the difficulty of the task.",2023-10-12
DistillSpec: Improving Speculative Decoding via Knowledge Distillation,2023-10-12 16:21:04+00:00,http://arxiv.org/abs/2310.08461v1,"Yongchao Zhou, Kaifeng Lyu, Ankit Singh Rawat, Aditya Krishna Menon, Afshin Rostamizadeh, Sanjiv Kumar, Jean-François Kagy, Rishabh Agarwal","cs.CL, cs.AI, cs.LG",knowledge,"Speculative decoding (SD) accelerates large language model inference by
employing a faster draft model for generating multiple tokens, which are then
verified in parallel by the larger target model, resulting in the text
generated according to the target model distribution. However, identifying a
compact draft model that is well-aligned with the target model is challenging.
To tackle this issue, we propose DistillSpec that uses knowledge distillation
to better align the draft model with the target model, before applying SD.
DistillSpec makes two key design choices, which we demonstrate via systematic
study to be crucial to improving the draft and target alignment: utilizing
on-policy data generation from the draft model, and tailoring the divergence
function to the task and decoding strategy. Notably, DistillSpec yields
impressive 10 - 45% speedups over standard SD on a range of standard
benchmarks, using both greedy and non-greedy sampling. Furthermore, we combine
DistillSpec with lossy SD to achieve fine-grained control over the latency vs.
task performance trade-off. Finally, in practical scenarios with models of
varying sizes, first using distillation to boost the performance of the target
model and then applying DistillSpec to train a well-aligned draft model can
reduce decoding latency by 6-10x with minimal performance drop, compared to
standard decoding without distillation.",2023-10-12
"CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large
  Language Models",2023-10-12 12:31:23+00:00,http://arxiv.org/abs/2310.08279v1,"Rui Yang, Li Fang, Yi Zhou","cs.CL, cs.AI",knowledge,"Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce
and infer missing connections within knowledge graphs. Text-based approaches,
like SimKGC, have outperformed graph embedding methods, showcasing the promise
of inductive KGC. However, the efficacy of text-based methods hinges on the
quality of entity textual descriptions. In this paper, we identify the key
issue of whether large language models (LLMs) can generate effective text. To
mitigate hallucination in LLM-generated text in this paper, we introduce a
constraint-based prompt that utilizes the entity and its textual description as
contextual constraints to enhance data quality. Our Constrained-Prompt
Knowledge Graph Completion (CP-KGC) method demonstrates effective inference
under low resource computing conditions and surpasses prior results on the
WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC
tasks and provides new directions for future research.",2023-10-12
"Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task
  Instruction Tuning",2023-10-12 09:39:17+00:00,http://arxiv.org/abs/2310.08166v1,"Junyu Lu, Dixiang Zhang, Xiaojun Wu, Xinyu Gao, Ruyi Gan, Jiaxing Zhang, Yan Song, Pingjian Zhang",cs.CL,knowledge,"Recent advancements enlarge the capabilities of large language models (LLMs)
in zero-shot image-to-text generation and understanding by integrating
multi-modal inputs. However, such success is typically limited to English
scenarios due to the lack of large-scale and high-quality non-English
multi-modal resources, making it extremely difficult to establish competitive
counterparts in other languages. In this paper, we introduce the Ziya-VL
series, a set of bilingual large-scale vision-language models (LVLMs) designed
to incorporate visual semantics into LLM for multi-modal dialogue. Composed of
Ziya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from
BLIP-2, further exploring the assistance of optimization schemes such as
instruction tuning, multi-stage training and low-rank adaptation module for
visual-language alignment. In addition, we stimulate the understanding ability
of GPT-4 in multi-modal scenarios, translating our gathered English image-text
datasets into Chinese and generating instruction-response through the
in-context learning method. The experiment results demonstrate that compared to
the existing LVLMs, Ziya-VL achieves competitive performance across a wide
range of English-only tasks including zero-shot image-text retrieval, image
captioning, and visual question answering. The evaluation leaderboard accessed
by GPT-4 also indicates that our models possess satisfactory image-text
understanding and generation capabilities in Chinese multi-modal scenario
dialogues. Code, demo and models are available at
~\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.",2023-10-12
Multimodal Graph Learning for Generative Tasks,2023-10-11 13:25:03+00:00,http://arxiv.org/abs/2310.07478v2,"Minji Yoon, Jing Yu Koh, Bryan Hooi, Ruslan Salakhutdinov",cs.AI,knowledge,"Multimodal learning combines multiple data modalities, broadening the types
and complexity of data our models can utilize: for example, from plain text to
image-caption pairs. Most multimodal learning algorithms focus on modeling
simple one-to-one pairs of data from two modalities, such as image-caption
pairs, or audio-text pairs. However, in most real-world settings, entities of
different modalities interact with each other in more complex and multifaceted
ways, going beyond one-to-one mappings. We propose to represent these complex
relationships as graphs, allowing us to capture data with any number of
modalities, and with complex relationships between modalities that can flexibly
vary from one sample to another. Toward this goal, we propose Multimodal Graph
Learning (MMGL), a general and systematic framework for capturing information
from multiple multimodal neighbors with relational structures among them. In
particular, we focus on MMGL for generative tasks, building upon pretrained
Language Models (LMs), aiming to augment their text generation with multimodal
neighbor contexts. We study three research questions raised by MMGL: (1) how
can we infuse multiple neighbor information into the pretrained LMs, while
avoiding scalability issues? (2) how can we infuse the graph structure
information among multimodal neighbors into the LMs? and (3) how can we
finetune the pretrained LMs to learn from the neighbor context in a
parameter-efficient manner? We conduct extensive experiments to answer these
three questions on MMGL and analyze the empirical results to pave the way for
future MMGL research.",2023-10-11
"MatChat: A Large Language Model and Application Service Platform for
  Materials Science",2023-10-11 05:11:46+00:00,http://arxiv.org/abs/2310.07197v1,"Ziyi Chen, Fankai Xie, Meng Wan, Yang Yuan, Miao Liu, Zongguo Wang, Sheng Meng, Yangang Wang","cond-mat.mtrl-sci, cs.AI",knowledge,"The prediction of chemical synthesis pathways plays a pivotal role in
materials science research. Challenges, such as the complexity of synthesis
pathways and the lack of comprehensive datasets, currently hinder our ability
to predict these chemical processes accurately. However, recent advancements in
generative artificial intelligence (GAI), including automated text generation
and question-answering systems, coupled with fine-tuning techniques, have
facilitated the deployment of large-scale AI models tailored to specific
domains. In this study, we harness the power of the LLaMA2-7B model and enhance
it through a learning process that incorporates 13,878 pieces of structured
material knowledge data. This specialized AI model, named MatChat, focuses on
predicting inorganic material synthesis pathways. MatChat exhibits remarkable
proficiency in generating and reasoning with knowledge in materials science.
Although MatChat requires further refinement to meet the diverse material
design needs, this research undeniably highlights its impressive reasoning
capabilities and innovative potential in the field of materials science.
MatChat is now accessible online and open for use, with both the model and its
application framework available as open source. This study establishes a robust
foundation for collaborative innovation in the integration of generative AI in
materials science.",2023-10-11
"The Temporal Structure of Language Processing in the Human Brain
  Corresponds to The Layered Hierarchy of Deep Language Models",2023-10-11 01:03:42+00:00,http://arxiv.org/abs/2310.07106v1,"Ariel Goldstein, Eric Ham, Mariano Schain, Samuel Nastase, Zaid Zada, Avigail Dabush, Bobbi Aubrey, Harshvardhan Gazula, Amir Feder, Werner K Doyle, Sasha Devore, Patricia Dugan, Daniel Friedman, Roi Reichart, Michael Brenner, Avinatan Hassidim, Orrin Devinsky, Adeen Flinker, Omer Levy, Uri Hasson","cs.CL, cs.AI, cs.LG, q-bio.NC",knowledge,"Deep Language Models (DLMs) provide a novel computational paradigm for
understanding the mechanisms of natural language processing in the human brain.
Unlike traditional psycholinguistic models, DLMs use layered sequences of
continuous numerical vectors to represent words and context, allowing a
plethora of emerging applications such as human-like text generation. In this
paper we show evidence that the layered hierarchy of DLMs may be used to model
the temporal dynamics of language comprehension in the brain by demonstrating a
strong correlation between DLM layer depth and the time at which layers are
most predictive of the human brain. Our ability to temporally resolve
individual layers benefits from our use of electrocorticography (ECoG) data,
which has a much higher temporal resolution than noninvasive methods like fMRI.
Using ECoG, we record neural activity from participants listening to a
30-minute narrative while also feeding the same narrative to a high-performing
DLM (GPT2-XL). We then extract contextual embeddings from the different layers
of the DLM and use linear encoding models to predict neural activity. We first
focus on the Inferior Frontal Gyrus (IFG, or Broca's area) and then extend our
model to track the increasing temporal receptive window along the linguistic
processing hierarchy from auditory to syntactic and semantic areas. Our results
reveal a connection between human language processing and DLMs, with the DLM's
layer-by-layer accumulation of contextual information mirroring the timing of
neural activity in high-order language areas.",2023-10-11
A Semantic Invariant Robust Watermark for Large Language Models,2023-10-10 06:49:43+00:00,http://arxiv.org/abs/2310.06356v1,"Aiwei Liu, Leyi Pan, Xuming Hu, Shiao Meng, Lijie Wen","cs.CR, cs.CL, 68T50, I.2.7",knowledge,"Watermark algorithms for large language models (LLMs) have achieved extremely
high accuracy in detecting text generated by LLMs. Such algorithms typically
involve adding extra watermark logits to the LLM's logits at each generation
step. However, prior algorithms face a trade-off between attack robustness and
security robustness. This is because the watermark logits for a token are
determined by a certain number of preceding tokens; a small number leads to low
security robustness, while a large number results in insufficient attack
robustness. In this work, we propose a semantic invariant watermarking method
for LLMs that provides both attack robustness and security robustness. The
watermark logits in our work are determined by the semantics of all preceding
tokens. Specifically, we utilize another embedding LLM to generate semantic
embeddings for all preceding tokens, and then these semantic embeddings are
transformed into the watermark logits through our trained watermark model.
Subsequent analyses and experiments demonstrated the attack robustness of our
method in semantically invariant settings: synonym substitution and text
paraphrasing settings. Finally, we also show that our watermark possesses
adequate security robustness. Our code and data are available at
https://github.com/THU-BPM/Robust_Watermark.",2023-10-10
"CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain
  Performance and Calibration",2023-09-14 16:16:40+00:00,http://arxiv.org/abs/2309.07822v1,"Rachneet Sachdeva, Martin Tutek, Iryna Gurevych",cs.CL,knowledge,"In recent years, large language models (LLMs) have shown remarkable
capabilities at scale, particularly at generating text conditioned on a prompt.
In our work, we investigate the use of LLMs to augment training data of small
language models~(SLMs) with automatically generated counterfactual~(CF)
instances -- i.e. minimally altered inputs -- in order to improve
out-of-domain~(OOD) performance of SLMs in the extractive question
answering~(QA) setup. We show that, across various LLM generators, such data
augmentation consistently enhances OOD performance and improves model
calibration for both confidence-based and rationale-augmented calibrator
models. Furthermore, these performance improvements correlate with higher
diversity of CF instances in terms of their surface form and semantic content.
Finally, we show that CF augmented models which are easier to calibrate also
exhibit much lower entropy when assigning importance, indicating that
rationale-augmented calibrators prefer concise explanations.",2023-09-14
Semantic reconstruction of continuous language from MEG signals,2023-09-14 13:19:53+00:00,http://arxiv.org/abs/2309.07701v1,"Bo Wang, Xiran Xu, Longxiang Zhang, Boda Xiao, Xihong Wu, Jing Chen","cs.HC, eess.SP, q-bio.NC",knowledge,"Decoding language from neural signals holds considerable theoretical and
practical importance. Previous research has indicated the feasibility of
decoding text or speech from invasive neural signals. However, when using
non-invasive neural signals, significant challenges are encountered due to
their low quality. In this study, we proposed a data-driven approach for
decoding semantic of language from Magnetoencephalography (MEG) signals
recorded while subjects were listening to continuous speech. First, a
multi-subject decoding model was trained using contrastive learning to
reconstruct continuous word embeddings from MEG data. Subsequently, a beam
search algorithm was adopted to generate text sequences based on the
reconstructed word embeddings. Given a candidate sentence in the beam, a
language model was used to predict the subsequent words. The word embeddings of
the subsequent words were correlated with the reconstructed word embedding.
These correlations were then used as a measure of the probability for the next
word. The results showed that the proposed continuous word embedding model can
effectively leverage both subject-specific and subject-shared information.
Additionally, the decoded text exhibited significant similarity to the target
text, with an average BERTScore of 0.816, a score comparable to that in the
previous fMRI study.",2023-09-14
"Text Encoders Lack Knowledge: Leveraging Generative LLMs for
  Domain-Specific Semantic Textual Similarity",2023-09-12 19:32:45+00:00,http://arxiv.org/abs/2309.06541v1,"Joseph Gatto, Omar Sharif, Parker Seegmiller, Philip Bohlman, Sarah Masud Preum",cs.CL,knowledge,"Amidst the sharp rise in the evaluation of large language models (LLMs) on
various tasks, we find that semantic textual similarity (STS) has been
under-explored. In this study, we show that STS can be cast as a text
generation problem while maintaining strong performance on multiple STS
benchmarks. Additionally, we show generative LLMs significantly outperform
existing encoder-based STS models when characterizing the semantic similarity
between two texts with complex semantic relationships dependent on world
knowledge. We validate this claim by evaluating both generative LLMs and
existing encoder-based STS models on three newly collected STS challenge sets
which require world knowledge in the domains of Health, Politics, and Sports.
All newly collected data is sourced from social media content posted after May
2023 to ensure the performance of closed-source models like ChatGPT cannot be
credited to memorization. Our results show that, on average, generative LLMs
outperform the best encoder-only baselines by an average of 22.3% on STS tasks
requiring world knowledge. Our results suggest generative language models with
STS-specific prompting strategies achieve state-of-the-art performance in
complex, domain-specific STS tasks.",2023-09-12
"Unveiling the potential of large language models in generating semantic
  and cross-language clones",2023-09-12 17:40:49+00:00,http://arxiv.org/abs/2309.06424v1,"Palash R. Roy, Ajmain I. Alam, Farouq Al-omari, Banani Roy, Chanchal K. Roy, Kevin A. Schneider","cs.SE, cs.AI, cs.LG",knowledge,"Semantic and Cross-language code clone generation may be useful for code
reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has
potential in such clone generation as GPT is used for text generation. When
developers copy/paste codes from Stack Overflow (SO) or within a system, there
might be inconsistent changes leading to unexpected behaviours. Similarly, if
someone possesses a code snippet in a particular programming language but seeks
equivalent functionality in a different language, a semantic cross-language
code clone generation approach could provide valuable assistance. In this
study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3
model could help generate semantic and cross-language clone variants for a
given fragment.We have comprised a diverse set of code fragments and assessed
GPT-3s performance in generating code variants.Through extensive
experimentation and analysis, where 9 judges spent 158 hours to validate, we
investigate the model's ability to produce accurate and semantically correct
variants. Our findings shed light on GPT-3's strengths in code generation,
offering insights into the potential applications and challenges of using
advanced language models in software development. Our quantitative analysis
yields compelling results. In the realm of semantic clones, GPT-3 attains an
impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot
prompt engineering. Furthermore, the model shines in transcending linguistic
confines, boasting an exceptional 91.25% accuracy in generating cross-language
clones",2023-09-12
"BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation
  Suite for Large Language Models",2023-09-12 09:31:25+00:00,http://arxiv.org/abs/2309.06085v1,"Wei Qi Leong, Jian Gang Ngui, Yosephine Susanto, Hamsawardhini Rengarajan, Kengatharaiyer Sarveswaran, William Chandra Tjhi",cs.CL,knowledge,"The rapid development of Large Language Models (LLMs) and the emergence of
novel abilities with scale have necessitated the construction of holistic,
diverse and challenging benchmarks such as HELM and BIG-bench. However, at the
moment, most of these benchmarks focus only on performance in English and
evaluations that include Southeast Asian (SEA) languages are few in number. We
therefore propose BHASA, a holistic linguistic and cultural evaluation suite
for LLMs in SEA languages. It comprises three components: (1) a NLP benchmark
covering eight tasks across Natural Language Understanding (NLU), Generation
(NLG) and Reasoning (NLR) tasks, (2) LINDSEA, a linguistic diagnostic toolkit
that spans the gamut of linguistic phenomena including syntax, semantics and
pragmatics, and (3) a cultural diagnostics dataset that probes for both
cultural representation and sensitivity. For this preliminary effort, we
implement the NLP benchmark only for Indonesian, Vietnamese, Thai and Tamil,
and we only include Indonesian and Tamil for LINDSEA and the cultural
diagnostics dataset. As GPT-4 is purportedly one of the best-performing
multilingual LLMs at the moment, we use it as a yardstick to gauge the
capabilities of LLMs in the context of SEA languages. Our initial experiments
on GPT-4 with BHASA find it lacking in various aspects of linguistic
capabilities, cultural representation and sensitivity in the targeted SEA
languages. BHASA is a work in progress and will continue to be improved and
expanded in the future.",2023-09-12
"Neural Latent Geometry Search: Product Manifold Inference via
  Gromov-Hausdorff-Informed Bayesian Optimization",2023-09-09 14:29:22+00:00,http://arxiv.org/abs/2309.04810v1,"Haitz Saez de Ocariz Borde, Alvaro Arroyo, Ismael Morales, Ingmar Posner, Xiaowen Dong","cs.LG, stat.ML",knowledge,"Recent research indicates that the performance of machine learning models can
be improved by aligning the geometry of the latent space with the underlying
data structure. Rather than relying solely on Euclidean space, researchers have
proposed using hyperbolic and spherical spaces with constant curvature, or
combinations thereof, to better model the latent space and enhance model
performance. However, little attention has been given to the problem of
automatically identifying the optimal latent geometry for the downstream task.
We mathematically define this novel formulation and coin it as neural latent
geometry search (NLGS). More specifically, we introduce a principled method
that searches for a latent geometry composed of a product of constant curvature
model spaces with minimal query evaluations. To accomplish this, we propose a
novel notion of distance between candidate latent geometries based on the
Gromov-Hausdorff distance from metric geometry. In order to compute the
Gromov-Hausdorff distance, we introduce a mapping function that enables the
comparison of different manifolds by embedding them in a common
high-dimensional ambient space. Finally, we design a graph search space based
on the calculated distances between candidate manifolds and use Bayesian
optimization to search for the optimal latent geometry in a query-efficient
manner. This is a general method which can be applied to search for the optimal
latent geometry for a variety of models and downstream tasks. Extensive
experiments on synthetic and real-world datasets confirm the efficacy of our
method in identifying the optimal latent geometry for multiple machine learning
problems.",2023-09-09
"Parameter Efficient Audio Captioning With Faithful Guidance Using
  Audio-text Shared Latent Representation",2023-09-06 19:42:52+00:00,http://arxiv.org/abs/2309.03340v1,"Arvind Krishna Sridhar, Yinyi Guo, Erik Visser, Rehana Mahfuz","cs.CL, cs.MM, cs.SD",knowledge,"There has been significant research on developing pretrained transformer
architectures for multimodal-to-text generation tasks. Albeit performance
improvements, such models are frequently overparameterized, hence suffer from
hallucination and large memory footprint making them challenging to deploy on
edge devices. In this paper, we address both these issues for the application
of automated audio captioning. First, we propose a data augmentation technique
for generating hallucinated audio captions and show that similarity based on an
audio-text shared latent space is suitable for detecting hallucination. Then,
we propose a parameter efficient inference time faithful decoding algorithm
that enables smaller audio captioning models with performance equivalent to
larger models trained with more data. During the beam decoding step, the
smaller model utilizes an audio-text shared latent representation to
semantically align the generated text with corresponding input audio. Faithful
guidance is introduced into the beam probability by incorporating the cosine
similarity between latent representation projections of greedy rolled out
intermediate beams and audio clip. We show the efficacy of our algorithm on
benchmark datasets and evaluate the proposed scheme against baselines using
conventional audio captioning and semantic similarity metrics while
illustrating tradeoffs between performance and complexity.",2023-09-06
Synthetic Text Generation using Hypergraph Representations,2023-09-06 14:14:37+00:00,http://arxiv.org/abs/2309.06550v1,"Natraj Raman, Sameena Shah","cs.CL, cs.AI",knowledge,"Generating synthetic variants of a document is often posed as text-to-text
transformation. We propose an alternate LLM based method that first decomposes
a document into semantic frames and then generates text using this interim
sparse format. The frames are modeled using a hypergraph, which allows
perturbing the frame contents in a principled manner. Specifically, new
hyperedges are mined through topological analysis and complex polyadic
relationships including hierarchy and temporal dynamics are accommodated. We
show that our solution generates documents that are diverse, coherent and vary
in style, sentiment, format, composition and facts.",2023-09-06
Persona-aware Generative Model for Code-mixed Language,2023-09-06 11:20:41+00:00,http://arxiv.org/abs/2309.02915v1,"Ayan Sengupta, Md Shad Akhtar, Tanmoy Chakraborty","cs.CL, cs.LG",knowledge,"Code-mixing and script-mixing are prevalent across online social networks and
multilingual societies. However, a user's preference toward code-mixing depends
on the socioeconomic status, demographics of the user, and the local context,
which existing generative models mostly ignore while generating code-mixed
texts. In this work, we make a pioneering attempt to develop a persona-aware
generative model to generate texts resembling real-life code-mixed texts of
individuals. We propose a Persona-aware Generative Model for Code-mixed
Generation, PARADOX, a novel Transformer-based encoder-decoder model that
encodes an utterance conditioned on a user's persona and generates code-mixed
texts without monolingual reference data. We propose an alignment module that
re-calibrates the generated sequence to resemble real-life code-mixed texts.
PARADOX generates code-mixed texts that are semantically more meaningful and
linguistically more valid. To evaluate the personification capabilities of
PARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM
KS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better
perplexity and 32% better semantic coherence than the non-persona-based
counterparts.",2023-09-06
HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus,2023-09-06 05:33:57+00:00,http://arxiv.org/abs/2309.02731v1,"Zhenpeng Su, Xing Wu, Wei Zhou, Guangyuan Ma, Songlin Hu","cs.CL, cs.AI",knowledge,"ChatGPT has gained significant interest due to its impressive performance,
but people are increasingly concerned about its potential risks, particularly
around the detection of AI-generated content (AIGC), which is often difficult
for untrained humans to identify. Current datasets utilized for detecting
ChatGPT-generated text primarily center around question-answering, yet they
tend to disregard tasks that possess semantic-invariant properties, such as
summarization, translation, and paraphrasing. Our primary studies demonstrate
that detecting model-generated text on semantic-invariant tasks is more
difficult. To fill this gap, we introduce a more extensive and comprehensive
dataset that considers more types of tasks than previous work, including
semantic-invariant tasks. In addition, the model after a large number of task
instruction fine-tuning shows a strong powerful performance. Owing to its
previous success, we further instruct fine-tuning Tk-instruct and built a more
powerful detection system. Experimental results show that our proposed detector
outperforms the previous state-of-the-art RoBERTa-based detector.",2023-09-06
"Generative AI-aided Joint Training-free Secure Semantic Communications
  via Multi-modal Prompts",2023-09-05 23:24:56+00:00,http://arxiv.org/abs/2309.02616v1,"Hongyang Du, Guangyuan Liu, Dusit Niyato, Jiayi Zhang, Jiawen Kang, Zehui Xiong, Bo Ai, Dong In Kim","eess.IV, cs.LG, cs.NI",knowledge,"Semantic communication (SemCom) holds promise for reducing network resource
consumption while achieving the communications goal. However, the computational
overheads in jointly training semantic encoders and decoders-and the subsequent
deployment in network devices-are overlooked. Recent advances in Generative
artificial intelligence (GAI) offer a potential solution. The robust learning
abilities of GAI models indicate that semantic decoders can reconstruct source
messages using a limited amount of semantic information, e.g., prompts, without
joint training with the semantic encoder. A notable challenge, however, is the
instability introduced by GAI's diverse generation ability. This instability,
evident in outputs like text-generated images, limits the direct application of
GAI in scenarios demanding accurate message recovery, such as face image
transmission. To solve the above problems, this paper proposes a GAI-aided
SemCom system with multi-model prompts for accurate content decoding. Moreover,
in response to security concerns, we introduce the application of covert
communications aided by a friendly jammer. The system jointly optimizes the
diffusion step, jamming, and transmitting power with the aid of the generative
diffusion models, enabling successful and secure transmission of the source
messages.",2023-09-05
"Optimizing Factual Accuracy in Text Generation through Dynamic Knowledge
  Selection",2023-08-30 02:22:40+00:00,http://arxiv.org/abs/2308.15711v1,"Hongjin Qian, Zhicheng Dou, Jiejun Tan, Haonan Chen, Haoqi Gu, Ruofei Lai, Xinyu Zhang, Zhao Cao, Ji-Rong Wen","cs.CL, cs.AI",knowledge,"Language models (LMs) have revolutionized the way we interact with
information, but they often generate nonfactual text, raising concerns about
their reliability. Previous methods use external knowledge as references for
text generation to enhance factuality but often struggle with the knowledge
mix-up(e.g., entity mismatch) of irrelevant references. Besides,as the length
of the output text grows, the randomness of sampling can escalate,
detrimentally impacting the factual accuracy of the generated text. In this
paper, we present DKGen, which divide the text generation process into an
iterative process. In each iteration, DKGen takes the input query, the
previously generated text and a subset of the reference passages as input to
generate short text. During the process, the subset is dynamically selected
from the full passage set based on their relevance to the previously generated
text and the query, largely eliminating the irrelevant references from input.
To further enhance DKGen's ability to correctly use these external knowledge,
DKGen distills the relevance order of reference passages to the cross-attention
distribution of decoder. We train and evaluate DKGen on a large-scale benchmark
dataset. Experiment results show that DKGen outperforms all baseline models.",2023-08-30
"Towards Vision-Language Mechanistic Interpretability: A Causal Tracing
  Tool for BLIP",2023-08-27 18:46:47+00:00,http://arxiv.org/abs/2308.14179v1,"Vedant Palit, Rohan Pandey, Aryaman Arora, Paul Pu Liang","cs.CL, cs.AI, cs.CV",knowledge,"Mechanistic interpretability seeks to understand the neural mechanisms that
enable specific behaviors in Large Language Models (LLMs) by leveraging
causality-based methods. While these approaches have identified neural circuits
that copy spans of text, capture factual knowledge, and more, they remain
unusable for multimodal models since adapting these tools to the
vision-language domain requires considerable architectural changes. In this
work, we adapt a unimodal causal tracing tool to BLIP to enable the study of
the neural mechanisms underlying image-conditioned text generation. We
demonstrate our approach on a visual question answering dataset, highlighting
the causal relevance of later layer representations for all tokens.
Furthermore, we release our BLIP causal tracing tool as open source to enable
further experimentation in vision-language mechanistic interpretability by the
community. Our code is available at
https://github.com/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability.",2023-08-27
"Planning with Logical Graph-based Language Model for Instruction
  Generation",2023-08-26 06:28:14+00:00,http://arxiv.org/abs/2308.13782v1,"Fan Zhang, Kebing Jin, Hankz Hankui Zhuo","cs.CL, cs.AI",knowledge,"Despite the superior performance of large language models to generate natural
language texts, it is hard to generate texts with correct logic according to a
given task, due to the difficulties for neural models to capture implied rules
from free-form texts. In this paper, we propose a novel graph-based language
model, Logical-GLM, to infuse logic into language models for more valid text
generation and interpretability. Specifically, we first capture information
from natural language instructions and construct logical bayes graphs that
generally describe domains. Next, we generate logical skeletons to guide
language model training, infusing domain knowledge into language models.
Finally, we alternately optimize the searching policy of graphs and language
models until convergence. The experimental results show that Logical-GLM is
both effective and efficient compared with traditional language models, despite
using smaller-scale training data and fewer parameters. Our approach can
generate instructional texts with more correct logic owing to the internalized
domain knowledge. Moreover, the usage of logical graphs reflects the inner
mechanism of the language models, which improves the interpretability of
black-box models.",2023-08-26
"GeoExplainer: A Visual Analytics Framework for Spatial Modeling
  Contextualization and Report Generation",2023-08-25 16:55:33+00:00,http://arxiv.org/abs/2308.13588v1,"Fan Lei, Yuxin Ma, Stewart Fotheringham, Elizabeth Mack, Ziqi Li, Mehak Sachdeva, Sarah Bardin, Ross Maciejewski","cs.HC, cs.LG",knowledge,"Geographic regression models of various descriptions are often applied to
identify patterns and anomalies in the determinants of spatially distributed
observations. These types of analyses focus on answering why questions about
underlying spatial phenomena, e.g., why is crime higher in this locale, why do
children in one school district outperform those in another, etc.? Answers to
these questions require explanations of the model structure, the choice of
parameters, and contextualization of the findings with respect to their
geographic context. This is particularly true for local forms of regression
models which are focused on the role of locational context in determining human
behavior. In this paper, we present GeoExplainer, a visual analytics framework
designed to support analysts in creating explanative documentation that
summarizes and contextualizes their spatial analyses. As analysts create their
spatial models, our framework flags potential issues with model parameter
selections, utilizes template-based text generation to summarize model outputs,
and links with external knowledge repositories to provide annotations that help
to explain the model results. As analysts explore the model results, all
visualizations and annotations can be captured in an interactive report
generation widget. We demonstrate our framework using a case study modeling the
determinants of voting in the 2016 US Presidential Election.",2023-08-25
ARTIST: ARTificial Intelligence for Simplified Text,2023-08-25 16:06:06+00:00,http://arxiv.org/abs/2308.13458v1,"Lorenzo Corti, Jie Yang",cs.CL,knowledge,"Complex text is a major barrier for many citizens when accessing public
information and knowledge. While often done manually, Text Simplification is a
key Natural Language Processing task that aims for reducing the linguistic
complexity of a text while preserving the original meaning. Recent advances in
Generative Artificial Intelligence (AI) have enabled automatic text
simplification both on the lexical and syntactical levels. However, as
applications often focus on English, little is understood about the
effectiveness of Generative AI techniques on low-resource languages such as
Dutch. For this reason, we carry out empirical studies to understand the
benefits and limitations of applying generative technologies for text
simplification and provide the following outcomes: 1) the design and
implementation for a configurable text simplification pipeline that
orchestrates state-of-the-art generative text simplification models, domain and
reader adaptation, and visualisation modules; 2) insights and lessons learned,
showing the strengths of automatic text simplification while exposing the
challenges in handling cultural and commonsense knowledge. These outcomes
represent a first step in the exploration of Dutch text simplification and shed
light on future endeavours both for research and practice.",2023-08-25
"Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal
  Embeddings",2023-08-22 21:57:22+00:00,http://arxiv.org/abs/2308.11804v1,"Eugene Bagdasaryan, Vitaly Shmatikov","cs.CR, cs.AI, cs.LG",knowledge,"Multi-modal encoders map images, sounds, texts, videos, etc. into a single
embedding space, aligning representations across modalities (e.g., associate an
image of a dog with a barking sound). We show that multi-modal embeddings can
be vulnerable to an attack we call ""adversarial illusions."" Given an input in
any modality, an adversary can perturb it so as to make its embedding close to
that of an arbitrary, adversary-chosen input in another modality. Illusions
thus enable the adversary to align any image with any text, any text with any
sound, etc.
  Adversarial illusions exploit proximity in the embedding space and are thus
agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how
adversarially aligned inputs, generated without knowledge of specific
downstream tasks, mislead image generation, text generation, and zero-shot
classification.",2023-08-22
Semantic Consistency for Assuring Reliability of Large Language Models,2023-08-17 18:11:33+00:00,http://arxiv.org/abs/2308.09138v1,"Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar","cs.CL, cs.AI, cs.CY",knowledge,"Large Language Models (LLMs) exhibit remarkable fluency and competence across
various natural language tasks. However, recent research has highlighted their
sensitivity to variations in input prompts. To deploy LLMs in a safe and
reliable manner, it is crucial for their outputs to be consistent when prompted
with expressions that carry the same meaning or intent. While some existing
work has explored how state-of-the-art LLMs address this issue, their
evaluations have been confined to assessing lexical equality of single- or
multi-word answers, overlooking the consistency of generative text sequences.
For a more comprehensive understanding of the consistency of LLMs in open-ended
text generation scenarios, we introduce a general measure of semantic
consistency, and formulate multiple versions of this metric to evaluate the
performance of various LLMs. Our proposal demonstrates significantly higher
consistency and stronger correlation with human evaluations of output
consistency than traditional metrics based on lexical consistency. Finally, we
propose a novel prompting strategy, called Ask-to-Choose (A2C), to enhance
semantic consistency. When evaluated for closed-book question answering based
on answer variations from the TruthfulQA benchmark, A2C increases accuracy
metrics for pretrained and finetuned LLMs by up to 47%, and semantic
consistency metrics for instruction-tuned models by up to 7-fold.",2023-08-17
Can Knowledge Graphs Simplify Text?,2023-08-14 07:20:49+00:00,http://arxiv.org/abs/2308.06975v2,"Anthony Colas, Haodi Ma, Xuanli He, Yang Bai, Daisy Zhe Wang",cs.CL,knowledge,"Knowledge Graph (KG)-to-Text Generation has seen recent improvements in
generating fluent and informative sentences which describe a given KG. As KGs
are widespread across multiple domains and contain important entity-relation
information, and as text simplification aims to reduce the complexity of a text
while preserving the meaning of the original text, we propose KGSimple, a novel
approach to unsupervised text simplification which infuses KG-established
techniques in order to construct a simplified KG path and generate a concise
text which preserves the original input's meaning. Through an iterative and
sampling KG-first approach, our model is capable of simplifying text when
starting from a KG by learning to keep important information while harnessing
KG-to-text generation to output fluent and descriptive sentences. We evaluate
various settings of the KGSimple model on currently-available KG-to-text
datasets, demonstrating its effectiveness compared to unsupervised text
simplification models which start with a given complex text. Our code is
available on GitHub.",2023-08-14
"Classification of Human- and AI-Generated Texts: Investigating Features
  for ChatGPT",2023-08-10 05:09:42+00:00,http://arxiv.org/abs/2308.05341v1,"Lorenz Mindner, Tim Schlippe, Kristina Schaaff","cs.CL, cs.AI",knowledge,"Recently, generative AIs like ChatGPT have become available to the wide
public. These tools can for instance be used by students to generate essays or
whole theses. But how does a teacher know whether a text is written by a
student or an AI? In our work, we explore traditional and new features to (1)
detect text generated by AI from scratch and (2) text rephrased by AI. Since we
found that classification is more difficult when the AI has been instructed to
create the text in a way that a human would not recognize that it was generated
by an AI, we also investigate this more advanced case. For our experiments, we
produced a new text corpus covering 10 school topics. Our best systems to
classify basic and advanced human-generated/AI-generated texts have F1-scores
of over 96%. Our best systems for classifying basic and advanced
human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems
use a combination of perplexity, semantic, list lookup, error-based,
readability, AI feedback, and text vector features. Our results show that the
new features substantially help to improve the performance of many classifiers.
Our best basic text rephrasing detection system even outperforms GPTZero by
183.8% relative in F1-score.",2023-08-10
"Few-Shot Data-to-Text Generation via Unified Representation and
  Multi-Source Learning",2023-08-10 03:09:12+00:00,http://arxiv.org/abs/2308.05317v1,"Alexander Hanbo Li, Mingyue Shang, Evangelia Spiliopoulou, Jie Ma, Patrick Ng, Zhiguo Wang, Bonan Min, William Wang, Kathleen McKeown, Vittorio Castelli, Dan Roth, Bing Xiang",cs.CL,knowledge,"We present a novel approach for structured data-to-text generation that
addresses the limitations of existing methods that primarily focus on specific
types of structured data. Our proposed method aims to improve performance in
multi-task training, zero-shot and few-shot scenarios by providing a unified
representation that can handle various forms of structured data such as tables,
knowledge graph triples, and meaning representations. We demonstrate that our
proposed approach can effectively adapt to new structured forms, and can
improve performance in comparison to current methods. For example, our method
resulted in a 66% improvement in zero-shot BLEU scores when transferring models
trained on table inputs to a knowledge graph dataset. Our proposed method is an
important step towards a more general data-to-text generation framework.",2023-08-10
"Boosting Chinese ASR Error Correction with Dynamic Error Scaling
  Mechanism",2023-08-07 09:19:59+00:00,http://arxiv.org/abs/2308.03423v1,"Jiaxin Fan, Yong Zhang, Hanzhang Li, Jianzong Wang, Zhitao Li, Sheng Ouyang, Ning Cheng, Jing Xiao","cs.CL, cs.AI",knowledge,"Chinese Automatic Speech Recognition (ASR) error correction presents
significant challenges due to the Chinese language's unique features, including
a large character set and borderless, morpheme-based structure. Current
mainstream models often struggle with effectively utilizing word-level features
and phonetic information. This paper introduces a novel approach that
incorporates a dynamic error scaling mechanism to detect and correct
phonetically erroneous text generated by ASR output. This mechanism operates by
dynamically fusing word-level features and phonetic information, thereby
enriching the model with additional semantic data. Furthermore, our method
implements unique error reduction and amplification strategies to address the
issues of matching wrong words caused by incorrect characters. Experimental
results indicate substantial improvements in ASR error correction,
demonstrating the effectiveness of our proposed method and yielding promising
results on established datasets.",2023-08-07
Evaluating Generative Models for Graph-to-Text Generation,2023-07-27 09:03:05+00:00,http://arxiv.org/abs/2307.14712v1,"Shuzhou Yuan, Michael Färber","cs.CL, cs.AI",knowledge,"Large language models (LLMs) have been widely employed for graph-to-text
generation tasks. However, the process of finetuning LLMs requires significant
training resources and annotation work. In this paper, we explore the
capability of generative models to generate descriptive text from graph data in
a zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on two
graph-to-text datasets and compare their performance with that of finetuned LLM
models such as T5 and BART. Our results demonstrate that generative models are
capable of generating fluent and coherent text, achieving BLEU scores of 10.57
and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error
analysis reveals that generative models still struggle with understanding the
semantic relations between entities, and they also tend to generate text with
hallucinations or irrelevant information. As a part of error analysis, we
utilize BERT to detect machine-generated text and achieve high macro-F1 scores.
We have made the text generated by generative models publicly available.",2023-07-27
"Controllable Generation of Dialogue Acts for Dialogue Systems via
  Few-Shot Response Generation and Ranking",2023-07-26 18:16:45+00:00,http://arxiv.org/abs/2307.14440v1,"Angela Ramirez, Karik Agarwal, Juraj Juraska, Utkarsh Garg, Marilyn A. Walker",cs.CL,knowledge,"Dialogue systems need to produce responses that realize multiple types of
dialogue acts (DAs) with high semantic fidelity. In the past, natural language
generators (NLGs) for dialogue were trained on large parallel corpora that map
from a domain-specific DA and its semantic attributes to an output utterance.
Recent work shows that pretrained language models (LLMs) offer new
possibilities for controllable NLG using prompt-based learning. Here we develop
a novel few-shot overgenerate-and-rank approach that achieves the controlled
generation of DAs. We compare eight few-shot prompt styles that include a novel
method of generating from textual pseudo-references using a textual style
transfer approach. We develop six automatic ranking functions that identify
outputs with both the correct DA and high semantic accuracy at generation time.
We test our approach on three domains and four LLMs. To our knowledge, this is
the first work on NLG for dialogue that automatically ranks outputs using both
DA and attribute accuracy. For completeness, we compare our results to
fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results
show that several prompt settings achieve perfect DA accuracy, and near perfect
semantic accuracy (99.81%) and perform better than few-shot fine-tuning.",2023-07-26
"Watermarking Conditional Text Generation for AI Detection: Unveiling
  Challenges and a Semantic-Aware Watermark Remedy",2023-07-25 20:24:22+00:00,http://arxiv.org/abs/2307.13808v1,"Yu Fu, Deyi Xiong, Yue Dong","cs.CL, cs.CR",knowledge,"To mitigate potential risks associated with language models, recent AI
detection research proposes incorporating watermarks into machine-generated
text through random vocabulary restrictions and utilizing this information for
detection. While these watermarks only induce a slight deterioration in
perplexity, our empirical investigation reveals a significant detriment to the
performance of conditional text generation. To address this issue, we introduce
a simple yet effective semantic-aware watermarking algorithm that considers the
characteristics of conditional text generation and the input context.
Experimental results demonstrate that our proposed method yields substantial
improvements across various text generation models, including BART and Flan-T5,
in tasks such as summarization and data-to-text generation while maintaining
detection ability.",2023-07-25
"FacTool: Factuality Detection in Generative AI -- A Tool Augmented
  Framework for Multi-Task and Multi-Domain Scenarios",2023-07-25 14:20:51+00:00,http://arxiv.org/abs/2307.13528v2,"I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu","cs.CL, cs.AI",knowledge,"The emergence of generative pre-trained models has facilitated the synthesis
of high-quality text, but it has also posed challenges in identifying factual
errors in the generated text. In particular: (1) A wider range of tasks now
face an increasing risk of containing factual errors when handled by generative
models. (2) Generated texts tend to be lengthy and lack a clearly defined
granularity for individual facts. (3) There is a scarcity of explicit evidence
available during the process of fact checking. With the above challenges in
mind, in this paper, we propose FacTool, a task and domain agnostic framework
for detecting factual errors of texts generated by large language models (e.g.,
ChatGPT). Experiments on four different tasks (knowledge-based QA, code
generation, mathematical reasoning, and scientific literature review) show the
efficacy of the proposed method. We release the code of FacTool associated with
ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .",2023-07-25
Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?,2023-07-22 04:20:30+00:00,http://arxiv.org/abs/2307.11978v1,"Cheng-En Wu, Yu Tian, Haichao Yu, Heng Wang, Pedro Morgado, Yu Hen Hu, Linjie Yang","cs.CV, cs.AI, cs.LG",knowledge,"Vision-language models such as CLIP learn a generic text-image embedding from
large-scale training data. A vision-language model can be adapted to a new
classification task through few-shot prompt tuning. We find that such a prompt
tuning process is highly robust to label noises. This intrigues us to study the
key reasons contributing to the robustness of the prompt tuning paradigm. We
conducted extensive experiments to explore this property and find the key
factors are: 1) the fixed classname tokens provide a strong regularization to
the optimization of the model, reducing gradients induced by the noisy samples;
2) the powerful pre-trained image-text embedding that is learned from diverse
and generic web data provides strong prior knowledge for image classification.
Further, we demonstrate that noisy zero-shot predictions from CLIP can be used
to tune its own prompt, significantly enhancing prediction accuracy in the
unsupervised setting. The code is available at https://github.com/CEWu/PTNL.",2023-07-22
OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?,2023-07-21 14:58:44+00:00,http://arxiv.org/abs/2307.11636v1,"Runjia Li, Shuyang Sun, Mohamed Elhoseiny, Philip Torr","cs.CV, cs.CL",knowledge,"This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale
dataset for humour generation and understanding. Humour is an abstract,
subjective, and context-dependent cognitive construct involving several
cognitive factors, making it a challenging task to generate and interpret.
Hence, humour generation and understanding can serve as a new task for
evaluating the ability of deep-learning methods to process abstract and
subjective information. Due to the scarcity of data, humour-related generation
tasks such as captioning remain under-explored. To address this gap,
OxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to
train a generalizable humour captioning model. Contrary to existing captioning
datasets, OxfordTVG-HIC features a wide range of emotional and semantic
diversity resulting in out-of-context examples that are particularly conducive
to generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive
content. We also show how OxfordTVG-HIC can be leveraged for evaluating the
humour of a generated text. Through explainability analysis of the trained
models, we identify the visual and linguistic cues influential for evoking
humour prediction (and generation). We observe qualitatively that these cues
are aligned with the benign violation theory of humour in cognitive psychology.",2023-07-21
"Jina Embeddings: A Novel Set of High-Performance Sentence Embedding
  Models",2023-07-20 20:37:24+00:00,http://arxiv.org/abs/2307.11224v1,"Michael Günther, Louis Milliken, Jonathan Geuter, Georgios Mastrapas, Bo Wang, Han Xiao","cs.CL, cs.AI, cs.IR, cs.LG, 68T50, H.3.1; H.3.3; I.2.7; I.5.4",knowledge,"Jina Embeddings constitutes a set of high-performance sentence embedding
models adept at translating various textual inputs into numerical
representations, thereby capturing the semantic essence of the text. While
these models are not exclusively designed for text generation, they excel in
applications such as dense retrieval and semantic textual similarity. This
paper details the development of Jina Embeddings, starting with the creation of
a high-quality pairwise and triplet dataset. It underlines the crucial role of
data cleaning in dataset preparation, gives in-depth insights into the model
training process, and concludes with a comprehensive performance evaluation
using the Massive Textual Embedding Benchmark (MTEB).",2023-07-20
Generative Language Models on Nucleotide Sequences of Human Genes,2023-07-20 06:59:02+00:00,http://arxiv.org/abs/2307.10634v1,"Musa Nuri Ihtiyar, Arzucan Ozgur","q-bio.GN, cs.CL, cs.LG",knowledge,"Language models, primarily transformer-based ones, obtained colossal success
in NLP. To be more precise, studies like BERT in NLU and works such as GPT-3
for NLG are very crucial. DNA sequences are very close to natural language in
terms of structure, so if the DNA-related bioinformatics domain is concerned,
discriminative models, like DNABert, exist. Yet, the generative side of the
coin is mainly unexplored to the best of our knowledge. Consequently, we
focused on developing an autoregressive generative language model like GPT-3
for DNA sequences. Because working with whole DNA sequences is challenging
without substantial computational resources, we decided to carry out our study
on a smaller scale, focusing on nucleotide sequences of human genes, unique
parts in DNA with specific functionalities, instead of the whole DNA. This
decision did not change the problem structure a lot due to the fact that both
DNA and genes can be seen as 1D sequences consisting of four different
nucleotides without losing much information and making too much simplification.
First of all, we systematically examined an almost entirely unexplored problem
and observed that RNNs performed the best while simple techniques like N-grams
were also promising. Another beneficial point was learning how to work with
generative models on languages we do not understand, unlike natural language.
How essential using real-life tasks beyond the classical metrics such as
perplexity is observed. Furthermore, checking whether the data-hungry nature of
these models can be changed through selecting a language with minimal
vocabulary size, four owing to four different types of nucleotides, is
examined. The reason for reviewing this was that choosing such a language might
make the problem easier. However, what we observed in this study was it did not
provide that much of a change in the amount of data needed.",2023-07-20
"On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large
  Language Models",2023-07-19 07:17:43+00:00,http://arxiv.org/abs/2307.09793v1,"Sarah Gao, Andrew Kean Gao","cs.DL, cs.CL, I.2.1; H.5.0",knowledge,"Since late 2022, Large Language Models (LLMs) have become very prominent with
LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs
are announced each week, many of which are deposited to Hugging Face, a
repository of machine learning models and datasets. To date, nearly 16,000 Text
Generation models have been uploaded to the site. Given the huge influx of
LLMs, it is of interest to know which LLM backbones, settings, training
methods, and families are popular or trending. However, there is no
comprehensive index of LLMs available. We take advantage of the relatively
systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering
and identify communities amongst LLMs using n-grams and term frequency-inverse
document frequency. Our methods successfully identify families of LLMs and
accurately cluster LLMs into meaningful subgroups. We present a public web
application to navigate and explore Constellation, our atlas of 15,821 LLMs.
Constellation rapidly generates a variety of visualizations, namely
dendrograms, graphs, word clouds, and scatter plots. Constellation is available
at the following link: https://constellation.sites.stanford.edu/.",2023-07-19
"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and
  Addressing Sociological Implications",2023-07-18 11:38:45+00:00,http://arxiv.org/abs/2307.09162v1,Vishesh Thakur,cs.CL,knowledge,"Gender bias in artificial intelligence (AI) and natural language processing
has garnered significant attention due to its potential impact on societal
perceptions and biases. This research paper aims to analyze gender bias in
Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2
and GPT-3.5, some prominent language models, to better understand its
implications. Through a comprehensive literature review, the study examines
existing research on gender bias in AI language models and identifies gaps in
the current knowledge. The methodology involves collecting and preprocessing
data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis
techniques to evaluate gender bias in the generated text. The findings shed
light on gendered word associations, language usage, and biased narratives
present in the outputs of these Large Language Models. The discussion explores
the ethical implications of gender bias and its potential consequences on
social perceptions and marginalized communities. Additionally, the paper
presents strategies for reducing gender bias in LLMs, including algorithmic
approaches and data augmentation techniques. The research highlights the
importance of interdisciplinary collaborations and the role of sociological
studies in mitigating gender bias in AI models. By addressing these issues, we
can pave the way for more inclusive and unbiased AI systems that have a
positive impact on society.",2023-07-18
Large Language Models Perform Diagnostic Reasoning,2023-07-18 01:43:00+00:00,http://arxiv.org/abs/2307.08922v1,"Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen",cs.CL,knowledge,"We explore the extension of chain-of-thought (CoT) prompting to medical
reasoning for the task of automatic diagnosis. Motivated by doctors' underlying
reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical
results demonstrate that by simply prompting large language models trained only
on general text corpus with two DR-CoT exemplars, the diagnostic accuracy
improves by 15% comparing to standard prompting. Moreover, the gap reaches a
pronounced 18% in out-domain settings. Our findings suggest expert-knowledge
reasoning in large language models can be elicited through proper promptings.",2023-07-18
COLLIE: Systematic Construction of Constrained Text Generation Tasks,2023-07-17 17:48:51+00:00,http://arxiv.org/abs/2307.08689v1,"Shunyu Yao, Howard Chen, Austin W. Hanjie, Runzhe Yang, Karthik Narasimhan","cs.CL, cs.AI, cs.LG",knowledge,"Text generation under constraints have seen increasing interests in natural
language processing, especially with the rapidly improving capabilities of
large language models. However, existing benchmarks for constrained generation
usually focus on fixed constraint types (e.g.,generate a sentence containing
certain words) that have proved to be easy for state-of-the-art models like
GPT-4. We present COLLIE, a grammar-based framework that allows the
specification of rich, compositional constraints with diverse generation levels
(word, sentence, paragraph, passage) and modeling challenges (e.g.,language
understanding, logical reasoning, counting, semantic planning). We also develop
tools for automatic extraction of task instances given a constraint structure
and a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 2080
instances comprising 13 constraint structures. We perform systematic
experiments across five state-of-the-art instruction-tuned language models and
analyze their performances to reveal shortcomings. COLLIE is designed to be
extensible and lightweight, and we hope the community finds it useful to
develop more complex constraints and evaluations in the future.",2023-07-17
"A Dialogue System for Assessing Activities of Daily Living: Improving
  Consistency with Grounded Knowledge",2023-07-15 22:41:59+00:00,http://arxiv.org/abs/2307.07544v1,"Zhecheng Sheng, Raymond Finzel, Michael Lucke, Sheena Dufresne, Maria Gini, Serguei Pakhomov","cs.CL, cs.AI",knowledge,"In healthcare, the ability to care for oneself is reflected in the
""Activities of Daily Living (ADL),"" which serve as a measure of functional
ability (functioning). A lack of functioning may lead to poor living conditions
requiring personal care and assistance. To accurately identify those in need of
support, assistance programs continuously evaluate participants' functioning
across various domains. However, the assessment process may encounter
consistency issues when multiple assessors with varying levels of expertise are
involved. Novice assessors, in particular, may lack the necessary preparation
for real-world interactions with participants. To address this issue, we
developed a dialogue system that simulates interactions between assessors and
individuals of varying functioning in a natural and reproducible way. The
dialogue system consists of two major modules, one for natural language
understanding (NLU) and one for natural language generation (NLG),
respectively. In order to generate responses consistent with the underlying
knowledge base, the dialogue system requires both an understanding of the
user's query and of biographical details of an individual being simulated. To
fulfill this requirement, we experimented with query classification and
generated responses based on those biographical details using some recently
released InstructGPT-like models.",2023-07-15
"Using Large Language Models for Zero-Shot Natural Language Generation
  from Knowledge Graphs",2023-07-14 12:45:03+00:00,http://arxiv.org/abs/2307.07312v1,"Agnes Axelsson, Gabriel Skantze","cs.CL, 68T50, I.2.7; I.2.4",knowledge,"In any system that uses structured knowledge graph (KG) data as its
underlying knowledge representation, KG-to-text generation is a useful tool for
turning parts of the graph data into text that can be understood by humans.
Recent work has shown that models that make use of pretraining on large amounts
of text data can perform well on the KG-to-text task even with relatively small
sets of training data on the specific graph-to-text task. In this paper, we
build on this concept by using large language models to perform zero-shot
generation based on nothing but the model's understanding of the triple
structure from what it can read. We show that ChatGPT achieves near
state-of-the-art performance on some measures of the WebNLG 2020 challenge, but
falls behind on others. Additionally, we compare factual, counter-factual and
fictional statements, and show that there is a significant connection between
what the LLM already knows about the data it is parsing and the quality of the
output text.",2023-07-14
Reading Radiology Imaging Like The Radiologist,2023-07-12 05:36:47+00:00,http://arxiv.org/abs/2307.05921v3,Yuhao Wang,"cs.CV, cs.AI",knowledge,"Automated radiology report generation aims to generate radiology reports that
contain rich, fine-grained descriptions of radiology imaging. Compared with
image captioning in the natural image domain, medical images are very similar
to each other, with only minor differences in the occurrence of diseases. Given
the importance of these minor differences in the radiology report, it is
crucial to encourage the model to focus more on the subtle regions of disease
occurrence. Secondly, the problem of visual and textual data biases is serious.
Not only do normal cases make up the majority of the dataset, but sentences
describing areas with pathological changes also constitute only a small part of
the paragraph. Lastly, generating medical image reports involves the challenge
of long text generation, which requires more expertise and empirical training
in medical knowledge. As a result, the difficulty of generating such reports is
increased. To address these challenges, we propose a disease-oriented retrieval
framework that utilizes similar reports as prior knowledge references. We
design a factual consistency captioning generator to generate more accurate and
factually consistent disease descriptions. Our framework can find most similar
reports for a given disease from the CXR database by retrieving a
disease-oriented mask consisting of the position and morphological
characteristics. By referencing the disease-oriented similar report and the
visual features, the factual consistency model can generate a more accurate
radiology report.",2023-07-12
"SkipDecode: Autoregressive Skip Decoding with Batching and Caching for
  Efficient LLM Inference",2023-07-05 19:59:09+00:00,http://arxiv.org/abs/2307.02628v1,"Luciano Del Corro, Allie Del Giorno, Sahaj Agarwal, Bin Yu, Ahmed Awadallah, Subhabrata Mukherjee",cs.CL,knowledge,"Autoregressive large language models (LLMs) have made remarkable progress in
various natural language generation tasks. However, they incur high computation
cost and latency resulting from the autoregressive token-by-token generation.
To address this issue, several approaches have been proposed to reduce
computational cost using early-exit strategies. These strategies enable faster
text generation using reduced computation without applying the full computation
graph to each token. While existing token-level early exit methods show
promising results for online inference, they cannot be readily applied for
batch inferencing and Key-Value caching. This is because they have to wait
until the last token in a batch exits before they can stop computing. This
severely limits the practical application of such techniques. In this paper, we
propose a simple and effective token-level early exit method, SkipDecode,
designed to work seamlessly with batch inferencing and KV caching. It overcomes
prior constraints by setting up a singular exit point for every token in a
batch at each sequence position. It also guarantees a monotonic decrease in
exit points, thereby eliminating the need to recompute KV Caches for preceding
tokens. Rather than terminating computation prematurely as in prior works, our
approach bypasses lower to middle layers, devoting most of the computational
resources to upper layers, allowing later tokens to benefit from the compute
expenditure by earlier tokens. Our experimental results show that SkipDecode
can obtain 2x to 5x inference speedups with negligible regression across a
variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7
billion parameters, all the while being directly compatible with batching and
KV caching optimization techniques.",2023-07-05
"A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image
  Diagnosis",2023-07-05 01:45:19+00:00,http://arxiv.org/abs/2307.01981v1,"Jiaxiang Liu, Tianxiang Hu, Yan Zhang, Xiaotang Gai, Yang Feng, Zuozhu Liu","eess.IV, cs.CV, cs.LG",knowledge,"Zero-shot medical image classification is a critical process in real-world
scenarios where we have limited access to all possible diseases or large-scale
annotated data. It involves computing similarity scores between a query medical
image and possible disease categories to determine the diagnostic result.
Recent advances in pretrained vision-language models (VLMs) such as CLIP have
shown great performance for zero-shot natural image recognition and exhibit
benefits in medical applications. However, an explainable zero-shot medical
image recognition framework with promising performance is yet under
development. In this paper, we propose a novel CLIP-based zero-shot medical
image classification framework supplemented with ChatGPT for explainable
diagnosis, mimicking the diagnostic process performed by human experts. The key
idea is to query large language models (LLMs) with category names to
automatically generate additional cues and knowledge, such as disease symptoms
or descriptions other than a single category name, to help provide more
accurate and explainable diagnosis in CLIP. We further design specific prompts
to enhance the quality of generated texts by ChatGPT that describe visual
medical features. Extensive results on one private dataset and four public
datasets along with detailed analysis demonstrate the effectiveness and
explainability of our training-free zero-shot diagnosis pipeline, corroborating
the great potential of VLMs and LLMs for medical applications.",2023-07-05
"Knowledge-Aware Audio-Grounded Generative Slot Filling for Limited
  Annotated Data",2023-07-04 15:05:42+00:00,http://arxiv.org/abs/2307.01764v1,"Guangzhi Sun, Chao Zhang, Ivan Vulić, Paweł Budzianowski, Philip C. Woodland",cs.CL,knowledge,"Manually annotating fine-grained slot-value labels for task-oriented dialogue
(ToD) systems is an expensive and time-consuming endeavour. This motivates
research into slot-filling methods that operate with limited amounts of
labelled data. Moreover, the majority of current work on ToD is based solely on
text as the input modality, neglecting the additional challenges of imperfect
automatic speech recognition (ASR) when working with spoken language. In this
work, we propose a Knowledge-Aware Audio-Grounded generative slot-filling
framework, termed KA2G, that focuses on few-shot and zero-shot slot filling for
ToD with speech input. KA2G achieves robust and data-efficient slot filling for
speech-based ToD by 1) framing it as a text generation task, 2) grounding text
generation additionally in the audio modality, and 3) conditioning on available
external knowledge (e.g. a predefined list of possible slot values). We show
that combining both modalities within the KA2G framework improves the
robustness against ASR errors. Further, the knowledge-aware slot-value
generator in KA2G, implemented via a pointer generator mechanism, particularly
benefits few-shot and zero-shot learning. Experiments, conducted on the
standard speech-based single-turn SLURP dataset and a multi-turn dataset
extracted from a commercial ToD system, display strong and consistent gains
over prior work, especially in few-shot and zero-shot setups.",2023-07-04
"PatternGPT :A Pattern-Driven Framework for Large Language Model Text
  Generation",2023-07-02 04:32:41+00:00,http://arxiv.org/abs/2307.00470v4,"Le Xiao, Xin Shan","cs.CL, cs.AI",knowledge,"Large language models(LLMS)have shown excellent text generation capabilities,
capable of generating fluent human-like responses for many downstream tasks.
However, applying large language models to real-world critical tasks remains
challenging due to their susceptibility to hallucinations and inability to
directly use external knowledge. To cope with the above challenges, this paper
proposes PatternGPT, a pattern-driven text generation framework for Large
Language Models. Firstly, the framework utilizes the extraction capability of
Large Language Models to generate rich and diversified structured and
formalized patterns, which facilitates the introduction of external knowledge
to do the computation, and then draws on the idea of federated learning to use
multiple agents to achieve the sharing in order to obtain more diversified
patterns, and finally uses judgment criteria and optimization algorithm to
search for high-quality patterns to guide the generation of models. Finally,
external knowledge such as judgment criteria and optimization algorithms are
used to search for high-quality patterns, and the searched patterns are used to
guide model generation. This framework has the advantages of generating
diversified patterns, protecting data privacy, combining external knowledge,
and improving the quality of generation, which provides an effective method to
optimize the text generation capability of large language models, and make it
better applied to the field of intelligent dialogue and content generation.",2023-07-02
Concept-Oriented Deep Learning with Large Language Models,2023-06-29 16:47:11+00:00,http://arxiv.org/abs/2306.17089v1,Daniel T. Chang,"cs.LG, cs.CL",knowledge,"Large Language Models (LLMs) have been successfully used in many
natural-language tasks and applications including text generation and AI
chatbots. They also are a promising new technology for concept-oriented deep
learning (CODL). However, the prerequisite is that LLMs understand concepts and
ensure conceptual consistency. We discuss these in this paper, as well as major
uses of LLMs for CODL including concept extraction from text, concept graph
extraction from text, and concept learning. Human knowledge consists of both
symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only
LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal
LLMs, on the other hand, are capable of representing the full range (conceptual
and sensory) of human knowledge. We discuss conceptual understanding in
visual-language LLMs, the most important multimodal LLMs, and major uses of
them for CODL including concept extraction from image, concept graph extraction
from image, and concept learning. While uses of LLMs for CODL are valuable
standalone, they are particularly valuable as part of LLM applications such as
AI chatbots.",2023-06-29
"Most Language Models can be Poets too: An AI Writing Assistant and
  Constrained Text Generation Studio",2023-06-28 05:10:51+00:00,http://arxiv.org/abs/2306.15926v1,"Allen Roush, Sanjay Basu, Akshay Moorthy, Dmitry Dubovoy","cs.CL, cs.AI, cs.LG",knowledge,"Despite rapid advancement in the field of Constrained Natural Language
Generation, little time has been spent on exploring the potential of language
models which have had their vocabularies lexically, semantically, and/or
phonetically constrained. We find that most language models generate compelling
text even under significant constraints. We present a simple and universally
applicable technique for modifying the output of a language model by
compositionally applying filter functions to the language models vocabulary
before a unit of text is generated. This approach is plug-and-play and requires
no modification to the model. To showcase the value of this technique, we
present an easy to use AI writing assistant called Constrained Text Generation
Studio (CTGS). CTGS allows users to generate or choose from text with any
combination of a wide variety of constraints, such as banning a particular
letter, forcing the generated words to have a certain number of syllables,
and/or forcing the words to be partial anagrams of another word. We introduce a
novel dataset of prose that omits the letter e. We show that our method results
in strictly superior performance compared to fine-tuning alone on this dataset.
We also present a Huggingface space web-app presenting this technique called
Gadsby. The code is available to the public here:
https://github.com/Hellisotherpeople/Constrained-Text-Generation-Studio",2023-06-28
Knowledge Graph-Augmented Korean Generative Commonsense Reasoning,2023-06-26 07:23:47+00:00,http://arxiv.org/abs/2306.14470v1,"Dahyun Jung, Jaehyung Seo, Jaewook Lee, Chanjun Park, Heuiseok Lim","cs.CL, cs.AI",knowledge,"Generative commonsense reasoning refers to the task of generating acceptable
and logical assumptions about everyday situations based on commonsense
understanding. By utilizing an existing dataset such as Korean CommonGen,
language generation models can learn commonsense reasoning specific to the
Korean language. However, language models often fail to consider the
relationships between concepts and the deep knowledge inherent to concepts. To
address these limitations, we propose a method to utilize the Korean knowledge
graph data for text generation. Our experimental result shows that the proposed
method can enhance the efficiency of Korean commonsense inference, thereby
underlining the significance of employing supplementary data.",2023-06-26
Long-range Language Modeling with Self-retrieval,2023-06-23 10:18:02+00:00,http://arxiv.org/abs/2306.13421v1,"Ohad Rubin, Jonathan Berant",cs.CL,knowledge,"Retrieval-augmented language models (LMs) have received much attention
recently. However, typically the retriever is not trained jointly as a native
component of the LM, but added to an already-pretrained LM, which limits the
ability of the LM and the retriever to adapt to one another. In this work, we
propose the Retrieval-Pretrained Transformer (RPT), an architecture and
training procedure for jointly training a retrieval-augmented LM from scratch
for the task of modeling long texts. Given a recently generated text chunk in a
long document, the LM computes query representations, which are then used to
retrieve earlier chunks in the document, located potentially tens of thousands
of tokens before. Information from retrieved chunks is fused into the LM
representations to predict the next target chunk. We train the retriever
component with a semantic objective, where the goal is to retrieve chunks that
increase the probability of the next chunk, according to a reference LM. We
evaluate RPT on four long-range language modeling tasks, spanning books, code,
and mathematical writing, and demonstrate that RPT improves retrieval quality
and subsequently perplexity across the board compared to strong baselines.",2023-06-23
AudioPaLM: A Large Language Model That Can Speak and Listen,2023-06-22 14:37:54+00:00,http://arxiv.org/abs/2306.12925v1,"Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zalán Borsos, Félix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo Velimirović, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank","cs.CL, cs.AI, cs.SD, eess.AS, stat.ML",knowledge,"We introduce AudioPaLM, a large language model for speech understanding and
generation. AudioPaLM fuses text-based and speech-based language models, PaLM-2
[Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified
multimodal architecture that can process and generate text and speech with
applications including speech recognition and speech-to-speech translation.
AudioPaLM inherits the capability to preserve paralinguistic information such
as speaker identity and intonation from AudioLM and the linguistic knowledge
present only in text large language models such as PaLM-2. We demonstrate that
initializing AudioPaLM with the weights of a text-only large language model
improves speech processing, successfully leveraging the larger quantity of text
training data used in pretraining to assist with the speech tasks. The
resulting model significantly outperforms existing systems for speech
translation tasks and has the ability to perform zero-shot speech-to-text
translation for many languages for which input/target language combinations
were not seen in training. AudioPaLM also demonstrates features of audio
language models, such as transferring a voice across languages based on a short
spoken prompt. We release examples of our method at
https://google-research.github.io/seanet/audiopalm/examples",2023-06-22
Learning to Generate Better Than Your LLM,2023-06-20 18:19:17+00:00,http://arxiv.org/abs/2306.11816v1,"Jonathan D. Chang, Kiante Brantley, Rajkumar Ramamurthy, Dipendra Misra, Wen Sun","cs.LG, cs.AI, cs.CL",knowledge,"Reinforcement learning (RL) has emerged as a powerful paradigm for
fine-tuning Large Language Models (LLMs) for conditional text generation. In
particular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent
conversations with users by incorporating RL and feedback from humans. Inspired
by learning-to-search algorithms and capitalizing on key properties of text
generation, we seek to investigate reinforcement learning algorithms beyond
general purpose algorithms such as Proximal policy optimization (PPO). In
particular, we extend RL algorithms to allow them to interact with a dynamic
black-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a
suite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive
review and CommonGen text generation task from the GRUE benchmark. We show that
our RL algorithms achieve higher performance than supervised learning (SL) and
default PPO baselines, demonstrating the benefit of interaction with the guide
LLM. On CommonGen, we not only outperform our SL baselines but also improve
beyond PPO across a variety of lexical and semantic metrics beyond the one we
optimized for. Notably, on the IMDB dataset, we show that our GPT-2 based
policy outperforms the zero-shot GPT-3 oracle, indicating that our algorithms
can learn from a powerful, black-box GPT-3 oracle with a simpler, cheaper, and
publicly available GPT-2 model while gaining performance.",2023-06-20
"ChatGPT is not Enough: Enhancing Large Language Models with Knowledge
  Graphs for Fact-aware Language Modeling",2023-06-20 12:21:06+00:00,http://arxiv.org/abs/2306.11489v1,"Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, Xindong Wu","cs.CL, cs.AI",knowledge,"Recently, ChatGPT, a representative large language model (LLM), has gained
considerable attention due to its powerful emergent abilities. Some researchers
suggest that LLMs could potentially replace structured knowledge bases like
knowledge graphs (KGs) and function as parameterized knowledge bases. However,
while LLMs are proficient at learning probabilistic language patterns based on
large corpus and engaging in conversations with humans, they, like previous
smaller pre-trained language models (PLMs), still have difficulty in recalling
facts while generating knowledge-grounded contents. To overcome these
limitations, researchers have proposed enhancing data-driven PLMs with
knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus
improving their performance to generate texts requiring factual knowledge and
providing more informed responses to user queries. This paper reviews the
studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced
pre-trained language models (KGPLMs) as well as their applications. Inspired by
existing studies on KGPLM, this paper proposes to enhance LLMs with KGs by
developing knowledge graph-enhanced large language models (KGLLMs). KGLLM
provides a solution to enhance LLMs' factual reasoning ability, opening up new
avenues for LLM research.",2023-06-20
"FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for
  Task-Oriented Dialogue",2023-06-17 10:40:07+00:00,http://arxiv.org/abs/2306.10315v1,"Weihao Zeng, Keqing He, Yejie Wang, Chen Zeng, Jingang Wang, Yunsen Xian, Weiran Xu",cs.CL,knowledge,"Pre-trained language models based on general text enable huge success in the
NLP scenario. But the intrinsical difference of linguistic patterns between
general text and task-oriented dialogues makes existing pre-trained language
models less useful in practice. Current dialogue pre-training methods rely on a
contrastive framework and face the challenges of both selecting true positives
and hard negatives. In this paper, we propose a novel dialogue pre-training
model, FutureTOD, which distills future knowledge to the representation of the
previous dialogue context using a self-training framework. Our intuition is
that a good dialogue representation both learns local context information and
predicts future information. Extensive experiments on diverse downstream
dialogue tasks demonstrate the effectiveness of our model, especially the
generalization, robustness, and learning discriminative dialogue
representations capabilities.",2023-06-17
"Semi-supervised Relation Extraction via Data Augmentation and
  Consistency-training",2023-06-16 19:45:42+00:00,http://arxiv.org/abs/2306.10153v1,Komal K. Teru,"cs.CL, cs.IR",knowledge,"Due to the semantic complexity of the Relation extraction (RE) task,
obtaining high-quality human labelled data is an expensive and noisy process.
To improve the sample efficiency of the models, semi-supervised learning (SSL)
methods aim to leverage unlabelled data in addition to learning from limited
labelled data points. Recently, strong data augmentation combined with
consistency-based semi-supervised learning methods have advanced the state of
the art in several SSL tasks. However, adapting these methods to the RE task
has been challenging due to the difficulty of data augmentation for RE. In this
work, we leverage the recent advances in controlled text generation to perform
high quality data augmentation for the RE task. We further introduce small but
significant changes to model architecture that allows for generation of more
training data by interpolating different data points in their latent space.
These data augmentations along with consistency training result in very
competitive results for semi-supervised relation extraction on four benchmark
datasets.",2023-06-16
"Energy-Based Cross Attention for Bayesian Context Update in
  Text-to-Image Diffusion Models",2023-06-16 14:30:41+00:00,http://arxiv.org/abs/2306.09869v2,"Geon Yeong Park, Jeongsol Kim, Beomsu Kim, Sang Wan Lee, Jong Chul Ye","cs.CV, cs.AI, cs.CL, cs.LG",knowledge,"Despite the remarkable performance of text-to-image diffusion models in image
generation tasks, recent studies have raised the issue that generated images
sometimes cannot capture the intended semantic contents of the text prompts,
which phenomenon is often called semantic misalignment. To address this, here
we present a novel energy-based model (EBM) framework. Specifically, we first
formulate EBMs of latent image representations and text embeddings in each
cross-attention layer of the denoising autoencoder. Then, we obtain the
gradient of the log posterior of context vectors, which can be updated and
transferred to the subsequent cross-attention layer, thereby implicitly
minimizing a nested hierarchy of energy functions. Our latent EBMs further
allow zero-shot compositional generation as a linear combination of
cross-attention outputs from different contexts. Using extensive experiments,
we demonstrate that the proposed method is highly effective in handling various
image generation tasks, including multi-concept generation, text-guided image
inpainting, and real and synthetic image editing.",2023-06-16
Neural models for Factual Inconsistency Classification with Explanations,2023-06-15 06:06:50+00:00,http://arxiv.org/abs/2306.08872v1,"Tathagata Raha, Mukund Choudhary, Abhinav Menon, Harshit Gupta, KV Aditya Srivatsa, Manish Gupta, Vasudeva Varma","cs.CL, cs.AI",knowledge,"Factual consistency is one of the most important requirements when editing
high quality documents. It is extremely important for automatic text generation
systems like summarization, question answering, dialog modeling, and language
modeling. Still, automated factual inconsistency detection is rather
under-studied. Existing work has focused on (a) finding fake news keeping a
knowledge base in context, or (b) detecting broad contradiction (as part of
natural language inference literature). However, there has been no work on
detecting and explaining types of factual inconsistencies in text, without any
knowledge base in context. In this paper, we leverage existing work in
linguistics to formally define five types of factual inconsistencies. Based on
this categorization, we contribute a novel dataset, FICLE (Factual
Inconsistency CLassification with Explanation), with ~8K samples where each
sample consists of two sentences (claim and context) annotated with type and
span of inconsistency. When the inconsistency relates to an entity type, it is
labeled as well at two levels (coarse and fine-grained). Further, we leverage
this dataset to train a pipeline of four neural models to predict inconsistency
type with explanations, given a (claim, context) sentence pair. Explanations
include inconsistent claim fact triple, inconsistent context span, inconsistent
claim component, coarse and fine-grained inconsistent entity types. The
proposed system first predicts inconsistent spans from claim and context; and
then uses them to predict inconsistency types and inconsistent entity types
(when inconsistency is due to entities). We experiment with multiple
Transformer-based natural language classification as well as generative models,
and find that DeBERTa performs the best. Our proposed methods provide a
weighted F1 of ~87% for inconsistency type classification across the five
classes.",2023-06-15
Knowledge Distillation of Large Language Models,2023-06-14 14:44:03+00:00,http://arxiv.org/abs/2306.08543v1,"Yuxian Gu, Li Dong, Furu Wei, Minlie Huang","cs.CL, cs.AI",knowledge,"Knowledge Distillation (KD) is a promising technique for reducing the high
computational demand of large language models (LLMs). However, previous KD
methods are primarily applied to white-box classification models or training
small models to imitate black-box model APIs like ChatGPT. How to effectively
distill the knowledge from white-box generative LLMs is still under-explored,
which becomes more and more important with the prosperity of LLMs. In this
work, we propose MiniLLM that distills smaller language models from generative
larger language models. We first replace the forward Kullback-Leibler
divergence (KLD) objective in the standard KD approaches with reverse KLD,
which is more suitable for KD on generative language models, to prevent the
student model from overestimating the low-probability regions of the teacher
distribution. Then, we derive an effective optimization approach to learn this
objective. Extensive experiments in the instruction-following setting show that
the MiniLLM models generate more precise responses with the higher overall
quality, lower exposure bias, better calibration, and higher long-text
generation performance. Our method is also scalable for different model
families with 120M to 13B parameters. We will release our code and model
checkpoints at https://aka.ms/MiniLLM.",2023-06-14
"PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in
  Poetry Generation",2023-06-14 11:57:31+00:00,http://arxiv.org/abs/2306.08456v1,"Zhiyuan Hu, Chumin Liu, Yue Feng, Bryan Hooi",cs.CL,knowledge,"Poetry generation is a typical and popular task in natural language
generation. While prior works have shown success in controlling either semantic
or metrical aspects of poetry generation, there are still challenges in
addressing both perspectives simultaneously. In this paper, we employ the
Diffusion model to generate poetry in Sonnet and SongCi in Chinese for the
first time to tackle such challenges. Different from autoregressive generation,
our PoetryDiffusion model, based on Diffusion model, generates the complete
sentence or poetry by taking into account the whole sentence information,
resulting in improved semantic expression. Additionally, we incorporate a novel
metrical controller to manipulate and evaluate metrics (format and rhythm). The
denoising process in PoetryDiffusion allows for gradual enhancement of
semantics and flexible integration of the metrical controller. Experimental
results on two datasets demonstrate that our model outperforms existing models
in terms of semantic, metrical and overall performance.",2023-06-14
Unifying Large Language Models and Knowledge Graphs: A Roadmap,2023-06-14 07:15:26+00:00,http://arxiv.org/abs/2306.08302v2,"Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu","cs.CL, cs.AI",knowledge,"Large language models (LLMs), such as ChatGPT and GPT4, are making new waves
in the field of natural language processing and artificial intelligence, due to
their emergent ability and generalizability. However, LLMs are black-box
models, which often fall short of capturing and accessing factual knowledge. In
contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are
structured knowledge models that explicitly store rich factual knowledge. KGs
can enhance LLMs by providing external knowledge for inference and
interpretability. Meanwhile, KGs are difficult to construct and evolving by
nature, which challenges the existing methods in KGs to generate new facts and
represent unseen knowledge. Therefore, it is complementary to unify LLMs and
KGs together and simultaneously leverage their advantages. In this article, we
present a forward-looking roadmap for the unification of LLMs and KGs. Our
roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs,
which incorporate KGs during the pre-training and inference phases of LLMs, or
for the purpose of enhancing understanding of the knowledge learned by LLMs; 2)
LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding,
completion, construction, graph-to-text generation, and question answering; and
3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a
mutually beneficial way to enhance both LLMs and KGs for bidirectional
reasoning driven by both data and knowledge. We review and summarize existing
efforts within these three frameworks in our roadmap and pinpoint their future
research directions.",2023-06-14
GBSD: Generative Bokeh with Stage Diffusion,2023-06-14 05:34:02+00:00,http://arxiv.org/abs/2306.08251v1,"Jieren Deng, Xin Zhou, Hao Tian, Zhihong Pan, Derek Aguiar","cs.CV, cs.AI",knowledge,"The bokeh effect is an artistic technique that blurs out-of-focus areas in a
photograph and has gained interest due to recent developments in text-to-image
synthesis and the ubiquity of smart-phone cameras and photo-sharing apps. Prior
work on rendering bokeh effects have focused on post hoc image manipulation to
produce similar blurring effects in existing photographs using classical
computer graphics or neural rendering techniques, but have either depth
discontinuity artifacts or are restricted to reproducing bokeh effects that are
present in the training data. More recent diffusion based models can synthesize
images with an artistic style, but either require the generation of
high-dimensional masks, expensive fine-tuning, or affect global image
characteristics. In this paper, we present GBSD, the first generative
text-to-image model that synthesizes photorealistic images with a bokeh style.
Motivated by how image synthesis occurs progressively in diffusion models, our
approach combines latent diffusion models with a 2-stage conditioning algorithm
to render bokeh effects on semantically defined objects. Since we can focus the
effect on objects, this semantic bokeh effect is more versatile than classical
rendering techniques. We evaluate GBSD both quantitatively and qualitatively
and demonstrate its ability to be applied in both text-to-image and
image-to-image settings.",2023-06-14
"Question Decomposition Tree for Answering Complex Questions over
  Knowledge Bases",2023-06-13 07:44:29+00:00,http://arxiv.org/abs/2306.07597v1,"Xiang Huang, Sitao Cheng, Yiheng Shu, Yuheng Bao, Yuzhong Qu",cs.CL,knowledge,"Knowledge base question answering (KBQA) has attracted a lot of interest in
recent years, especially for complex questions which require multiple facts to
answer. Question decomposition is a promising way to answer complex questions.
Existing decomposition methods split the question into sub-questions according
to a single compositionality type, which is not sufficient for questions
involving multiple compositionality types. In this paper, we propose Question
Decomposition Tree (QDT) to represent the structure of complex questions.
Inspired by recent advances in natural language generation (NLG), we present a
two-staged method called Clue-Decipher to generate QDT. It can leverage the
strong ability of NLG model and simultaneously preserve the original questions.
To verify that QDT can enhance KBQA task, we design a decomposition-based KBQA
system called QDTQA. Extensive experiments show that QDTQA outperforms previous
state-of-the-art methods on ComplexWebQuestions dataset. Besides, our
decomposition method improves an existing KBQA system by 12% and sets a new
state-of-the-art on LC-QuAD 1.0.",2023-06-13
"Absformer: Transformer-based Model for Unsupervised Multi-Document
  Abstractive Summarization",2023-06-07 21:18:23+00:00,http://arxiv.org/abs/2306.04787v1,"Mohamed Trabelsi, Huseyin Uzunalioglu","cs.CL, cs.LG",knowledge,"Multi-document summarization (MDS) refers to the task of summarizing the text
in multiple documents into a concise summary. The generated summary can save
the time of reading many documents by providing the important content in the
form of a few sentences. Abstractive MDS aims to generate a coherent and fluent
summary for multiple documents using natural language generation techniques. In
this paper, we consider the unsupervised abstractive MDS setting where there
are only documents with no groundtruh summaries provided, and we propose
Absformer, a new Transformer-based method for unsupervised abstractive summary
generation. Our method consists of a first step where we pretrain a
Transformer-based encoder using the masked language modeling (MLM) objective as
the pretraining task in order to cluster the documents into semantically
similar groups; and a second step where we train a Transformer-based decoder to
generate abstractive summaries for the clusters of documents. To our knowledge,
we are the first to successfully incorporate a Transformer-based model to solve
the unsupervised abstractive MDS task. We evaluate our approach using three
real-world datasets from different domains, and we demonstrate both substantial
improvements in terms of evaluation metrics over state-of-the-art
abstractive-based methods, and generalization to datasets from different
domains.",2023-06-07
"Injecting knowledge into language generation: a case study in
  auto-charting after-visit care instructions from medical dialogue",2023-06-06 13:13:27+00:00,http://arxiv.org/abs/2306.03652v1,"Maksim Eremeev, Ilya Valmianski, Xavier Amatriain, Anitha Kannan",cs.CL,knowledge,"Factual correctness is often the limiting factor in practical applications of
natural language generation in high-stakes domains such as healthcare. An
essential requirement for maintaining factuality is the ability to deal with
rare tokens. This paper focuses on rare tokens that appear in both the source
and the reference sequences, and which, when missed during generation, decrease
the factual correctness of the output text. For high-stake domains that are
also knowledge-rich, we show how to use knowledge to (a) identify which rare
tokens that appear in both source and reference are important and (b) uplift
their conditional probability. We introduce the ``utilization rate'' that
encodes knowledge and serves as a regularizer by maximizing the marginal
probability of selected tokens. We present a study in a knowledge-rich domain
of healthcare, where we tackle the problem of generating after-visit care
instructions based on patient-doctor dialogues. We verify that, in our dataset,
specific medical concepts with high utilization rates are underestimated by
conventionally trained sequence-to-sequence models. We observe that correcting
this with our approach to knowledge injection reduces the uncertainty of the
model as well as improves factuality and coherence without negatively impacting
fluency.",2023-06-06
"PLANNER: Generating Diversified Paragraph via Latent Language Diffusion
  Model",2023-06-05 01:36:39+00:00,http://arxiv.org/abs/2306.02531v1,"Yizhe Zhang, Jiatao Gu, Zhuofeng Wu, Shuangfei Zhai, Josh Susskind, Navdeep Jaitly",cs.CL,knowledge,"Autoregressive models for text sometimes generate repetitive and low-quality
output because errors accumulate during the steps of generation. This issue is
often attributed to exposure bias - the difference between how a model is
trained, and how it is used during inference. Denoising diffusion models
provide an alternative approach in which a model can revisit and revise its
output. However, they can be computationally expensive and prior efforts on
text have led to models that produce less fluent output compared to
autoregressive models, especially for longer text and paragraphs. In this
paper, we propose PLANNER, a model that combines latent semantic diffusion with
autoregressive generation, to generate fluent text while exercising global
control over paragraphs. The model achieves this by combining an autoregressive
""decoding"" module with a ""planning"" module that uses latent diffusion to
generate semantic paragraph embeddings in a coarse-to-fine manner. The proposed
method is evaluated on various conditional generation tasks, and results on
semantic generation, text completion and summarization show its effectiveness
in generating high-quality long-form text in an efficient manner.",2023-06-05
"Adaptive and Personalized Exercise Generation for Online Language
  Learning",2023-06-04 20:18:40+00:00,http://arxiv.org/abs/2306.02457v1,"Peng Cui, Mrinmaya Sachan","cs.CL, cs.AI",knowledge,"Adaptive learning aims to provide customized educational activities (e.g.,
exercises) to address individual learning needs. However, manual construction
and delivery of such activities is a laborious process. Thus, in this paper, we
study a novel task of adaptive and personalized exercise generation for online
language learning. To this end, we combine a knowledge tracing model that
estimates each student's evolving knowledge states from their learning history
and a controlled text generation model that generates exercise sentences based
on the student's current estimated knowledge state and instructor requirements
of desired properties (e.g., domain knowledge and difficulty). We train and
evaluate our model on real-world learner interaction data from Duolingo and
demonstrate that LMs guided by student states can generate superior exercises.
Then, we discuss the potential use of our model in educational applications
using various simulations. These simulations show that our model can adapt to
students' individual abilities and can facilitate their learning efficiency by
personalizing learning sequences.",2023-06-04
Commonsense Knowledge Transfer for Pre-trained Language Models,2023-06-04 15:44:51+00:00,http://arxiv.org/abs/2306.02388v1,"Wangchunshu Zhou, Ronan Le Bras, Yejin Choi","cs.CL, cs.AI, cs.LG",knowledge,"Despite serving as the foundation models for a wide range of NLP benchmarks,
pre-trained language models have shown limited capabilities of acquiring
implicit commonsense knowledge from self-supervision alone, compared to
learning linguistic and factual knowledge that appear more explicitly in the
surface patterns in text. In this work, we introduce commonsense knowledge
transfer, a framework to transfer the commonsense knowledge stored in a neural
commonsense knowledge model to a general-purpose pre-trained language model. It
first exploits general texts to form queries for extracting commonsense
knowledge from the neural commonsense knowledge model and then refines the
language model with two self-supervised objectives: commonsense mask infilling
and commonsense relation prediction, which align human language with the
underlying commonsense knowledge. Empirical results show that our approach
consistently improves the model's performance on downstream tasks that require
commonsense reasoning. Moreover, we find that the improvement is more
significant in the few-shot setting. This suggests that our approach helps
language models better transfer to downstream tasks without extensive
supervision by injecting commonsense knowledge into their parameters.",2023-06-04
"Modular Transformers: Compressing Transformers into Modularized Layers
  for Flexible Efficient Inference",2023-06-04 15:26:28+00:00,http://arxiv.org/abs/2306.02379v1,"Wangchunshu Zhou, Ronan Le Bras, Yejin Choi","cs.CL, cs.LG",knowledge,"Pre-trained Transformer models like T5 and BART have advanced the state of
the art on a wide range of text generation tasks. Compressing these models into
smaller ones has become critically important for practical use. Common neural
network compression techniques such as knowledge distillation or quantization
are limited to static compression where the compression ratio is fixed. In this
paper, we introduce Modular Transformers, a modularized encoder-decoder
framework for flexible sequence-to-sequence model compression. Modular
Transformers train modularized layers that have the same function of two or
more consecutive layers in the original model via module replacing and
knowledge distillation. After training, the modularized layers can be flexibly
assembled into sequence-to-sequence models that meet different
performance-efficiency trade-offs. Experimental results show that after a
single training phase, by simply varying the assembling strategy, Modular
Transformers can achieve flexible compression ratios from 1.1x to 6x with
little to moderate relative performance drop.",2023-06-04
"FlexRound: Learnable Rounding based on Element-wise Division for
  Post-Training Quantization",2023-06-01 03:31:12+00:00,http://arxiv.org/abs/2306.00317v1,"Jung Hyun Lee, Jeonghoon Kim, Se Jung Kwon, Dongsoo Lee","cs.LG, cs.AI",knowledge,"Post-training quantization (PTQ) has been gaining popularity for the
deployment of deep neural networks on resource-limited devices since unlike
quantization-aware training, neither a full training dataset nor end-to-end
training is required at all. As PTQ schemes based on reconstructing each layer
or block output turn out to be effective to enhance quantized model
performance, recent works have developed algorithms to devise and learn a new
weight-rounding scheme so as to better reconstruct each layer or block output.
In this work, we propose a simple yet effective new weight-rounding mechanism
for PTQ, coined FlexRound, based on element-wise division instead of typical
element-wise addition such that FlexRound enables jointly learning a common
quantization grid size as well as a different scale for each pre-trained
weight. Thanks to the reciprocal rule of derivatives induced by element-wise
division, FlexRound is inherently able to exploit pre-trained weights when
updating their corresponding scales, and thus, flexibly quantize pre-trained
weights depending on their magnitudes. We empirically validate the efficacy of
FlexRound on a wide range of models and tasks. To the best of our knowledge,
our work is the first to carry out comprehensive experiments on not only image
classification and natural language understanding but also natural language
generation, assuming a per-tensor uniform PTQ setting. Moreover, we
demonstrate, for the first time, that large language models can be efficiently
quantized, with only a negligible impact on performance compared to
half-precision baselines, achieved by reconstructing the output in a
block-by-block manner.",2023-06-01
An Invariant Learning Characterization of Controlled Text Generation,2023-05-31 21:35:08+00:00,http://arxiv.org/abs/2306.00198v1,"Carolina Zheng, Claudia Shi, Keyon Vafa, Amir Feder, David M. Blei","cs.CL, cs.LG",knowledge,"Controlled generation refers to the problem of creating text that contains
stylistic or semantic attributes of interest. Many approaches reduce this
problem to training a predictor of the desired attribute. For example,
researchers hoping to deploy a large language model to produce non-toxic
content may use a toxicity classifier to filter generated text. In practice,
the generated text to classify, which is determined by user prompts, may come
from a wide range of distributions. In this paper, we show that the performance
of controlled generation may be poor if the distributions of text in response
to user prompts differ from the distribution the predictor was trained on. To
address this problem, we cast controlled generation under distribution shift as
an invariant learning problem: the most effective predictor should be invariant
across multiple text environments. We then discuss a natural solution that
arises from this characterization and propose heuristics for selecting natural
environments. We study this characterization and the proposed method
empirically using both synthetic and real data. Experiments demonstrate both
the challenge of distribution shift in controlled generation and the potential
of invariance methods in this setting.",2023-05-31
"Pre-Trained Language-Meaning Models for Multilingual Parsing and
  Generation",2023-05-31 19:00:33+00:00,http://arxiv.org/abs/2306.00124v1,"Chunliu Wang, Huiyuan Lai, Malvina Nissim, Johan Bos",cs.CL,knowledge,"Pre-trained language models (PLMs) have achieved great success in NLP and
have recently been used for tasks in computational semantics. However, these
tasks do not fully benefit from PLMs since meaning representations are not
explicitly included in the pre-training stage. We introduce multilingual
pre-trained language-meaning models based on Discourse Representation
Structures (DRSs), including meaning representations besides natural language
texts in the same model, and design a new strategy to reduce the gap between
the pre-training and fine-tuning objectives. Since DRSs are language neutral,
cross-lingual transfer learning is adopted to further improve the performance
of non-English tasks. Automatic evaluation results show that our approach
achieves the best performance on both the multilingual DRS parsing and
DRS-to-text generation tasks. Correlation analysis between automatic metrics
and human judgements on the generation task further validates the effectiveness
of our model. Human inspection reveals that out-of-vocabulary tokens are the
main cause of erroneous results.",2023-05-31
"Scalable Learning of Latent Language Structure With Logical Offline
  Cycle Consistency",2023-05-31 16:47:20+00:00,http://arxiv.org/abs/2305.20018v1,"Maxwell Crouse, Ramon Astudillo, Tahira Naseem, Subhajit Chaudhury, Pavan Kapanipathi, Salim Roukos, Alexander Gray","cs.CL, cs.AI",knowledge,"We introduce Logical Offline Cycle Consistency Optimization (LOCCO), a
scalable, semi-supervised method for training a neural semantic parser.
Conceptually, LOCCO can be viewed as a form of self-learning where the semantic
parser being trained is used to generate annotations for unlabeled text that
are then used as new supervision. To increase the quality of annotations, our
method utilizes a count-based prior over valid formal meaning representations
and a cycle-consistency score produced by a neural text generation model as
additional signals. Both the prior and semantic parser are updated in an
alternate fashion from full passes over the training data, which can be seen as
approximating the marginalization of latent structures through stochastic
variational inference. The use of a count-based prior, frozen text generation
model, and offline annotation process yields an approach with negligible
complexity and latency increases as compared to conventional self-learning. As
an added bonus, the annotations produced by LOCCO can be trivially repurposed
to train a neural text generation model. We demonstrate the utility of LOCCO on
the well-known WebNLG benchmark where we obtain an improvement of 2 points
against a self-learning parser under equivalent conditions, an improvement of
1.3 points against the previous state-of-the-art parser, and competitive text
generation performance in terms of BLEU score.",2023-05-31
Fine-grained Text Style Transfer with Diffusion-Based Language Models,2023-05-31 02:51:26+00:00,http://arxiv.org/abs/2305.19512v1,"Yiwei Lyu, Tiange Luo, Jiacheng Shi, Todd C. Hollon, Honglak Lee","cs.CL, cs.AI, cs.LG",knowledge,"Diffusion probabilistic models have shown great success in generating
high-quality images controllably, and researchers have tried to utilize this
controllability into text generation domain. Previous works on diffusion-based
language models have shown that they can be trained without external knowledge
(such as pre-trained weights) and still achieve stable performance and
controllability. In this paper, we trained a diffusion-based model on StylePTB
dataset, the standard benchmark for fine-grained text style transfers. The
tasks in StylePTB requires much more refined control over the output text
compared to tasks evaluated in previous works, and our model was able to
achieve state-of-the-art performance on StylePTB on both individual and
compositional transfers. Moreover, our model, trained on limited data from
StylePTB without external knowledge, outperforms previous works that utilized
pretrained weights, embeddings, and external grammar parsers, and this may
indicate that diffusion-based language models have great potential under
low-resource settings.",2023-05-31
"ScoNe: Benchmarking Negation Reasoning in Language Models With
  Fine-Tuning and In-Context Learning",2023-05-30 21:43:11+00:00,http://arxiv.org/abs/2305.19426v1,"Jingyuan Selena She, Christopher Potts, Samuel R. Bowman, Atticus Geiger","cs.CL, cs.LG",knowledge,"A number of recent benchmarks seek to assess how well models handle natural
language negation. However, these benchmarks lack the controlled example
paradigms that would allow us to infer whether a model had learned how negation
morphemes semantically scope. To fill these analytical gaps, we present the
Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six
examples with up to two negations where either zero, one, or both negative
morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and
in-context learning strategies. We find that RoBERTa and DeBERTa models solve
ScoNe-NLI after many shot fine-tuning. For in-context learning, we test
InstructGPT models and find that most prompt strategies are not successful,
including those using step-by-step reasoning. To better understand this result,
we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds
negation reasoning in short narratives. Here, InstructGPT is successful, which
reveals the model can correctly reason about negation, but struggles to do so
on prompt-adapted NLI examples outside of its core pretraining regime.",2023-05-30
"Generating with Confidence: Uncertainty Quantification for Black-box
  Large Language Models",2023-05-30 16:31:26+00:00,http://arxiv.org/abs/2305.19187v1,"Zhen Lin, Shubhendu Trivedi, Jimeng Sun","cs.CL, cs.LG, stat.ML",knowledge,"Large language models (LLMs) specializing in natural language generation
(NLG) have recently started exhibiting promising capabilities across a variety
of domains. However, gauging the trustworthiness of responses generated by LLMs
remains an open challenge, with limited research on uncertainty quantification
for NLG. Furthermore, existing literature typically assumes white-box access to
language models, which is becoming unrealistic either due to the closed-source
nature of the latest LLMs or due to computational constraints. In this work, we
investigate uncertainty quantification in NLG for $\textit{black-box}$ LLMs. We
first differentiate two closely-related notions: $\textit{uncertainty}$, which
depends only on the input, and $\textit{confidence}$, which additionally
depends on the generated response. We then propose and compare several
confidence/uncertainty metrics, applying them to $\textit{selective NLG}$,
where unreliable results could either be ignored or yielded for further
assessment. Our findings on several popular LLMs and datasets reveal that a
simple yet effective metric for the average semantic dispersion can be a
reliable predictor of the quality of LLM responses. This study can provide
valuable insights for practitioners on uncertainty management when adopting
LLMs. The code to replicate all our experiments is available at
https://github.com/zlin7/UQ-NLG.",2023-05-30
"Response Generation in Longitudinal Dialogues: Which Knowledge
  Representation Helps?",2023-05-25 10:13:53+00:00,http://arxiv.org/abs/2305.15908v1,"Seyed Mahed Mousavi, Simone Caldarella, Giuseppe Riccardi",cs.CL,knowledge,"Longitudinal Dialogues (LD) are the most challenging type of conversation for
human-machine dialogue systems. LDs include the recollections of events,
personal thoughts, and emotions specific to each individual in a sparse
sequence of dialogue sessions. Dialogue systems designed for LDs should
uniquely interact with the users over multiple sessions and long periods of
time (e.g. weeks), and engage them in personal dialogues to elaborate on their
feelings, thoughts, and real-life events. In this paper, we study the task of
response generation in LDs. We evaluate whether general-purpose Pre-trained
Language Models (PLM) are appropriate for this purpose. We fine-tune two PLMs,
GePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different
representations of the personal knowledge extracted from LDs for grounded
response generation, including the graph representation of the mentioned events
and participants. We evaluate the performance of the models via automatic
metrics and the contribution of the knowledge via the Integrated Gradients
technique. We categorize the natural language generation errors via human
evaluations of contextualization, appropriateness and engagement of the user.",2023-05-25
"Self-contradictory Hallucinations of Large Language Models: Evaluation,
  Detection and Mitigation",2023-05-25 08:43:46+00:00,http://arxiv.org/abs/2305.15852v1,"Niels Mündler, Jingxuan He, Slobodan Jenko, Martin Vechev","cs.CL, cs.AI, cs.LG",knowledge,"Large language models (large LMs) are susceptible to producing text with
hallucinated content. Self-contradiction, where the LM generates two
contradictory sentences within the same context, is an important form of
hallucination. In this work, we present a comprehensive analysis on
self-contradiction for state-of-the-art, instruction-tuned LMs, including
evaluation, detection, and mitigation. To effectively trigger
self-contradictions, we design a framework that constrains LMs to generate
appropriate sentence pairs. Our evaluation on these sentence pairs reveals that
self-contradictions occur frequently across different LMs for both famous and
lesser-known topics. Next, we prompt the LMs to detect self-contradictions. Our
results indicate that ChatGPT and GPT-4 are able to accurately identify
self-contradictions, while Vicuna-13B struggles to do so. For example, with our
best prompting method, ChatGPT achieves 91.0% precision and 80.5% recall on the
sentence pairs generated by itself. To automatically mitigate
self-contradictions, we develop an iterative algorithm that prompts the LMs to
remove the detected self-contradictions from the generated text. Our algorithm
successfully revises the text such that self-contradictions are significantly
reduced, while maintaining its fluency and informativeness. Importantly, our
entire pipeline of triggering, detecting, and mitigating self-contradictions is
applicable to black-box LMs and does not require any external grounded
knowledge.",2023-05-25
"Peek Across: Improving Multi-Document Modeling via Cross-Document
  Question-Answering",2023-05-24 17:48:40+00:00,http://arxiv.org/abs/2305.15387v1,"Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, Arman Cohan","cs.CL, cs.AI",knowledge,"The integration of multi-document pre-training objectives into language
models has resulted in remarkable improvements in multi-document downstream
tasks. In this work, we propose extending this idea by pre-training a generic
multi-document model from a novel cross-document question answering
pre-training objective. To that end, given a set (or cluster) of
topically-related documents, we systematically generate semantically-oriented
questions from a salient sentence in one document and challenge the model,
during pre-training, to answer these questions while ""peeking"" into other
topically-related documents. In a similar manner, the model is also challenged
to recover the sentence from which the question was generated, again while
leveraging cross-document information. This novel multi-document QA formulation
directs the model to better recover cross-text informational relations, and
introduces a natural augmentation that artificially increases the pre-training
data. Further, unlike prior multi-document models that focus on either
classification or summarization tasks, our pre-training objective formulation
enables the model to perform tasks that involve both short text generation
(e.g., QA) and long text generation (e.g., summarization). Following this
scheme, we pre-train our model -- termed QAmden -- and evaluate its performance
across several multi-document tasks, including multi-document QA,
summarization, and query-focused summarization, yielding improvements of up to
7%, and significantly outperforms zero-shot GPT-3.5 and GPT-4.",2023-05-24
"Not All Metrics Are Guilty: Improving NLG Evaluation with LLM
  Paraphrasing",2023-05-24 11:53:29+00:00,http://arxiv.org/abs/2305.15067v1,"Tianyi Tang, Hongyuan Lu, Yuchen Eleanor Jiang, Haoyang Huang, Dongdong Zhang, Wayne Xin Zhao, Furu Wei",cs.CL,knowledge,"Most research about natural language generation (NLG) relies on evaluation
benchmarks with limited references for a sample, which may result in poor
correlations with human judgements. The underlying reason is that one semantic
meaning can actually be expressed in different forms, and the evaluation with a
single or few references may not accurately reflect the quality of the model's
hypotheses. To address this issue, this paper presents a novel method, named
Para-Ref, to enhance existing evaluation benchmarks by enriching the number of
references. We leverage large language models (LLMs) to paraphrase a single
reference into multiple high-quality ones in diverse expressions. Experimental
results on representative NLG tasks of machine translation, text summarization,
and image caption demonstrate that our method can effectively improve the
correlation with human evaluation for sixteen automatic evaluation metrics by
+7.82% in ratio. We release the code and data at
https://github.com/RUCAIBox/Para-Ref.",2023-05-24
The ACL OCL Corpus: advancing Open science in Computational Linguistics,2023-05-24 10:35:56+00:00,http://arxiv.org/abs/2305.14996v1,"Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, Min-Yen Kan","cs.CL, cs.DL",knowledge,"We present a scholarly corpus from the ACL Anthology to assist Open
scientific research in the Computational Linguistics domain, named as ACL OCL.
Compared with previous ARC and AAN versions, ACL OCL includes structured
full-texts with logical sections, references to figures, and links to a large
knowledge resource (semantic scholar). ACL OCL contains 74k scientific papers,
together with 210k figures extracted up to September 2022. To observe the
development in the computational linguistics domain, we detect the topics of
all OCL papers with a supervised neural model. We observe ''Syntax: Tagging,
Chunking and Parsing'' topic is significantly shrinking and ''Natural Language
Generation'' is resurging. Our dataset is open and available to download from
HuggingFace in https://huggingface.co/datasets/ACL-OCL/ACL-OCL-Corpus.",2023-05-24
Trusting Your Evidence: Hallucinate Less with Context-aware Decoding,2023-05-24 05:19:15+00:00,http://arxiv.org/abs/2305.14739v1,"Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, Scott Wen-tau Yih",cs.CL,knowledge,"Language models (LMs) often struggle to pay enough attention to the input
context, and generate texts that are unfaithful or contain hallucinations. To
mitigate this issue, we present context-aware decoding (CAD), which follows a
contrastive output distribution that amplifies the difference between the
output probabilities when a model is used with and without context. Our
experiments show that CAD, without additional training, significantly improves
the faithfulness of different LM families, including OPT, GPT, LLaMA and
FLAN-T5 for summarization tasks (e.g., 14.3% gain for LLaMA in factuality
metrics). Furthermore, CAD is particularly effective in overriding a model's
prior knowledge when it contradicts the provided context, leading to
substantial improvements in tasks where resolving the knowledge conflict is
essential.",2023-05-24
Diffusion Models in NLP: A Survey,2023-05-24 03:25:32+00:00,http://arxiv.org/abs/2305.14671v1,"Hao Zou, Zae Myung Kim, Dongyeop Kang",cs.CL,knowledge,"This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP.",2023-05-24
"Enhancing Generation through Summarization Duality and Explicit Outline
  Control",2023-05-23 18:33:52+00:00,http://arxiv.org/abs/2305.14459v1,"Yunzhe Li, Qian Chen, Weixiang Yan, Wen Wang, Qinglin Zhang, Hari Sundaram","cs.CL, cs.AI",knowledge,"Automatically open-ended long text generation poses significant challenges
due to semantic incoherence and plot implausibility. Previous works usually
alleviate this problem through outlines in the form of short phrases or
abstractive signals by designing unsupervised tasks, which tend to be unstable
and weakly interpretable.
  Assuming that a summary serves as a mature outline, we introduce a two-stage,
summary-enhanced outline supervised generation framework. This framework
leverages the dual characteristics of the summarization task to improve outline
prediction, resulting in more explicit and plausible outlines. Furthermore, we
identify an underutilization issue in outline-based generation with both
standard pretrained language models (e.g., GPT-2, BART) and large language
models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit
outline control method for more effective utilization of generated outlines.",2023-05-23
"INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with
  Automatic Feedback",2023-05-23 17:27:22+00:00,http://arxiv.org/abs/2305.14282v1,"Wenda Xu, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag, William Yang Wang, Lei Li","cs.CL, cs.AI",knowledge,"The field of automatic evaluation of text generation made tremendous progress
in the last few years. In particular, since the advent of neural metrics, like
COMET, BLEURT, and SEScore2, the newest generation of metrics show a high
correlation with human judgment. Unfortunately, quality scores generated with
neural metrics are not interpretable, and it is unclear which part of the
generation output is criticized by the metrics. To address this limitation, we
present INSTRUCTSCORE, an open-source, explainable evaluation metric for text
generation. By harnessing both explicit human instruction and the implicit
knowledge of GPT4, we fine-tune a LLAMA model to create an evaluative metric
that can produce a diagnostic report aligned with human judgment. We evaluate
INSTRUCTSCORE on the WMT22 Zh-En translation task, where our 7B model surpasses
other LLM-based baselines, including those based on 175B GPT3. Impressively,
our INSTRUCTSCORE, even without direct supervision from human-rated data,
achieves performance levels on par with state-of-the-art metrics like COMET22,
which was fine-tuned on human ratings.",2023-05-23
"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long
  Form Text Generation",2023-05-23 17:06:00+00:00,http://arxiv.org/abs/2305.14251v1,"Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, Hannaneh Hajishirzi","cs.CL, cs.AI, cs.LG",knowledge,"Evaluating the factuality of long-form text generated by large language
models (LMs) is non-trivial because (1) generations often contain a mixture of
supported and unsupported pieces of information, making binary judgments of
quality inadequate, and (2) human evaluation is time-consuming and costly. In
this paper, we introduce FActScore (Factual precision in Atomicity Score), a
new evaluation that breaks a generation into a series of atomic facts and
computes the percentage of atomic facts supported by a reliable knowledge
source. We conduct an extensive human evaluation to obtain FActScores of people
biographies generated by several state-of-the-art commercial LMs --
InstructGPT, ChatGPT, and the retrieval-augmented PerplexityAI -- and report
new analysis demonstrating the need for such a fine-grained score (e.g.,
ChatGPT only achieves 58%). Since human evaluation is costly, we also introduce
an automated model that estimates FActScore, using retrieval and a strong
language model, with less than a 2% error rate. Finally, we use this automated
metric to evaluate 6,500 generations from a new set of 13 recent LMs that would
have cost $26K if evaluated by humans, with various findings: GPT-4 and ChatGPT
are more factual than public models, and Vicuna and Alpaca are some of the best
public models.",2023-05-23
Evaluating Factual Consistency of Texts with Semantic Role Labeling,2023-05-22 17:59:42+00:00,http://arxiv.org/abs/2305.13309v1,"Jing Fan, Dennis Aumiller, Michael Gertz",cs.CL,knowledge,"Automated evaluation of text generation systems has recently seen increasing
attention, particularly checking whether generated text stays truthful to input
sources. Existing methods frequently rely on an evaluation using task-specific
language models, which in turn allows for little interpretability of generated
scores. We introduce SRLScore, a reference-free evaluation metric designed with
text summarization in mind. Our approach generates fact tuples constructed from
Semantic Role Labels, applied to both input and summary texts. A final
factuality score is computed by an adjustable scoring mechanism, which allows
for easy adaption of the method across domains. Correlation with human
judgments on English summarization datasets shows that SRLScore is competitive
with state-of-the-art methods and exhibits stable generalization across
datasets without requiring further training or hyperparameter tuning. We
experiment with an optional co-reference resolution step, but find that the
performance boost is mostly outweighed by the additional compute required. Our
metric is available online at https://github.com/heyjing/SRLScore.",2023-05-22
"GEST: the Graph of Events in Space and Time as a Common Representation
  between Vision and Language",2023-05-22 11:38:27+00:00,http://arxiv.org/abs/2305.12940v1,"Mihai Masala, Nicolae Cudlenco, Traian Rebedea, Marius Leordeanu",cs.CL,knowledge,"One of the essential human skills is the ability to seamlessly build an inner
representation of the world. By exploiting this representation, humans are
capable of easily finding consensus between visual, auditory and linguistic
perspectives. In this work, we set out to understand and emulate this ability
through an explicit representation for both vision and language - Graphs of
Events in Space and Time (GEST). GEST alows us to measure the similarity
between texts and videos in a semantic and fully explainable way, through graph
matching. It also allows us to generate text and videos from a common
representation that provides a well understood content. In this work we show
that the graph matching similarity metrics based on GEST outperform classical
text generation metrics and can also boost the performance of state of art,
heavily trained metrics.",2023-05-22
STOAT: Structured Data to Analytical Text With Controls,2023-05-19 17:03:09+00:00,http://arxiv.org/abs/2305.11826v1,"Deepanway Ghosal, Preksha Nema, Aravindan Raghuveer","cs.CL, cs.AI",knowledge,"Recent language models have made tremendous progress in the structured data
to text generation task. However, these models still give sub-optimal
performance where logical inference is required to generate the descriptions.
In this work, we specifically focus on analytical text generation from
structured data such as tables. Building on the taxonomy proposed in (Gupta et
al., 2020) we focus on controllable table to text generation for the following
reasoning categories: numerical reasoning, commonsense reasoning, temporal
reasoning, table knowledge, and entity knowledge. We propose STOAT model, which
is table and reasoning aware, with vector-quantization to infuse the given
reasoning categories in the output. We observe that our model provides 10.19%,
1.13% improvement on the PARENT metric in iToTTo and Infotabs for the
analytical sentence task. We also found that our model generates 15.3% more
faithful and analytical descriptions as compared to the baseline models in
human evaluation. We curate and release two reasoning category annotated
table-to-interesting text generation datasets based on the ToTTo (Parikh et
al., 2020) and InfoTabs datasets (Gupta et al.,2020).",2023-05-19
"Generating Visual Spatial Description via Holistic 3D Scene
  Understanding",2023-05-19 15:53:56+00:00,http://arxiv.org/abs/2305.11768v1,"Yu Zhao, Hao Fei, Wei Ji, Jianguo Wei, Meishan Zhang, Min Zhang, Tat-Seng Chua","cs.CV, cs.CL",knowledge,"Visual spatial description (VSD) aims to generate texts that describe the
spatial relations of the given objects within images. Existing VSD work merely
models the 2D geometrical vision features, thus inevitably falling prey to the
problem of skewed spatial understanding of target objects. In this work, we
investigate the incorporation of 3D scene features for VSD. With an external 3D
scene extractor, we obtain the 3D objects and scene features for input images,
based on which we construct a target object-centered 3D spatial scene graph
(Go3D-S2G), such that we model the spatial semantics of target objects within
the holistic 3D scenes. Besides, we propose a scene subgraph selecting
mechanism, sampling topologically-diverse subgraphs from Go3D-S2G, where the
diverse local structure features are navigated to yield spatially-diversified
text generation. Experimental results on two VSD datasets demonstrate that our
framework outperforms the baselines significantly, especially improving on the
cases with complex visual spatial relations. Meanwhile, our method can produce
more spatially-diversified generation. Code is available at
https://github.com/zhaoyucs/VSD.",2023-05-19
"What Comes Next? Evaluating Uncertainty in Neural Text Generators
  Against Human Production Variability",2023-05-19 14:41:55+00:00,http://arxiv.org/abs/2305.11707v1,"Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fernández, Barbara Plank","cs.CL, cs.AI, cs.LG",knowledge,"In Natural Language Generation (NLG) tasks, for any input, multiple
communicative goals are plausible, and any goal can be put into words, or
produced, in multiple ways. We characterise the extent to which human
production varies lexically, syntactically, and semantically across four NLG
tasks, connecting human production variability to aleatoric or data
uncertainty. We then inspect the space of output strings shaped by a generation
system's predicted probability distribution and decoding algorithm to probe its
uncertainty. For each test input, we measure the generator's calibration to
human production variability. Following this instance-level approach, we
analyse NLG models and decoding strategies, demonstrating that probing a
generator with multiple samples and, when possible, multiple references,
provides the level of detail necessary to gain understanding of a model's
representation of uncertainty.",2023-05-19
"Cross-modality Data Augmentation for End-to-End Sign Language
  Translation",2023-05-18 16:34:18+00:00,http://arxiv.org/abs/2305.11096v1,"Jinhui Ye, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Hui Xiong",cs.CL,knowledge,"End-to-end sign language translation (SLT) aims to convert sign language
videos into spoken language texts directly without intermediate
representations. It has been a challenging task due to the modality gap between
sign videos and texts and the data scarcity of labeled data. To tackle these
challenges, we propose a novel Cross-modality Data Augmentation (XmDA)
framework to transfer the powerful gloss-to-text translation capabilities to
end-to-end sign language translation (i.e. video-to-text) by exploiting pseudo
gloss-text pairs from the sign gloss translation model. Specifically, XmDA
consists of two key components, namely, cross-modality mix-up and
cross-modality knowledge distillation. The former explicitly encourages the
alignment between sign video features and gloss embeddings to bridge the
modality gap. The latter utilizes the generation knowledge from gloss-to-text
teacher models to guide the spoken language text generation. Experimental
results on two widely used SLT datasets, i.e., PHOENIX-2014T and CSL-Daily,
demonstrate that the proposed XmDA framework significantly and consistently
outperforms the baseline models. Extensive analyses confirm our claim that XmDA
enhances spoken language text generation by reducing the representation
distance between videos and texts, as well as improving the processing of
low-frequency words and long sentences.",2023-05-18
What You See is What You Read? Improving Text-Image Alignment Evaluation,2023-05-17 17:43:38+00:00,http://arxiv.org/abs/2305.10400v1,"Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, Eran Ofek, Idan Szpektor","cs.CL, cs.CV",knowledge,"Automatically determining whether a text and a corresponding image are
semantically aligned is a significant challenge for vision-language models,
with applications in generative text-to-image and image-to-text tasks. In this
work, we study methods for automatic text-image alignment evaluation. We first
introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets
from both text-to-image and image-to-text generation tasks, with human
judgements for whether a given text-image pair is semantically aligned. We then
describe two automatic methods to determine alignment: the first involving a
pipeline based on question generation and visual question answering models, and
the second employing an end-to-end classification approach by finetuning
multimodal pretrained models. Both methods surpass prior approaches in various
text-image alignment tasks, with significant improvements in challenging cases
that involve complex composition or unnatural images. Finally, we demonstrate
how our approaches can localize specific misalignments between an image and a
given text, and how they can be used to automatically re-rank candidates in
text-to-image generation.",2023-05-17
Boosting Event Extraction with Denoised Structure-to-Text Augmentation,2023-05-16 16:52:07+00:00,http://arxiv.org/abs/2305.09598v1,"bo wang, Heyan Huang, Xiaochi Wei, Ge Shi, Xiao Liu, Chong Feng, Tong Zhou, Shuaiqiang Wang, Dawei Yin",cs.CL,knowledge,"Event extraction aims to recognize pre-defined event triggers and arguments
from texts, which suffer from the lack of high-quality annotations. In most NLP
applications, involving a large scale of synthetic training data is a practical
and effective approach to alleviate the problem of data scarcity. However, when
applying to the task of event extraction, recent data augmentation methods
often neglect the problem of grammatical incorrectness, structure misalignment,
and semantic drifting, leading to unsatisfactory performances. In order to
solve these problems, we propose a denoised structure-to-text augmentation
framework for event extraction DAEE, which generates additional training data
through the knowledge-based structure-to-text generation model and selects the
effective subset from the generated data iteratively with a deep reinforcement
learning agent. Experimental results on several datasets demonstrate that the
proposed method generates more diverse text representations for event
extraction and achieves comparable results with the state-of-the-art.",2023-05-16
Watermarking Text Generated by Black-Box Language Models,2023-05-14 07:37:33+00:00,http://arxiv.org/abs/2305.08883v1,"Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, Nenghai Yu","cs.CL, cs.AI",knowledge,"LLMs now exhibit human-like skills in various fields, leading to worries
about misuse. Thus, detecting generated text is crucial. However, passive
detection methods are stuck in domain specificity and limited adversarial
robustness. To achieve reliable detection, a watermark-based method was
proposed for white-box LLMs, allowing them to embed watermarks during text
generation. The method involves randomly dividing the model vocabulary to
obtain a special list and adjusting the probability distribution to promote the
selection of words in the list. A detection algorithm aware of the list can
identify the watermarked text. However, this method is not applicable in many
real-world scenarios where only black-box language models are available. For
instance, third-parties that develop API-based vertical applications cannot
watermark text themselves because API providers only supply generated text and
withhold probability distributions to shield their commercial interests. To
allow third-parties to autonomously inject watermarks into generated text, we
develop a watermarking framework for black-box language model usage scenarios.
Specifically, we first define a binary encoding function to compute a random
binary encoding corresponding to a word. The encodings computed for
non-watermarked text conform to a Bernoulli distribution, wherein the
probability of a word representing bit-1 being approximately 0.5. To inject a
watermark, we alter the distribution by selectively replacing words
representing bit-0 with context-based synonyms that represent bit-1. A
statistical test is then used to identify the watermark. Experiments
demonstrate the effectiveness of our method on both Chinese and English
datasets. Furthermore, results under re-translation, polishing, word deletion,
and synonym substitution attacks reveal that it is arduous to remove the
watermark without compromising the original semantics.",2023-05-14
"ProKnow: Process Knowledge for Safety Constrained and Explainable
  Question Generation for Mental Health Diagnostic Assistance",2023-05-13 21:31:02+00:00,http://arxiv.org/abs/2305.08010v1,"Kaushik Roy, Manas Gaur, Misagh Soltani, Vipula Rawte, Ashwin Kalyan, Amit Sheth",cs.CL,knowledge,"Current Virtual Mental Health Assistants (VMHAs) provide counseling and
suggestive care. They refrain from patient diagnostic assistance because they
lack training in safety-constrained and specialized clinical process knowledge.
In this work, we define Proknow as an ordered set of information that maps to
evidence-based guidelines or categories of conceptual understanding to experts
in a domain. We also introduce a new dataset of diagnostic conversations guided
by safety constraints and Proknow that healthcare professionals use. We develop
a method for natural language question generation (NLG) that collects
diagnostic information from the patient interactively. We demonstrate the
limitations of using state-of-the-art large-scale language models (LMs) on this
dataset. Our algorithm models the process knowledge through explicitly modeling
safety, knowledge capture, and explainability. LMs augmented with ProKnow
guided method generated 89% safer questions in the depression and anxiety
domain. The Explainability of the generated question is assessed by computing
similarity with concepts in depression and anxiety knowledge bases. Overall,
irrespective of the type of LMs augmented with our ProKnow, we achieved an
average 82% improvement over simple pre-trained LMs on safety, explainability,
and process-guided question generation. We qualitatively and quantitatively
evaluate the efficacy of the proposed ProKnow-guided methods by introducing
three new evaluation metrics for safety, explainability, and process knowledge
adherence.",2023-05-13
"Autocorrelations Decay in Texts and Applicability Limits of Language
  Models",2023-05-11 07:23:01+00:00,http://arxiv.org/abs/2305.06615v1,"Nikolay Mikhaylovskiy, Ilya Churilov","cs.CL, I.2.7",knowledge,"We show that the laws of autocorrelations decay in texts are closely related
to applicability limits of language models. Using distributional semantics we
empirically demonstrate that autocorrelations of words in texts decay according
to a power law. We show that distributional semantics provides coherent
autocorrelations decay exponents for texts translated to multiple languages.
The autocorrelations decay in generated texts is quantitatively and often
qualitatively different from the literary texts. We conclude that language
models exhibiting Markov behavior, including large autoregressive language
models, may have limitations when applied to long texts, whether analysis or
generation.",2023-05-11
Long-Tailed Question Answering in an Open World,2023-05-11 04:28:58+00:00,http://arxiv.org/abs/2305.06557v1,"Yi Dai, Hao Lang, Yinhe Zheng, Fei Huang, Yongbin Li","cs.CL, cs.AI, cs.LG",knowledge,"Real-world data often have an open long-tailed distribution, and building a
unified QA model supporting various tasks is vital for practical QA
applications. However, it is non-trivial to extend previous QA approaches since
they either require access to seen tasks of adequate samples or do not
explicitly model samples from unseen tasks. In this paper, we define Open
Long-Tailed QA (OLTQA) as learning from long-tailed distributed data and
optimizing performance over seen and unseen QA tasks. We propose an OLTQA model
that encourages knowledge sharing between head, tail and unseen tasks, and
explicitly mines knowledge from a large pre-trained language model (LM).
Specifically, we organize our model through a pool of fine-grained components
and dynamically combine these components for an input to facilitate knowledge
sharing. A retrieve-then-rerank frame is further introduced to select
in-context examples, which guild the LM to generate text that express knowledge
for QA tasks. Moreover, a two-stage training approach is introduced to
pre-train the framework by knowledge distillation (KD) from the LM and then
jointly train the frame and a QA model through an adaptive mutual KD method. On
a large-scale OLTQA dataset we curate from 43 existing QA datasets, our model
consistently outperforms the state-of-the-art. We release the code and data at
\url{https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/oltqa}.",2023-05-11
"Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text
  Analytics? An Examination on Several Typical Tasks",2023-05-10 03:13:54+00:00,http://arxiv.org/abs/2305.05862v1,"Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, Sameena Shah","cs.CL, cs.AI",knowledge,"The most recent large language models such as ChatGPT and GPT-4 have garnered
significant attention, as they are capable of generating high-quality responses
to human input. Despite the extensive testing of ChatGPT and GPT-4 on generic
text corpora, showcasing their impressive capabilities, a study focusing on
financial corpora has not been conducted. In this study, we aim to bridge this
gap by examining the potential of ChatGPT and GPT-4 as a solver for typical
financial text analytic problems in the zero-shot or few-shot setting.
Specifically, we assess their capabilities on four representative tasks over
five distinct financial textual datasets. The preliminary study shows that
ChatGPT and GPT-4 struggle on tasks such as financial named entity recognition
(NER) and sentiment analysis, where domain-specific knowledge is required,
while they excel in numerical reasoning tasks. We report both the strengths and
limitations of the current versions of ChatGPT and GPT-4, comparing them to the
state-of-the-art finetuned models as well as pretrained domain-specific
generative models. Our experiments provide qualitative studies, through which
we hope to help understand the capability of the existing models and facilitate
further improvements.",2023-05-10
Vārta: A Large-Scale Headline-Generation Dataset for Indic Languages,2023-05-10 03:07:17+00:00,http://arxiv.org/abs/2305.05858v1,"Rahul Aralikatte, Ziling Cheng, Sumanth Doddapaneni, Jackie Chi Kit Cheung",cs.CL,knowledge,"We present V\=arta, a large-scale multilingual dataset for headline
generation in Indic languages. This dataset includes 41.8 million news articles
in 14 different Indic languages (and English), which come from a variety of
high-quality sources. To the best of our knowledge, this is the largest
collection of curated articles for Indic languages currently available. We use
the data collected in a series of experiments to answer important questions
related to Indic NLP and multilinguality research in general. We show that the
dataset is challenging even for state-of-the-art abstractive models and that
they perform only slightly better than extractive baselines. Owing to its size,
we also show that the dataset can be used to pretrain strong language models
that outperform competitive baselines in both NLU and NLG benchmarks.",2023-05-10
"Vision-Language Models in Remote Sensing: Current Progress and Future
  Trends",2023-05-09 19:17:07+00:00,http://arxiv.org/abs/2305.05726v1,"Congcong Wen, Yuan Hu, Xiang Li, Zhenghang Yuan, Xiao Xiang Zhu","cs.CV, cs.AI",knowledge,"The remarkable achievements of ChatGPT and GPT-4 have sparked a wave of
interest and research in the field of large language models for Artificial
General Intelligence (AGI). These models provide us with intelligent solutions
that are more similar to human thinking, enabling us to use general artificial
intelligence to solve problems in various applications. However, in the field
of remote sensing, the scientific literature on the implementation of AGI
remains relatively scant. Existing AI-related research primarily focuses on
visual understanding tasks while neglecting the semantic understanding of the
objects and their relationships. This is where vision-language models excel, as
they enable reasoning about images and their associated textual descriptions,
allowing for a deeper understanding of the underlying semantics.
Vision-language models can go beyond recognizing the objects in an image and
can infer the relationships between them, as well as generate natural language
descriptions of the image. This makes them better suited for tasks that require
both visual and textual understanding, such as image captioning, text-based
image retrieval, and visual question answering. This paper provides a
comprehensive review of the research on vision-language models in remote
sensing, summarizing the latest progress, highlighting the current challenges,
and identifying potential research opportunities. Specifically, we review the
application of vision-language models in several mainstream remote sensing
tasks, including image captioning, text-based image generation, text-based
image retrieval, visual question answering, scene classification, semantic
segmentation, and object detection. For each task, we briefly describe the task
background and review some representative works. Finally, we summarize the
limitations of existing work and provide some possible directions for future
development.",2023-05-09
"Dreams Are More ""Predictable'' Than You Think",2023-05-08 21:24:12+00:00,http://arxiv.org/abs/2305.05054v1,Lorenzo Bertolini,cs.CL,knowledge,"A consistent body of evidence suggests that dream reports significantly vary
from other types of textual transcripts with respect to semantic content.
Furthermore, it appears to be a widespread belief in the dream/sleep research
community that dream reports constitute rather ``unique'' strings of text. This
might be a notable issue for the growing amount of approaches using natural
language processing (NLP) tools to automatically analyse dream reports, as they
largely rely on neural models trained on non-dream corpora scraped from the
web. In this work, I will adopt state-of-the-art (SotA) large language models
(LLMs), to study if and how dream reports deviate from other human-generated
text strings, such as Wikipedia. Results show that, taken as a whole, DreamBank
does not deviate from Wikipedia. Moreover, on average, single dream reports are
significantly more predictable than Wikipedia articles. Preliminary evidence
suggests that word count, gender, and visual impairment can significantly shape
how predictable a dream report can appear to the model.",2023-05-08
"Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive
  Text Generation",2023-05-06 13:20:31+00:00,http://arxiv.org/abs/2305.04044v1,"Kun Zhou, Yifan Li, Wayne Xin Zhao, Ji-Rong Wen",cs.CL,knowledge,"Recently, continuous diffusion models (CDM) have been introduced into
non-autoregressive (NAR) text-to-text generation. However, the discrete nature
of text increases the difficulty of CDM to generate coherent and fluent texts,
and also causes the incompatibility problem between CDM and advanced NLP
techniques, especially the popular pre-trained language models~(PLMs). To solve
it, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM)
into NAR text-to-text generation and integrates BART to improve the
performance. By revising the decoding process of BART and the typical settings
of DDM, we unify the inference process of BART and the denoising process of DDM
into the same NAR masked tokens recovering task. In this way, DDM can rely on
BART to perform denoising, which can benefit from both the rich pre-learned
knowledge of BART and the iterative refining paradigm of DDM. Besides, we also
propose the iterative self-prompting strategy to further improve the generation
quality. Experimental results on 7 datasets show that our approach can
outperform competitive NAR methods, and even surpass autoregressive methods.
Our code and data will be publicly released.",2023-05-06
"Expository Text Generation: Imitate, Retrieve, Paraphrase",2023-05-05 04:26:29+00:00,http://arxiv.org/abs/2305.03276v1,"Nishant Balepur, Jie Huang, Kevin Chen-Chuan Chang",cs.CL,knowledge,"Expository documents are vital resources for conveying complex information to
readers. Despite their usefulness, writing expository documents by hand is a
time-consuming and labor-intensive process that requires knowledge of the
domain of interest, careful content planning, and the ability to synthesize
information from multiple sources. To ease these burdens, we introduce the task
of expository text generation, which seeks to automatically generate an
accurate and informative expository document from a knowledge source. We solve
our task by developing IRP, an iterative framework that overcomes the
limitations of language models and separately tackles the steps of content
planning, fact selection, and rephrasing. Through experiments on three diverse
datasets, we demonstrate that IRP produces high-quality expository documents
that accurately inform readers.",2023-05-05
Stylized Data-to-Text Generation: A Case Study in the E-Commerce Domain,2023-05-05 03:02:41+00:00,http://arxiv.org/abs/2305.03256v1,"Liqiang Jing, Xuemeng Song, Xuming Lin, Zhongzhou Zhao, Wei Zhou, Liqiang Nie",cs.CL,knowledge,"Existing data-to-text generation efforts mainly focus on generating a
coherent text from non-linguistic input data, such as tables and
attribute-value pairs, but overlook that different application scenarios may
require texts of different styles. Inspired by this, we define a new task,
namely stylized data-to-text generation, whose aim is to generate coherent text
for the given non-linguistic data according to a specific style. This task is
non-trivial, due to three challenges: the logic of the generated text,
unstructured style reference, and biased training samples. To address these
challenges, we propose a novel stylized data-to-text generation model, named
StyleD2T, comprising three components: logic planning-enhanced data embedding,
mask-based style embedding, and unbiased stylized text generation. In the first
component, we introduce a graph-guided logic planner for attribute organization
to ensure the logic of generated text. In the second component, we devise
feature-level mask-based style embedding to extract the essential style signal
from the given unstructured style reference. In the last one, pseudo triplet
augmentation is utilized to achieve unbiased text generation, and a
multi-condition based confidence assignment function is designed to ensure the
quality of pseudo samples. Extensive experiments on a newly collected dataset
from Taobao have been conducted, and the results show the superiority of our
model over existing methods.",2023-05-05
"Can LLM Already Serve as A Database Interface? A BIg Bench for
  Large-Scale Database Grounded Text-to-SQLs",2023-05-04 19:02:29+00:00,http://arxiv.org/abs/2305.03111v1,"Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen Li, Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Chenhao Ma, Kevin C. C. Chang, Fei Huang, Reynold Cheng, Yongbin Li",cs.CL,knowledge,"Text-to-SQL parsing, which aims at converting natural language instructions
into executable SQLs, has gained increasing attention in recent years. In
particular, Codex and ChatGPT have shown impressive results in this task.
However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on
database schema with few rows of database contents leaving the gap between
academic study and real-world applications. To mitigate this gap, we present
Bird, a big benchmark for large-scale database grounded in text-to-SQL tasks,
containing 12,751 pairs of text-to-SQL data and 95 databases with a total size
of 33.4 GB, spanning 37 professional domains. Our emphasis on database values
highlights the new challenges of dirty database contents, external knowledge
between NL questions and database contents, and SQL efficiency, particularly in
the context of massive databases. To solve these problems, text-to-SQL models
must feature database value comprehension in addition to semantic parsing. The
experimental results demonstrate the significance of database values in
generating accurate text-to-SQLs for big databases. Furthermore, even the most
effective text-to-SQL models, i.e. ChatGPT, only achieves 40.08% in execution
accuracy, which is still far from the human result of 92.96%, proving that
challenges still stand. Besides, we also provide an efficiency analysis to
offer insights into generating text-to-efficient-SQLs that are beneficial to
industries. We believe that BIRD will contribute to advancing real-world
applications of text-to-SQL research. The leaderboard and source code are
available: https://bird-bench.github.io/.",2023-05-04
"A Systematic Study of Knowledge Distillation for Natural Language
  Generation with Pseudo-Target Training",2023-05-03 10:49:38+00:00,http://arxiv.org/abs/2305.02031v1,"Nitay Calderon, Subhabrata Mukherjee, Roi Reichart, Amir Kantor","cs.CL, cs.AI",knowledge,"Modern Natural Language Generation (NLG) models come with massive
computational and storage requirements. In this work, we study the potential of
compressing them, which is crucial for real-world applications serving millions
of users. We focus on Knowledge Distillation (KD) techniques, in which a small
student model learns to imitate a large teacher model, allowing to transfer
knowledge from the teacher to the student. In contrast to much of the previous
work, our goal is to optimize the model for a specific NLG task and a specific
dataset. Typically, in real-world applications, in addition to labeled data
there is abundant unlabeled task-specific data, which is crucial for attaining
high compression rates via KD. In this work, we conduct a systematic study of
task-specific KD techniques for various NLG tasks under realistic assumptions.
We discuss the special characteristics of NLG distillation and particularly the
exposure bias problem. Following, we derive a family of Pseudo-Target (PT)
augmentation methods, substantially extending prior work on sequence-level KD.
We propose the Joint-Teaching method for NLG distillation, which applies
word-level KD to multiple PTs generated by both the teacher and the student.
Our study provides practical model design observations and demonstrates the
effectiveness of PT training for task-specific KD in NLG.",2023-05-03
The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers,2023-05-02 17:42:37+00:00,http://arxiv.org/abs/2305.01628v1,"Ariel Gera, Roni Friedman, Ofir Arviv, Chulaka Gunasekara, Benjamin Sznajder, Noam Slonim, Eyal Shnarch","cs.CL, cs.LG",knowledge,"Applying language models to natural language processing tasks typically
relies on the representations in the final model layer, as intermediate hidden
layer representations are presumed to be less informative. In this work, we
argue that due to the gradual improvement across model layers, additional
information can be gleaned from the contrast between higher and lower layers
during inference. Specifically, in choosing between the probable next token
predictions of a generative model, the predictions of lower layers can be used
to highlight which candidates are best avoided. We propose a novel approach
that utilizes the contrast between layers to improve text generation outputs,
and show that it mitigates degenerative behaviors of the model in open-ended
generation, significantly improving the quality of generated texts.
Furthermore, our results indicate that contrasting between model layers at
inference time can yield substantial benefits to certain aspects of general
language model capabilities, more effectively extracting knowledge during
inference from a given set of model parameters.",2023-05-02
Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond,2023-04-26 17:52:30+00:00,http://arxiv.org/abs/2304.13712v2,"Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, Xia Hu","cs.CL, cs.AI, cs.LG",knowledge,"This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{https://github.com/Mooler0410/LLMsPracticalGuide}.",2023-04-26
Evaluating Inter-Bilingual Semantic Parsing for Indian Languages,2023-04-25 17:24:32+00:00,http://arxiv.org/abs/2304.13005v1,"Divyanshu Aggarwal, Vivek Gupta, Anoop Kunchukuttan",cs.CL,knowledge,"Despite significant progress in Natural Language Generation for Indian
languages (IndicNLP), there is a lack of datasets around complex structured
tasks such as semantic parsing. One reason for this imminent gap is the
complexity of the logical form, which makes English to multilingual translation
difficult. The process involves alignment of logical forms, intents and slots
with translated unstructured utterance. To address this, we propose an
Inter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct
Indian languages. We highlight the proposed task's practicality, and evaluate
existing multilingual seq2seq models across several train-test strategies. Our
experiment reveals a high correlation across performance of original
multilingual semantic parsing datasets (such as mTOP, multilingual TOP and
multiATIS++) and our proposed IE-SEMPARSE suite.",2023-04-25
Divide and Prompt: Chain of Thought Prompting for Text-to-SQL,2023-04-23 06:52:35+00:00,http://arxiv.org/abs/2304.11556v1,"Xiping Liu, Zhao Tan","cs.CL, cs.AI",knowledge,"Chain-of-thought (CoT) prompting combined with large language models (LLMs)
have achieved encouraging results on complex reasoning tasks. Text-to-SQL is a
critical semantic parsing task that converts natural language questions into
SQL statements, involving a complex reasoning process. However, there is little
work about using CoT prompting to activate LLM's reasoning capabilities on
Text-to-SQL tasks. In this work, we propose a new paradigm for prompting
Text-to-SQL tasks, called Divide-and-Prompt, which first divides the task into
subtasks, and then approach each subtask through CoT. We present 3
prompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments
show that these prompts guide LLMs to generate Text-to-SQL with higher
execution accuracy.",2023-04-23
Translationese Reduction using Abstract Meaning Representation,2023-04-23 00:04:14+00:00,http://arxiv.org/abs/2304.11501v1,"Shira Wein, Nathan Schneider",cs.CL,knowledge,"Translated texts or utterances bear several hallmarks distinct from texts
originating in the language. This phenomenon, known as translationese, is
well-documented, and when found in training or test sets can affect model
performance. Still, work to mitigate the effect of translationese in human
translated text is understudied. We hypothesize that Abstract Meaning
Representation (AMR), a semantic representation which abstracts away from the
surface form, can be used as an interlingua to reduce the amount of
translationese in translated texts. By parsing English translations into an AMR
graph and then generating text from that AMR, we obtain texts that more closely
resemble non-translationese by macro-level measures. We show that across four
metrics, and qualitatively, using AMR as an interlingua enables the reduction
of translationese and we compare our results to two additional approaches: one
based on round-trip machine translation and one based on syntactically
controlled generation.",2023-04-23
"GeneGPT: Augmenting Large Language Models with Domain Tools for Improved
  Access to Biomedical Information",2023-04-19 13:53:19+00:00,http://arxiv.org/abs/2304.09667v2,"Qiao Jin, Yifan Yang, Qingyu Chen, Zhiyong Lu","cs.CL, cs.AI, q-bio.GN",knowledge,"While large language models (LLMs) have been successfully applied to various
tasks, they still face challenges with hallucinations and generating erroneous
content. Augmenting LLMs with domain-specific tools such as database utilities
has the potential to facilitate more precise and straightforward access to
specialized knowledge. In this paper, we present GeneGPT, a novel method for
teaching LLMs to use the Web Application Programming Interfaces (APIs) of the
National Center for Biotechnology Information (NCBI) and answer genomics
questions. Specifically, we prompt Codex (code-davinci-002) to solve the
GeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations
for in-context learning. During inference, we stop the decoding once a call
request is detected and make the API call with the generated URL. We then
append the raw execution results returned by NCBI APIs to the generated texts
and continue the generation until the answer is found or another API call is
detected. Our preliminary results show that GeneGPT achieves state-of-the-art
results on three out of four one-shot tasks and four out of five zero-shot
tasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average
score of 0.76, which is much higher than retrieval-augmented LLMs such as the
New Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as
well as other LLMs such as GPT-3 (0.16) and ChatGPT (0.12).",2023-04-19
"ArguGPT: evaluating, understanding and identifying argumentative essays
  generated by GPT models",2023-04-16 01:50:26+00:00,http://arxiv.org/abs/2304.07666v1,"Yikang Liu, Ziyin Zhang, Wanyang Zhang, Shisen Yue, Xiaojing Zhao, Xinyuan Cheng, Yiwen Zhang, Hai Hu",cs.CL,knowledge,"AI generated content (AIGC) presents considerable challenge to educators
around the world. Instructors need to be able to detect such text generated by
large language models, either with the naked eye or with the help of some
tools. There is also growing need to understand the lexical, syntactic and
stylistic features of AIGC. To address these challenges in English language
teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative
essays generated by 7 GPT models in response to essay prompts from three
sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing
tasks. Machine-generated texts are paired with roughly equal number of
human-written essays with three score levels matched in essay prompts. We then
hire English instructors to distinguish machine essays from human ones. Results
show that when first exposed to machine-generated essays, the instructors only
have an accuracy of 61% in detecting them. But the number rises to 67% after
one round of minimal self-training. Next, we perform linguistic analyses of
these essays, which show that machines produce sentences with more complex
syntactic structures while human essays tend to be lexically more complex.
Finally, we test existing AIGC detectors and build our own detectors using SVMs
and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of
ArguGPT achieves above 90% accuracy in both essay- and sentence-level
classification. To the best of our knowledge, this is the first comprehensive
analysis of argumentative essays produced by generative large language models.
Machine-authored essays in ArguGPT and our models will be made publicly
available at https://github.com/huhailinguist/ArguGPT",2023-04-16
"Shall We Pretrain Autoregressive Language Models with Retrieval? A
  Comprehensive Study",2023-04-13 18:04:19+00:00,http://arxiv.org/abs/2304.06762v1,"Boxin Wang, Wei Ping, Peng Xu, Lawrence McAfee, Zihan Liu, Mohammad Shoeybi, Yi Dong, Oleksii Kuchaiev, Bo Li, Chaowei Xiao, Anima Anandkumar, Bryan Catanzaro","cs.CL, cs.AI, cs.IR, cs.LG",knowledge,"Large decoder-only language models (LMs) can be largely improved in terms of
perplexity by retrieval (e.g., RETRO), but its impact on text generation
quality and downstream task accuracy is unclear. Thus, it is still an open
question: shall we pretrain large autoregressive LMs with retrieval? To answer
it, we perform a comprehensive study on a scalable pre-trained
retrieval-augmented LM (i.e., RETRO) compared with standard GPT and
retrieval-augmented GPT incorporated at fine-tuning or inference stages. We
first provide the recipe to reproduce RETRO up to 9.5B parameters while
retrieving a text corpus with 330B tokens. Based on that, we have the following
novel findings: i) RETRO outperforms GPT on text generation with much less
degeneration (i.e., repetition), moderately higher factual accuracy, and
slightly lower toxicity with a nontoxic retrieval database. ii) On the LM
Evaluation Harness benchmark, RETRO largely outperforms GPT on
knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,
we introduce a simple variant of the model, RETRO++, which largely improves
open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural
Question) and significantly outperforms retrieval-augmented GPT across
different model sizes. Our findings highlight the promising direction of
pretraining autoregressive LMs with retrieval as future foundation models. We
release our implementation at: https://github.com/NVIDIA/Megatron-LM#retro",2023-04-13
Training Large Language Models Efficiently with Sparsity and Dataflow,2023-04-11 21:37:13+00:00,http://arxiv.org/abs/2304.05511v1,"Venkat Srinivasan, Darshan Gandhi, Urmish Thakker, Raghu Prabhakar",cs.LG,knowledge,"Large foundation language models have shown their versatility in being able
to be adapted to perform a wide variety of downstream tasks, such as text
generation, sentiment analysis, semantic search etc. However, training such
large foundational models is a non-trivial exercise that requires a significant
amount of compute power and expertise from machine learning and systems
experts. As models get larger, these demands are only increasing. Sparsity is a
promising technique to relieve the compute requirements for training. However,
sparsity introduces new challenges in training the sparse model to the same
quality as the dense counterparts. Furthermore, sparsity drops the operation
intensity and introduces irregular memory access patterns that makes it
challenging to efficiently utilize compute resources. This paper demonstrates
an end-to-end training flow on a large language model - 13 billion GPT - using
sparsity and dataflow. The dataflow execution model and architecture enables
efficient on-chip irregular memory accesses as well as native kernel fusion and
pipelined parallelism that helps recover device utilization. We show that we
can successfully train GPT 13B to the same quality as the dense GPT 13B model,
while achieving an end-end speedup of 4.5x over dense A100 baseline.",2023-04-11
"To ChatGPT, or not to ChatGPT: That is the question!",2023-04-04 03:04:28+00:00,http://arxiv.org/abs/2304.01487v2,"Alessandro Pegoraro, Kavita Kumari, Hossein Fereidooni, Ahmad-Reza Sadeghi","cs.LG, cs.AI, cs.CL",knowledge,"ChatGPT has become a global sensation. As ChatGPT and other Large Language
Models (LLMs) emerge, concerns of misusing them in various ways increase, such
as disseminating fake news, plagiarism, manipulating public opinion, cheating,
and fraud. Hence, distinguishing AI-generated from human-generated becomes
increasingly essential. Researchers have proposed various detection
methodologies, ranging from basic binary classifiers to more complex
deep-learning models. Some detection techniques rely on statistical
characteristics or syntactic patterns, while others incorporate semantic or
contextual information to improve accuracy. The primary objective of this study
is to provide a comprehensive and contemporary assessment of the most recent
techniques in ChatGPT detection. Additionally, we evaluated other AI-generated
text detection tools that do not specifically claim to detect ChatGPT-generated
content to assess their performance in detecting ChatGPT-generated content. For
our evaluation, we have curated a benchmark dataset consisting of prompts from
ChatGPT and humans, including diverse questions from medical, open Q&A, and
finance domains and user-generated responses from popular social networking
platforms. The dataset serves as a reference to assess the performance of
various techniques in detecting ChatGPT-generated content. Our evaluation
results demonstrate that none of the existing methods can effectively detect
ChatGPT-generated content.",2023-04-04
Measuring and Manipulating Knowledge Representations in Language Models,2023-04-03 06:24:10+00:00,http://arxiv.org/abs/2304.00740v1,"Evan Hernandez, Belinda Z. Li, Jacob Andreas",cs.CL,knowledge,"Neural language models (LMs) represent facts about the world described by
text. Sometimes these facts derive from training data (in most LMs, a
representation of the word banana encodes the fact that bananas are fruits).
Sometimes facts derive from input text itself (a representation of the sentence
""I poured out the bottle"" encodes the fact that the bottle became empty). Tools
for inspecting and modifying LM fact representations would be useful almost
everywhere LMs are used: making it possible to update them when the world
changes, to localize and remove sources of bias, and to identify errors in
generated text. We describe REMEDI, an approach for querying and modifying
factual knowledge in LMs. REMEDI learns a map from textual queries to fact
encodings in an LM's internal representation system. These encodings can be
used as knowledge editors: by adding them to LM hidden representations, we can
modify downstream generation to be consistent with new facts. REMEDI encodings
can also be used as model probes: by comparing them to LM representations, we
can ascertain what properties LMs attribute to mentioned entities, and predict
when they will generate outputs that conflict with background knowledge or
input text. REMEDI thus links work on probing, prompting, and model editing,
and offers steps toward general tools for fine-grained inspection and control
of knowledge in LMs.",2023-04-03
Assessing Language Model Deployment with Risk Cards,2023-03-31 16:45:42+00:00,http://arxiv.org/abs/2303.18190v1,"Leon Derczynski, Hannah Rose Kirk, Vidhisha Balachandran, Sachin Kumar, Yulia Tsvetkov, M. R. Leiser, Saif Mohammad",cs.CL,knowledge,"This paper introduces RiskCards, a framework for structured assessment and
documentation of risks associated with an application of language models. As
with all language, text generated by language models can be harmful, or used to
bring about harm. Automating language generation adds both an element of scale
and also more subtle or emergent undesirable tendencies to the generated text.
Prior work establishes a wide variety of language model harms to many different
actors: existing taxonomies identify categories of harms posed by language
models; benchmarks establish automated tests of these harms; and documentation
standards for models, tasks and datasets encourage transparent reporting.
However, there is no risk-centric framework for documenting the complexity of a
landscape in which some risks are shared across models and contexts, while
others are specific, and where certain conditions may be required for risks to
manifest as harms. RiskCards address this methodological gap by providing a
generic framework for assessing the use of a given language model in a given
scenario. Each RiskCard makes clear the routes for the risk to manifest harm,
their placement in harm taxonomies, and example prompt-output pairs. While
RiskCards are designed to be open-source, dynamic and participatory, we present
a ""starter set"" of RiskCards taken from a broad literature survey, each of
which details a concrete risk presentation. Language model RiskCards initiate a
community knowledge base which permits the mapping of risks and harms to a
specific model or its application scenario, ultimately contributing to a
better, safer and shared understanding of the risk landscape.",2023-03-31
"ChatGPT or academic scientist? Distinguishing authorship with over 99%
  accuracy using off-the-shelf machine learning tools",2023-03-28 23:16:00+00:00,http://arxiv.org/abs/2303.16352v1,"Heather Desaire, Aleesa E. Chua, Madeline Isom, Romana Jarosova, David Hua","cs.LG, cs.CL",knowledge,"ChatGPT has enabled access to AI-generated writing for the masses, and within
just a few months, this product has disrupted the knowledge economy, initiating
a culture shift in the way people work, learn, and write. The need to
discriminate human writing from AI is now both critical and urgent,
particularly in domains like higher education and academic writing, where AI
had not been a significant threat or contributor to authorship. Addressing this
need, we developed a method for discriminating text generated by ChatGPT from
(human) academic scientists, relying on prevalent and accessible supervised
classification methods. We focused on how a particular group of humans,
academic scientists, write differently than ChatGPT, and this targeted approach
led to the discovery of new features for discriminating (these) humans from AI;
as examples, scientists write long paragraphs and have a penchant for equivocal
language, frequently using words like but, however, and although. With a set of
20 features, including the aforementioned ones and others, we built a model
that assigned the author, as human or AI, at well over 99% accuracy, resulting
in 20 times fewer misclassified documents compared to the field-leading
approach. This strategy for discriminating a particular set of humans writing
from AI could be further adapted and developed by others with basic skills in
supervised classification, enabling access to many highly accurate and targeted
models for detecting AI usage in academic writing and beyond.",2023-03-28
On Codex Prompt Engineering for OCL Generation: An Empirical Study,2023-03-28 18:50:51+00:00,http://arxiv.org/abs/2303.16244v1,"Seif Abukhalaf, Mohammad Hamdaqa, Foutse Khomh","cs.SE, cs.AI",knowledge,"The Object Constraint Language (OCL) is a declarative language that adds
constraints and object query expressions to MOF models. Despite its potential
to provide precision and conciseness to UML models, the unfamiliar syntax of
OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have
shown their capability in many NLP tasks, including semantic parsing and text
generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly
available code from GitHub and can generate code in many programming languages.
We investigate the reliability of OCL constraints generated by Codex from
natural language specifications. To achieve this, we compiled a dataset of 15
UML models and 168 specifications and crafted a prompt template with slots to
populate with UML information and the target task, using both zero- and
few-shot learning methods. By measuring the syntactic validity and execution
accuracy metrics of the generated OCL constraints, we found that enriching the
prompts with UML information and enabling few-shot learning increases the
reliability of the generated OCL constraints. Furthermore, the results reveal a
close similarity based on sentence embedding between the generated OCL
constraints and the human-written ones in the ground truth, implying a level of
clarity and understandability in the generated OCL constraints by Codex.",2023-03-28
"Large Language Models are Diverse Role-Players for Summarization
  Evaluation",2023-03-27 10:40:59+00:00,http://arxiv.org/abs/2303.15078v2,"Ning Wu, Ming Gong, Linjun Shou, Shining Liang, Daxin Jiang",cs.CL,knowledge,"Text summarization has a wide range of applications in many scenarios. The
evaluation of the quality of the generated text is a complex problem. A big
challenge to language evaluation is that there is a clear divergence between
existing metrics and human evaluation. For example, the quality of a document
summary can be measured by human annotators from both objective aspects, such
as grammatical and semantic correctness, as well as subjective dimensions, such
as comprehensiveness, succinctness, and interestingness. Most of the automatic
evaluation methods like BLUE/ROUGE may be not able to capture the above
dimensions well. In this paper, we propose a new evaluation framework based on
LLMs, which provides a comprehensive evaluation framework by comparing
generated text and reference text from both objective and subjective aspects.
First, we propose to model objective and subjective dimensions of generated
text based on roleplayers prompting mechanism. Furthermore, we introduce a
context-based prompting mechanism that is able to generate dynamic roleplayer
profiles based on input context. Finally, we design a multi-roleplayer
prompting technology based on batch prompting to integrate multiple evaluation
results into evaluation results. Experimental results on two real datasets for
summarization show that our model is highly competitive and has a very high
consistency with human annotators.",2023-03-27
Paraphrase Detection: Human vs. Machine Content,2023-03-24 13:25:46+00:00,http://arxiv.org/abs/2303.13989v1,"Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp","cs.CL, cs.AI",knowledge,"The growing prominence of large language models, such as GPT-4 and ChatGPT,
has led to increased concerns over academic integrity due to the potential for
machine-generated content and paraphrasing. Although studies have explored the
detection of human- and machine-paraphrased content, the comparison between
these types of content remains underexplored. In this paper, we conduct a
comprehensive analysis of various datasets commonly employed for paraphrase
detection tasks and evaluate an array of detection methods. Our findings
highlight the strengths and limitations of different detection methods in terms
of performance on individual datasets, revealing a lack of suitable
machine-generated datasets that can be aligned with human expectations. Our
main finding is that human-authored paraphrases exceed machine-generated ones
in terms of difficulty, diversity, and similarity implying that automatically
generated texts are not yet on par with human-level performance. Transformers
emerged as the most effective method across datasets with TF-IDF excelling on
semantically diverse corpora. Additionally, we identify four datasets as the
most diverse and challenging for paraphrase detection.",2023-03-24
CoBIT: A Contrastive Bi-directional Image-Text Generation Model,2023-03-23 17:24:31+00:00,http://arxiv.org/abs/2303.13455v1,"Haoxuan You, Mandy Guo, Zhecan Wang, Kai-Wei Chang, Jason Baldridge, Jiahui Yu","cs.CV, cs.CL",knowledge,"The field of vision and language has witnessed a proliferation of pre-trained
foundation models. Most existing methods are independently pre-trained with
contrastive objective like CLIP, image-to-text generative objective like PaLI,
or text-to-image generative objective like Parti. However, the three objectives
can be pre-trained on the same data, image-text pairs, and intuitively they
complement each other as contrasting provides global alignment capacity and
generation grants fine-grained understanding. In this work, we present a
Contrastive Bi-directional Image-Text generation model (CoBIT), which attempts
to unify the three pre-training objectives in one framework. Specifically,
CoBIT employs a novel unicoder-decoder structure, consisting of an image
unicoder, a text unicoder and a cross-modal decoder. The image/text unicoders
can switch between encoding and decoding in different tasks, enabling
flexibility and shared knowledge that benefits both image-to-text and
text-to-image generations. CoBIT achieves superior performance in image
understanding, image-text understanding (Retrieval, Captioning, VQA, SNLI-VE)
and text-based content creation, particularly in zero-shot scenarios. For
instance, 82.7% in zero-shot ImageNet classification, 9.37 FID score in
zero-shot text-to-image generation and 44.8 CIDEr in zero-shot captioning.",2023-03-23
"Paraphrasing evades detectors of AI-generated text, but retrieval is an
  effective defense",2023-03-23 16:29:27+00:00,http://arxiv.org/abs/2303.13408v1,"Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, Mohit Iyyer","cs.CL, cs.CR, cs.LG",knowledge,"To detect the deployment of large language models for malicious use cases
(e.g., fake content creation or academic plagiarism), several approaches have
recently been proposed for identifying AI-generated text via watermarks or
statistical irregularities. How robust are these detection algorithms to
paraphrases of AI-generated text? To stress test these detectors, we first
train an 11B parameter paraphrase generation model (DIPPER) that can paraphrase
paragraphs, optionally leveraging surrounding text (e.g., user-written prompts)
as context. DIPPER also uses scalar knobs to control the amount of lexical
diversity and reordering in the paraphrases. Paraphrasing text generated by
three large language models (including GPT3.5-davinci-003) with DIPPER
successfully evades several detectors, including watermarking, GPTZero,
DetectGPT, and OpenAI's text classifier. For example, DIPPER drops the
detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false
positive rate of 1%), without appreciably modifying the input semantics. To
increase the robustness of AI-generated text detection to paraphrase attacks,
we introduce a simple defense that relies on retrieving semantically-similar
generations and must be maintained by a language model API provider. Given a
candidate text, our algorithm searches a database of sequences previously
generated by the API, looking for sequences that match the candidate text
within a certain threshold. We empirically verify our defense using a database
of 15M generations from a fine-tuned T5-XXL model and find that it can detect
80% to 97% of paraphrased generations across different settings, while only
classifying 1% of human-written sequences as AI-generated. We will open source
our code, model and data for future research.",2023-03-23
Compositional Zero-Shot Domain Transfer with Text-to-Text Models,2023-03-23 15:58:41+00:00,http://arxiv.org/abs/2303.13386v1,"Fangyu Liu, Qianchu Liu, Shruthi Bannur, Fernando Pérez-García, Naoto Usuyama, Sheng Zhang, Tristan Naumann, Aditya Nori, Hoifung Poon, Javier Alvarez-Valle, Ozan Oktay, Stephanie L. Hyland","cs.CL, cs.LG",knowledge,"Label scarcity is a bottleneck for improving task performance in specialised
domains. We propose a novel compositional transfer learning framework (DoT5 -
domain compositional zero-shot T5) for zero-shot domain transfer. Without
access to in-domain labels, DoT5 jointly learns domain knowledge (from MLM of
unlabelled in-domain free text) and task knowledge (from task training on more
readily available general-domain data) in a multi-task manner. To improve the
transferability of task training, we design a strategy named NLGU: we
simultaneously train NLG for in-domain label-to-data generation which enables
data augmentation for self-finetuning and NLU for label prediction. We evaluate
DoT5 on the biomedical domain and the resource-lean subdomain of radiology,
focusing on NLI, text summarisation and embedding learning. DoT5 demonstrates
the effectiveness of compositional transfer learning through multi-task
learning. In particular, DoT5 outperforms the current SOTA in zero-shot
transfer by over 7 absolute points in accuracy on RadNLI. We validate DoT5 with
ablations and a case study demonstrating its ability to solve challenging NLI
examples requiring in-domain expertise.",2023-03-23
Language Model Behavior: A Comprehensive Survey,2023-03-20 23:54:26+00:00,http://arxiv.org/abs/2303.11504v1,"Tyler A. Chang, Benjamin K. Bergen",cs.CL,knowledge,"Transformer language models have received widespread public attention, yet
their generated text is often surprising even to NLP researchers. In this
survey, we discuss over 250 recent studies of English language model behavior
before task-specific fine-tuning. Language models possess basic capabilities in
syntax, semantics, pragmatics, world knowledge, and reasoning, but these
capabilities are sensitive to specific inputs and surface features. Despite
dramatic increases in generated text quality as models scale to hundreds of
billions of parameters, the models are still prone to unfactual responses,
commonsense errors, memorized text, and social biases. Many of these weaknesses
can be framed as over-generalizations or under-generalizations of learned
patterns in text. We synthesize recent results to highlight what is currently
known about what large language models can and cannot do.",2023-03-20
"SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language
  Models",2023-03-18 17:56:01+00:00,http://arxiv.org/abs/2303.10464v1,"Vithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin Leong, Dennis DeCoste, Sean Lie, Shreyas Saxena","cs.LG, cs.CL",knowledge,"The pre-training and fine-tuning paradigm has contributed to a number of
breakthroughs in Natural Language Processing (NLP). Instead of directly
training on a downstream task, language models are first pre-trained on large
datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then
fine-tuned on task-specific data (e.g., natural language generation, text
summarization, etc.). Scaling the model and dataset size has helped improve the
performance of LLMs, but unfortunately, this also leads to highly prohibitive
computational costs. Pre-training LLMs often require orders of magnitude more
FLOPs than fine-tuning and the model capacity often remains the same between
the two phases. To achieve training efficiency w.r.t training FLOPs, we propose
to decouple the model capacity between the two phases and introduce Sparse
Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits
of using unstructured weight sparsity to train only a subset of weights during
pre-training (Sparse Pre-training) and then recover the representational
capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We
demonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3
XL model resulting in a 2.5x reduction in pre-training FLOPs, without a
significant loss in accuracy on the downstream tasks relative to the dense
baseline. By rigorously evaluating multiple downstream tasks, we also establish
a relationship between sparsity, task complexity, and dataset size. Our work
presents a promising direction to train large GPT models at a fraction of the
training FLOPs using weight sparsity while retaining the benefits of
pre-trained textual representations for downstream tasks.",2023-03-18
Input-length-shortening and text generation via attention values,2023-03-14 02:11:24+00:00,http://arxiv.org/abs/2303.07585v1,"Neşet Özkan Tan, Alex Yuxuan Peng, Joshua Bensemann, Qiming Bao, Tim Hartill, Mark Gahegan, Michael Witbrock",cs.CL,knowledge,"Identifying words that impact a task's performance more than others is a
challenge in natural language processing. Transformers models have recently
addressed this issue by incorporating an attention mechanism that assigns
greater attention (i.e., relevance) scores to some words than others. Because
of the attention mechanism's high computational cost, transformer models
usually have an input-length limitation caused by hardware constraints. This
limitation applies to many transformers, including the well-known bidirectional
encoder representations of the transformer (BERT) model. In this paper, we
examined BERT's attention assignment mechanism, focusing on two questions: (1)
How can attention be employed to reduce input length? (2) How can attention be
used as a control mechanism for conditional text generation? We investigated
these questions in the context of a text classification task. We discovered
that BERT's early layers assign more critical attention scores for text
classification tasks compared to later layers. We demonstrated that the first
layer's attention sums could be used to filter tokens in a given sequence,
considerably decreasing the input length while maintaining good test accuracy.
We also applied filtering, which uses a compute-efficient semantic similarities
algorithm, and discovered that retaining approximately 6\% of the original
sequence is sufficient to obtain 86.5\% accuracy. Finally, we showed that we
could generate data in a stable manner and indistinguishable from the original
one by only using a small percentage (10\%) of the tokens with high attention
scores according to BERT's first layer.",2023-03-14
Transformer-based Planning for Symbolic Regression,2023-03-13 03:29:58+00:00,http://arxiv.org/abs/2303.06833v1,"Parshin Shojaee, Kazem Meidani, Amir Barati Farimani, Chandan K. Reddy","cs.LG, cs.AI",knowledge,"Symbolic regression (SR) is a challenging task in machine learning that
involves finding a mathematical expression for a function based on its values.
Recent advancements in SR have demonstrated the efficacy of pretrained
transformer-based models for generating equations as sequences, which benefit
from large-scale pretraining on synthetic datasets and offer considerable
advantages over GP-based methods in terms of inference time. However, these
models focus on supervised pretraining goals borrowed from text generation and
ignore equation-specific objectives like accuracy and complexity. To address
this, we propose TPSR, a Transformer-based Planning strategy for Symbolic
Regression that incorporates Monte Carlo Tree Search into the transformer
decoding process. TPSR, as opposed to conventional decoding strategies, allows
for the integration of non-differentiable feedback, such as fitting accuracy
and complexity, as external sources of knowledge into the equation generation
process. Extensive experiments on various datasets show that our approach
outperforms state-of-the-art methods, enhancing the model's fitting-complexity
trade-off, extrapolation abilities, and robustness to noise. We also
demonstrate that the utilization of various caching mechanisms can further
enhance the efficiency of TPSR.",2023-03-13
"Large Language Models as Zero-Shot Human Models for Human-Robot
  Interaction",2023-03-06 23:16:24+00:00,http://arxiv.org/abs/2303.03548v1,"Bowen Zhang, Harold Soh","cs.RO, cs.CL, cs.HC, cs.LG",knowledge,"Human models play a crucial role in human-robot interaction (HRI), enabling
robots to consider the impact of their actions on people and plan their
behavior accordingly. However, crafting good human models is challenging;
capturing context-dependent human behavior requires significant prior knowledge
and/or large amounts of interaction data, both of which are difficult to
obtain. In this work, we explore the potential of large-language models (LLMs)
-- which have consumed vast amounts of human-generated text data -- to act as
zero-shot human models for HRI. Our experiments on three social datasets yield
promising results; the LLMs are able to achieve performance comparable to
purpose-built models. That said, we also discuss current limitations, such as
sensitivity to prompts and spatial/numerical reasoning mishaps. Based on our
findings, we demonstrate how LLM-based human models can be integrated into a
social robot's planning process and applied in HRI scenarios. Specifically, we
present one case study on a simulated trust-based table-clearing task and
replicate past results that relied on custom models. Next, we conduct a new
robot utensil-passing experiment (n = 65) where preliminary results show that
planning with a LLM-based human model can achieve gains over a basic myopic
plan. In summary, our results show that LLMs offer a promising (but incomplete)
approach to human modeling for HRI.",2023-03-06
A Universal Question-Answering Platform for Knowledge Graphs,2023-03-01 15:35:32+00:00,http://arxiv.org/abs/2303.00595v1,"Reham Omar, Ishika Dhall, Panos Kalnis, Essam Mansour","cs.AI, cs.CL, cs.DB",knowledge,"Knowledge from diverse application domains is organized as knowledge graphs
(KGs) that are stored in RDF engines accessible in the web via SPARQL
endpoints. Expressing a well-formed SPARQL query requires information about the
graph structure and the exact URIs of its components, which is impractical for
the average user. Question answering (QA) systems assist by translating natural
language questions to SPARQL. Existing QA systems are typically based on
application-specific human-curated rules, or require prior information,
expensive pre-processing and model adaptation for each targeted KG. Therefore,
they are hard to generalize to a broad set of applications and KGs.
  In this paper, we propose KGQAn, a universal QA system that does not need to
be tailored to each target KG. Instead of curated rules, KGQAn introduces a
novel formalization of question understanding as a text generation problem to
convert a question into an intermediate abstract representation via a neural
sequence-to-sequence model. We also develop a just-in-time linker that maps at
query time the abstract representation to a SPARQL query for a specific KG,
using only the publicly accessible APIs and the existing indices of the RDF
store, without requiring any pre-processing. Our experiments with several real
KGs demonstrate that KGQAn is easily deployed and outperforms by a large margin
the state-of-the-art in terms of quality of answers and processing time,
especially for arbitrary KGs, unseen during the training.",2023-03-01
Inseq: An Interpretability Toolkit for Sequence Generation Models,2023-02-27 16:45:50+00:00,http://arxiv.org/abs/2302.13942v1,"Gabriele Sarti, Nils Feldhus, Ludwig Sickert, Oskar van der Wal","cs.CL, cs.AI, cs.HC, cs.LG",knowledge,"Past work in natural language processing interpretability focused mainly on
popular classification tasks while largely overlooking generation settings,
partly due to a lack of dedicated tools. In this work, we introduce Inseq, a
Python library to democratize access to interpretability analyses of sequence
generation models. Inseq enables intuitive and optimized extraction of models'
internal information and feature importance scores for popular decoder-only and
encoder-decoder Transformers architectures. We showcase its potential by
adopting it to highlight gender biases in machine translation models and locate
factual knowledge inside GPT-2. Thanks to its extensible interface supporting
cutting-edge techniques such as contrastive feature attribution, Inseq can
drive future advances in explainable natural language generation, centralizing
good practices and enabling fair and reproducible model evaluations.",2023-02-27
"Toward Fairness in Text Generation via Mutual Information Minimization
  based on Importance Sampling",2023-02-25 18:29:02+00:00,http://arxiv.org/abs/2302.13136v1,"Rui Wang, Pengyu Cheng, Ricardo Henao","cs.CL, cs.AI",knowledge,"Pretrained language models (PLMs), such as GPT2, have achieved remarkable
empirical performance in text generation tasks. However, pretrained on
large-scale natural language corpora, the generated text from PLMs may exhibit
social bias against disadvantaged demographic groups. To improve the fairness
of PLMs in text generation, we propose to minimize the mutual information
between the semantics in the generated text sentences and their demographic
polarity, i.e., the demographic group to which the sentence is referring. In
this way, the mentioning of a demographic group (e.g., male or female) is
encouraged to be independent from how it is described in the generated text,
thus effectively alleviating the social bias. Moreover, we propose to
efficiently estimate the upper bound of the above mutual information via
importance sampling, leveraging a natural language corpus. We also propose a
distillation mechanism that preserves the language modeling ability of the PLMs
after debiasing. Empirical results on real-world benchmarks demonstrate that
the proposed method yields superior performance in term of both fairness and
language modeling ability.",2023-02-25
Few-Shot Table-to-Text Generation with Prompt-based Adapter,2023-02-24 05:48:53+00:00,http://arxiv.org/abs/2302.12468v1,"Zhixin Guo, Minyxuan Yan, Jiexing Qi, Jianping Zhou, Ziwei He, Zhouhan Lin, Guanjie Zheng, Xinbing Wang",cs.CL,knowledge,"Pre-trained language models (PLMs) have made remarkable progress in
table-to-text generation tasks. However, the topological gap between tabular
data and text and the lack of domain-specific knowledge make it difficult for
PLMs to produce faithful text, especially in real-world applications with
limited resources. In this paper, we mitigate the above challenges by
introducing a novel augmentation method: Prompt-based Adapter (PA), which
targets table-to-text generation under few-shot conditions. The core insight
design of the PA is to inject prompt templates for augmenting domain-specific
knowledge and table-related representations into the model for bridging the
structural gap between tabular data and descriptions through adapters. Such
prompt-based knowledge augmentation method brings at least two benefits: (1)
enables us to fully use the large amounts of unlabelled domain-specific
knowledge, which can alleviate the PLMs' inherent shortcomings of lacking
domain knowledge; (2) allows us to design different types of tasks supporting
the generative challenge. Extensive experiments and analyses are conducted on
three open-domain few-shot NLG datasets: Humans, Books, and Songs. Compared to
previous state-of-the-art approaches, our model achieves superior performance
in terms of both fluency and accuracy as judged by human and automatic
evaluations.",2023-02-24
How Does In-Context Learning Help Prompt Tuning?,2023-02-22 17:45:12+00:00,http://arxiv.org/abs/2302.11521v1,"Simeng Sun, Yang Liu, Dan Iter, Chenguang Zhu, Mohit Iyyer",cs.CL,knowledge,"Fine-tuning large language models is becoming ever more impractical due to
their rapidly-growing scale. This motivates the use of parameter-efficient
adaptation methods such as prompt tuning (PT), which adds a small number of
tunable embeddings to an otherwise frozen model, and in-context learning (ICL),
in which demonstrations of the task are provided to the model in natural
language without any additional training. Recently, Singhal et al. (2022)
propose ``instruction prompt tuning'' (IPT), which combines PT with ICL by
concatenating a natural language demonstration with learned prompt embeddings.
While all of these methods have proven effective on different tasks, how they
interact with each other remains unexplored. In this paper, we empirically
study when and how in-context examples improve prompt tuning by measuring the
effectiveness of ICL, PT, and IPT on five text generation tasks with multiple
base language models. We observe that (1) IPT does \emph{not} always outperform
PT, and in fact requires the in-context demonstration to be semantically
similar to the test input to yield improvements; (2) PT is unstable and
exhibits high variance, but combining PT and ICL (into IPT) consistently
reduces variance across all five tasks; and (3) prompts learned for a specific
source task via PT exhibit positive transfer when paired with in-context
examples of a different target task. Our results offer actionable insights on
choosing a suitable parameter-efficient adaptation method for a given task.",2023-02-22
KILM: Knowledge Injection into Encoder-Decoder Language Models,2023-02-17 22:48:07+00:00,http://arxiv.org/abs/2302.09170v1,"Yan Xu, Mahdi Namazifar, Devamanyu Hazarika, Aishwarya Padmakumar, Yang Liu, Dilek Hakkani-Tür","cs.CL, cs.AI",knowledge,"Large pre-trained language models (PLMs) have been shown to retain implicit
knowledge within their parameters. To enhance this implicit knowledge, we
propose Knowledge Injection into Language Models (KILM), a novel approach that
injects entity-related knowledge into encoder-decoder PLMs, via a generative
knowledge infilling objective through continued pre-training. This is done
without architectural modifications to the PLMs or adding additional
parameters. Experimental results over a suite of knowledge-intensive tasks
spanning numerous datasets show that KILM enables models to retain more
knowledge and hallucinate less, while preserving their original performance on
general NLU and NLG tasks. KILM also demonstrates improved zero-shot
performances on tasks such as entity disambiguation, outperforming
state-of-the-art models having 30x more parameters.",2023-02-17
Do We Still Need Clinical Language Models?,2023-02-16 05:08:34+00:00,http://arxiv.org/abs/2302.08091v1,"Eric Lehman, Evan Hernandez, Diwakar Mahajan, Jonas Wulff, Micah J. Smith, Zachary Ziegler, Daniel Nadler, Peter Szolovits, Alistair Johnson, Emily Alsentzer",cs.CL,knowledge,"Although recent advances in scaling large language models (LLMs) have
resulted in improvements on many NLP tasks, it remains unclear whether these
models trained primarily with general web text are the right tool in highly
specialized, safety critical domains such as clinical text. Recent results have
suggested that LLMs encode a surprising amount of medical knowledge. This
raises an important question regarding the utility of smaller domain-specific
language models. With the success of general-domain LLMs, is there still a need
for specialized clinical models? To investigate this question, we conduct an
extensive empirical analysis of 12 language models, ranging from 220M to 175B
parameters, measuring their performance on 3 different clinical tasks that test
their ability to parse and reason over electronic health records. As part of
our experiments, we train T5-Base and T5-Large models from scratch on clinical
notes from MIMIC III and IV to directly investigate the efficiency of clinical
tokens. We show that relatively small specialized clinical models substantially
outperform all in-context learning approaches, even when finetuned on limited
annotated data. Further, we find that pretraining on clinical tokens allows for
smaller, more parameter-efficient models that either match or outperform much
larger language models trained on general text. We release the code and the
models used under the PhysioNet Credentialed Health Data license and data use
agreement.",2023-02-16
"Tree-Based Representation and Generation of Natural and Mathematical
  Language",2023-02-15 22:38:34+00:00,http://arxiv.org/abs/2302.07974v1,"Alexander Scarlatos, Andrew Lan",cs.CL,knowledge,"Mathematical language in scientific communications and educational scenarios
is important yet relatively understudied compared to natural languages. Recent
works on mathematical language focus either on representing stand-alone
mathematical expressions, especially in their natural tree format, or
mathematical reasoning in pre-trained natural language models. Existing works
on jointly modeling and generating natural and mathematical languages simply
treat mathematical expressions as text, without accounting for the rigid
structural properties of mathematical expressions. In this paper, we propose a
series of modifications to existing language models to jointly represent and
generate text and math: representing mathematical expressions as sequences of
node tokens in their operator tree format, using math symbol and tree position
embeddings to preserve the semantic and structural properties of mathematical
expressions, and using a constrained decoding method to generate mathematically
valid expressions. We ground our modifications in GPT-2, resulting in a model
MathGPT, and demonstrate that it outperforms baselines on mathematical
expression generation tasks.",2023-02-15
"Investigating the Effect of Relative Positional Embeddings on
  AMR-to-Text Generation with Structural Adapters",2023-02-12 12:43:36+00:00,http://arxiv.org/abs/2302.05900v1,"Sebastien Montella, Alexis Nasr, Johannes Heinecke, Frederic Bechet, Lina M. Rojas-Barahona",cs.CL,knowledge,"Text generation from Abstract Meaning Representation (AMR) has substantially
benefited from the popularized Pretrained Language Models (PLMs). Myriad
approaches have linearized the input graph as a sequence of tokens to fit the
PLM tokenization requirements. Nevertheless, this transformation jeopardizes
the structural integrity of the graph and is therefore detrimental to its
resulting representation. To overcome this issue, Ribeiro et al. have recently
proposed StructAdapt, a structure-aware adapter which injects the input graph
connectivity within PLMs using Graph Neural Networks (GNNs). In this paper, we
investigate the influence of Relative Position Embeddings (RPE) on AMR-to-Text,
and, in parallel, we examine the robustness of StructAdapt. Through ablation
studies, graph attack and link prediction, we reveal that RPE might be
partially encoding input graphs. We suggest further research regarding the role
of RPE will provide valuable insights for Graph-to-Text generation.",2023-02-12
TextDefense: Adversarial Text Detection based on Word Importance Entropy,2023-02-12 11:12:44+00:00,http://arxiv.org/abs/2302.05892v1,"Lujia Shen, Xuhong Zhang, Shouling Ji, Yuwen Pu, Chunpeng Ge, Xing Yang, Yanghe Feng","cs.CL, cs.AI, cs.CR",knowledge,"Currently, natural language processing (NLP) models are wildly used in
various scenarios. However, NLP models, like all deep models, are vulnerable to
adversarially generated text. Numerous works have been working on mitigating
the vulnerability from adversarial attacks. Nevertheless, there is no
comprehensive defense in existing works where each work targets a specific
attack category or suffers from the limitation of computation overhead,
irresistible to adaptive attack, etc.
  In this paper, we exhaustively investigate the adversarial attack algorithms
in NLP, and our empirical studies have discovered that the attack algorithms
mainly disrupt the importance distribution of words in a text. A well-trained
model can distinguish subtle importance distribution differences between clean
and adversarial texts. Based on this intuition, we propose TextDefense, a new
adversarial example detection framework that utilizes the target model's
capability to defend against adversarial attacks while requiring no prior
knowledge. TextDefense differs from previous approaches, where it utilizes the
target model for detection and thus is attack type agnostic. Our extensive
experiments show that TextDefense can be applied to different architectures,
datasets, and attack methods and outperforms existing methods. We also discover
that the leading factor influencing the performance of TextDefense is the
target model's generalizability. By analyzing the property of the target model
and the property of the adversarial example, we provide our insights into the
adversarial attacks in NLP and the principles of our defense method.",2023-02-12
"Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot
  Image Captioning",2023-02-09 18:57:56+00:00,http://arxiv.org/abs/2302.04858v1,"Zhuolin Yang, Wei Ping, Zihan Liu, Vijay Korthikanti, Weili Nie, De-An Huang, Linxi Fan, Zhiding Yu, Shiyi Lan, Bo Li, Ming-Yu Liu, Yuke Zhu, Mohammad Shoeybi, Bryan Catanzaro, Chaowei Xiao, Anima Anandkumar","cs.CV, cs.AI, cs.CL, cs.IR, cs.LG",knowledge,"Augmenting pretrained language models (LMs) with a vision encoder (e.g.,
Flamingo) has obtained state-of-the-art results in image-to-text generation.
However, these models store all the knowledge within their parameters, thus
often requiring enormous model parameters to model the abundant visual concepts
and very rich textual descriptions. Additionally, they are inefficient in
incorporating new data, requiring a computational-expensive fine-tuning
process. In this work, we introduce a Retrieval-augmented Visual Language
Model, Re-ViLM, built upon the Flamingo, that supports retrieving the relevant
knowledge from the external database for zero and in-context few-shot
image-to-text generations. By storing certain knowledge explicitly in the
external database, our approach reduces the number of model parameters and can
easily accommodate new data during evaluation by simply updating the database.
We also construct an interleaved image and text data that facilitates
in-context few-shot learning capabilities. We demonstrate that Re-ViLM
significantly boosts performance for image-to-text generation tasks, especially
for zero-shot and few-shot generation in out-of-domain settings with 4 times
less parameters compared with baseline methods.",2023-02-09
Lightweight Transformers for Clinical Natural Language Processing,2023-02-09 16:07:31+00:00,http://arxiv.org/abs/2302.04725v1,"Omid Rohanian, Mohammadmahdi Nouriborji, Hannah Jauncey, Samaneh Kouchaki, ISARIC Clinical Characterisation Group, Lei Clifton, Laura Merson, David A. Clifton","cs.CL, cs.AI, cs.LG, 68T50, I.2.7",knowledge,"Specialised pre-trained language models are becoming more frequent in NLP
since they can potentially outperform models trained on generic texts. BioBERT
and BioClinicalBERT are two examples of such models that have shown promise in
medical NLP tasks. Many of these models are overparametrised and
resource-intensive, but thanks to techniques like Knowledge Distillation (KD),
it is possible to create smaller versions that perform almost as well as their
larger counterparts. In this work, we specifically focus on development of
compact language models for processing clinical texts (i.e. progress notes,
discharge summaries etc). We developed a number of efficient lightweight
clinical transformers using knowledge distillation and continual learning, with
the number of parameters ranging from 15 million to 65 million. These models
performed comparably to larger models such as BioBERT and ClinicalBioBERT and
significantly outperformed other compact models trained on general or
biomedical data. Our extensive evaluation was done across several standard
datasets and covered a wide range of clinical text-mining tasks, including
Natural Language Inference, Relation Extraction, Named Entity Recognition, and
Sequence Classification. To our knowledge, this is the first comprehensive
study specifically focused on creating efficient and compact transformers for
clinical NLP tasks. The models and code used in this study can be found on our
Huggingface profile at https://huggingface.co/nlpie and Github page at
https://github.com/nlpie-research/Lightweight-Clinical-Transformers,
respectively, promoting reproducibility of our results.",2023-02-09
"Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge
  Memorization",2023-02-09 03:04:11+00:00,http://arxiv.org/abs/2302.04415v1,"Zhixin Guo, Minyxuan Yan, Jiexing Qi, Jianping Zhou, Ziwei He, Zhouhan Lin, Guanjie Zheng, Xinbing Wang","cs.CL, cs.AI",knowledge,"Pre-trained language models (PLM) have achieved remarkable advancement in
table-to-text generation tasks. However, the lack of labeled domain-specific
knowledge and the topology gap between tabular data and text make it difficult
for PLMs to yield faithful text. Low-resource generation likewise faces unique
challenges in this domain. Inspired by how humans descript tabular data with
prior knowledge, we suggest a new framework: PromptMize, which targets
table-to-text generation under few-shot settings. The design of our framework
consists of two aspects: a prompt planner and a knowledge adapter. The prompt
planner aims to generate a prompt signal that provides instance guidance for
PLMs to bridge the topology gap between tabular data and text. Moreover, the
knowledge adapter memorizes domain-specific knowledge from the unlabelled
corpus to supply essential information during generation. Extensive experiments
and analyses are investigated on three open domain few-shot NLG datasets:
human, song, and book. Compared with previous state-of-the-art approaches, our
model achieves remarkable performance in generating quality as judged by human
and automatic evaluations.",2023-02-09
"Auto-Learning: An Adversarial Process of Two Pre-trained Models for
  Natural Language Generation",2023-02-08 06:09:55+00:00,http://arxiv.org/abs/2302.03896v1,"Zhengqing Yuan, Yuelin Lu, Chao Zhang, Huiwen Xue",cs.CL,knowledge,"Pre-trained models have been used in many fields in recent years, ranging
from natural language understanding to computer vision and natural language
generation. However, the performance of these natural language generation
models is overly dependent on the scale of the model and the size of the
dataset. While the larger language model is excellent in some respects, it
cannot learn up-to-date knowledge and is relatively difficult to relearn. In
this paper, a new adversarial process learning method called Auto-Learning.
This can improve the performance of any natural language generation model
without the help of additional datasets. Auto-Learning includes two models: $G$
is a text generation model and $D$ can test whether the data generated by G is
legitimate. Firstly, the fine-tuned $D$ model is used as the brain's knowledge
base before the process. Then the text generated by the $G$ model is used as
the input of $D$ to determine whether the text is legitimate or not. Finally,
$G$ is fine-tuned according to the output of $D$. This adversarial process is
like a self-escalation of the brain through some a priori knowledge. When this
adversarial system wants to learn something new, simply fine-tune the $D$
model. Our approach applies to Autoregressive Language Modeling for all
Transformer classes. The results are good in existing experimental tasks,
including more grammatical text generation and better performance on some text
comprehension tasks.",2023-02-08
"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based
  Learning",2023-02-08 02:45:21+00:00,http://arxiv.org/abs/2302.03848v1,"Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker",cs.CL,knowledge,"Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.",2023-02-08
Execution-based Code Generation using Deep Reinforcement Learning,2023-01-31 18:02:26+00:00,http://arxiv.org/abs/2301.13816v1,"Parshin Shojaee, Aneesh Jain, Sindhu Tipirneni, Chandan K. Reddy","cs.LG, cs.AI, cs.CL, cs.PL",knowledge,"The utilization of programming language (PL) models, pretrained on
large-scale code corpora, as a means of automating software engineering
processes has demonstrated considerable potential in streamlining various code
generation tasks such as code completion, code translation, and program
synthesis. However, current approaches mainly rely on supervised fine-tuning
objectives borrowed from text generation, neglecting specific sequence-level
features of code, including but not limited to compilability as well as
syntactic and functional correctness. To address this limitation, we propose
PPOCoder, a new framework for code generation that combines pretrained PL
models with Proximal Policy Optimization (PPO) deep reinforcement learning and
employs execution feedback as the external source of knowledge into the model
optimization. PPOCoder is transferable across different code generation tasks
and PLs. Extensive experiments on three code generation tasks demonstrate the
effectiveness of our proposed approach compared to SOTA methods, improving the
success rate of compilation and functional correctness over different PLs. Our
code can be found at https://github.com/reddy-lab-code-research/PPOCoder .",2023-01-31
"DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability
  Curvature",2023-01-26 18:44:06+00:00,http://arxiv.org/abs/2301.11305v1,"Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, Chelsea Finn","cs.CL, cs.AI",knowledge,"The fluency and factual knowledge of large language models (LLMs) heightens
the need for corresponding systems to detect whether a piece of text is
machine-written. For example, students may use LLMs to complete written
assignments, leaving instructors unable to accurately assess student learning.
In this paper, we first demonstrate that text sampled from an LLM tends to
occupy negative curvature regions of the model's log probability function.
Leveraging this observation, we then define a new curvature-based criterion for
judging if a passage is generated from a given LLM. This approach, which we
call DetectGPT, does not require training a separate classifier, collecting a
dataset of real or generated passages, or explicitly watermarking generated
text. It uses only log probabilities computed by the model of interest and
random perturbations of the passage from another generic pre-trained language
model (e.g, T5). We find DetectGPT is more discriminative than existing
zero-shot methods for model sample detection, notably improving detection of
fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the
strongest zero-shot baseline to 0.95 AUROC for DetectGPT. See
https://ericmitchell.ai/detectgpt for code, data, and other project
information.",2023-01-26
"One Model for All Domains: Collaborative Domain-Prefix Tuning for
  Cross-Domain NER",2023-01-25 05:16:43+00:00,http://arxiv.org/abs/2301.10410v1,"Xiang Chen, Lei Li, Qiaoshuo Fei, Ningyu Zhang, Chuanqi Tan, Yong Jiang, Fei Huang, Huajun Chen","cs.CL, cs.AI, cs.DB, cs.IR, cs.LG",knowledge,"Cross-domain NER is a challenging task to address the low-resource problem in
practical scenarios. Previous typical solutions mainly obtain a NER model by
pre-trained language models (PLMs) with data from a rich-resource domain and
adapt it to the target domain. Owing to the mismatch issue among entity types
in different domains, previous approaches normally tune all parameters of PLMs,
ending up with an entirely new NER model for each domain. Moreover, current
models only focus on leveraging knowledge in one general source domain while
failing to successfully transfer knowledge from multiple sources to the target.
To address these issues, we introduce Collaborative Domain-Prefix Tuning for
cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically,
we present text-to-text generation grounding domain-related instructors to
transfer knowledge to new domain NER tasks without structural modifications. We
utilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate
the potential of PLMs to handle NER tasks across various domains. Experimental
results on the Cross-NER benchmark show that the proposed approach has flexible
transfer ability and performs better on both one-source and multiple-source
cross-domain NER tasks. Codes will be available in
https://github.com/zjunlp/DeepKE/tree/main/example/ner/cross.",2023-01-25
"Semantic-aware Contrastive Learning for Electroencephalography-to-Text
  Generation with Curriculum Learning",2023-01-23 00:54:48+00:00,http://arxiv.org/abs/2301.09237v1,"Xiachong Feng, Xiaocheng Feng, Bing Qin","cs.HC, cs.CL",knowledge,"Electroencephalography-to-Text generation (EEG-to-Text), which aims to
directly generate natural text from EEG signals has drawn increasing attention
in recent years due to the enormous potential for Brain-computer interfaces
(BCIs). However, the remarkable discrepancy between the subject-dependent EEG
representation and the semantic-dependent text representation poses a great
challenge to this task. To mitigate this challenge, we devise a Curriculum
Semantic-aware Contrastive Learning strategy (C-SCL), which effectively
re-calibrates the subject-dependent EEG representation to the
semantic-dependent EEG representation, thus reducing the discrepancy.
Specifically, our C-SCL pulls semantically similar EEG representations together
while pushing apart dissimilar ones. Besides, in order to introduce more
meaningful contrastive pairs, we carefully employ curriculum learning to not
only craft meaningful contrastive pairs but also make the learning
progressively. We conduct extensive experiments on the ZuCo benchmark and our
method combined with diverse models and architectures shows stable improvements
across three types of metrics while achieving the new state-of-the-art. Further
investigation proves not only its superiority in both the single-subject and
low-resource settings but also its robust generalizability in the zero-shot
setting.",2023-01-23
Rationalization for Explainable NLP: A Survey,2023-01-21 07:58:03+00:00,http://arxiv.org/abs/2301.08912v1,"Sai Gurrapu, Ajay Kulkarni, Lifu Huang, Ismini Lourentzou, Laura Freeman, Feras A. Batarseh","cs.CL, cs.LG",knowledge,"Recent advances in deep learning have improved the performance of many
Natural Language Processing (NLP) tasks such as translation,
question-answering, and text classification. However, this improvement comes at
the expense of model explainability. Black-box models make it difficult to
understand the internals of a system and the process it takes to arrive at an
output. Numerical (LIME, Shapley) and visualization (saliency heatmap)
explainability techniques are helpful; however, they are insufficient because
they require specialized knowledge. These factors led rationalization to emerge
as a more accessible explainable technique in NLP. Rationalization justifies a
model's output by providing a natural language explanation (rationale). Recent
improvements in natural language generation have made rationalization an
attractive technique because it is intuitive, human-comprehensible, and
accessible to non-technical users. Since rationalization is a relatively new
field, it is disorganized. As the first survey, rationalization literature in
NLP from 2007-2022 is analyzed. This survey presents available methods,
explainable evaluations, code, and datasets used across various NLP tasks that
use rationalization. Further, a new subfield in Explainable AI (XAI), namely,
Rational AI (RAI), is introduced to advance the current state of
rationalization. A discussion on observed insights, challenges, and future
directions is provided to point to promising research opportunities.",2023-01-21
A Multi-Modal Geographic Pre-Training Method,2023-01-11 03:05:12+00:00,http://arxiv.org/abs/2301.04283v1,"Ruixue Ding, Boli Chen, Pengjun Xie, Fei Huang, Xin Li, Qiang Zhang, Yao Xu",cs.CL,knowledge,"As a core task in location-based services (LBS) (e.g., navigation maps),
query and point of interest (POI) matching connects users' intent with
real-world geographic information. Recently, pre-trained models (PTMs) have
made advancements in many natural language processing (NLP) tasks. Generic
text-based PTMs do not have enough geographic knowledge for query-POI matching.
To overcome this limitation, related literature attempts to employ
domain-adaptive pre-training based on geo-related corpus. However, a query
generally contains mentions of multiple geographic objects, such as nearby
roads and regions of interest (ROIs). The geographic context (GC), i.e., these
diverse geographic objects and their relationships, is therefore pivotal to
retrieving the most relevant POI. Single-modal PTMs can barely make use of the
important GC and therefore have limited performance. In this work, we propose a
novel query-POI matching method Multi-modal Geographic language model (MGeo),
which comprises a geographic encoder and a multi-modal interaction module. MGeo
represents GC as a new modality and is able to fully extract multi-modal
correlations for accurate query-POI matching. Besides, there is no publicly
available benchmark for this topic. In order to facilitate further research, we
build a new open-source large-scale benchmark Geographic TExtual Similarity
(GeoTES). The POIs come from an open-source geographic information system
(GIS). The queries are manually generated by annotators to prevent privacy
issues. Compared with several strong baselines, the extensive experiment
results and detailed ablation analyses on GeoTES demonstrate that our proposed
multi-modal pre-training method can significantly improve the query-POI
matching capability of generic PTMs, even when the queries' GC is not provided.
Our code and dataset are publicly available at
https://github.com/PhantomGrapes/MGeo.",2023-01-11
Universal Multimodal Representation for Language Understanding,2023-01-09 13:54:11+00:00,http://arxiv.org/abs/2301.03344v1,"Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao Li, Hai Zhao","cs.CL, cs.AI, cs.CV",knowledge,"Representation learning is the foundation of natural language processing
(NLP). This work presents new methods to employ visual information as assistant
signals to general NLP tasks. For each sentence, we first retrieve a flexible
number of images either from a light topic-image lookup table extracted over
the existing sentence-image pairs or a shared cross-modal embedding space that
is pre-trained on out-of-shelf text-image pairs. Then, the text and images are
encoded by a Transformer encoder and convolutional neural network,
respectively. The two sequences of representations are further fused by an
attention layer for the interaction of the two modalities. In this study, the
retrieval process is controllable and flexible. The universal visual
representation overcomes the lack of large-scale bilingual sentence-image
pairs. Our method can be easily applied to text-only tasks without manually
annotated multimodal parallel corpora. We apply the proposed method to a wide
range of natural language generation and understanding tasks, including neural
machine translation, natural language inference, and semantic similarity.
Experimental results show that our method is generally effective for different
tasks and languages. Analysis indicates that the visual signals enrich textual
representations of content words, provide fine-grained grounding information
about the relationship between concepts and events, and potentially conduce to
disambiguation.",2023-01-09
"TegFormer: Topic-to-Essay Generation with Good Topic Coverage and High
  Text Coherence",2022-12-27 11:50:14+00:00,http://arxiv.org/abs/2212.13456v1,"Wang Qi, Rui Liu, Yuan Zuo, Yong Chen, Dell Zhang",cs.CL,knowledge,"Creating an essay based on a few given topics is a challenging NLP task.
Although several effective methods for this problem, topic-to-essay generation,
have appeared recently, there is still much room for improvement, especially in
terms of the coverage of the given topics and the coherence of the generated
text. In this paper, we propose a novel approach called TegFormer which
utilizes the Transformer architecture where the encoder is enriched with
domain-specific contexts while the decoder is enhanced by a large-scale
pre-trained language model. Specifically, a \emph{Topic-Extension} layer
capturing the interaction between the given topics and their domain-specific
contexts is plugged into the encoder. Since the given topics are usually
concise and sparse, such an additional layer can bring more topic-related
semantics in to facilitate the subsequent natural language generation.
Moreover, an \emph{Embedding-Fusion} module that combines the domain-specific
word embeddings learnt from the given corpus and the general-purpose word
embeddings provided by a GPT-2 model pre-trained on massive text data is
integrated into the decoder. Since GPT-2 is at a much larger scale, it contains
a lot more implicit linguistic knowledge which would help the decoder to
produce more grammatical and readable text. Extensive experiments have shown
that the pieces of text generated by TegFormer have better topic coverage and
higher text coherence than those from SOTA topic-to-essay techniques, according
to automatic and human evaluations. As revealed by ablation studies, both the
Topic-Extension layer and the Embedding-Fusion module contribute substantially
to TegFormer's performance advantage.",2022-12-27
Do DALL-E and Flamingo Understand Each Other?,2022-12-23 10:46:56+00:00,http://arxiv.org/abs/2212.12249v1,"Hang Li, Jindong Gu, Rajat Koner, Sahand Sharifzadeh, Volker Tresp","cs.CV, cs.LG",knowledge,"A major goal of multimodal research is to improve machine understanding of
images and text. Tasks include image captioning, text-to-image generation, and
vision-language representation learning. So far, research has focused on the
relationships between images and text. For example, captioning models attempt
to understand the semantics of images which are then transformed into text. An
important question is: which annotation reflects best a deep understanding of
image content? Similarly, given a text, what is the best image that can present
the semantics of the text? In this work, we argue that the best text or caption
for a given image is the text which would generate the image which is the most
similar to that image. Likewise, the best image for a given text is the image
that results in the caption which is best aligned with the original text. To
this end, we propose a unified framework that includes both a text-to-image
generative model and an image-to-text generative model. Extensive experiments
validate our approach.",2022-12-23
"Understanding Stereotypes in Language Models: Towards Robust Measurement
  and Zero-Shot Debiasing",2022-12-20 22:41:24+00:00,http://arxiv.org/abs/2212.10678v1,"Justus Mattern, Zhijing Jin, Mrinmaya Sachan, Rada Mihalcea, Bernhard Schölkopf","cs.CL, cs.LG",knowledge,"Generated texts from large pretrained language models have been shown to
exhibit a variety of harmful, human-like biases about various demographics.
These findings prompted large efforts aiming to understand and measure such
effects, with the goal of providing benchmarks that can guide the development
of techniques mitigating these stereotypical associations. However, as recent
research has pointed out, the current benchmarks lack a robust experimental
setup, consequently hindering the inference of meaningful conclusions from
their evaluation metrics. In this paper, we extend these arguments and
demonstrate that existing techniques and benchmarks aiming to measure
stereotypes tend to be inaccurate and consist of a high degree of experimental
noise that severely limits the knowledge we can gain from benchmarking language
models based on them. Accordingly, we propose a new framework for robustly
measuring and quantifying biases exhibited by generative language models.
Finally, we use this framework to investigate GPT-3's occupational gender bias
and propose prompting techniques for mitigating these biases without the need
for fine-tuning.",2022-12-20
Controllable Text Generation with Language Constraints,2022-12-20 17:39:21+00:00,http://arxiv.org/abs/2212.10466v1,"Howard Chen, Huihan Li, Danqi Chen, Karthik Narasimhan",cs.CL,knowledge,"We consider the task of text generation in language models with constraints
specified in natural language. To this end, we first create a challenging
benchmark Cognac that provides as input to the model a topic with example text,
along with a constraint on text to be avoided. Unlike prior work, our benchmark
contains knowledge-intensive constraints sourced from databases like Wordnet
and Wikidata, which allows for straightforward evaluation while striking a
balance between broad attribute-level and narrow lexical-level controls. We
find that even state-of-the-art language models like GPT-3 fail often on this
task, and propose a solution to leverage a language model's own internal
knowledge to guide generation. Our method, called CognacGen, first queries the
language model to generate guidance terms for a specified topic or constraint,
and uses the guidance to modify the model's token generation probabilities. We
propose three forms of guidance (binary verifier, top-k tokens, textual
example), and employ prefix-tuning approaches to distill the guidance to tackle
diverse natural language constraints. Through extensive empirical evaluations,
we demonstrate that CognacGen can successfully generalize to unseen
instructions and outperform competitive baselines in generating constraint
conforming text.",2022-12-20
"CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data
  Limitation With Contrastive Learning",2022-12-20 15:26:19+00:00,http://arxiv.org/abs/2212.10341v1,"Xiaoming Liu, Zhaohan Zhang, Yichen Wang, Yu Lan, Chao Shen",cs.CL,knowledge,"Machine-Generated Text (MGT) detection, a task that discriminates MGT from
Human-Written Text (HWT), plays a crucial role in preventing misuse of text
generative models, which excel in mimicking human writing style recently.
Latest proposed detectors usually take coarse text sequence as input and output
some good results by fine-tune pretrained models with standard cross-entropy
loss. However, these methods fail to consider the linguistic aspect of text
(e.g., coherence) and sentence-level structures. Moreover, they lack the
ability to handle the low-resource problem which could often happen in practice
considering the enormous amount of textual data online. In this paper, we
present a coherence-based contrastive learning model named CoCo to detect the
possible MGT under low-resource scenario. Inspired by the distinctiveness and
permanence properties of linguistic feature, we represent text as a coherence
graph to capture its entity consistency, which is further encoded by the
pretrained model and graph neural network. To tackle the challenges of data
limitations, we employ a contrastive learning framework and propose an improved
contrastive loss for making full use of hard negative samples in training
stage. The experiment results on two public datasets prove our approach
outperforms the state-of-art methods significantly.",2022-12-20
"One Embedder, Any Task: Instruction-Finetuned Text Embeddings",2022-12-19 18:57:05+00:00,http://arxiv.org/abs/2212.09741v2,"Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A. Smith, Luke Zettlemoyer, Tao Yu",cs.CL,knowledge,"We introduce INSTRUCTOR, a new method for computing text embeddings given
task instructions: every text input is embedded together with instructions
explaining the use case (e.g., task and domain descriptions). Unlike encoders
from prior work that are more specialized, INSTRUCTOR is a single embedder that
can generate text embeddings tailored to different downstream tasks and
domains, without any further training. We first annotate instructions for 330
diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive
loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are
unseen during training), ranging from classification and information retrieval
to semantic textual similarity and text generation evaluation. INSTRUCTOR,
while having an order of magnitude fewer parameters than the previous best
model, achieves state-of-the-art performance, with an average improvement of
3.4% compared to the previous best results on the 70 diverse datasets. Our
analysis suggests that INSTRUCTOR is robust to changes in instructions, and
that instruction finetuning mitigates the challenge of training a single model
on diverse datasets. Our model, code, and data are available at
https://instructor-embedding.github.io.",2022-12-19
"Synthesis and Evaluation of a Domain-specific Large Data Set for
  Dungeons & Dragons",2022-12-18 12:54:45+00:00,http://arxiv.org/abs/2212.09080v1,"Akila Peiris, Nisansa de Silva","cs.CL, cs.LG",knowledge,"This paper introduces the Forgotten Realms Wiki (FRW) data set and domain
specific natural language generation using FRW along with related analyses.
Forgotten Realms is the de-facto default setting of the popular open ended
tabletop fantasy role playing game, Dungeons & Dragons. The data set was
extracted from the Forgotten Realms Fandom wiki consisting of more than over
45,200 articles. The FRW data set is constituted of 11 sub-data sets in a
number of formats: raw plain text, plain text annotated by article title,
directed link graphs, wiki info-boxes annotated by the wiki article title,
Poincar\'e embedding of first link graph, multiple Word2Vec and Doc2Vec models
of the corpus. This is the first data set of this size for the Dungeons &
Dragons domain. We then present a pairwise similarity comparison benchmark
which utilizes similarity measures. In addition, we perform D&D domain specific
natural language generation using the corpus and evaluate the named entity
classification with respect to the lore of Forgotten Realms.",2022-12-18
Plansformer: Generating Symbolic Plans using Transformers,2022-12-16 19:06:49+00:00,http://arxiv.org/abs/2212.08681v1,"Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava, Francesco Fabiano, Andrea Loreggia",cs.AI,knowledge,"Large Language Models (LLMs) have been the subject of active research,
significantly advancing the field of Natural Language Processing (NLP). From
BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural
language tasks such as question answering, summarization, and text generation.
Many ongoing efforts focus on understanding LLMs' capabilities, including their
knowledge of the world, syntax, and semantics. However, extending the textual
prowess of LLMs to symbolic reasoning has been slow and predominantly focused
on tackling problems related to the mathematical field. In this paper, we
explore the use of LLMs for automated planning - a branch of AI concerned with
the realization of action sequences (plans) to achieve a goal, typically
executed by intelligent agents, autonomous robots, and unmanned vehicles. We
introduce Plansformer; an LLM fine-tuned on planning problems and capable of
generating plans with favorable behavior in terms of correctness and length
with reduced knowledge-engineering efforts. We also demonstrate the
adaptability of Plansformer in solving different planning domains with varying
complexities, owing to the transfer learning abilities of LLMs. For one
configuration of Plansformer, we achieve ~97% valid plans, out of which ~95%
are optimal for Towers of Hanoi - a puzzle-solving domain.",2022-12-16
"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text
  Generation",2022-12-16 17:36:23+00:00,http://arxiv.org/abs/2212.08607v1,"Swarnadeep Saha, Xinyan Velocity Yu, Mohit Bansal, Ramakanth Pasunuru, Asli Celikyilmaz","cs.CL, cs.AI, cs.LG",knowledge,"Prompting large language models has enabled significant recent progress in
multi-step reasoning over text. However, when applied to text generation from
semi-structured data (e.g., graphs or tables), these methods typically suffer
from low semantic coverage, hallucination, and logical inconsistency. We
propose MURMUR, a neuro-symbolic modular approach to text generation from
semi-structured data with multi-step reasoning. MURMUR is a best-first search
method that generates reasoning paths using: (1) neural and symbolic modules
with specific linguistic and logical skills, (2) a grammar whose production
rules define valid compositions of modules, and (3) value functions that assess
the quality of each reasoning step. We conduct experiments on two diverse
data-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in
their data representations (graphs and tables) and span multiple linguistic and
logical skills. MURMUR obtains significant improvements over recent few-shot
baselines like direct prompting and chain-of-thought prompting, while also
achieving comparable performance to fine-tuned GPT-2 on out-of-domain data.
Moreover, human evaluation shows that MURMUR generates highly faithful and
correct reasoning paths that lead to 26% more logically consistent summaries on
LogicNLG, compared to direct prompting.",2022-12-16
ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning,2022-12-15 15:52:39+00:00,http://arxiv.org/abs/2212.07919v1,"Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz","cs.CL, cs.LG",knowledge,"Large language models show improved downstream task performance when prompted
to generate step-by-step reasoning to justify their final answers. These
reasoning steps greatly improve model interpretability and verification, but
objectively studying their correctness (independent of the final answer) is
difficult without reliable methods for automatic evaluation. We simply do not
know how often the stated reasoning steps actually support the final end task
predictions. In this work, we present ROSCOE, a suite of interpretable,
unsupervised automatic scores that improve and extend previous text generation
evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a
typology of reasoning errors and collect synthetic and human evaluation scores
on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE
can measure semantic consistency, logicality, informativeness, fluency, and
factuality - among other traits - by leveraging properties of step-by-step
rationales. We empirically verify the strength of our metrics on five human
annotated and six programmatically perturbed diagnostics datasets - covering a
diverse set of tasks that require reasoning skills and show that ROSCOE can
consistently outperform baseline metrics.",2022-12-15
"Collaborating Heterogeneous Natural Language Processing Tasks via
  Federated Learning",2022-12-12 09:27:50+00:00,http://arxiv.org/abs/2212.05789v1,"Chenhe Dong, Yuexiang Xie, Bolin Ding, Ying Shen, Yaliang Li",cs.CL,knowledge,"The increasing privacy concerns on personal private text data promote the
development of federated learning (FL) in recent years. However, the existing
studies on applying FL in NLP are not suitable to coordinate participants with
heterogeneous or private learning objectives. In this study, we further broaden
the application scope of FL in NLP by proposing an Assign-Then-Contrast
(denoted as ATC) framework, which enables clients with heterogeneous NLP tasks
to construct an FL course and learn useful knowledge from each other.
Specifically, the clients are suggested to first perform local training with
the unified tasks assigned by the server rather than using their own learning
objectives, which is called the Assign training stage. After that, in the
Contrast training stage, clients train with different local learning objectives
and exchange knowledge with other clients who contribute consistent and useful
model updates. We conduct extensive experiments on six widely-used datasets
covering both Natural Language Understanding (NLU) and Natural Language
Generation (NLG) tasks, and the proposed ATC framework achieves significant
improvements compared with various baseline methods. The source code is
available at
\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}.",2022-12-12
Discovering Latent Knowledge in Language Models Without Supervision,2022-12-07 18:17:56+00:00,http://arxiv.org/abs/2212.03827v1,"Collin Burns, Haotian Ye, Dan Klein, Jacob Steinhardt","cs.CL, cs.AI, cs.LG",knowledge,"Existing techniques for training language models can be misaligned with the
truth: if we train models with imitation learning, they may reproduce errors
that humans make; if we train them to generate text that humans rate highly,
they may output errors that human evaluators can't detect. We propose
circumventing this issue by directly finding latent knowledge inside the
internal activations of a language model in a purely unsupervised way.
Specifically, we introduce a method for accurately answering yes-no questions
given only unlabeled model activations. It works by finding a direction in
activation space that satisfies logical consistency properties, such as that a
statement and its negation have opposite truth values. We show that despite
using no supervision and no model outputs, our method can recover diverse
knowledge represented in large language models: across 6 models and 10
question-answering datasets, it outperforms zero-shot accuracy by 4\% on
average. We also find that it cuts prompt sensitivity in half and continues to
maintain high accuracy even when models are prompted to generate incorrect
answers. Our results provide an initial step toward discovering what language
models know, distinct from what they say, even when we don't have access to
explicit ground truth labels.",2022-12-07
"Harnessing Knowledge and Reasoning for Human-Like Natural Language
  Generation: A Brief Review",2022-12-07 16:18:19+00:00,http://arxiv.org/abs/2212.03747v1,"Jiangjie Chen, Yanghua Xiao",cs.CL,knowledge,"The rapid development and application of natural language generation (NLG)
techniques has revolutionized the field of automatic text production. However,
these techniques are still limited in their ability to produce human-like text
that is truly reasonable and informative. In this paper, we explore the
importance of NLG being guided by knowledge, in order to convey human-like
reasoning through language generation. We propose ten goals for intelligent NLG
systems to pursue, and briefly review the achievement of NLG techniques guided
by knowledge and reasoning. We also conclude by envisioning future directions
and challenges in the pursuit of these goals.",2022-12-07
Momentum Decoding: Open-ended Text Generation As Graph Exploration,2022-12-05 11:16:47+00:00,http://arxiv.org/abs/2212.02175v1,"Tian Lan, Yixuan Su, Shuhang Liu, Heyan Huang, Xian-Ling Mao",cs.CL,knowledge,"Open-ended text generation with autoregressive language models (LMs) is one
of the core tasks in natural language processing. However, maximization-based
decoding methods (e.g., greedy/beam search) often lead to the degeneration
problem, i.e., the generated text is unnatural and contains undesirable
repetitions. Existing solutions to this problem either introduce randomness
prone to incoherence or require a look-ahead mechanism that demands extra
computational overhead. In this study, we formulate open-ended text generation
from a new perspective, i.e., we view it as an exploration process within a
directed graph. Thereby, we understand the phenomenon of degeneration as
circular loops within the directed graph. Based on our formulation, we propose
a novel decoding method -- \textit{momentum decoding} -- which encourages the
LM to \textit{greedily} explore new nodes outside the current graph. Meanwhile,
it also allows the LM to return to the existing nodes with a momentum
downgraded by a pre-defined resistance function. We extensively test our
approach on three benchmarks from different domains through automatic and human
evaluations. The results show that momentum decoding performs comparably with
the current state of the art while enjoying notably improved inference speed
and computation FLOPs. Furthermore, we conduct a detailed analysis to reveal
the merits and inner workings of our approach. Our codes and other related
resources are publicly available at
https://github.com/gmftbyGMFTBY/MomentumDecoding.",2022-12-05
"Learning Automata-Based Task Knowledge Representation from Large-Scale
  Generative Language Models",2022-12-04 22:34:16+00:00,http://arxiv.org/abs/2212.01944v1,"Yunhao Yang, Jean-Raphaël Gaglione, Ufuk Topcu","cs.FL, cs.CL",knowledge,"Automata-based representations play an important role in control and planning
in sequential decision-making, but obtaining high-level task knowledge for
building automata is often difficult. Although large-scale generative language
models (GLMs) can help automatically distill task knowledge, the textual
outputs from GLMs are not directly utilizable in sequential decision-making. We
resolve this problem by proposing a novel algorithm named GLM2FSA, which
obtains high-level task knowledge, represented in a finite state automaton
(FSA), from a given brief description of the task goal. GLM2FSA sends queries
to a GLM for task knowledge in textual form and then builds a FSA to represent
the textual knowledge. This algorithm fills the gap between text and
automata-based representations, and the constructed FSA can be directly
utilized in sequential decision-making. We provide examples to demonstrate how
GLM2FSA constructs FSAs to represent knowledge encoded in the texts generated
by the large-scale GLMs.",2022-12-04
"What do you MEME? Generating Explanations for Visual Semantic Role
  Labelling in Memes",2022-12-01 18:21:36+00:00,http://arxiv.org/abs/2212.00715v1,"Shivam Sharma, Siddhant Agarwal, Tharun Suresh, Preslav Nakov, Md. Shad Akhtar, Tanmoy Charkraborty","cs.CY, cs.CL",knowledge,"Memes are powerful means for effective communication on social media. Their
effortless amalgamation of viral visuals and compelling messages can have
far-reaching implications with proper marketing. Previous research on memes has
primarily focused on characterizing their affective spectrum and detecting
whether the meme's message insinuates any intended harm, such as hate, offense,
racism, etc. However, memes often use abstraction, which can be elusive. Here,
we introduce a novel task - EXCLAIM, generating explanations for visual
semantic role labeling in memes. To this end, we curate ExHVV, a novel dataset
that offers natural language explanations of connotative roles for three types
of entities - heroes, villains, and victims, encompassing 4,680 entities
present in 3K memes. We also benchmark ExHVV with several strong unimodal and
multimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task
learning framework that endeavors to address EXCLAIM optimally by jointly
learning to predict the correct semantic roles and correspondingly to generate
suitable natural language explanations. LUMEN distinctly outperforms the best
baseline across 18 standard natural language generation evaluation metrics. Our
systematic evaluation and analyses demonstrate that characteristic multimodal
cues required for adjudicating semantic roles are also helpful for generating
suitable explanations.",2022-12-01
"CliMedBERT: A Pre-trained Language Model for Climate and Health-related
  Text",2022-12-01 17:44:09+00:00,http://arxiv.org/abs/2212.00689v1,"B. Jalalzadeh Fard, S. A. Hasan, J. E. Bell","cs.CL, 68T50, I.2.7",knowledge,"Climate change is threatening human health in unprecedented orders and many
ways. These threats are expected to grow unless effective and evidence-based
policies are developed and acted upon to minimize or eliminate them. Attaining
such a task requires the highest degree of the flow of knowledge from science
into policy. The multidisciplinary, location-specific, and vastness of
published science makes it challenging to keep track of novel work in this
area, as well as making the traditional knowledge synthesis methods inefficient
in infusing science into policy. To this end, we consider developing multiple
domain-specific language models (LMs) with different variations from Climate-
and Health-related information, which can serve as a foundational step toward
capturing available knowledge to enable solving different tasks, such as
detecting similarities between climate- and health-related concepts,
fact-checking, relation extraction, evidence of health effects to policy text
generation, and more. To our knowledge, this is the first work that proposes
developing multiple domain-specific language models for the considered domains.
We will make the developed models, resources, and codebase available for the
researchers.",2022-12-01
"On the Importance of Image Encoding in Automated Chest X-Ray Report
  Generation",2022-11-24 08:02:52+00:00,http://arxiv.org/abs/2211.13465v1,"Otabek Nazarov, Mohammad Yaqub, Karthik Nandakumar","cs.CV, cs.AI",knowledge,"Chest X-ray is one of the most popular medical imaging modalities due to its
accessibility and effectiveness. However, there is a chronic shortage of
well-trained radiologists who can interpret these images and diagnose the
patient's condition. Therefore, automated radiology report generation can be a
very helpful tool in clinical practice. A typical report generation workflow
consists of two main steps: (i) encoding the image into a latent space and (ii)
generating the text of the report based on the latent image embedding. Many
existing report generation techniques use a standard convolutional neural
network (CNN) architecture for image encoding followed by a Transformer-based
decoder for medical text generation. In most cases, CNN and the decoder are
trained jointly in an end-to-end fashion. In this work, we primarily focus on
understanding the relative importance of encoder and decoder components.
Towards this end, we analyze four different image encoding approaches: direct,
fine-grained, CLIP-based, and Cluster-CLIP-based encodings in conjunction with
three different decoders on the large-scale MIMIC-CXR dataset. Among these
encoders, the cluster CLIP visual encoder is a novel approach that aims to
generate more discriminative and explainable representations. CLIP-based
encoders produce comparable results to traditional CNN-based encoders in terms
of NLP metrics, while fine-grained encoding outperforms all other encoders both
in terms of NLP and clinical accuracy metrics, thereby validating the
importance of image encoder to effectively extract semantic information. GitHub
repository: https://github.com/mudabek/encoding-cxr-report-gen",2022-11-24
Retrieval-Augmented Multimodal Language Modeling,2022-11-22 20:26:44+00:00,http://arxiv.org/abs/2211.12561v1,"Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, Wen-tau Yih","cs.CV, cs.CL, cs.LG",knowledge,"Recent multimodal models such as DALL-E and CM3 have achieved remarkable
progress in text-to-image and image-to-text generation. However, these models
store all learned knowledge (e.g., the appearance of the Eiffel Tower) in the
model parameters, requiring increasingly larger models and training data to
capture more knowledge. To integrate knowledge in a more scalable and modular
way, we propose a retrieval-augmented multimodal model, which enables a base
multimodal model (generator) to refer to relevant knowledge fetched by a
retriever from external memory (e.g., multimodal documents on the web).
Specifically, we implement a retriever using the pretrained CLIP model and a
generator using the CM3 Transformer architecture, and train this model using
the LAION dataset. Our resulting model, named Retrieval-Augmented CM3 (RA-CM3),
is the first multimodal model that can retrieve and generate mixtures of text
and images. We show that RA-CM3 significantly outperforms baseline multimodal
models such as DALL-E and CM3 on both image and caption generation tasks (12
FID and 17 CIDEr improvements on MS-COCO), while requiring much less compute
for training (<30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel
capabilities such as knowledge-intensive image generation and multimodal
in-context learning.",2022-11-22
"Towards Computationally Verifiable Semantic Grounding for Language
  Models",2022-11-16 17:35:52+00:00,http://arxiv.org/abs/2211.09070v1,"Chris Alberti, Kuzman Ganchev, Michael Collins, Sebastian Gehrmann, Ciprian Chelba",cs.CL,knowledge,"The paper presents an approach to semantic grounding of language models (LMs)
that conceptualizes the LM as a conditional model generating text given a
desired semantic message formalized as a set of entity-relationship triples. It
embeds the LM in an auto-encoder by feeding its output to a semantic parser
whose output is in the same representation domain as the input message.
Compared to a baseline that generates text using greedy search, we demonstrate
two techniques that improve the fluency and semantic accuracy of the generated
text: The first technique samples multiple candidate text sequences from which
the semantic parser chooses. The second trains the language model while keeping
the semantic parser frozen to improve the semantic accuracy of the
auto-encoder. We carry out experiments on the English WebNLG 3.0 data set,
using BLEU to measure the fluency of generated text and standard parsing
metrics to measure semantic accuracy. We show that our proposed approaches
significantly improve on the greedy search baseline. Human evaluation
corroborates the results of the automatic evaluation experiments.",2022-11-16
kogito: A Commonsense Knowledge Inference Toolkit,2022-11-15 19:04:13+00:00,http://arxiv.org/abs/2211.08451v1,"Mete Ismayilzada, Antoine Bosselut",cs.CL,knowledge,"In this paper, we present kogito, an open-source tool for generating
commonsense inferences about situations described in text. kogito provides an
intuitive and extensible interface to interact with natural language generation
models that can be used for hypothesizing commonsense knowledge inference from
a textual input. In particular, kogito offers several features for targeted,
multi-granularity knowledge generation. These include a standardized API for
training and evaluating knowledge models, and generating and filtering
inferences from them. We also include helper functions for converting natural
language texts into a format ingestible by knowledge models - intermediate
pipeline stages such as knowledge head extraction from text, heuristic and
model-based knowledge head-relation matching, and an ability to define and use
custom knowledge relations. We make the code for kogito available at
https://github.com/epfl-nlp/kogito along with thorough documentation at
https://kogito.readthedocs.io.",2022-11-15
A Survey of Knowledge-Enhanced Pre-trained Language Models,2022-11-11 04:29:02+00:00,http://arxiv.org/abs/2211.05994v3,"Linmei Hu, Zeyi Liu, Ziwang Zhao, Lei Hou, Liqiang Nie, Juanzi Li",cs.CL,knowledge,"Pre-trained Language Models (PLMs) which are trained on large text corpus via
self-supervised learning method, have yielded promising performance on various
tasks in Natural Language Processing (NLP). However, though PLMs with huge
parameters can effectively possess rich knowledge learned from massive training
text and benefit downstream tasks at the fine-tuning stage, they still have
some limitations such as poor reasoning ability due to the lack of external
knowledge. Research has been dedicated to incorporating knowledge into PLMs to
tackle these issues. In this paper, we present a comprehensive review of
Knowledge-Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear
insight into this thriving field. We introduce appropriate taxonomies
respectively for Natural Language Understanding (NLU) and Natural Language
Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide
the types of knowledge into four categories: linguistic knowledge, text
knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are
categorized into KG-based and retrieval-based methods. Finally, we point out
some promising future directions of KE-PLMs.",2022-11-11
"CCPrompt: Counterfactual Contrastive Prompt-Tuning for Many-Class
  Classification",2022-11-11 03:45:59+00:00,http://arxiv.org/abs/2211.05987v1,"Yang Li, Canran Xu, Tao Shen, Jing Jiang, Guodong Long",cs.CL,knowledge,"With the success of the prompt-tuning paradigm in Natural Language Processing
(NLP), various prompt templates have been proposed to further stimulate
specific knowledge for serving downstream tasks, e.g., machine translation,
text generation, relation extraction, and so on. Existing prompt templates are
mainly shared among all training samples with the information of task
description. However, training samples are quite diverse. The sharing task
description is unable to stimulate the unique task-related information in each
training sample, especially for tasks with the finite-label space. To exploit
the unique task-related information, we imitate the human decision process
which aims to find the contrastive attributes between the objective factual and
their potential counterfactuals. Thus, we propose the \textbf{C}ounterfactual
\textbf{C}ontrastive \textbf{Prompt}-Tuning (CCPrompt) approach for many-class
classification, e.g., relation classification, topic classification, and entity
typing. Compared with simple classification tasks, these tasks have more
complex finite-label spaces and are more rigorous for prompts. First of all, we
prune the finite label space to construct fact-counterfactual pairs. Then, we
exploit the contrastive attributes by projecting training instances onto every
fact-counterfactual pair. We further set up global prototypes corresponding
with all contrastive attributes for selecting valid contrastive attributes as
additional tokens in the prompt template. Finally, a simple Siamese
representation learning is employed to enhance the robustness of the model. We
conduct experiments on relation classification, topic classification, and
entity typing tasks in both fully supervised setting and few-shot setting. The
results indicate that our model outperforms former baselines.",2022-11-11
"Measuring Reliability of Large Language Models through Semantic
  Consistency",2022-11-10 20:21:07+00:00,http://arxiv.org/abs/2211.05853v1,"Harsh Raj, Domenic Rosati, Subhabrata Majumdar","cs.CL, cs.AI, cs.CY",knowledge,"While large pretrained language models (PLMs) demonstrate incredible fluency
and performance on many natural language tasks, recent work has shown that
well-performing PLMs are very sensitive to what prompts are feed into them.
Even when prompts are semantically identical, language models may give very
different answers. When considering safe and trustworthy deployments of PLMs we
would like their outputs to be consistent under prompts that mean the same
thing or convey the same intent. While some work has looked into how
state-of-the-art PLMs address this need, they have been limited to only
evaluating lexical equality of single- or multi-word answers and do not address
consistency of generative text sequences. In order to understand consistency of
PLMs under text generation settings, we develop a measure of semantic
consistency that allows the comparison of open-ended text outputs. We implement
several versions of this consistency metric to evaluate the performance of a
number of PLMs on paraphrased versions of questions in the TruthfulQA dataset,
we find that our proposed metrics are considerably more consistent than
traditional metrics embodying lexical consistency, and also correlate with
human evaluation of output consistency to a higher degree.",2022-11-10
Generative Transformers for Design Concept Generation,2022-11-07 11:29:10+00:00,http://arxiv.org/abs/2211.03468v1,"Qihao Zhu, Jianxi Luo",cs.CL,knowledge,"Generating novel and useful concepts is essential during the early design
stage to explore a large variety of design opportunities, which usually
requires advanced design thinking ability and a wide range of knowledge from
designers. Growing works on computer-aided tools have explored the retrieval of
knowledge and heuristics from design data. However, they only provide stimuli
to inspire designers from limited aspects. This study explores the recent
advance of the natural language generation (NLG) technique in the artificial
intelligence (AI) field to automate the early-stage design concept generation.
Specifically, a novel approach utilizing the generative pre-trained transformer
(GPT) is proposed to leverage the knowledge and reasoning from textual data and
transform them into new concepts in understandable language. Three concept
generation tasks are defined to leverage different knowledge and reasoning:
domain knowledge synthesis, problem-driven synthesis, and analogy-driven
synthesis. The experiments with both human and data-driven evaluation show good
performance in generating novel and useful concepts.",2022-11-07
CLSE: Corpus of Linguistically Significant Entities,2022-11-04 12:56:12+00:00,http://arxiv.org/abs/2211.02423v1,"Aleksandr Chuklin, Justin Zhao, Mihir Kale",cs.CL,knowledge,"One of the biggest challenges of natural language generation (NLG) is the
proper handling of named entities. Named entities are a common source of
grammar mistakes such as wrong prepositions, wrong article handling, or
incorrect entity inflection. Without factoring linguistic representation, such
errors are often underrepresented when evaluating on a small set of arbitrarily
picked argument values, or when translating a dataset from a linguistically
simpler language, like English, to a linguistically complex language, like
Russian. However, for some applications, broadly precise grammatical
correctness is critical -- native speakers may find entity-related grammar
errors silly, jarring, or even offensive.
  To enable the creation of more linguistically diverse NLG datasets, we
release a Corpus of Linguistically Significant Entities (CLSE) annotated by
linguist experts. The corpus includes 34 languages and covers 74 different
semantic types to support various applications from airline ticketing to video
games. To demonstrate one possible use of CLSE, we produce an augmented version
of the Schema-Guided Dialog Dataset, SGD-CLSE. Using the CLSE's entities and a
small number of human translations, we create a linguistically representative
NLG evaluation benchmark in three languages: French (high-resource), Marathi
(low-resource), and Russian (highly inflected language). We establish quality
baselines for neural, template-based, and hybrid NLG systems and discuss the
strengths and weaknesses of each approach.",2022-11-04
Dialect-robust Evaluation of Generated Text,2022-11-02 07:12:23+00:00,http://arxiv.org/abs/2211.00922v1,"Jiao Sun, Thibault Sellam, Elizabeth Clark, Tu Vu, Timothy Dozat, Dan Garrette, Aditya Siddhant, Jacob Eisenstein, Sebastian Gehrmann",cs.CL,knowledge,"Evaluation metrics that are not robust to dialect variation make it
impossible to tell how well systems perform for many groups of users, and can
even penalize systems for producing text in lower-resource dialects. However,
currently, there exists no way to quantify how metrics respond to change in the
dialect of a generated utterance. We thus formalize dialect robustness and
dialect awareness as goals for NLG evaluation metrics. We introduce a suite of
methods and corresponding statistical tests one can use to assess metrics in
light of the two goals. Applying the suite to current state-of-the-art metrics,
we demonstrate that they are not dialect-robust and that semantic perturbations
frequently lead to smaller decreases in a metric than the introduction of
dialect features. As a first step to overcome this limitation, we propose a
training schema, NANO, which introduces regional and language information to
the pretraining process of a metric. We demonstrate that NANO provides a
size-efficient way for models to improve the dialect robustness while
simultaneously improving their performance on the standard metric benchmark.",2022-11-02
"Seq2Seq-SC: End-to-End Semantic Communication Systems with Pre-trained
  Language Model",2022-10-27 07:48:18+00:00,http://arxiv.org/abs/2210.15237v1,"Ju-Hyung Lee, Dong-Ho Lee, Eunsoo Sheen, Thomas Choi, Jay Pujara, Joongheon Kim","eess.SP, cs.CL",knowledge,"While semantic communication is expected to bring unprecedented communication
efficiency in comparison to classical communication, many challenges must be
resolved to realize its potential. In this work, we provide a realistic
semantic network dubbed seq2seq-SC, which is compatible to 5G NR and can work
with generalized text dataset utilizing pre-trained language model. We also
utilize a performance metric (SBERT) which can accurately measure semantic
similarity and show that seq2seq-SC achieves superior performance while
extracting semantically meaningful information.",2022-10-27
Contrastive Search Is What You Need For Neural Text Generation,2022-10-25 16:40:48+00:00,http://arxiv.org/abs/2210.14140v1,"Yixuan Su, Nigel Collier",cs.CL,knowledge,"Generating text with autoregressive language models (LMs) is of great
importance to many natural language processing (NLP) applications. Previous
solutions for this task often produce text that contains degenerative
expressions or lacks semantic consistency. Recently, Su et al. introduced a new
decoding method, contrastive search, based on the isotropic representation
space of the language model and obtained new state of the art on various
benchmarks. Additionally, Su et al. argued that the representations of
autoregressive LMs (e.g. GPT-2) are intrinsically anisotropic which is also
shared by previous study. Therefore, to ensure the language model follows an
isotropic distribution, Su et al. proposed a contrastive learning scheme,
SimCTG, which calibrates the language model's representations through
additional training.
  In this study, we first answer the question: ""Are autoregressive LMs really
anisotropic?"". To this end, we extensively evaluate the isotropy of LMs across
16 major languages. Surprisingly, we find that the anisotropic problem only
exists in the two specific English GPT-2-small/medium models. On the other
hand, all other evaluated LMs are naturally isotropic which is in contrast to
the conclusion drawn by previous studies. Based on our findings, we further
assess the contrastive search decoding method using off-the-shelf LMs on four
generation tasks across 16 languages. Our experimental results demonstrate that
contrastive search significantly outperforms previous decoding methods without
any additional training. More notably, on 12 out of 16 evaluated languages,
contrastive search performs comparably with human-level performances as judged
by human evaluations.",2022-10-25
"Mapping Process for the Task: Wikidata Statements to Text as Wikipedia
  Sentences",2022-10-23 08:34:33+00:00,http://arxiv.org/abs/2210.12659v1,"Hoang Thang Ta, Alexander Gelbukha, Grigori Sidorov","cs.CL, cs.AI",knowledge,"Acknowledged as one of the most successful online cooperative projects in
human society, Wikipedia has obtained rapid growth in recent years and desires
continuously to expand content and disseminate knowledge values for everyone
globally. The shortage of volunteers brings to Wikipedia many issues, including
developing content for over 300 languages at the present. Therefore, the
benefit that machines can automatically generate content to reduce human
efforts on Wikipedia language projects could be considerable. In this paper, we
propose our mapping process for the task of converting Wikidata statements to
natural language text (WS2T) for Wikipedia projects at the sentence level. The
main step is to organize statements, represented as a group of quadruples and
triples, and then to map them to corresponding sentences in English Wikipedia.
We evaluate the output corpus in various aspects: sentence structure analysis,
noise filtering, and relationships between sentence components based on word
embedding models. The results are helpful not only for the data-to-text
generation task but also for other relevant works in the field.",2022-10-23
"Hard Gate Knowledge Distillation -- Leverage Calibration for Robust and
  Reliable Language Model",2022-10-22 11:57:10+00:00,http://arxiv.org/abs/2210.12427v1,"Dongkyu Lee, Zhiliang Tian, Yingxiu Zhao, Ka Chun Cheung, Nevin L. Zhang","cs.CL, cs.AI",knowledge,"In knowledge distillation, a student model is trained with supervisions from
both knowledge from a teacher and observations drawn from a training data
distribution. Knowledge of a teacher is considered a subject that holds
inter-class relations which send a meaningful supervision to a student; hence,
much effort has been put to find such knowledge to be distilled. In this paper,
we explore a question that has been given little attention: ""when to distill
such knowledge."" The question is answered in our work with the concept of model
calibration; we view a teacher model not only as a source of knowledge but also
as a gauge to detect miscalibration of a student. This simple and yet novel
view leads to a hard gate knowledge distillation scheme that switches between
learning from a teacher model and training data. We verify the gating mechanism
in the context of natural language generation at both the token-level and the
sentence-level. Empirical comparisons with strong baselines show that hard gate
knowledge distillation not only improves model generalization, but also
significantly lowers model calibration error.",2022-10-22
What do Large Language Models Learn beyond Language?,2022-10-21 23:43:13+00:00,http://arxiv.org/abs/2210.12302v1,"Avinash Madasu, Shashank Srivastava",cs.CL,knowledge,"Large language models (LMs) have rapidly become a mainstay in Natural
Language Processing. These models are known to acquire rich linguistic
knowledge from training on large amounts of text. In this paper, we investigate
if pre-training on text also confers these models with helpful `inductive
biases' for non-linguistic reasoning. On a set of 19 diverse non-linguistic
tasks involving quantitative computations, recognizing regular expressions and
reasoning over strings. We find that pretrained models significantly outperform
comparable non-pretrained neural models. This remains true also in experiments
with training non-pretrained models with fewer parameters to account for model
regularization effects. We further explore the effect of text domain on LMs by
pretraining models from text from different domains and provenances. Our
experiments surprisingly reveal that the positive effects of pre-training
persist even when pretraining on multi-lingual text or computer code, and even
for text generated from synthetic languages. Our findings suggest a hitherto
unexplored deep connection between pre-training and inductive learning
abilities of language models.",2022-10-21
Image Semantic Relation Generation,2022-10-19 16:15:19+00:00,http://arxiv.org/abs/2210.11253v1,Mingzhe Du,"cs.CV, cs.CL",knowledge,"Scene graphs provide structured semantic understanding beyond images. For
downstream tasks, such as image retrieval, visual question answering, visual
relationship detection, and even autonomous vehicle technology, scene graphs
can not only distil complex image information but also correct the bias of
visual models using semantic-level relations, which has broad application
prospects. However, the heavy labour cost of constructing graph annotations may
hinder the application of PSG in practical scenarios. Inspired by the
observation that people usually identify the subject and object first and then
determine the relationship between them, we proposed to decouple the scene
graphs generation task into two sub-tasks: 1) an image segmentation task to
pick up the qualified objects. 2) a restricted auto-regressive text generation
task to generate the relation between given objects. Therefore, in this work,
we introduce image semantic relation generation (ISRG), a simple but effective
image-to-text model, which achieved 31 points on the OpenPSG dataset and
outperforms strong baselines respectively by 16 points (ResNet-50) and 5 points
(CLIP).",2022-10-19
NGEP: A Graph-based Event Planning Framework for Story Generation,2022-10-19 14:49:27+00:00,http://arxiv.org/abs/2210.10602v1,"Chen Tang, Zhihao Zhang, Tyler Loakman, Chenghua Lin, Frank Guerin","cs.CL, cs.AI",knowledge,"To improve the performance of long text generation, recent studies have
leveraged automatically planned event structures (i.e. storylines) to guide
story generation. Such prior works mostly employ end-to-end neural generation
models to predict event sequences for a story. However, such generation models
struggle to guarantee the narrative coherence of separate events due to the
hallucination problem, and additionally the generated event sequences are often
hard to control due to the end-to-end nature of the models. To address these
challenges, we propose NGEP, an novel event planning framework which generates
an event sequence by performing inference on an automatically constructed event
graph and enhances generalisation ability through a neural event advisor. We
conduct a range of experiments on multiple criteria, and the results
demonstrate that our graph-based neural framework outperforms the
state-of-the-art (SOTA) event planning approaches, considering both the
performance of event sequence generation and the effectiveness on the
downstream task of story generation.",2022-10-19
SafeText: A Benchmark for Exploring Physical Safety in Language Models,2022-10-18 17:59:31+00:00,http://arxiv.org/abs/2210.10045v1,"Sharon Levy, Emily Allaway, Melanie Subbiah, Lydia Chilton, Desmond Patton, Kathleen McKeown, William Yang Wang","cs.CL, cs.AI",knowledge,"Understanding what constitutes safe text is an important issue in natural
language processing and can often prevent the deployment of models deemed
harmful and unsafe. One such type of safety that has been scarcely studied is
commonsense physical safety, i.e. text that is not explicitly violent and
requires additional commonsense knowledge to comprehend that it leads to
physical harm. We create the first benchmark dataset, SafeText, comprising
real-life scenarios with paired safe and physically unsafe pieces of advice. We
utilize SafeText to empirically study commonsense physical safety across
various models designed for text generation and commonsense reasoning tasks. We
find that state-of-the-art large language models are susceptible to the
generation of unsafe text and have difficulty rejecting unsafe advice. As a
result, we argue for further studies of safety and the assessment of
commonsense physical safety in models before release.",2022-10-18
"DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for
  Controllable Text Generation",2022-10-18 02:59:06+00:00,http://arxiv.org/abs/2210.09551v1,"Hanqing Zhang, Dawei Song",cs.CL,knowledge,"Prompt learning with immensely large Casual Language Models (CLMs) has been
shown promising for attribute-controllable text generation (CTG). However,
vanilla prompt tuning tends to imitate training corpus characteristics beyond
the control attributes, resulting in a poor generalization ability. Moreover,
it is less able to capture the relationship between different attributes,
further limiting the control performance. In this paper, we propose a new CTG
approach, namely DisCup, which incorporates the attribute knowledge of
discriminator to optimize the control-prompts, steering a frozen CLM to produce
attribute-specific texts. Specifically, the frozen CLM model, capable of
producing multitudinous texts, is first used to generate the next-token
candidates based on the context, so as to ensure the diversity of tokens to be
predicted. Then, we leverage an attribute-discriminator to select
desired/undesired tokens from those candidates, providing the inter-attribute
knowledge. Finally, we bridge the above two traits by an unlikelihood objective
for prompt-tuning. Extensive experimental results show that DisCup can achieve
a new state-of-the-art control performance while maintaining an efficient and
high-quality text generation, only relying on around 10 virtual tokens.",2022-10-18
"UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation
  Model on a Single Image",2022-10-17 23:46:05+00:00,http://arxiv.org/abs/2210.09477v3,"Dani Valevski, Matan Kalman, Yossi Matias, Yaniv Leviathan","cs.CV, cs.GR, cs.LG",knowledge,"We present UniTune, a simple and novel method for general text-driven image
editing. UniTune gets as input an arbitrary image and a textual edit
description, and carries out the edit while maintaining high semantic and
visual fidelity to the input image. UniTune uses text, an intuitive interface
for art-direction, and does not require additional inputs, like masks or
sketches. At the core of our method is the observation that with the right
choice of parameters, we can fine-tune a large text-to-image diffusion model on
a single image, encouraging the model to maintain fidelity to the input image
while still allowing expressive manipulations. We used Imagen as our
text-to-image model, but we expect UniTune to work with other large-scale
models as well. We test our method in a range of different use cases, and
demonstrate its wide applicability.",2022-10-17
Deepfake Text Detection: Limitations and Opportunities,2022-10-17 20:40:14+00:00,http://arxiv.org/abs/2210.09421v1,"Jiameng Pu, Zain Sarwar, Sifat Muhammad Abdullah, Abdullah Rehman, Yoonjin Kim, Parantapa Bhattacharya, Mobin Javed, Bimal Viswanath","cs.CR, cs.CL, cs.LG",knowledge,"Recent advances in generative models for language have enabled the creation
of convincing synthetic text or deepfake text. Prior work has demonstrated the
potential for misuse of deepfake text to mislead content consumers. Therefore,
deepfake text detection, the task of discriminating between human and
machine-generated text, is becoming increasingly critical. Several defenses
have been proposed for deepfake text detection. However, we lack a thorough
understanding of their real-world applicability. In this paper, we collect
deepfake text from 4 online services powered by Transformer-based tools to
evaluate the generalization ability of the defenses on content in the wild. We
develop several low-cost adversarial attacks, and investigate the robustness of
existing defenses against an adaptive attacker. We find that many defenses show
significant degradation in performance under our evaluation scenarios compared
to their original claimed performance. Our evaluation shows that tapping into
the semantic information in the text content is a promising approach for
improving the robustness and generalization performance of deepfake text
detection schemes.",2022-10-17
Towards a Unified Multi-Dimensional Evaluator for Text Generation,2022-10-13 17:17:03+00:00,http://arxiv.org/abs/2210.07197v1,"Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, Jiawei Han",cs.CL,knowledge,"Multi-dimensional evaluation is the dominant paradigm for human evaluation in
Natural Language Generation (NLG), i.e., evaluating the generated text from
multiple explainable dimensions, such as coherence and fluency. However,
automatic evaluation in NLG is still dominated by similarity-based metrics, and
we lack a reliable framework for a more comprehensive evaluation of advanced
models. In this paper, we propose a unified multi-dimensional evaluator UniEval
for NLG. We re-frame NLG evaluation as a Boolean Question Answering (QA) task,
and by guiding the model with different questions, we can use one evaluator to
evaluate from multiple dimensions. Furthermore, thanks to the unified Boolean
QA format, we are able to introduce an intermediate learning phase that enables
UniEval to incorporate external knowledge from multiple related tasks and gain
further improvement. Experiments on three typical NLG tasks show that UniEval
correlates substantially better with human judgments than existing metrics.
Specifically, compared to the top-performing unified evaluators, UniEval
achieves a 23% higher correlation on text summarization, and over 43% on
dialogue response generation. Also, UniEval demonstrates a strong zero-shot
learning ability for unseen evaluation dimensions and tasks. Source code, data
and all pre-trained evaluators are available on our GitHub repository
(https://github.com/maszhongming/UniEval).",2022-10-13
"RaP: Redundancy-aware Video-language Pre-training for Text-Video
  Retrieval",2022-10-13 10:11:41+00:00,http://arxiv.org/abs/2210.06881v1,"Xing Wu, Chaochen Gao, Zijia Lin, Zhongyuan Wang, Jizhong Han, Songlin Hu","cs.CV, cs.AI",knowledge,"Video language pre-training methods have mainly adopted sparse sampling
techniques to alleviate the temporal redundancy of videos. Though effective,
sparse sampling still suffers inter-modal redundancy: visual redundancy and
textual redundancy. Compared with highly generalized text, sparsely sampled
frames usually contain text-independent portions, called visual redundancy.
Sparse sampling is also likely to miss important frames corresponding to some
text portions, resulting in textual redundancy. Inter-modal redundancy leads to
a mismatch of video and text information, hindering the model from better
learning the shared semantics across modalities. To alleviate it, we propose
Redundancy-aware Video-language Pre-training. We design a redundancy
measurement of video patches and text tokens by calculating the cross-modal
minimum dis-similarity. Then, we penalize the highredundant video patches and
text tokens through a proposed redundancy-aware contrastive learning. We
evaluate our method on four benchmark datasets, MSRVTT, MSVD, DiDeMo, and
LSMDC, achieving a significant improvement over the previous stateof-the-art
results. Our code are available at
https://github.com/caskcsg/VLP/tree/main/RaP.",2022-10-13
Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models,2022-10-13 08:45:23+00:00,http://arxiv.org/abs/2210.06475v1,"Sourya Basu, Prasanna Sattigeri, Karthikeyan Natesan Ramamurthy, Vijil Chenthamarakshan, Kush R. Varshney, Lav R. Varshney, Payel Das","cs.LG, cs.CL",knowledge,"We introduce equi-tuning, a novel fine-tuning method that transforms
(potentially non-equivariant) pretrained models into group equivariant models
while incurring minimum $L_2$ loss between the feature representations of the
pretrained and the equivariant models. Large pretrained models can be
equi-tuned for different groups to satisfy the needs of various downstream
tasks. Equi-tuned models benefit from both group equivariance as an inductive
bias and semantic priors from pretrained models. We provide applications of
equi-tuning on three different tasks: image classification, compositional
generalization in language, and fairness in natural language generation (NLG).
We also provide a novel group-theoretic definition for fairness in NLG. The
effectiveness of this definition is shown by testing it against a standard
empirical method of fairness in NLG. We provide experimental results for
equi-tuning using a variety of pretrained models: Alexnet, Resnet, VGG, and
Densenet for image classification; RNNs, GRUs, and LSTMs for compositional
generalization; and GPT2 for fairness in NLG. We test these models on benchmark
datasets across all considered tasks to show the generality and effectiveness
of the proposed method.",2022-10-13
"CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text
  Generation Models",2022-10-09 07:16:58+00:00,http://arxiv.org/abs/2210.04191v1,"Steven Y. Feng, Vivek Khetan, Bogdan Sacaleanu, Anatole Gershman, Eduard Hovy","cs.CL, cs.AI, cs.LG",knowledge,"We motivate and introduce CHARD: Clinical Health-Aware Reasoning across
Dimensions, to investigate the capability of text generation models to act as
implicit clinical knowledge bases and generate free-flow textual explanations
about various health-related conditions across several dimensions. We collect
and present an associated dataset, CHARDat, consisting of explanations about 52
health conditions across three clinical dimensions. We conduct extensive
experiments using BART and T5 along with data augmentation, and perform
automatic, human, and qualitative analyses. We show that while our models can
perform decently, CHARD is very challenging with strong potential for further
exploration.",2022-10-09
BLAB Reporter: Automated journalism covering the Blue Amazon,2022-10-08 21:51:50+00:00,http://arxiv.org/abs/2210.06431v1,"Yan V. Sym, João Gabriel M. Campos, Fabio G. Cozman",cs.CL,knowledge,"This demo paper introduces the BLAB Reporter, a robot-journalist covering the
Brazilian Blue Amazon. The Reporter is based on a pipeline architecture for
Natural Language Generation; it offers daily reports, news summaries and
curious facts in Brazilian Portuguese. By collecting, storing and analysing
structured data from publicly available sources, the robot-journalist uses
domain knowledge to generate and publish texts in Twitter. Code and corpus are
publicly available",2022-10-08
Bird-Eye Transformers for Text Generation Models,2022-10-08 09:51:15+00:00,http://arxiv.org/abs/2210.03985v1,"Lei Sha, Yuhang Song, Yordan Yordanov, Tommaso Salvatori, Thomas Lukasiewicz",cs.CL,knowledge,"Transformers have become an indispensable module for text generation models
since their great success in machine translation. Previous works attribute
the~success of transformers to the query-key-value dot-product attention, which
provides a robust inductive bias by the fully connected token graphs. However,
we found that self-attention has a severe limitation. When predicting the
(i+1)-th token, self-attention only takes the i-th token as an information
collector, and it tends to give a high attention weight to those tokens similar
to itself. Therefore, most of the historical information that occurred before
the i-th token is not taken into consideration. Based on this observation, in
this paper, we propose a new architecture, called bird-eye transformer(BET),
which goes one step further to improve the performance of transformers by
reweighting self-attention to encourage it to focus more on important
historical information. We have conducted experiments on multiple text
generation tasks, including machine translation (2 datasets) and language
models (3 datasets). These experimental~results show that our proposed model
achieves a better performance than the baseline transformer architectures
on~all~datasets. The code is released at:
\url{https://sites.google.com/view/bet-transformer/home}.",2022-10-08
A Unified Encoder-Decoder Framework with Entity Memory,2022-10-07 01:15:30+00:00,http://arxiv.org/abs/2210.03273v1,"Zhihan Zhang, Wenhao Yu, Chenguang Zhu, Meng Jiang",cs.CL,knowledge,"Entities, as important carriers of real-world knowledge, play a key role in
many NLP tasks. We focus on incorporating entity knowledge into an
encoder-decoder framework for informative text generation. Existing approaches
tried to index, retrieve, and read external documents as evidence, but they
suffered from a large computational overhead. In this work, we propose an
encoder-decoder framework with an entity memory, namely EDMem. The entity
knowledge is stored in the memory as latent representations, and the memory is
pre-trained on Wikipedia along with encoder-decoder parameters. To precisely
generate entity names, we design three decoding methods to constrain entity
generation by linking entities in the memory. EDMem is a unified framework that
can be used on various entity-intensive question answering and generation
tasks. Extensive experimental results show that EDMem outperforms both
memory-based auto-encoder models and non-memory encoder-decoder models.",2022-10-07
"Unsupervised Sentence Textual Similarity with Compositional Phrase
  Semantics",2022-10-05 14:14:04+00:00,http://arxiv.org/abs/2210.02284v1,"Zihao Wang, Jiaheng Dou, Yong Zhang",cs.CL,knowledge,"Measuring Sentence Textual Similarity (STS) is a classic task that can be
applied to many downstream NLP applications such as text generation and
retrieval. In this paper, we focus on unsupervised STS that works on various
domains but only requires minimal data and computational resources.
Theoretically, we propose a light-weighted Expectation-Correction (EC)
formulation for STS computation. EC formulation unifies unsupervised STS
approaches including the cosine similarity of Additively Composed (AC) sentence
embeddings, Optimal Transport (OT), and Tree Kernels (TK). Moreover, we propose
the Recursive Optimal Transport Similarity (ROTS) algorithm to capture the
compositional phrase semantics by composing multiple recursive EC formulations.
ROTS finishes in linear time and is faster than its predecessors. ROTS is
empirically more effective and scalable than previous approaches. Extensive
experiments on 29 STS tasks under various settings show the clear advantage of
ROTS over existing approaches. Detailed ablation studies demonstrate the
effectiveness of our approaches.",2022-10-05
Synonym Detection Using Syntactic Dependency And Neural Embeddings,2022-09-30 03:16:41+00:00,http://arxiv.org/abs/2209.15202v1,"Dongqiang Yang, Pikun Wang, Xiaodong Sun, Ning Li","cs.CL, cs.AI",knowledge,"Recent advances on the Vector Space Model have significantly improved some
NLP applications such as neural machine translation and natural language
generation. Although word co-occurrences in context have been widely used in
counting-/predicting-based distributional models, the role of syntactic
dependencies in deriving distributional semantics has not yet been thoroughly
investigated. By comparing various Vector Space Models in detecting synonyms in
TOEFL, we systematically study the salience of syntactic dependencies in
accounting for distributional similarity. We separate syntactic dependencies
into different groups according to their various grammatical roles and then use
context-counting to construct their corresponding raw and SVD-compressed
matrices. Moreover, using the same training hyperparameters and corpora, we
study typical neural embeddings in the evaluation. We further study the
effectiveness of injecting human-compiled semantic knowledge into neural
embeddings on computing distributional similarity. Our results show that the
syntactically conditioned contexts can interpret lexical semantics better than
the unconditioned ones, whereas retrofitting neural embeddings with semantic
knowledge can significantly improve synonym detection.",2022-09-30
"Co-Writing Screenplays and Theatre Scripts with Language Models: An
  Evaluation by Industry Professionals",2022-09-29 17:26:22+00:00,http://arxiv.org/abs/2209.14958v1,"Piotr Mirowski, Kory W. Mathewson, Jaylen Pittman, Richard Evans","cs.HC, cs.CL",knowledge,"Language models are increasingly attracting interest from writers. However,
such models lack long-range semantic coherence, limiting their usefulness for
longform creative writing. We address this limitation by applying language
models hierarchically, in a system we call Dramatron. By building structural
context via prompt chaining, Dramatron can generate coherent scripts and
screenplays complete with title, characters, story beats, location
descriptions, and dialogue. We illustrate Dramatron's usefulness as an
interactive co-creative system with a user study of 15 theatre and film
industry professionals. Participants co-wrote theatre scripts and screenplays
with Dramatron and engaged in open-ended interviews. We report critical
reflections both from our interviewees and from independent reviewers who
watched stagings of the works to illustrate how both Dramatron and hierarchical
text generation could be useful for human-machine co-creativity. Finally, we
discuss the suitability of Dramatron for co-creativity, ethical considerations
-- including plagiarism and bias -- and participatory models for the design and
deployment of such tools.",2022-09-29
"DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language
  Processing",2022-09-29 16:05:53+00:00,http://arxiv.org/abs/2209.14901v1,"Yanjun Gao, Dmitriy Dligach, Timothy Miller, John Caskey, Brihat Sharma, Matthew M Churpek, Majid Afshar","cs.CL, cs.AI",knowledge,"The meaningful use of electronic health records (EHR) continues to progress
in the digital era with clinical decision support systems augmented by
artificial intelligence. A priority in improving provider experience is to
overcome information overload and reduce the cognitive burden so fewer medical
errors and cognitive biases are introduced during patient care. One major type
of medical error is diagnostic error due to systematic or predictable errors in
judgment that rely on heuristics. The potential for clinical natural language
processing (cNLP) to model diagnostic reasoning in humans with forward
reasoning from data to diagnosis and potentially reduce the cognitive burden
and medical error has not been investigated. Existing tasks to advance the
science in cNLP have largely focused on information extraction and named entity
recognition through classification tasks. We introduce a novel suite of tasks
coined as Diagnostic Reasoning Benchmarks, DR.BENCH, as a new benchmark for
developing and evaluating cNLP models with clinical diagnostic reasoning
ability. The suite includes six tasks from ten publicly available datasets
addressing clinical text understanding, medical knowledge reasoning, and
diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to
be a natural language generation framework to evaluate pre-trained language
models. Experiments with state-of-the-art pre-trained generative language
models using large general domain models and models that were continually
trained on a medical corpus demonstrate opportunities for improvement when
evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab
repository with a systematic approach to load and evaluate models for the cNLP
community.",2022-09-29
FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation,2022-09-28 17:54:55+00:00,http://arxiv.org/abs/2209.14290v1,"Sebastian Hofstätter, Jiecao Chen, Karthik Raman, Hamed Zamani","cs.CL, cs.IR",knowledge,"Retrieval-augmented generation models offer many benefits over standalone
language models: besides a textual answer to a given query they provide
provenance items retrieved from an updateable knowledge base. However, they are
also more complex systems and need to handle long inputs. In this work, we
introduce FiD-Light to strongly increase the efficiency of the state-of-the-art
retrieval-augmented FiD model, while maintaining the same level of
effectiveness. Our FiD-Light model constrains the information flow from the
encoder (which encodes passages separately) to the decoder (using concatenated
encoded representations). Furthermore, we adapt FiD-Light with re-ranking
capabilities through textual source pointers, to improve the top-ranked
provenance precision. Our experiments on a diverse set of seven knowledge
intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier
between query latency and effectiveness. FiD-Light with source pointing sets
substantial new state-of-the-art results on six KILT tasks for combined text
generation and provenance retrieval evaluation, while maintaining reasonable
efficiency.",2022-09-28
Informative Text Generation from Knowledge Triples,2022-09-26 14:35:57+00:00,http://arxiv.org/abs/2209.12733v1,"Zihao Fu, Yijiang River Dong, Lidong Bing, Wai Lam",cs.CL,knowledge,"As the development of the encoder-decoder architecture, researchers are able
to study the text generation tasks with broader types of data. Among them,
KB-to-text aims at converting a set of knowledge triples into human readable
sentences. In the original setting, the task assumes that the input triples and
the text are exactly aligned in the perspective of the embodied
knowledge/information. In this paper, we extend this setting and explore how to
facilitate the trained model to generate more informative text, namely,
containing more information about the triple entities but not conveyed by the
input triples. To solve this problem, we propose a novel memory augmented
generator that employs a memory network to memorize the useful knowledge
learned during the training and utilizes such information together with the
input triples to generate text in the operational or testing phase. We derive a
dataset from WebNLG for our new setting and conduct extensive experiments to
investigate the effectiveness of our model as well as uncover the intrinsic
characteristics of the setting.",2022-09-26
Controllable Text Generation for Open-Domain Creativity and Fairness,2022-09-24 22:40:01+00:00,http://arxiv.org/abs/2209.12099v1,Nanyun Peng,"cs.CL, cs.AI",knowledge,"Recent advances in large pre-trained language models have demonstrated strong
results in generating natural languages and significantly improved performances
for many natural language generation (NLG) applications such as machine
translation and text summarization. However, when the generation tasks are more
open-ended and the content is under-specified, existing techniques struggle to
generate long-term coherent and creative content. Moreover, the models exhibit
and even amplify social biases that are learned from the training corpora. This
happens because the generation models are trained to capture the surface
patterns (i.e. sequences of words), instead of capturing underlying semantics
and discourse structures, as well as background knowledge including social
norms. In this paper, I introduce our recent works on controllable text
generation to enhance the creativity and fairness of language generation
models. We explore hierarchical generation and constrained decoding, with
applications to creative language generation including story, poetry, and
figurative languages, and bias mitigation for generation models.",2022-09-24
"Can we do that simpler? Simple, Efficient, High-Quality Evaluation
  Metrics for NLG",2022-09-20 10:12:07+00:00,http://arxiv.org/abs/2209.09593v1,"Jens Grünwald, Christoph Leiter, Steffen Eger","cs.CL, cs.LG",knowledge,"We explore efficient evaluation metrics for Natural Language Generation
(NLG). To implement efficient metrics, we replace (i) computation-heavy
transformers in metrics such as BERTScore, MoverScore, BARTScore, XMoverScore,
etc. with lighter versions (such as distilled ones) and (ii) cubic inference
time alignment algorithms such as Word Mover Distance with linear and quadratic
approximations. We consider six evaluation metrics (both monolingual and
multilingual), assessed on three different machine translation datasets, and 16
light-weight transformers as replacement. We find, among others, that (a)
TinyBERT shows best quality-efficiency tradeoff for semantic similarity metrics
of the BERTScore family, retaining 97\% quality and being 5x faster at
inference time on average, (b) there is a large difference in speed-ups on CPU
vs. GPU (much higher speed-ups on CPU), and (c) WMD approximations yield no
efficiency gains but lead to a substantial drop in quality on 2 out of 3
datasets we examine.",2022-09-20
Selective Token Generation for Few-shot Natural Language Generation,2022-09-17 00:48:52+00:00,http://arxiv.org/abs/2209.08206v1,"Daejin Jo, Taehwan Kwon, Eun-Sol Kim, Sungwoong Kim","cs.CL, cs.LG",knowledge,"Natural language modeling with limited training data is a challenging
problem, and many algorithms make use of large-scale pretrained language models
(PLMs) for this due to its great generalization ability. Among them, additive
learning that incorporates a task-specific adapter on top of the fixed
large-scale PLM has been popularly used in the few-shot setting. However, this
added adapter is still easy to disregard the knowledge of the PLM especially
for few-shot natural language generation (NLG) since an entire sequence is
usually generated by only the newly trained adapter. Therefore, in this work,
we develop a novel additive learning algorithm based on reinforcement learning
(RL) that selectively outputs language tokens between the task-general PLM and
the task-specific adapter during both training and inference. This output token
selection over the two generators allows the adapter to take into account
solely the task-relevant parts in sequence generation, and therefore makes it
more robust to overfitting as well as more stable in RL training. In addition,
to obtain the complementary adapter from the PLM for each few-shot task, we
exploit a separate selecting module that is also simultaneously trained using
RL. Experimental results on various few-shot NLG tasks including question
answering, data-to-text generation and text summarization demonstrate that the
proposed selective token generation significantly outperforms the previous
additive learning algorithms based on the PLMs.",2022-09-17
"TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for
  Multilingual Tweet Representations",2022-09-15 19:01:21+00:00,http://arxiv.org/abs/2209.07562v1,"Xinyang Zhang, Yury Malkov, Omar Florez, Serim Park, Brian McWilliams, Jiawei Han, Ahmed El-Kishky",cs.CL,knowledge,"We present TwHIN-BERT, a multilingual language model trained on in-domain
data from the popular social network Twitter. TwHIN-BERT differs from prior
pre-trained language models as it is trained with not only text-based
self-supervision, but also with a social objective based on the rich social
engagements within a Twitter heterogeneous information network (TwHIN). Our
model is trained on 7 billion tweets covering over 100 distinct languages
providing a valuable representation to model short, noisy, user-generated text.
We evaluate our model on a variety of multilingual social recommendation and
semantic understanding tasks and demonstrate significant metric improvement
over established pre-trained language models. We will freely open-source
TwHIN-BERT and our curated hashtag prediction and social engagement benchmark
datasets to the research community.",2022-09-15
Distribution Aware Metrics for Conditional Natural Language Generation,2022-09-15 17:58:13+00:00,http://arxiv.org/abs/2209.07518v1,"David M Chan, Yiming Ni, Austin Myers, Sudheendra Vijayanarasimhan, David A Ross, John Canny","cs.CL, cs.AI, cs.CV, cs.LG",knowledge,"Traditional automated metrics for evaluating conditional natural language
generation use pairwise comparisons between a single generated text and the
best-matching gold-standard ground truth text. When multiple ground truths are
available, scores are aggregated using an average or max operation across
references. While this approach works well when diversity in the ground truth
data (i.e. dispersion of the distribution of conditional texts) can be ascribed
to noise, such as in automated speech recognition, it does not allow for robust
evaluation in the case where diversity in the ground truths represents signal
for the model. In this work we argue that existing metrics are not appropriate
for domains such as visual description or summarization where ground truths are
semantically diverse, and where the diversity in those captions captures useful
additional information about the context. We propose a novel paradigm for
multi-candidate evaluation of conditional language generation models, and a new
family of metrics that compare the distributions of reference and
model-generated caption sets using small sample sets of each. We demonstrate
the utility of our approach with a case study in visual description: where we
show that existing models optimize for single-description quality over
diversity, and gain some insights into how sampling methods and temperature
impact description quality and diversity.",2022-09-15
vec2text with Round-Trip Translations,2022-09-14 17:20:18+00:00,http://arxiv.org/abs/2209.06792v1,"Geoffrey Cideron, Sertan Girgin, Anton Raichuk, Olivier Pietquin, Olivier Bachem, Léonard Hussenot","cs.CL, cs.LG",knowledge,"We investigate models that can generate arbitrary natural language text (e.g.
all English sentences) from a bounded, convex and well-behaved control space.
We call them universal vec2text models. Such models would allow making semantic
decisions in the vector space (e.g. via reinforcement learning) while the
natural language generation is handled by the vec2text model. We propose four
desired properties: universality, diversity, fluency, and semantic structure,
that such vec2text models should possess and we provide quantitative and
qualitative methods to assess them. We implement a vec2text model by adding a
bottleneck to a 250M parameters Transformer model and training it with an
auto-encoding objective on 400M sentences (10B tokens) extracted from a massive
web corpus. We propose a simple data augmentation technique based on round-trip
translations and show in extensive experiments that the resulting vec2text
model surprisingly leads to vector spaces that fulfill our four desired
properties and that this model strongly outperforms both standard and denoising
auto-encoders.",2022-09-14
"Visual Recipe Flow: A Dataset for Learning Visual State Changes of
  Objects with Recipe Flows",2022-09-13 09:38:32+00:00,http://arxiv.org/abs/2209.05840v1,"Keisuke Shirai, Atsushi Hashimoto, Taichi Nishimura, Hirotaka Kameko, Shuhei Kurita, Yoshitaka Ushiku, Shinsuke Mori","cs.CL, cs.AI",knowledge,"We present a new multimodal dataset called Visual Recipe Flow, which enables
us to learn each cooking action result in a recipe text. The dataset consists
of object state changes and the workflow of the recipe text. The state change
is represented as an image pair, while the workflow is represented as a recipe
flow graph (r-FG). The image pairs are grounded in the r-FG, which provides the
cross-modal relation. With our dataset, one can try a range of applications,
from multimodal commonsense reasoning and procedural text generation.",2022-09-13
Elaboration-Generating Commonsense Question Answering at Scale,2022-09-02 18:32:09+00:00,http://arxiv.org/abs/2209.01232v1,"Wenya Wang, Vivek Srikumar, Hanna Hajishirzi, Noah A. Smith",cs.CL,knowledge,"In question answering requiring common sense, language models (e.g., GPT-3)
have been used to generate text expressing background knowledge that helps
improve performance. Yet the cost of working with such models is very high; in
this work, we finetune smaller language models to generate useful intermediate
context, referred to here as elaborations. Our framework alternates between
updating two language models -- an elaboration generator and an answer
predictor -- allowing each to influence the other. Using less than 0.5% of the
parameters of GPT-3, our model outperforms alternatives with similar sizes and
closes the gap on GPT-3 on four commonsense question answering benchmarks.
Human evaluations show that the quality of the generated elaborations is high.",2022-09-02
Multi-Modal Experience Inspired AI Creation,2022-09-02 11:50:41+00:00,http://arxiv.org/abs/2209.02427v1,"Qian Cao, Xu Chen, Ruihua Song, Hao Jiang, Guang Yang, Zhao Cao",cs.AI,knowledge,"AI creation, such as poem or lyrics generation, has attracted increasing
attention from both industry and academic communities, with many promising
models proposed in the past few years. Existing methods usually estimate the
outputs based on single and independent visual or textual information. However,
in reality, humans usually make creations according to their experiences, which
may involve different modalities and be sequentially correlated. To model such
human capabilities, in this paper, we define and solve a novel AI creation
problem based on human experiences. More specifically, we study how to generate
texts based on sequential multi-modal information. Compared with the previous
works, this task is much more difficult because the designed model has to well
understand and adapt the semantics among different modalities and effectively
convert them into the output in a sequential manner. To alleviate these
difficulties, we firstly design a multi-channel sequence-to-sequence
architecture equipped with a multi-modal attention network. For more effective
optimization, we then propose a curriculum negative sampling strategy tailored
for the sequential inputs. To benchmark this problem and demonstrate the
effectiveness of our model, we manually labeled a new multi-modal experience
dataset. With this dataset, we conduct extensive experiments by comparing our
model with a series of representative baselines, where we can demonstrate
significant improvements in our model based on both automatic and
human-centered metrics. The code and data are available at:
\url{https://github.com/Aman-4-Real/MMTG}.",2022-09-02
Unified Knowledge Prompt Pre-training for Customer Service Dialogues,2022-08-31 06:23:53+00:00,http://arxiv.org/abs/2208.14652v1,"Keqing He, Jingang Wang, Chaobo Sun, Wei Wu",cs.CL,knowledge,"Dialogue bots have been widely applied in customer service scenarios to
provide timely and user-friendly experience. These bots must classify the
appropriate domain of a dialogue, understand the intent of users, and generate
proper responses. Existing dialogue pre-training models are designed only for
several dialogue tasks and ignore weakly-supervised expert knowledge in
customer service dialogues. In this paper, we propose a novel unified knowledge
prompt pre-training framework, UFA (\textbf{U}nified Model \textbf{F}or
\textbf{A}ll Tasks), for customer service dialogues. We formulate all the tasks
of customer service dialogues as a unified text-to-text generation task and
introduce a knowledge-driven prompt strategy to jointly learn from a mixture of
distinct dialogue tasks. We pre-train UFA on a large-scale Chinese customer
service corpus collected from practical scenarios and get significant
improvements on both natural language understanding (NLU) and natural language
generation (NLG) benchmarks.",2022-08-31
"StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse
  Representations and Content Enhancing",2022-08-29 08:47:49+00:00,http://arxiv.org/abs/2208.13423v1,"Xuekai Zhu, Jian Guan, Minlie Huang, Juan Liu",cs.CL,knowledge,"Non-parallel text style transfer is an important task in natural language
generation. However, previous studies concentrate on the token or sentence
level, such as sentence sentiment and formality transfer, but neglect long
style transfer at the discourse level. Long texts usually involve more
complicated author linguistic preferences such as discourse structures than
sentences. In this paper, we formulate the task of non-parallel story
author-style transfer, which requires transferring an input story into a
specified author style while maintaining source semantics. To tackle this
problem, we propose a generation model, named StoryTrans, which leverages
discourse representations to capture source content information and transfer
them to target styles with learnable style embeddings. We use an additional
training objective to disentangle stylistic features from the learned discourse
representation to prevent the model from degenerating to an auto-encoder.
Moreover, to enhance content preservation, we design a mask-and-fill framework
to explicitly fuse style-specific keywords of source texts into generation.
Furthermore, we constructed new datasets for this task in Chinese and English,
respectively. Extensive experiments show that our model outperforms strong
baselines in overall performance of style transfer and content preservation.",2022-08-29
"GenTUS: Simulating User Behaviour and Language in Task-oriented
  Dialogues with Generative Transformers",2022-08-23 09:01:17+00:00,http://arxiv.org/abs/2208.10817v1,"Hsien-Chin Lin, Christian Geishauser, Shutong Feng, Nurul Lubis, Carel van Niekerk, Michael Heck, Milica Gašić",cs.CL,knowledge,"User simulators (USs) are commonly used to train task-oriented dialogue
systems (DSs) via reinforcement learning. The interactions often take place on
semantic level for efficiency, but there is still a gap from semantic actions
to natural language, which causes a mismatch between training and deployment
environment. Incorporating a natural language generation (NLG) module with USs
during training can partly deal with this problem. However, since the policy
and NLG of USs are optimised separately, these simulated user utterances may
not be natural enough in a given context. In this work, we propose a generative
transformer-based user simulator (GenTUS). GenTUS consists of an
encoder-decoder structure, which means it can optimise both the user policy and
natural language generation jointly. GenTUS generates both semantic actions and
natural language utterances, preserving interpretability and enhancing language
variation. In addition, by representing the inputs and outputs as word
sequences and by using a large pre-trained language model we can achieve
generalisability in feature representation. We evaluate GenTUS with automatic
metrics and human evaluation. Our results show that GenTUS generates more
natural language and is able to transfer to an unseen ontology in a zero-shot
fashion. In addition, its behaviour can be further shaped with reinforcement
learning opening the door to training specialised user simulators.",2022-08-23
Automatic tagging of knowledge points for K12 math problems,2022-08-21 11:11:30+00:00,http://arxiv.org/abs/2208.09867v1,"Xiaolu Wang, Ziqi Ding, Liangyu Chen",cs.CL,knowledge,"Automatic tagging of knowledge points for practice problems is the basis for
managing question bases and improving the automation and intelligence of
education. Therefore, it is of great practical significance to study the
automatic tagging technology for practice problems. However, there are few
studies on the automatic tagging of knowledge points for math problems. Math
texts have more complex structures and semantics compared with general texts
because they contain unique elements such as symbols and formulas. Therefore,
it is difficult to meet the accuracy requirement of knowledge point prediction
by directly applying the text classification techniques in general domains. In
this paper, K12 math problems taken as the research object, the LABS model
based on label-semantic attention and multi-label smoothing combining textual
features is proposed to improve the automatic tagging of knowledge points for
math problems. The model combines the text classification techniques in general
domains and the unique features of math texts. The results show that the models
using label-semantic attention or multi-label smoothing perform better on
precision, recall, and F1-score metrics than the traditional BiLSTM model,
while the LABS model using both performs best. It can be seen that label
information can guide the neural networks to extract meaningful information
from the problem text, which improves the text classification performance of
the model. Moreover, multi-label smoothing combining textual features can fully
explore the relationship between text and labels, improve the model's
prediction ability for new data and improve the model's classification
accuracy.",2022-08-21
"Performance Optimization for Semantic Communications: An Attention-based
  Reinforcement Learning Approach",2022-08-17 11:39:16+00:00,http://arxiv.org/abs/2208.08239v1,"Yining Wang, Mingzhe Chen, Tao Luo, Walid Saad, Dusit Niyato, H. Vincent Poor, Shuguang Cui","cs.IT, cs.AI, math.IT",knowledge,"In this paper, a semantic communication framework is proposed for textual
data transmission. In the studied model, a base station (BS) extracts the
semantic information from textual data, and transmits it to each user. The
semantic information is modeled by a knowledge graph (KG) that consists of a
set of semantic triples. After receiving the semantic information, each user
recovers the original text using a graph-to-text generation model. To measure
the performance of the considered semantic communication framework, a metric of
semantic similarity (MSS) that jointly captures the semantic accuracy and
completeness of the recovered text is proposed. Due to wireless resource
limitations, the BS may not be able to transmit the entire semantic information
to each user and satisfy the transmission delay constraint. Hence, the BS must
select an appropriate resource block for each user as well as determine and
transmit part of the semantic information to the users. As such, we formulate
an optimization problem whose goal is to maximize the total MSS by jointly
optimizing the resource allocation policy and determining the partial semantic
information to be transmitted. To solve this problem, a
proximal-policy-optimization-based reinforcement learning (RL) algorithm
integrated with an attention network is proposed. The proposed algorithm can
evaluate the importance of each triple in the semantic information using an
attention network and then, build a relationship between the importance
distribution of the triples in the semantic information and the total MSS.
Compared to traditional RL algorithms, the proposed algorithm can dynamically
adjust its learning rate thus ensuring convergence to a locally optimal
solution.",2022-08-17
Understanding Attention for Vision-and-Language Tasks,2022-08-17 06:45:07+00:00,http://arxiv.org/abs/2208.08104v1,"Feiqi Cao, Soyeon Caren Han, Siqu Long, Changwei Xu, Josiah Poon","cs.CV, cs.CL",knowledge,"Attention mechanism has been used as an important component across
Vision-and-Language(VL) tasks in order to bridge the semantic gap between
visual and textual features. While attention has been widely used in VL tasks,
it has not been examined the capability of different attention alignment
calculation in bridging the semantic gap between visual and textual clues. In
this research, we conduct a comprehensive analysis on understanding the role of
attention alignment by looking into the attention score calculation methods and
check how it actually represents the visual region's and textual token's
significance for the global assessment. We also analyse the conditions which
attention score calculation mechanism would be more (or less) interpretable,
and which may impact the model performance on three different VL tasks,
including visual question answering, text-to-image generation, text-and-image
matching (both sentence and image retrieval). Our analysis is the first of its
kind and provides useful insights of the importance of each attention alignment
score calculation when applied at the training phase of VL tasks, commonly
ignored in attention-based cross modal models, and/or pretrained models.",2022-08-17
"A Representation Modeling Based Language GAN with Completely Random
  Initialization",2022-08-04 08:56:04+00:00,http://arxiv.org/abs/2208.02531v1,"Da Ren, Qing Li",cs.CL,knowledge,"Text generative models trained via Maximum Likelihood Estimation (MLE) suffer
from the notorious exposure bias problem, and Generative Adversarial Networks
(GANs) are shown to have potential to tackle it. Existing language GANs adopt
estimators like REINFORCE or continuous relaxations to model word
distributions. The inherent limitations of such estimators lead current models
to rely on pre-training techniques (MLE pre-training or pre-trained
embeddings). Representation modeling methods which are free from those
limitations, however, are seldom explored because of its poor performance in
previous attempts. Our analyses reveal that invalid sampling method and
unhealthy gradients are the main contributors to its unsatisfactory
performance. In this work, we present two techniques to tackle these problems:
dropout sampling and fully normalized LSTM. Based on these two techniques, we
propose InitialGAN whose parameters are randomly initialized completely.
Besides, we introduce a new evaluation metric, Least Coverage Rate, to better
evaluate the quality of generated samples. The experimental results demonstrate
that InitialGAN outperforms both MLE and other compared models. To the best of
our knowledge, it is the first time a language GAN can outperform MLE without
any pre-training techniques.",2022-08-04
"LaKo: Knowledge-driven Visual Question Answering via Late
  Knowledge-to-Text Injection",2022-07-26 13:29:51+00:00,http://arxiv.org/abs/2207.12888v1,"Zhuo Chen, Yufeng Huang, Jiaoyan Chen, Yuxia Geng, Yin Fang, Jeff Pan, Ningyu Zhang, Wen Zhang","cs.CV, cs.AI",knowledge,"Visual question answering (VQA) often requires an understanding of visual
concepts and language semantics, which relies on external knowledge. Most
existing methods exploit pre-trained language models or/and unstructured text,
but the knowledge in these resources are often incomplete and noisy. Some
methods prefer to use knowledge graphs (KGs) which often have intensive
structured knowledge, but the research is still quite preliminary. In this
paper, we propose LaKo, a knowledge-driven VQA method via Late
Knowledge-to-text Injection. To effectively incorporate an external KG, we
transfer triples into text and propose a late injection mechanism. Finally we
address VQA as a text generation task with an effective encoder-decoder
paradigm. In the evaluation with OKVQA datasets, our method achieves
state-of-the-art results.",2022-07-26
"Leveraging Natural Supervision for Language Representation Learning and
  Generation",2022-07-21 17:26:03+00:00,http://arxiv.org/abs/2207.10617v1,Mingda Chen,cs.CL,knowledge,"Recent breakthroughs in Natural Language Processing (NLP) have been driven by
language models trained on a massive amount of plain text. While powerful,
deriving supervision from textual resources is still an open question. For
example, language model pretraining often neglects the rich, freely-available
structures in textual data. In this thesis, we describe three lines of work
that seek to improve the training and evaluation of neural models using
naturally-occurring supervision.
  We first investigate self-supervised training losses to help enhance the
performance of pretrained language models for various NLP tasks. Specifically,
we alter the sentence prediction loss to make it better suited to other
pretraining losses and more challenging to solve. We design an intermediate
finetuning step that uses self-supervised training to promote models' ability
in cross-task generalization.
  Then we describe methods to leverage the structures in Wikipedia and
paraphrases. In particular, we propose training losses to exploit hyperlinks,
article structures, and article category graphs for entity-, discourse-,
entailment-related knowledge. We propose a framework that uses paraphrase pairs
to disentangle semantics and syntax in sentence representations. We extend the
framework for a novel generation task that controls the syntax of output text
with a sentential exemplar.
  Lastly, we discuss our work on tailoring textual resources for establishing
challenging evaluation tasks. We introduce three datasets by defining novel
tasks using various fan-contributed websites, including a long-form
data-to-text generation dataset, a screenplay summarization dataset, and a
long-form story generation dataset. These datasets have unique characteristics
offering challenges to future work in their respective task settings.",2022-07-21
"Syntax Controlled Knowledge Graph-to-Text Generation with Order and
  Semantic Consistency",2022-07-02 02:42:14+00:00,http://arxiv.org/abs/2207.00719v1,"Jin Liu, Chongfeng Fan, Fengyu Zhou, Huijuan Xu",cs.AI,knowledge,"The knowledge graph (KG) stores a large amount of structural knowledge, while
it is not easy for direct human understanding. Knowledge graph-to-text
(KG-to-text) generation aims to generate easy-to-understand sentences from the
KG, and at the same time, maintains semantic consistency between generated
sentences and the KG. Existing KG-to-text generation methods phrase this task
as a sequence-to-sequence generation task with linearized KG as input and
consider the consistency issue of the generated texts and KG through a simple
selection between decoded sentence word and KG node word at each time step.
However, the linearized KG order is commonly obtained through a heuristic
search without data-driven optimization. In this paper, we optimize the
knowledge description order prediction under the order supervision extracted
from the caption and further enhance the consistency of the generated sentences
and KG through syntactic and semantic regularization. We incorporate the
Part-of-Speech (POS) syntactic tags to constrain the positions to copy words
from the KG and employ a semantic context scoring function to evaluate the
semantic fitness for each word in its local context when decoding each word in
the generated sentence. Extensive experiments are conducted on two datasets,
WebNLG and DART, and achieve state-of-the-art performances.",2022-07-02
"Is neural language acquisition similar to natural? A chronological
  probing study",2022-07-01 17:24:11+00:00,http://arxiv.org/abs/2207.00560v1,"Ekaterina Voloshina, Oleg Serikov, Tatiana Shavrina",cs.CL,knowledge,"The probing methodology allows one to obtain a partial representation of
linguistic phenomena stored in the inner layers of the neural network, using
external classifiers and statistical analysis. Pre-trained transformer-based
language models are widely used both for natural language understanding (NLU)
and natural language generation (NLG) tasks making them most commonly used for
downstream applications. However, little analysis was carried out, whether the
models were pre-trained enough or contained knowledge correlated with
linguistic theory. We are presenting the chronological probing study of
transformer English models such as MultiBERT and T5. We sequentially compare
the information about the language learned by the models in the process of
training on corpora. The results show that 1) linguistic information is
acquired in the early stages of training 2) both language models demonstrate
capabilities to capture various features from various levels of language,
including morphology, syntax, and even discourse, while they also can
inconsistently fail on tasks that are perceived as easy. We also introduce the
open-source framework for chronological probing research, compatible with other
transformer-based models.
https://github.com/EkaterinaVoloshina/chronological_probing",2022-07-01
Evaluation of Semantic Answer Similarity Metrics,2022-06-25 14:40:36+00:00,http://arxiv.org/abs/2206.12664v1,"Farida Mustafazade, Peter F. Ebbinghaus","cs.CL, cs.AI, cs.LG",knowledge,"There are several issues with the existing general machine translation or
natural language generation evaluation metrics, and question-answering (QA)
systems are indifferent in that context. To build robust QA systems, we need
the ability to have equivalently robust evaluation systems to verify whether
model predictions to questions are similar to ground-truth annotations. The
ability to compare similarity based on semantics as opposed to pure string
overlap is important to compare models fairly and to indicate more realistic
acceptance criteria in real-life applications. We build upon the first to our
knowledge paper that uses transformer-based model metrics to assess semantic
answer similarity and achieve higher correlations to human judgement in the
case of no lexical overlap. We propose cross-encoder augmented bi-encoder and
BERTScore models for semantic answer similarity, trained on a new dataset
consisting of name pairs of US-American public figures. As far as we are
concerned, we provide the first dataset of co-referent name string pairs along
with their similarities, which can be used for training.
  Machine Learning & Applications 4th International Conference on Machine
Learning & Applications (CMLA 2022) June 25~26, 2022, Copenhagen, Denmark
Volume Editors : David C. Wyld, Dhinaharan Nagamalai (Eds) ISBN :
978-1-925953-69-5",2022-06-25
"BenchCLAMP: A Benchmark for Evaluating Language Models on Semantic
  Parsing",2022-06-21 18:34:11+00:00,http://arxiv.org/abs/2206.10668v1,"Subhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, Benjamin Van Durme",cs.CL,knowledge,"We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model
Parsing, which produces semantic outputs based on the analysis of input text
through constrained decoding of a prompted or fine-tuned language model.
Developers of pretrained language models currently benchmark on classification,
span extraction and free-text generation tasks. Semantic parsing is neglected
in language model evaluation because of the complexity of handling
task-specific architectures and representations. Recent work has shown that
generation from a prompted or fine-tuned language model can perform well at
semantic parsing when the output is constrained to be a valid semantic
representation. BenchCLAMP includes context-free grammars for six semantic
parsing datasets with varied output meaning representations, as well as a
constrained decoding interface to generate outputs covered by these grammars.
We provide low, medium, and high resource splits for each dataset, allowing
accurate comparison of various language models under different data regimes.
Our benchmark supports both prompt-based learning as well as fine-tuning, and
provides an easy-to-use toolkit for language model developers to evaluate on
semantic parsing.",2022-06-21
"Interpretable AMR-Based Question Decomposition for Multi-hop Question
  Answering",2022-06-16 23:46:33+00:00,http://arxiv.org/abs/2206.08486v1,"Zhenyun Deng, Yonghua Zhu, Yang Chen, Michael Witbrock, Patricia Riddle",cs.CL,knowledge,"Effective multi-hop question answering (QA) requires reasoning over multiple
scattered paragraphs and providing explanations for answers. Most existing
approaches cannot provide an interpretable reasoning process to illustrate how
these models arrive at an answer. In this paper, we propose a Question
Decomposition method based on Abstract Meaning Representation (QDAMR) for
multi-hop QA, which achieves interpretable reasoning by decomposing a multi-hop
question into simpler sub-questions and answering them in order. Since
annotating the decomposition is expensive, we first delegate the complexity of
understanding the multi-hop question to an AMR parser. We then achieve the
decomposition of a multi-hop question via segmentation of the corresponding AMR
graph based on the required reasoning type. Finally, we generate sub-questions
using an AMR-to-Text generation model and answer them with an off-the-shelf QA
model. Experimental results on HotpotQA demonstrate that our approach is
competitive for interpretable reasoning and that the sub-questions generated by
QDAMR are well-formed, outperforming existing question-decomposition-based
multi-hop QA approaches.",2022-06-16
An Exploration of Post-Editing Effectiveness in Text Summarization,2022-06-13 18:00:02+00:00,http://arxiv.org/abs/2206.06383v1,"Vivian Lai, Alison Smith-Renner, Ke Zhang, Ruijia Cheng, Wenjuan Zhang, Joel Tetreault, Alejandro Jaimes","cs.CL, cs.AI, cs.HC",knowledge,"Automatic summarization methods are efficient but can suffer from low
quality. In comparison, manual summarization is expensive but produces higher
quality. Can humans and AI collaborate to improve summarization performance? In
similar text generation tasks (e.g., machine translation), human-AI
collaboration in the form of ""post-editing"" AI-generated text reduces human
workload and improves the quality of AI output. Therefore, we explored whether
post-editing offers advantages in text summarization. Specifically, we
conducted an experiment with 72 participants, comparing post-editing provided
summaries with manual summarization for summary quality, human efficiency, and
user experience on formal (XSum news) and informal (Reddit posts) text. This
study sheds valuable insights on when post-editing is useful for text
summarization: it helped in some cases (e.g., when participants lacked domain
knowledge) but not in others (e.g., when provided summaries include inaccurate
information). Participants' different editing strategies and needs for
assistance offer implications for future human-AI summarization systems.",2022-06-13
Plot Writing From Pre-Trained Language Models,2022-06-07 05:30:46+00:00,http://arxiv.org/abs/2206.03021v1,"Yiping Jin, Vishakha Kadam, Dittaya Wanvarie",cs.CL,knowledge,"Pre-trained language models (PLMs) fail to generate long-form narrative text
because they do not consider global structure. As a result, the generated texts
are often incohesive, repetitive, or lack content. Recent work in story
generation reintroduced explicit content planning in the form of prompts,
keywords, or semantic frames. Trained on large parallel corpora, these models
can generate more logical event sequences and thus more contentful stories.
However, these intermediate representations are often not in natural language
and cannot be utilized by PLMs without fine-tuning. We propose generating story
plots using off-the-shelf PLMs while maintaining the benefit of content
planning to generate cohesive and contentful stories. Our proposed method,
ScratchPlot, first prompts a PLM to compose a content plan. Then, we generate
the story's body and ending conditioned on the content plan. Furthermore, we
take a generate-and-rank approach by using additional PLMs to rank the
generated (story, ending) pairs. We benchmark our method with various baselines
and achieved superior results in both human and automatic evaluation.",2022-06-07
"Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for
  Answer Retrieval",2022-06-07 02:39:24+00:00,http://arxiv.org/abs/2206.02978v1,"Yanmeng Wang, Jun Bai, Ye Wang, Jianfei Zhang, Wenge Rong, Zongcheng Ji, Shaojun Wang, Jing Xiao","cs.CL, cs.AI",knowledge,"Dual-Encoders is a promising mechanism for answer retrieval in question
answering (QA) systems. Currently most conventional Dual-Encoders learn the
semantic representations of questions and answers merely through matching
score. Researchers proposed to introduce the QA interaction features in scoring
function but at the cost of low efficiency in inference stage. To keep
independent encoding of questions and answers during inference stage,
variational auto-encoder is further introduced to reconstruct answers
(questions) from question (answer) embeddings as an auxiliary task to enhance
QA interaction in representation learning in training stage. However, the needs
of text generation and answer retrieval are different, which leads to hardness
in training. In this work, we propose a framework to enhance the Dual-Encoders
model with question answer cross-embeddings and a novel Geometry Alignment
Mechanism (GAM) to align the geometry of embeddings from Dual-Encoders with
that from Cross-Encoders. Extensive experimental results show that our
framework significantly improves Dual-Encoders model and outperforms the
state-of-the-art method on multiple answer retrieval datasets.",2022-06-07
"Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for
  Text-to-Speech",2022-06-05 10:50:34+00:00,http://arxiv.org/abs/2206.02147v1,"Ziyue Jiang, Su Zhe, Zhou Zhao, Qian Yang, Yi Ren, Jinglin Liu, Zhenhui Ye","eess.AS, cs.CL, cs.SD",knowledge,"Polyphone disambiguation aims to capture accurate pronunciation knowledge
from natural text sequences for reliable Text-to-speech (TTS) systems. However,
previous approaches require substantial annotated training data and additional
efforts from language experts, making it difficult to extend high-quality
neural TTS systems to out-of-domain daily conversations and countless languages
worldwide. This paper tackles the polyphone disambiguation problem from a
concise and novel perspective: we propose Dict-TTS, a semantic-aware generative
text-to-speech model with an online website dictionary (the existing prior
information in the natural language). Specifically, we design a
semantics-to-pronunciation attention (S2PA) module to match the semantic
patterns between the input text sequence and the prior semantics in the
dictionary and obtain the corresponding pronunciations; The S2PA module can be
easily trained with the end-to-end TTS model without any annotated phoneme
labels. Experimental results in three languages show that our model outperforms
several strong baseline models in terms of pronunciation accuracy and improves
the prosody modeling of TTS systems. Further extensive analyses with different
linguistic encoders demonstrate that each design in Dict-TTS is effective.
Audio samples are available at \url{https://dicttts.github.io/DictTTS-Demo/}.",2022-06-05
Beyond Opinion Mining: Summarizing Opinions of Customer Reviews,2022-06-03 12:43:40+00:00,http://arxiv.org/abs/2206.01543v1,"Reinald Kim Amplayo, Arthur Bražinskas, Yoshi Suhara, Xiaolan Wang, Bing Liu","cs.CL, cs.AI, cs.LG",knowledge,"Customer reviews are vital for making purchasing decisions in the Information
Age. Such reviews can be automatically summarized to provide the user with an
overview of opinions. In this tutorial, we present various aspects of opinion
summarization that are useful for researchers and practitioners. First, we will
introduce the task and major challenges. Then, we will present existing opinion
summarization solutions, both pre-neural and neural. We will discuss how
summarizers can be trained in the unsupervised, few-shot, and supervised
regimes. Each regime has roots in different machine learning methods, such as
auto-encoding, controllable text generation, and variational inference.
Finally, we will discuss resources and evaluation methods and conclude with the
future directions. This three-hour tutorial will provide a comprehensive
overview over major advances in opinion summarization. The listeners will be
well-equipped with the knowledge that is both useful for research and practical
applications.",2022-06-03
Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach,2022-05-26 06:36:53+00:00,http://arxiv.org/abs/2205.13183v1,"Chao Zhao, Faeze Brahman, Tenghao Huang, Snigdha Chaturvedi",cs.CL,knowledge,"Pre-trained models (PTMs) have lead to great improvements in natural language
generation (NLG). However, it is still unclear how much commonsense knowledge
they possess. With the goal of evaluating commonsense knowledge of NLG models,
recent work has proposed the problem of generative commonsense reasoning, e.g.,
to compose a logical sentence given a set of unordered concepts. Existing
approaches to this problem hypothesize that PTMs lack sufficient parametric
knowledge for this task, which can be overcome by introducing external
knowledge or task-specific pre-training objectives. Different from this trend,
we argue that PTM's inherent ability for generative commonsense reasoning is
underestimated due to the order-agnostic property of its input. In particular,
we hypothesize that the order of the input concepts can affect the PTM's
ability to utilize its commonsense knowledge. To this end, we propose a
pre-ordering approach to elaborately manipulate the order of the given concepts
before generation. Experiments show that our approach can outperform the more
sophisticated models that have access to a lot of external data and resources.",2022-05-26
"Automatic question generation based on sentence structure analysis using
  machine learning approach",2022-05-25 14:35:29+00:00,http://arxiv.org/abs/2205.12811v1,"Miroslav Blšták, Viera Rozinajová","cs.CL, cs.AI",knowledge,"Automatic question generation is one of the most challenging tasks of Natural
Language Processing. It requires ""bidirectional"" language processing: firstly,
the system has to understand the input text (Natural Language Understanding)
and it then has to generate questions also in the form of text (Natural
Language Generation). In this article, we introduce our framework for
generating the factual questions from unstructured text in the English
language. It uses a combination of traditional linguistic approaches based on
sentence patterns with several machine learning methods. We firstly obtain
lexical, syntactic and semantic information from an input text and we then
construct a hierarchical set of patterns for each sentence. The set of features
is extracted from the patterns and it is then used for automated learning of
new transformation rules. Our learning process is totally data-driven because
the transformation rules are obtained from a set of initial sentence-question
pairs. The advantages of this approach lie in a simple expansion of new
transformation rules which allows us to generate various types of questions and
also in the continuous improvement of the system by reinforcement learning. The
framework also includes a question evaluation module which estimates the
quality of generated questions. It serves as a filter for selecting the best
questions and eliminating incorrect ones or duplicates. We have performed
several experiments to evaluate the correctness of generated questions and we
have also compared our system with several state-of-the-art systems. Our
results indicate that the quality of generated questions outperforms the
state-of-the-art systems and our questions are also comparable to questions
created by humans. We have also created and published an interface with all
created datasets and evaluated questions, so it is possible to follow up on our
work.",2022-05-25
PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation,2022-05-25 11:55:54+00:00,http://arxiv.org/abs/2205.12697v1,"Ao Liu, Haoyu Dong, Naoaki Okazaki, Shi Han, Dongmei Zhang",cs.CL,knowledge,"Logical table-to-text generation is a task that involves generating logically
faithful sentences from tables, which requires models to derive logical level
facts from table records via logical inference. It raises a new challenge on
the logical-level content planning of table-to-text models. However, directly
learning the logical inference knowledge from table-text pairs is very
difficult for neural models because of the ambiguity of natural language and
the scarcity of parallel data. Hence even large-scale pre-trained language
models present low logical fidelity on logical table-to-text. In this work, we
propose a PLOG (Pretrained Logical Form Generator) framework to improve the
generation fidelity. Specifically, PLOG is first pretrained on a
table-to-logic-form generation (table-to-logic) task, then finetuned on
downstream table-to-text tasks. The formal definition of logical forms enables
us to collect large amount of accurate logical forms from tables without human
annotation. In addition, PLOG can learn logical inference from table-logic
pairs much more definitely than from table-text pairs. To evaluate our model,
we further collect a controlled logical table-to-text dataset CONTLOG based on
an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms
strong baselines by a large margin on the logical fidelity, demonstrating the
effectiveness of table-to-logic pretraining.",2022-05-25
Exploring industrial safety knowledge via Zipf law,2022-05-25 10:22:14+00:00,http://arxiv.org/abs/2205.12636v1,"Zhenhua Wang, Ming Ren, Dong Gao, Zhuang Li",cs.CL,knowledge,"The hazard and operability analysis (HAZOP) report contains precious
industrial safety knowledge (ISK) with expert experience and process nature,
which is of great significance to the development of industrial intelligence.
Subject to the attributes of ISK, existing researches mine them through
sequence labeling in deep learning. Yet, there are two thorny issues: (1)
Uneven distribution of ISK and (2) Consistent importance of ISK: for safety
review. In this study, we propose a novel generative mining strategy called
CRGM to explore ISK. Inspired Zipf law in linguistics, CRGM consists of
common-rare discriminator, induction-extension generator and ISK extractor.
Firstly, the common-rare discriminator divides HAZOP descriptions into common
words and rare words, and obtains the common description and the rare
description, where the latter contains more industrial substances. Then, they
are operated by the induction-extension generator in the way of deep text
generation, the common description is induced and the rare description is
extended, the material knowledge and the equipment knowledge can be enriched.
Finally, the ISK extractor processes the material knowledge and equipment
knowledge from the generated description through the rule template method, the
additional ISK is regarded as the supplement of the training set to train the
proposed sequence labeling model. We conduct multiple evaluation experiments on
two industrial safety datasets. The results show that CRGM has promising and
gratifying aptitudes, greatly improves the performance of the model, and is
efficient and generalized. Our sequence labeling model also shows the expected
performance, which is better than the existing research. Our research provides
a new perspective for exploring ISK, we hope it can contribute support for the
intelligent progress of industrial safety.",2022-05-25
"RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText
  Generators",2022-05-25 09:06:04+00:00,http://arxiv.org/abs/2205.12590v1,"Rilwan A. Adewoyin, Ritabrata Dutta, Yulan He",cs.CL,knowledge,"In this paper, we study the task of improving the cohesion and coherence of
long-form text generated by language models. To this end, we propose RSTGen, a
framework that utilises Rhetorical Structure Theory (RST), a classical language
theory, to control the discourse structure, semantics and topics of generated
text. Firstly, we demonstrate our model's ability to control structural
discourse and semantic features of generated text in open generation
evaluation. Then we experiment on the two challenging long-form text tasks of
argument generation and story generation. Evaluation using automated metrics
and a metric with high correlation to human evaluation, shows that our model
performs competitively against existing models, while offering significantly
more controls over generated text than alternative methods.",2022-05-25
"A Dynamic, Interpreted CheckList for Meaning-oriented NLG Metric
  Evaluation -- through the Lens of Semantic Similarity Rating",2022-05-24 16:19:32+00:00,http://arxiv.org/abs/2205.12176v1,"Laura Zeidler, Juri Opitz, Anette Frank",cs.CL,knowledge,"Evaluating the quality of generated text is difficult, since traditional NLG
evaluation metrics, focusing more on surface form than meaning, often fail to
assign appropriate scores. This is especially problematic for AMR-to-text
evaluation, given the abstract nature of AMR. Our work aims to support the
development and improvement of NLG evaluation metrics that focus on meaning, by
developing a dynamic CheckList for NLG metrics that is interpreted by being
organized around meaning-relevant linguistic phenomena. Each test instance
consists of a pair of sentences with their AMR graphs and a human-produced
textual semantic similarity or relatedness score. Our CheckList facilitates
comparative evaluation of metrics and reveals strengths and weaknesses of novel
and traditional metrics. We demonstrate the usefulness of CheckList by
designing a new metric GraCo that computes lexical cohesion graphs over AMR
concepts. Our analysis suggests that GraCo presents an interesting NLG metric
worth future investigation and that meaning-oriented NLG metrics can profit
from graph-based metric components using AMR.",2022-05-24
What Makes Data-to-Text Generation Hard for Pretrained Language Models?,2022-05-23 17:58:39+00:00,http://arxiv.org/abs/2205.11505v1,"Moniba Keymanesh, Adrian Benton, Mark Dredze","cs.CL, cs.AI, cs.IR, cs.LG",knowledge,"Expressing natural language descriptions of structured facts or relations --
data-to-text generation (D2T) -- increases the accessibility of structured
knowledge repositories. Previous work shows that pre-trained language
models(PLMs) perform remarkably well on this task after fine-tuning on a
significant amount of task-specific training data. On the other hand, while
auto-regressive PLMs can generalize from a few task examples, their efficacy at
D2T is largely unexplored. Furthermore, we have an incomplete understanding of
the limits of PLMs on D2T.
  In this work, we conduct an empirical study of both fine-tuned and
auto-regressive PLMs on the DART multi-domain D2T dataset. We consider their
performance as a function of the amount of task-specific data and how these
data are incorporated into the models: zero and few-shot learning, and
fine-tuning of model weights. In addition, we probe the limits of PLMs by
measuring performance on subsets of the evaluation data: novel predicates and
abstractive test examples. To improve the performance on these subsets, we
investigate two techniques: providing predicate descriptions in the context and
re-ranking generated candidates by information reflected in the source.
Finally, we conduct a human evaluation of model errors and show that D2T
generation tasks would benefit from datasets with more careful manual curation.",2022-05-23
A Self-Paced Mixed Distillation Method for Non-Autoregressive Generation,2022-05-23 09:54:53+00:00,http://arxiv.org/abs/2205.11162v1,"Weizhen Qi, Yeyun Gong, Yelong Shen, Jian Jiao, Yu Yan, Houqiang Li, Ruofei Zhang, Weizhu Chen, Nan Duan",cs.CL,knowledge,"Non-Autoregressive generation is a sequence generation paradigm, which
removes the dependency between target tokens. It could efficiently reduce the
text generation latency with parallel decoding in place of token-by-token
sequential decoding. However, due to the known multi-modality problem,
Non-Autoregressive (NAR) models significantly under-perform Auto-regressive
(AR) models on various language generation tasks. Among the NAR models, BANG is
the first large-scale pre-training model on English un-labeled raw text corpus.
It considers different generation paradigms as its pre-training tasks including
Auto-regressive (AR), Non-Autoregressive (NAR), and semi-Non-Autoregressive
(semi-NAR) information flow with multi-stream strategy. It achieves
state-of-the-art performance without any distillation techniques. However, AR
distillation has been shown to be a very effective solution for improving NAR
performance. In this paper, we propose a novel self-paced mixed distillation
method to further improve the generation quality of BANG. Firstly, we propose
the mixed distillation strategy based on the AR stream knowledge. Secondly, we
encourage the model to focus on the samples with the same modality by
self-paced learning. The proposed self-paced mixed distillation algorithm
improves the generation quality and has no influence on the inference latency.
We carry out extensive experiments on summarization and question generation
tasks to validate the effectiveness. To further illustrate the commercial value
of our approach, we conduct experiments on three generation tasks in real-world
advertisements applications. Experimental results on commercial data show the
effectiveness of the proposed model. Compared with BANG, it achieves
significant BLEU score improvement. On the other hand, compared with
auto-regressive generation method, it achieves more than 7x speedup.",2022-05-23
"CORAL: Contextual Response Retrievability Loss Function for Training
  Dialog Generation Models",2022-05-21 10:36:22+00:00,http://arxiv.org/abs/2205.10558v1,"Bishal Santra, Ravi Ghadia, Arpit Dwivedi, Manish Gupta, Pawan Goyal",cs.CL,knowledge,"Natural Language Generation (NLG) represents a large collection of tasks in
the field of NLP. While many of these tasks have been tackled well by the
cross-entropy (CE) loss, the task of dialog generation poses a few unique
challenges for this loss function. First, CE loss assumes that for any given
input, the only possible output is the one available as the ground truth in the
training dataset. In general, this is not true for any task, as there can be
multiple semantically equivalent sentences, each with a different surface form.
This problem gets exaggerated further for the dialog generation task, as there
can be multiple valid responses (for a given context) that not only have
different surface forms but are also not semantically equivalent. Second, CE
loss does not take the context into consideration while processing the response
and, hence, it treats all ground truths with equal importance irrespective of
the context. But, we may want our final agent to avoid certain classes of
responses (e.g. bland, non-informative or biased responses) and give relatively
higher weightage for more context-specific responses. To circumvent these
shortcomings of the CE loss, in this paper, we propose a novel loss function,
CORAL, that directly optimizes recently proposed estimates of human preference
for generated responses. Using CORAL, we can train dialog generation models
without assuming non-existence of response other than the ground-truth. Also,
the CORAL loss is computed based on both the context and the response.
Extensive comparisons on two benchmark datasets show that the proposed methods
outperform strong state-of-the-art baseline models of different sizes.",2022-05-21
"Exploiting Inductive Bias in Transformers for Unsupervised
  Disentanglement of Syntax and Semantics with VAEs",2022-05-12 08:21:38+00:00,http://arxiv.org/abs/2205.05943v2,"Ghazi Felhi, Joseph Le Roux, Djamé Seddah","cs.CL, cs.LG",knowledge,"We propose a generative model for text generation, which exhibits
disentangled latent representations of syntax and semantics. Contrary to
previous work, this model does not need syntactic information such as
constituency parses, or semantic information such as paraphrase pairs. Our
model relies solely on the inductive bias found in attention-based
architectures such as Transformers.
  In the attention of Transformers, keys handle information selection while
values specify what information is conveyed. Our model, dubbed QKVAE, uses
Attention in its decoder to read latent variables where one latent variable
infers keys while another infers values. We run experiments on latent
representations and experiments on syntax/semantics transfer which show that
QKVAE displays clear signs of disentangled syntax and semantics. We also show
that our model displays competitive syntax transfer capabilities when compared
to supervised models and that comparable supervised models need a fairly large
amount of data (more than 50K samples) to outperform it on both syntactic and
semantic transfer. The code for our experiments is publicly available.",2022-05-12
"Robust (Controlled) Table-to-Text Generation with Structure-Aware
  Equivariance Learning",2022-05-08 23:37:27+00:00,http://arxiv.org/abs/2205.03972v1,"Fei Wang, Zhewei Xu, Pedro Szekely, Muhao Chen","cs.CL, cs.AI, cs.LG",knowledge,"Controlled table-to-text generation seeks to generate natural language
descriptions for highlighted subparts of a table. Previous SOTA systems still
employ a sequence-to-sequence generation method, which merely captures the
table as a linear structure and is brittle when table layouts change. We seek
to go beyond this paradigm by (1) effectively expressing the relations of
content pieces in the table, and (2) making our model robust to
content-invariant structural transformations. Accordingly, we propose an
equivariance learning framework, which encodes tables with a structure-aware
self-attention mechanism. This prunes the full self-attention structure into an
order-invariant graph attention that captures the connected graph structure of
cells belonging to the same row or column, and it differentiates between
relevant cells and irrelevant cells from the structural perspective. Our
framework also modifies the positional encoding mechanism to preserve the
relative position of tokens in the same cell but enforce position invariance
among different cells. Our technology is free to be plugged into existing
table-to-text generation models, and has improved T5-based models to offer
better performance on ToTTo and HiTab. Moreover, on a harder version of ToTTo,
we preserve promising performance, while previous SOTA systems, even with
transformation-based data augmentation, have seen significant performance
drops. Our code is available at https://github.com/luka-group/Lattice.",2022-05-08
Language Models Can See: Plugging Visual Controls in Text Generation,2022-05-05 13:56:18+00:00,http://arxiv.org/abs/2205.02655v1,"Yixuan Su, Tian Lan, Yahui Liu, Fangyu Liu, Dani Yogatama, Yan Wang, Lingpeng Kong, Nigel Collier","cs.CV, cs.CL",knowledge,"Generative language models (LMs) such as GPT-2/3 can be prompted to generate
text with remarkable quality. While they are designed for text-prompted
generation, it remains an open question how the generation process could be
guided by modalities beyond text such as images. In this work, we propose a
training-free framework, called MAGIC (iMAge-Guided text generatIon with CLIP),
for plugging in visual controls in the generation process and enabling LMs to
perform multimodal tasks (e.g., image captioning) in a zero-shot manner. MAGIC
is a simple yet efficient plug-and-play framework, which directly combines an
off-the-shelf LM (i.e., GPT-2) and an image-text matching model (i.e., CLIP)
for image-grounded text generation. During decoding, MAGIC influences the
generation of the LM by introducing a CLIP-induced score, called magic score,
which regularizes the generated result to be semantically related to a given
image while being coherent to the previously generated context. Notably, the
proposed decoding scheme does not involve any gradient update operation,
therefore being computationally efficient. On the challenging task of zero-shot
image captioning, MAGIC outperforms the state-of-the-art method by notable
margins with a nearly 27 times decoding speedup. MAGIC is a flexible framework
and is theoretically compatible with any text generation tasks that incorporate
image grounding. In the experiments, we showcase that it is also capable of
performing visually grounded story generation given both an image and a text
prompt.",2022-05-05
Efficient Few-Shot Fine-Tuning for Opinion Summarization,2022-05-04 16:38:37+00:00,http://arxiv.org/abs/2205.02170v1,"Arthur Bražinskas, Ramesh Nallapati, Mohit Bansal, Markus Dreyer","cs.CL, cs.AI, cs.LG",knowledge,"Abstractive summarization models are typically pre-trained on large amounts
of generic texts, then fine-tuned on tens or hundreds of thousands of annotated
samples. However, in opinion summarization, large annotated datasets of reviews
paired with reference summaries are not available and would be expensive to
create. This calls for fine-tuning methods robust to overfitting on small
datasets. In addition, generically pre-trained models are often not accustomed
to the specifics of customer reviews and, after fine-tuning, yield summaries
with disfluencies and semantic mistakes. To address these problems, we utilize
an efficient few-shot method based on adapters which, as we show, can easily
store in-domain knowledge. Instead of fine-tuning the entire model, we add
adapters and pre-train them in a task-specific way on a large corpus of
unannotated customer reviews, using held-out reviews as pseudo summaries. Then,
fine-tune the adapters on the small available human-annotated dataset. We show
that this self-supervised adapter pre-training improves summary quality over
standard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp
datasets, respectively. Finally, for summary personalization, we condition on
aspect keyword queries, automatically created from generic datasets. In the
same vein, we pre-train the adapters in a query-based manner on customer
reviews and then fine-tune them on annotated datasets. This results in
better-organized summary content reflected in improved coherence and fewer
redundancies.",2022-05-04
"Faithful to the Document or to the World? Mitigating Hallucinations via
  Entity-linked Knowledge in Abstractive Summarization",2022-04-28 20:28:45+00:00,http://arxiv.org/abs/2204.13761v1,"Yue Dong, John Wieting, Pat Verga",cs.CL,knowledge,"Despite recent advances in abstractive summarization, current summarization
systems still suffer from content hallucinations where models generate text
that is either irrelevant or contradictory to the source document. However,
prior work has been predicated on the assumption that any generated facts not
appearing explicitly in the source are undesired hallucinations. Methods have
been proposed to address this scenario by ultimately improving `faithfulness'
to the source document, but in reality, there is a large portion of entities in
the gold reference targets that are not directly in the source. In this work,
we show that these entities are not aberrations, but they instead require
utilizing external world knowledge to infer reasoning paths from entities in
the source. We show that by utilizing an external knowledge base, we can
improve the faithfulness of summaries without simply making them more
extractive, and additionally, we show that external knowledge bases linked from
the source can benefit the factuality of generated summaries.",2022-04-28
"Recovering Patient Journeys: A Corpus of Biomedical Entities and
  Relations on Twitter (BEAR)",2022-04-21 08:18:44+00:00,http://arxiv.org/abs/2204.09952v1,"Amelie Wührl, Roman Klinger","cs.CL, cs.IR",knowledge,"Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.",2022-04-21
"A Survey on Non-Autoregressive Generation for Neural Machine Translation
  and Beyond",2022-04-20 07:25:22+00:00,http://arxiv.org/abs/2204.09269v1,"Yisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, Tie-yan Liu","cs.CL, cs.LG",knowledge,"Non-autoregressive (NAR) generation, which is first proposed in neural
machine translation (NMT) to speed up inference, has attracted much attention
in both machine learning and natural language processing communities. While NAR
generation can significantly accelerate inference speed for machine
translation, the speedup comes at the cost of sacrificed translation accuracy
compared to its counterpart, auto-regressive (AR) generation. In recent years,
many new models and algorithms have been designed/proposed to bridge the
accuracy gap between NAR generation and AR generation. In this paper, we
conduct a systematic survey with comparisons and discussions of various
non-autoregressive translation (NAT) models from different aspects.
Specifically, we categorize the efforts of NAT into several groups, including
data manipulation, modeling methods, training criterion, decoding algorithms,
and the benefit from pre-trained models. Furthermore, we briefly review other
applications of NAR models beyond machine translation, such as dialogue
generation, text summarization, grammar error correction, semantic parsing,
speech synthesis, and automatic speech recognition. In addition, we also
discuss potential directions for future exploration, including releasing the
dependency of KD, dynamic length prediction, pre-training for NAR, and wider
applications, etc. We hope this survey can help researchers capture the latest
progress in NAR generation, inspire the design of advanced NAR models and
algorithms, and enable industry practitioners to choose appropriate solutions
for their applications. The web page of this survey is at
\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}.",2022-04-20
"Rows from Many Sources: Enriching row completions from Wikidata with a
  pre-trained Language Model",2022-04-14 15:11:52+00:00,http://arxiv.org/abs/2204.07014v1,"Carina Negreanu, Alperen Karaoglu, Jack Williams, Shuang Chen, Daniel Fabian, Andrew Gordon, Chin-Yew Lin","cs.CL, cs.AI",knowledge,"Row completion is the task of augmenting a given table of text and numbers
with additional, relevant rows. The task divides into two steps: subject
suggestion, the task of populating the main column; and gap filling, the task
of populating the remaining columns. We present state-of-the-art results for
subject suggestion and gap filling measured on a standard benchmark
(WikiTables). Our idea is to solve this task by harmoniously combining
knowledge base table interpretation and free text generation. We interpret the
table using the knowledge base to suggest new rows and generate metadata like
headers through property linking. To improve candidate diversity, we synthesize
additional rows using free text generation via GPT-3, and crucially, we exploit
the metadata we interpret to produce better prompts for text generation.
Finally, we verify that the additional synthesized content can be linked to the
knowledge base or a trusted web source such as Wikipedia.",2022-04-14
"GAP: A Graph-aware Language Model Framework for Knowledge Graph-to-Text
  Generation",2022-04-13 23:53:37+00:00,http://arxiv.org/abs/2204.06674v1,"Anthony Colas, Mehrdad Alvandipour, Daisy Zhe Wang",cs.CL,knowledge,"Recent improvements in KG-to-text generation are due to additional auxiliary
pre-trained tasks designed to give the fine-tune task a boost in performance.
These tasks require extensive computational resources while only suggesting
marginal improvements. Here, we demonstrate that by fusing graph-aware elements
into existing pre-trained language models, we are able to outperform
state-of-the-art models and close the gap imposed by additional pre-train
tasks. We do so by proposing a mask structure to capture neighborhood
information and a novel type encoder that adds a bias to the graph-attention
weights depending on the connection type. Experiments on two KG-to-text
benchmark datasets show these models to be superior in quality while involving
fewer parameters and no additional pre-trained tasks. By formulating the
problem as a framework, we can interchange the various proposed components and
begin interpreting KG-to-text generative models based on the topological and
type information found in a graph.",2022-04-13
"Explanation Graph Generation via Pre-trained Language Models: An
  Empirical Study with Contrastive Learning",2022-04-11 00:58:27+00:00,http://arxiv.org/abs/2204.04813v1,"Swarnadeep Saha, Prateek Yadav, Mohit Bansal","cs.CL, cs.AI, cs.LG",knowledge,"Pre-trained sequence-to-sequence language models have led to widespread
success in many natural language generation tasks. However, there has been
relatively less work on analyzing their ability to generate structured outputs
such as graphs. Unlike natural language, graphs have distinct structural and
semantic properties in the context of a downstream NLP task, e.g., generating a
graph that is connected and acyclic can be attributed to its structural
constraints, while the semantics of a graph can refer to how meaningfully an
edge represents the relation between two node concepts. In this work, we study
pre-trained language models that generate explanation graphs in an end-to-end
manner and analyze their ability to learn the structural constraints and
semantics of such graphs. We first show that with limited supervision,
pre-trained language models often generate graphs that either violate these
constraints or are semantically incoherent. Since curating large amount of
human-annotated graphs is expensive and tedious, we propose simple yet
effective ways of graph perturbations via node and edge edit operations that
lead to structurally and semantically positive and negative graphs. Next, we
leverage these graphs in different contrastive learning models with Max-Margin
and InfoNCE losses. Our methods lead to significant improvements in both
structural and semantic accuracy of explanation graphs and also generalize to
other similar graph generation tasks. Lastly, we show that human errors are the
best negatives for contrastive learning and also that automatically generating
more such human-like negative graphs can lead to further improvements. Our code
and models are publicly available at https://github.com/swarnaHub/ExplagraphGen",2022-04-11
"Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic
  Filter Attention",2022-04-10 04:57:56+00:00,http://arxiv.org/abs/2204.04601v1,"Yu Yang, Seungbae Kim, Jungseock Joo","cs.CV, cs.AI, cs.LG",knowledge,"Interpretability is an important property for visual models as it helps
researchers and users understand the internal mechanism of a complex model.
However, generating semantic explanations about the learned representation is
challenging without direct supervision to produce such explanations. We propose
a general framework, Latent Visual Semantic Explainer (LaViSE), to teach any
existing convolutional neural network to generate text descriptions about its
own latent representations at the filter level. Our method constructs a mapping
between the visual and semantic spaces using generic image datasets, using
images and category names. It then transfers the mapping to the target domain
which does not have semantic labels. The proposed framework employs a modular
structure and enables to analyze any trained network whether or not its
original training data is available. We show that our method can generate novel
descriptions for learned filters beyond the set of categories defined in the
training dataset and perform an extensive evaluation on multiple datasets. We
also demonstrate a novel application of our method for unsupervised dataset
bias analysis which allows us to automatically discover hidden biases in
datasets or compare different subsets without using additional labels. The
dataset and code are made public to facilitate further research.",2022-04-10
Knowledge Infused Decoding,2022-04-06 20:58:32+00:00,http://arxiv.org/abs/2204.03084v1,"Ruibo Liu, Guoqing Zheng, Shashank Gupta, Radhika Gaonkar, Chongyang Gao, Soroush Vosoughi, Milad Shokouhi, Ahmed Hassan Awadallah","cs.CL, cs.AI, cs.LG",knowledge,"Pre-trained language models (LMs) have been shown to memorize a substantial
amount of knowledge from the pre-training corpora; however, they are still
limited in recalling factually correct knowledge given a certain context.
Hence, they tend to suffer from counterfactual or hallucinatory generation when
used in knowledge-intensive natural language generation (NLG) tasks. Recent
remedies to this problem focus on modifying either the pre-training or task
fine-tuning objectives to incorporate knowledge, which normally require
additional costly training or architecture modification of LMs for practical
applications. We present Knowledge Infused Decoding (KID) -- a novel decoding
algorithm for generative LMs, which dynamically infuses external knowledge into
each step of the LM decoding. Specifically, we maintain a local knowledge
memory based on the current context, interacting with a dynamically created
external knowledge trie, and continuously update the local memory as a
knowledge-aware constraint to guide decoding via reinforcement learning. On six
diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)
armed with KID outperform many task-optimized state-of-the-art models, and show
particularly strong performance in few-shot scenarios over seven related
knowledge-infusion techniques. Human evaluation confirms KID's ability to
generate more relevant and factual language for the input context when compared
with multiple baselines. Finally, KID also alleviates exposure bias and
provides stable generation quality when generating longer sequences. Code for
KID is available at https://github.com/microsoft/KID.",2022-04-06
CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations,2022-04-05 17:38:04+00:00,http://arxiv.org/abs/2204.02380v1,"Leonard Salewski, A. Sophia Koepke, Hendrik P. A. Lensch, Zeynep Akata","cs.CV, cs.CL",knowledge,"Providing explanations in the context of Visual Question Answering (VQA)
presents a fundamental problem in machine learning. To obtain detailed insights
into the process of generating natural language explanations for VQA, we
introduce the large-scale CLEVR-X dataset that extends the CLEVR dataset with
natural language explanations. For each image-question pair in the CLEVR
dataset, CLEVR-X contains multiple structured textual explanations which are
derived from the original scene graphs. By construction, the CLEVR-X
explanations are correct and describe the reasoning and visual information that
is necessary to answer a given question. We conducted a user study to confirm
that the ground-truth explanations in our proposed dataset are indeed complete
and relevant. We present baseline results for generating natural language
explanations in the context of VQA using two state-of-the-art frameworks on the
CLEVR-X dataset. Furthermore, we provide a detailed analysis of the explanation
generation quality for different question and answer types. Additionally, we
study the influence of using different numbers of ground-truth explanations on
the convergence of natural language generation (NLG) metrics. The CLEVR-X
dataset is publicly available at
\url{https://explainableml.github.io/CLEVR-X/}.",2022-04-05
"Bridge-Prompt: Towards Ordinal Action Understanding in Instructional
  Videos",2022-03-26 15:52:27+00:00,http://arxiv.org/abs/2203.14104v1,"Muheng Li, Lei Chen, Yueqi Duan, Zhilan Hu, Jianjiang Feng, Jie Zhou, Jiwen Lu","cs.CV, cs.AI, cs.LG",knowledge,"Action recognition models have shown a promising capability to classify human
actions in short video clips. In a real scenario, multiple correlated human
actions commonly occur in particular orders, forming semantically meaningful
human activities. Conventional action recognition approaches focus on analyzing
single actions. However, they fail to fully reason about the contextual
relations between adjacent actions, which provide potential temporal logic for
understanding long videos. In this paper, we propose a prompt-based framework,
Bridge-Prompt (Br-Prompt), to model the semantics across adjacent actions, so
that it simultaneously exploits both out-of-context and contextual information
from a series of ordinal actions in instructional videos. More specifically, we
reformulate the individual action labels as integrated text prompts for
supervision, which bridge the gap between individual action semantics. The
generated text prompts are paired with corresponding video clips, and together
co-train the text encoder and the video encoder via a contrastive approach. The
learned vision encoder has a stronger capability for ordinal-action-related
downstream tasks, e.g. action segmentation and human activity recognition. We
evaluate the performances of our approach on several video datasets: Georgia
Tech Egocentric Activities (GTEA), 50Salads, and the Breakfast dataset.
Br-Prompt achieves state-of-the-art on multiple benchmarks. Code is available
at https://github.com/ttlmh/Bridge-Prompt",2022-03-26
A Roadmap for Big Model,2022-03-26 15:38:00+00:00,http://arxiv.org/abs/2203.14101v1,"Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangxiao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao, Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning Ding, Yongming Rao, Yizhao Gao, Liang Zhang, Ming Ding, Cong Fang, Yisen Wang, Mingsheng Long, Jing Zhang, Yinpeng Dong, Tianyu Pang, Peng Cui, Lingxiao Huang, Zheng Liang, Huawei Shen, Hui Zhang, Quanshi Zhang, Qingxiu Dong, Zhixing Tan, Mingxuan Wang, Shuo Wang, Long Zhou, Haoran Li, Junwei Bao, Yingwei Pan, Weinan Zhang, Zhou Yu, Rui Yan, Chence Shi, Minghao Xu, Zuobai Zhang, Guoqiang Wang, Xiang Pan, Mengjie Li, Xiaoyu Chu, Zijun Yao, Fangwei Zhu, Shulin Cao, Weicheng Xue, Zixuan Ma, Zhengyan Zhang, Shengding Hu, Yujia Qin, Chaojun Xiao, Zheni Zeng, Ganqu Cui, Weize Chen, Weilin Zhao, Yuan Yao, Peng Li, Wenzhao Zheng, Wenliang Zhao, Ziyi Wang, Borui Zhang, Nanyi Fei, Anwen Hu, Zenan Ling, Haoyang Li, Boxi Cao, Xianpei Han, Weidong Zhan, Baobao Chang, Hao Sun, Jiawen Deng, Juanzi Li, Lei Hou, Xigang Cao, Jidong Zhai, Zhiyuan Liu, Maosong Sun, Jiwen Lu, Zhiwu Lu, Qin Jin, Ruihua Song, Ji-Rong Wen, Zhouchen Lin, Liwei Wang, Hang Su, Jun Zhu, Zhifang Sui, Jiajun Zhang, Yang Liu, Xiaodong He, Minlie Huang, Jian Tang, Jie Tang","cs.LG, cs.AI, cs.CL",knowledge,"With the rapid development of deep learning, training Big Models (BMs) for
multiple downstream tasks becomes a popular paradigm. Researchers have achieved
various outcomes in the construction of BMs and the BM application in many
fields. At present, there is a lack of research work that sorts out the overall
progress of BMs and guides the follow-up research. In this paper, we cover not
only the BM technologies themselves but also the prerequisites for BM training
and applications with BMs, dividing the BM review into four parts: Resource,
Models, Key Technologies and Application. We introduce 16 specific BM-related
topics in those four parts, they are Data, Knowledge, Computing System,
Parallel Training System, Language Model, Vision Model, Multi-modal Model,
Theory&Interpretability, Commonsense Reasoning, Reliability&Security,
Governance, Evaluation, Machine Translation, Text Generation, Dialogue and
Protein Research. In each topic, we summarize clearly the current studies and
propose some future research directions. At the end of this paper, we conclude
the further development of BMs in a more general view.",2022-03-26
"Mitigating Gender Bias in Distilled Language Models via Counterfactual
  Role Reversal",2022-03-23 17:34:35+00:00,http://arxiv.org/abs/2203.12574v1,"Umang Gupta, Jwala Dhamala, Varun Kumar, Apurv Verma, Yada Pruksachatkun, Satyapriya Krishna, Rahul Gupta, Kai-Wei Chang, Greg Ver Steeg, Aram Galstyan","cs.CL, cs.LG",knowledge,"Language models excel at generating coherent text, and model compression
techniques such as knowledge distillation have enabled their use in
resource-constrained settings. However, these models can be biased in multiple
ways, including the unfounded association of male and female genders with
gender-neutral professions. Therefore, knowledge distillation without any
fairness constraints may preserve or exaggerate the teacher model's biases onto
the distilled model. To this end, we present a novel approach to mitigate
gender disparity in text generation by learning a fair model during knowledge
distillation. We propose two modifications to the base knowledge distillation
based on counterfactual role reversal$\unicode{x2014}$modifying teacher
probabilities and augmenting the training set. We evaluate gender polarity
across professions in open-ended text generated from the resulting distilled
and finetuned GPT$\unicode{x2012}$2 models and demonstrate a substantial
reduction in gender disparity with only a minor compromise in utility. Finally,
we observe that language models that reduce gender polarity in language
generation do not improve embedding fairness or downstream classification
fairness.",2022-03-23
"An Empirical Study on Learning and Improving the Search Objective for
  Unsupervised Paraphrasing",2022-03-23 00:30:28+00:00,http://arxiv.org/abs/2203.12106v1,Weikai Steven Lu,"cs.CL, cs.AI, cs.LG",knowledge,"Research in unsupervised text generation has been gaining attention over the
years. One recent approach is local search towards a heuristically defined
objective, which specifies language fluency, semantic meanings, and other
task-specific attributes. Search in the sentence space is realized by
word-level edit operations including insertion, replacement, and deletion.
However, such objective function is manually designed with multiple components.
Although previous work has shown maximizing this objective yields good
performance in terms of true measure of success (i.e. BLEU and iBLEU), the
objective landscape is considered to be non-smooth with significant noises,
posing challenges for optimization. In this dissertation, we address the
research problem of smoothing the noise in the heuristic search objective by
learning to model the search dynamics. Then, the learned model is combined with
the original objective function to guide the search in a bootstrapping fashion.
Experimental results show that the learned models combined with the original
search objective can indeed provide a smoothing effect, improving the search
performance by a small margin.",2022-03-23
"Perturbations in the Wild: Leveraging Human-Written Text Perturbations
  for Realistic Adversarial Attack and Defense",2022-03-19 16:00:01+00:00,http://arxiv.org/abs/2203.10346v1,"Thai Le, Jooyoung Lee, Kevin Yen, Yifan Hu, Dongwon Lee","cs.LG, cs.CL, cs.CR",knowledge,"We proposes a novel algorithm, ANTHRO, that inductively extracts over 600K
human-written text perturbations in the wild and leverages them for realistic
adversarial attack. Unlike existing character-based attacks which often
deductively hypothesize a set of manipulation strategies, our work is grounded
on actual observations from real-world texts. We find that adversarial texts
generated by ANTHRO achieve the best trade-off between (1) attack success rate,
(2) semantic preservation of the original text, and (3) stealthiness--i.e.
indistinguishable from human writings hence harder to be flagged as suspicious.
Specifically, our attacks accomplished around 83% and 91% attack success rates
on BERT and RoBERTa, respectively. Moreover, it outperformed the TextBugger
baseline with an increase of 50% and 40% in terms of semantic preservation and
stealthiness when evaluated by both layperson and professional human workers.
ANTHRO can further enhance a BERT classifier's performance in understanding
different variations of human-written toxic texts via adversarial training when
compared to the Perspective API.",2022-03-19
Dependency-based Mixture Language Models,2022-03-19 06:28:30+00:00,http://arxiv.org/abs/2203.10256v1,"Zhixian Yang, Xiaojun Wan",cs.CL,knowledge,"Various models have been proposed to incorporate knowledge of syntactic
structures into neural language models. However, previous works have relied
heavily on elaborate components for a specific language model, usually
recurrent neural network (RNN), which makes themselves unwieldy in practice to
fit into other neural language models, such as Transformer and GPT-2. In this
paper, we introduce the Dependency-based Mixture Language Models. In detail, we
first train neural language models with a novel dependency modeling objective
to learn the probability distribution of future dependent tokens given context.
We then formulate the next-token probability by mixing the previous dependency
modeling probability distributions with self-attention. Extensive experiments
and human evaluations show that our method can be easily and effectively
applied to different neural language models while improving neural text
generation on various tasks.",2022-03-19
RoMe: A Robust Metric for Evaluating Natural Language Generation,2022-03-17 09:07:39+00:00,http://arxiv.org/abs/2203.09183v1,"Md Rashad Al Hasan Rony, Liubov Kovriguina, Debanjan Chaudhuri, Ricardo Usbeck, Jens Lehmann","cs.CL, cs.AI",knowledge,"Evaluating Natural Language Generation (NLG) systems is a challenging task.
Firstly, the metric should ensure that the generated hypothesis reflects the
reference's semantics. Secondly, it should consider the grammatical quality of
the generated sentence. Thirdly, it should be robust enough to handle various
surface forms of the generated sentence. Thus, an effective evaluation metric
has to be multifaceted. In this paper, we propose an automatic evaluation
metric incorporating several core aspects of natural language understanding
(language competence, syntactic and semantic variation). Our proposed metric,
RoMe, is trained on language features such as semantic similarity combined with
tree edit distance and grammatical acceptability, using a self-supervised
neural network to assess the overall quality of the generated sentence.
Moreover, we perform an extensive robustness analysis of the state-of-the-art
methods and RoMe. Empirical results suggest that RoMe has a stronger
correlation to human judgment over state-of-the-art metrics in evaluating
system-generated sentences across several NLG tasks.",2022-03-17
"PLANET: Dynamic Content Planning in Autoregressive Transformers for
  Long-form Text Generation",2022-03-17 05:52:35+00:00,http://arxiv.org/abs/2203.09100v1,"Zhe Hu, Hou Pong Chan, Jiachen Liu, Xinyan Xiao, Hua Wu, Lifu Huang",cs.CL,knowledge,"Despite recent progress of pre-trained language models on generating fluent
text, existing methods still suffer from incoherence problems in long-form text
generation tasks that require proper content control and planning to form a
coherent high-level logical flow. In this work, we propose PLANET, a novel
generation framework leveraging autoregressive self-attention mechanism to
conduct content planning and surface realization dynamically. To guide the
generation of output sentences, our framework enriches the Transformer decoder
with latent representations to maintain sentence-level semantic plans grounded
by bag-of-words. Moreover, we introduce a new coherence-based contrastive
learning objective to further improve the coherence of output. Extensive
experiments are conducted on two challenging long-form text generation tasks
including counterargument generation and opinion article generation. Both
automatic and human evaluations show that our method significantly outperforms
strong baselines and generates more coherent texts with richer contents.",2022-03-17
"TegTok: Augmenting Text Generation via Task-specific and Open-world
  Knowledge",2022-03-16 10:37:59+00:00,http://arxiv.org/abs/2203.08517v1,"Chao-Hong Tan, Jia-Chen Gu, Chongyang Tao, Zhen-Hua Ling, Can Xu, Huang Hu, Xiubo Geng, Daxin Jiang","cs.CL, cs.AI",knowledge,"Generating natural and informative texts has been a long-standing problem in
NLP. Much effort has been dedicated into incorporating pre-trained language
models (PLMs) with various open-world knowledge, such as knowledge graphs or
wiki pages. However, their ability to access and manipulate the task-specific
knowledge is still limited on downstream tasks, as this type of knowledge is
usually not well covered in PLMs and is hard to acquire. To address the
problem, we propose augmenting TExt Generation via Task-specific and Open-world
Knowledge (TegTok) in a unified framework. Our model selects knowledge entries
from two types of knowledge sources through dense retrieval and then injects
them into the input encoding and output decoding stages respectively on the
basis of PLMs. With the help of these two types of knowledge, our model can
learn what and how to generate. Experiments on two text generation tasks of
dialogue generation and question generation, and on two datasets show that our
method achieves better performance than various baseline models.",2022-03-16
Graph Pre-training for AMR Parsing and Generation,2022-03-15 12:47:00+00:00,http://arxiv.org/abs/2203.07836v1,"Xuefeng Bai, Yulong Chen, Yue Zhang",cs.CL,knowledge,"Abstract meaning representation (AMR) highlights the core semantic
information of text in a graph structure. Recently, pre-trained language models
(PLMs) have advanced tasks of AMR parsing and AMR-to-text generation,
respectively. However, PLMs are typically pre-trained on textual data, thus are
sub-optimal for modeling structural knowledge. To this end, we investigate
graph self-supervised training to improve the structure awareness of PLMs over
AMR graphs. In particular, we introduce two graph auto-encoding strategies for
graph-to-graph pre-training and four tasks to integrate text and graph
information during pre-training. We further design a unified framework to
bridge the gap between pre-training and fine-tuning tasks. Experiments on both
AMR parsing and AMR-to-text generation show the superiority of our model. To
our knowledge, we are the first to consider pre-training on semantic graphs.",2022-03-15
Pruned Graph Neural Network for Short Story Ordering,2022-03-13 22:25:17+00:00,http://arxiv.org/abs/2203.06778v1,"Melika Golestani, Zeinab Borhanifard, Farnaz Tahmasebian, Heshaam Faili",cs.CL,knowledge,"Text coherence is a fundamental problem in natural language generation and
understanding. Organizing sentences into an order that maximizes coherence is
known as sentence ordering. This paper is proposing a new approach based on the
graph neural network approach to encode a set of sentences and learn orderings
of short stories. We propose a new method for constructing sentence-entity
graphs of short stories to create the edges between sentences and reduce noise
in our graph by replacing the pronouns with their referring entities. We
improve the sentence ordering by introducing an aggregation method based on
majority voting of state-of-the-art methods and our proposed one. Our approach
employs a BERT-based model to learn semantic representations of the sentences.
The results demonstrate that the proposed method significantly outperforms
existing baselines on a corpus of short stories with a new state-of-the-art
performance in terms of Perfect Match Ratio (PMR) and Kendall's Tau (Tau)
metrics. More precisely, our method increases PMR and Tau criteria by more than
5% and 4.3%, respectively. These outcomes highlight the benefit of forming the
edges between sentences based on their cosine similarity. We also observe that
replacing pronouns with their referring entities effectively encodes sentences
in sentence-entity graphs.",2022-03-13
"IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic
  Languages",2022-03-10 15:53:58+00:00,http://arxiv.org/abs/2203.05437v1,"Aman Kumar, Himani Shrotriya, Prachi Sahu, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Amogh Mishra, Mitesh M. Khapra, Pratyush Kumar","cs.CL, cs.AI",knowledge,"In this paper, we present the IndicNLG suite, a collection of datasets for
benchmarking Natural Language Generation (NLG) for 11 Indic languages. We focus
on five diverse tasks, namely, biography generation using Wikipedia infoboxes
(WikiBio), news headline generation, sentence summarization, question
generation and paraphrase generation. We describe the process of creating the
datasets and present statistics of the dataset, following which we train and
report a variety of strong monolingual and multilingual baselines that leverage
pre-trained sequence-to-sequence models and analyze the results to understand
the challenges involved in Indic language NLG. To the best of our knowledge,
this is the first NLG dataset for Indic languages and also the largest
multilingual NLG dataset. Our methods can also be easily applied to
modest-resource languages with reasonable monolingual and parallel corpora, as
well as corpora containing structured data like Wikipedia. We hope this dataset
spurs research in NLG on diverse languages and tasks, particularly for Indic
languages. The datasets and models are publicly available at
https://indicnlp.ai4bharat.org/indicnlg-suite.",2022-03-10
Recent Advances in Neural Text Generation: A Task-Agnostic Survey,2022-03-06 20:47:49+00:00,http://arxiv.org/abs/2203.03047v1,"Chen Tang, Frank Guerin, Yucheng Li, Chenghua Lin","cs.CL, cs.AI",knowledge,"In recent years much effort has been devoted to applying neural models to the
task of natural language generation. The challenge is to generate natural
human-like text, and to control the generation process. This paper presents a
task-agnostic survey of recent advances in neural text generation. These
advances have been achieved by numerous developments, which we group under the
following four headings: data construction, neural frameworks, training and
inference strategies, and evaluation metrics. Finally we discuss the future
directions for the development of neural text generation including neural
pipelines and exploiting back-ground knowledge.",2022-03-06
Deep Latent-Variable Models for Text Generation,2022-03-03 23:06:39+00:00,http://arxiv.org/abs/2203.02055v1,Xiaoyu Shen,cs.CL,knowledge,"Text generation aims to produce human-like natural language output for
down-stream tasks. It covers a wide range of applications like machine
translation, document summarization, dialogue generation and so on. Recently
deep neural network-based end-to-end architectures have been widely adopted.
The end-to-end approach conflates all sub-modules, which used to be designed by
complex handcrafted rules, into a holistic encode-decode architecture. Given
enough training data, it is able to achieve state-of-the-art performance yet
avoiding the need of language/domain-dependent knowledge. Nonetheless, deep
learning models are known to be extremely data-hungry, and text generated from
them usually suffer from low diversity, interpretability and controllability.
As a result, it is difficult to trust the output from them in real-life
applications. Deep latent-variable models, by specifying the probabilistic
distribution over an intermediate latent process, provide a potential way of
addressing these problems while maintaining the expressive power of deep neural
networks. This dissertation presents how deep latent-variable models can
improve over the standard encoder-decoder model for text generation.",2022-03-03
