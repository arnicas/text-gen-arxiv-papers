title,pubdate,id,authors,categories,search,abstract,displaydate
"AI-generated stories favour stability over change: homogeneity and
  cultural stereotyping in narratives generated by gpt-4o-mini",2025-07-30 07:44:28+00:00,http://arxiv.org/abs/2507.22445v1,"Jill Walker Rettberg, Hermann Wigers","cs.CL, cs.AI, H.1.2; I.2.4; I.2.0; I.2.7",story,"Can a language model trained largely on Anglo-American texts generate stories
that are culturally relevant to other nationalities? To find out, we generated
11,800 stories - 50 for each of 236 countries - by sending the prompt ""Write a
1500 word potential {demonym} story"" to OpenAI's model gpt-4o-mini. Although
the stories do include surface-level national symbols and themes, they
overwhelmingly conform to a single narrative plot structure across countries: a
protagonist lives in or returns home to a small town and resolves a minor
conflict by reconnecting with tradition and organising community events.
Real-world conflicts are sanitised, romance is almost absent, and narrative
tension is downplayed in favour of nostalgia and reconciliation. The result is
a narrative homogenisation: an AI-generated synthetic imaginary that
prioritises stability above change and tradition above growth. We argue that
the structural homogeneity of AI-generated narratives constitutes a distinct
form of AI bias, a narrative standardisation that should be acknowledged
alongside the more familiar representational bias. These findings are relevant
to literary studies, narratology, critical AI studies, NLP research, and
efforts to improve the cultural alignment of generative AI.",2025-07-30
Ta-G-T: Subjectivity Capture in Table to Text Generation via RDF Graphs,2025-07-25 23:06:00+00:00,http://arxiv.org/abs/2507.19710v1,"Ronak Upasham, Tathagata Dey, Pushpak Bhattacharyya",cs.CL,story,"In Table-to-Text (T2T) generation, existing approaches predominantly focus on
providing objective descriptions of tabular data. However, generating text that
incorporates subjectivity, where subjectivity refers to interpretations beyond
raw numerical data, remains underexplored. To address this, we introduce a
novel pipeline that leverages intermediate representations to generate both
objective and subjective text from tables. Our three-stage pipeline consists
of: 1) extraction of Resource Description Framework (RDF) triples, 2)
aggregation of text into coherent narratives, and 3) infusion of subjectivity
to enrich the generated text. By incorporating RDFs, our approach enhances
factual accuracy while maintaining interpretability. Unlike large language
models (LLMs) such as GPT-3.5, Mistral-7B, and Llama-2, our pipeline employs
smaller, fine-tuned T5 models while achieving comparable performance to GPT-3.5
and outperforming Mistral-7B and Llama-2 in several metrics. We evaluate our
approach through quantitative and qualitative analyses, demonstrating its
effectiveness in balancing factual accuracy with subjective interpretation. To
the best of our knowledge, this is the first work to propose a structured
pipeline for T2T generation that integrates intermediate representations to
enhance both factual correctness and subjectivity.",2025-07-25
Modeling Fair Play in Detective Stories with Language Models,2025-07-18 11:55:18+00:00,http://arxiv.org/abs/2507.13841v1,"Eitan Wagner, Renana Keydar, Omri Abend",cs.CL,story,"Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.",2025-07-18
"Enhancing Essay Cohesion Assessment: A Novel Item Response Theory
  Approach",2025-07-11 11:05:27+00:00,http://arxiv.org/abs/2507.08487v1,"Bruno Alexandre Rosa, Hil√°rio Oliveira, Luiz Rodrigues, Eduardo Araujo Oliveira, Rafael Ferreira Mello","cs.CL, cs.AI",story,"Essays are considered a valuable mechanism for evaluating learning outcomes
in writing. Textual cohesion is an essential characteristic of a text, as it
facilitates the establishment of meaning between its parts. Automatically
scoring cohesion in essays presents a challenge in the field of educational
artificial intelligence. The machine learning algorithms used to evaluate texts
generally do not consider the individual characteristics of the instances that
comprise the analysed corpus. In this meaning, item response theory can be
adapted to the context of machine learning, characterising the ability,
difficulty and discrimination of the models used. This work proposes and
analyses the performance of a cohesion score prediction approach based on item
response theory to adjust the scores generated by machine learning models. In
this study, the corpus selected for the experiments consisted of the extended
Essay-BR, which includes 6,563 essays in the style of the National High School
Exam (ENEM), and the Brazilian Portuguese Narrative Essays, comprising 1,235
essays written by 5th to 9th grade students from public schools. We extracted
325 linguistic features and treated the problem as a machine learning
regression task. The experimental results indicate that the proposed approach
outperforms conventional machine learning models and ensemble methods in
several evaluation metrics. This research explores a potential approach for
improving the automatic evaluation of cohesion in educational essays.",2025-07-11
"LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative
  Writing",2025-07-01 14:10:36+00:00,http://arxiv.org/abs/2507.00769v1,"Daniel Fein, Sebastian Russo, Violet Xiang, Kabir Jolly, Rafael Rafailov, Nick Haber","cs.CL, cs.AI",story,"Evaluating creative writing generated by large language models (LLMs) remains
challenging because open-ended narratives lack ground truths. Without
performant automated evaluation methods, off-the-shelf (OTS) language models
are employed as zero-shot judges, yet their reliability is unclear in this
context. In pursuit of robust evaluation for creative writing, we introduce
LitBench, the first standardized benchmark and paired dataset for creative
writing verification, comprising a held-out test set of 2,480 debiased,
human-labeled story comparisons drawn from Reddit and a 43,827-pair training
corpus of human preference labels. Using LitBench, we (i) benchmark zero-shot
LLM judges, (ii) train Bradley Terry and generative reward models, and (iii)
conduct an online human study to validate reward model rankings on newly
LLM-generated stories. Our benchmark identifies Claude-3.7-Sonnet as the
strongest off-the-shelf judge, reaching 73% agreement with human preferences;
among trained reward models, Bradley-Terry and Generative reward models both
attain an accuracy of 78%, outperforming all off-the-shelf judges. An online
human study further confirms that our trained reward models consistently align
with human preferences in novel LLM-generated stories. We release LitBench and
reward models at
https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461,
providing a vetted resource for reliable, automated evaluation and optimization
of creative writing systems.",2025-07-01
Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs,2025-06-29 19:26:37+00:00,http://arxiv.org/abs/2506.23377v1,"Taejin Kim, Siun-Chuon Mau, Konrad Vesey","cs.CL, cs.AI",story,"Large language models (LLMs) are used in a variety of mission-critical roles.
Due to the rapidly developing nature of LLMs, there is a lack of quantifiable
understanding of the bias and perspective associated with LLM output. Inspired
by this need, this paper considers the broader issue of perspective or
viewpoint of general text and perspective control of large-language model (LLM)
output. Perspective-Dial consists of two main components: a (1) metric space,
dubbed Perspective Space, that enables quantitative measurements of different
perspectives regarding a topic, and the use of (2) Systematic Prompt
Engineering that utilizes greedy-coordinate descent to control LLM output
perspective based on measurement feedback from the Perspective Space. The
empirical nature of the approach allows progress to side step a principled
understanding of perspective or bias -- effectively quantifying and adjusting
outputs for a variety of topics. Potential applications include detection,
tracking and mitigation of LLM bias, narrative detection, sense making and
tracking in public discourse, and debate bot advocating given perspective.",2025-06-29
"Structuralist Approach to AI Literary Criticism: Leveraging Greimas
  Semiotic Square for Large Language Models",2025-06-26 15:10:24+00:00,http://arxiv.org/abs/2506.21360v1,"Fangzhou Dong, Yifan Zeng, Yingpeng Sang, Hong Shen",cs.CL,story,"Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.",2025-06-26
Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?,2025-06-26 13:58:43+00:00,http://arxiv.org/abs/2506.21274v1,"Andrea McGlinchey, Peter J Barclay",cs.CL,story,"Large language models can produce convincing ""fake text"" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless ""arms race"", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify ""fake text"" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness",2025-06-26
FairyGen: Storied Cartoon Video from a Single Child-Drawn Character,2025-06-26 13:58:16+00:00,http://arxiv.org/abs/2506.21272v2,"Jiayi Zheng, Xiaodong Cun","cs.GR, cs.CV, cs.MM",story,"We propose FairyGen, an automatic system for generating story-driven cartoon
videos from a single child's drawing, while faithfully preserving its unique
artistic style. Unlike previous storytelling methods that primarily focus on
character consistency and basic motion, FairyGen explicitly disentangles
character modeling from stylized background generation and incorporates
cinematic shot design to support expressive and coherent storytelling. Given a
single character sketch, we first employ an MLLM to generate a structured
storyboard with shot-level descriptions that specify environment settings,
character actions, and camera perspectives. To ensure visual consistency, we
introduce a style propagation adapter that captures the character's visual
style and applies it to the background, faithfully retaining the character's
full visual identity while synthesizing style-consistent scenes. A shot design
module further enhances visual diversity and cinematic quality through frame
cropping and multi-view synthesis based on the storyboard. To animate the
story, we reconstruct a 3D proxy of the character to derive physically
plausible motion sequences, which are then used to fine-tune an MMDiT-based
image-to-video diffusion model. We further propose a two-stage motion
customization adapter: the first stage learns appearance features from
temporally unordered frames, disentangling identity from motion; the second
stage models temporal dynamics using a timestep-shift strategy with frozen
identity weights. Once trained, FairyGen directly renders diverse and coherent
video scenes aligned with the storyboard. Extensive experiments demonstrate
that our system produces animations that are stylistically faithful,
narratively structured natural motion, highlighting its potential for
personalized and engaging story animation. The code will be available at
https://github.com/GVCLab/FairyGen",2025-06-26
Compressed and Smooth Latent Space for Text Diffusion Modeling,2025-06-26 12:05:13+00:00,http://arxiv.org/abs/2506.21170v1,"Viacheslav Meshchaninov, Egor Chimbulatov, Alexander Shabalin, Aleksandr Abramov, Dmitry Vetrov",cs.CL,story,"Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.",2025-06-26
"Language Models Might Not Understand You: Evaluating Theory of Mind via
  Story Prompting",2025-06-23 20:06:53+00:00,http://arxiv.org/abs/2506.19089v2,"Nathaniel Getachew, Abulhair Saparov","cs.CL, cs.AI",story,"We introduce $\texttt{StorySim}$, a programmable framework for synthetically
generating stories to evaluate the theory of mind (ToM) and world modeling (WM)
capabilities of large language models (LLMs). Unlike prior benchmarks that may
suffer from contamination in pretraining data, $\texttt{StorySim}$ produces
novel, compositional story prompts anchored by a highly controllable
$\texttt{Storyboard}$, enabling precise manipulation of character perspectives
and events. We use this framework to design first- and second-order ToM tasks
alongside WM tasks that control for the ability to track and model mental
states. Our experiments across a suite of state-of-the-art LLMs reveal that
most models perform better on WM tasks than ToM tasks, and that models tend to
perform better reasoning with humans compared to inanimate objects.
Additionally, our framework enabled us to find evidence of heuristic behavior
such as recency bias and an over-reliance on earlier events in the story. All
code for generating data and evaluations is freely available.",2025-06-23
"How Large Language Models play humans in online conversations: a
  simulated study of the 2016 US politics on Reddit",2025-06-23 08:54:32+00:00,http://arxiv.org/abs/2506.21620v1,"Daniele Cirulli, Giulio Cimini, Giovanni Palermo","cs.CL, cs.AI, cs.CY, cs.SI, physics.soc-ph",story,"Large Language Models (LLMs) have recently emerged as powerful tools for
natural language generation, with applications spanning from content creation
to social simulations. Their ability to mimic human interactions raises both
opportunities and concerns, particularly in the context of politically relevant
online discussions. In this study, we evaluate the performance of LLMs in
replicating user-generated content within a real-world, divisive scenario:
Reddit conversations during the 2016 US Presidential election. In particular,
we conduct three different experiments, asking GPT-4 to generate comments by
impersonating either real or artificial partisan users. We analyze the
generated comments in terms of political alignment, sentiment, and linguistic
features, comparing them against real user contributions and benchmarking
against a null model. We find that GPT-4 is able to produce realistic comments,
both in favor of or against the candidate supported by the community, yet
tending to create consensus more easily than dissent. In addition we show that
real and artificial comments are well separated in a semantically embedded
space, although they are indistinguishable by manual inspection. Our findings
provide insights on the potential use of LLMs to sneak into online discussions,
influence political debate and shape political narratives, bearing broader
implications of AI-driven discourse manipulation.",2025-06-23
StoryWriter: A Multi-Agent Framework for Long Story Generation,2025-06-19 16:26:58+00:00,http://arxiv.org/abs/2506.16445v1,"Haotian Xia, Hao Peng, Yunjia Qi, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li","cs.CL, cs.AI",story,"Long story generation remains a challenge for existing large language models
(LLMs), primarily due to two main factors: (1) discourse coherence, which
requires plot consistency, logical coherence, and completeness in the long-form
generation, and (2) narrative complexity, which requires an interwoven and
engaging narrative. To address these challenges, we propose StoryWriter, a
multi-agent story generation framework, which consists of three main modules:
(1) outline agent, which generates event-based outlines containing rich event
plots, character, and event-event relationships. (2) planning agent, which
further details events and plans which events should be written in each chapter
to maintain an interwoven and engaging story. (3) writing agent, which
dynamically compresses the story history based on the current event to generate
and reflect new plots, ensuring the coherence of the generated story. We
conduct both human and automated evaluation, and StoryWriter significantly
outperforms existing story generation baselines in both story quality and
length. Furthermore, we use StoryWriter to generate a dataset, which contains
about $6,000$ high-quality long stories, with an average length of $8,000$
words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning
on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which
demonstrates advanced performance in long story generation.",2025-06-19
Curriculum-Guided Layer Scaling for Language Model Pretraining,2025-06-13 01:22:16+00:00,http://arxiv.org/abs/2506.11389v1,"Karanpartap Singh, Neil Band, Ehsan Adeli",cs.CL,story,"As the cost of pretraining large language models grows, there is continued
interest in strategies to improve learning efficiency during this core training
stage. Motivated by cognitive development, where humans gradually build
knowledge as their brains mature, we propose Curriculum-Guided Layer Scaling
(CGLS), a framework for compute-efficient pretraining that synchronizes
increasing data difficulty with model growth through progressive layer stacking
(i.e. gradually adding layers during training). At the 100M parameter scale,
using a curriculum transitioning from synthetic short stories to general web
data, CGLS outperforms baseline methods on the question-answering benchmarks
PIQA and ARC. Pretraining at the 1.2B scale, we stratify the DataComp-LM corpus
with a DistilBERT-based classifier and progress from general text to highly
technical or specialized content. Our results show that progressively
increasing model depth alongside sample difficulty leads to better
generalization and zero-shot performance on various downstream benchmarks.
Altogether, our findings demonstrate that CGLS unlocks the potential of
progressive stacking, offering a simple yet effective strategy for improving
generalization on knowledge-intensive and reasoning tasks.",2025-06-13
VINCIE: Unlocking In-context Image Editing from Video,2025-06-12 17:46:54+00:00,http://arxiv.org/abs/2506.10941v1,"Leigang Qu, Feng Cheng, Ziyan Yang, Qi Zhao, Shanchuan Lin, Yichun Shi, Yicong Li, Wenjie Wang, Tat-Seng Chua, Lu Jiang","cs.CV, cs.AI, cs.CL, cs.LG, cs.MM",story,"In-context image editing aims to modify images based on a contextual sequence
comprising text and previously generated images. Existing methods typically
depend on task-specific pipelines and expert models (e.g., segmentation and
inpainting) to curate training data. In this work, we explore whether an
in-context image editing model can be learned directly from videos. We
introduce a scalable approach to annotate videos as interleaved multimodal
sequences. To effectively learn from this data, we design a block-causal
diffusion transformer trained on three proxy tasks: next-image prediction,
current segmentation prediction, and next-segmentation prediction.
Additionally, we propose a novel multi-turn image editing benchmark to advance
research in this area. Extensive experiments demonstrate that our model
exhibits strong in-context image editing capabilities and achieves
state-of-the-art results on two multi-turn image editing benchmarks. Despite
being trained exclusively on videos, our model also shows promising abilities
in multi-concept composition, story generation, and chain-of-editing
applications.",2025-06-12
"Can LLMs Generate Good Stories? Insights and Challenges from a Narrative
  Planning Perspective",2025-06-11 20:27:08+00:00,http://arxiv.org/abs/2506.10161v1,"Yi Wang, Max Kreminski","cs.CL, cs.AI",story,"Story generation has been a prominent application of Large Language Models
(LLMs). However, understanding LLMs' ability to produce high-quality stories
remains limited due to challenges in automatic evaluation methods and the high
cost and subjectivity of manual evaluation. Computational narratology offers
valuable insights into what constitutes a good story, which has been applied in
the symbolic narrative planning approach to story generation. This work aims to
deepen the understanding of LLMs' story generation capabilities by using them
to solve narrative planning problems. We present a benchmark for evaluating
LLMs on narrative planning based on literature examples, focusing on causal
soundness, character intentionality, and dramatic conflict. Our experiments
show that GPT-4 tier LLMs can generate causally sound stories at small scales,
but planning with character intentionality and dramatic conflict remains
challenging, requiring LLMs trained with reinforcement learning for complex
reasoning. The results offer insights on the scale of stories that LLMs can
generate while maintaining quality from different aspects. Our findings also
highlight interesting problem solving behaviors and shed lights on challenges
and considerations for applying LLM narrative planning in game environments.",2025-06-11
"Advancing Decoding Strategies: Enhancements in Locally Typical Sampling
  for LLMs",2025-06-03 14:25:23+00:00,http://arxiv.org/abs/2506.05387v2,"Jaydip Sen, Saptarshi Sengupta, Subhasis Dasgupta","cs.CL, cs.AI",story,"This chapter explores advancements in decoding strategies for large language
models (LLMs), focusing on enhancing the Locally Typical Sampling (LTS)
algorithm. Traditional decoding methods, such as top-k and nucleus sampling,
often struggle to balance fluency, diversity, and coherence in text generation.
To address these challenges, Adaptive Semantic-Aware Typicality Sampling (ASTS)
is proposed as an improved version of LTS, incorporating dynamic entropy
thresholding, multi-objective scoring, and reward-penalty adjustments. ASTS
ensures contextually coherent and diverse text generation while maintaining
computational efficiency. Its performance is evaluated across multiple
benchmarks, including story generation and abstractive summarization, using
metrics such as perplexity, MAUVE, and diversity scores. Experimental results
demonstrate that ASTS outperforms existing sampling techniques by reducing
repetition, enhancing semantic alignment, and improving fluency.",2025-06-03
"Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM
  Integration",2025-04-17 17:37:49+00:00,http://arxiv.org/abs/2504.13119v1,"Yusi Sun, Haoyan Guan, leith Kin Yep Chan, Yong Hong Kuo",cs.HC,story,"Most adaptive AR storytelling systems define environmental semantics using
simple object labels and spatial coordinates, limiting narratives to rigid,
pre-defined logic. This oversimplification overlooks the contextual
significance of object relationships-for example, a wedding ring on a
nightstand might suggest marital conflict, yet is treated as just ""two objects""
in space. To address this, we explored integrating Vision Language Models
(VLMs) into AR pipelines. However, several challenges emerged: First, stories
generated with simple prompt guidance lacked narrative depth and spatial usage.
Second, spatial semantics were underutilized, failing to support meaningful
storytelling. Third, pre-generated scripts struggled to align with AR
Foundation's object naming and coordinate systems. We propose a scene-driven AR
storytelling framework that reimagines environments as active narrative agents,
built on three innovations: 1. State-aware object semantics: We decompose
object meaning into physical, functional, and metaphorical layers, allowing
VLMs to distinguish subtle narrative cues between similar objects. 2.
Structured narrative interface: A bidirectional JSON layer maps VLM-generated
metaphors to AR anchors, maintaining spatial and semantic coherence. 3. STAM
evaluation framework: A three-part experimental design evaluates narrative
quality, highlighting both strengths and limitations of VLM-AR integration. Our
findings show that the system can generate stories from the environment itself,
not just place them on top of it. In user studies, 70% of participants reported
seeing real-world objects differently when narratives were grounded in
environmental symbolism. By merging VLMs' generative creativity with AR's
spatial precision, this framework introduces a novel object-driven storytelling
paradigm, transforming passive spaces into active narrative landscapes.",2025-04-17
"Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models
  via Plot Hole Detection",2025-04-16 09:25:54+00:00,http://arxiv.org/abs/2504.11900v2,"Kabir Ahuja, Melanie Sclar, Yulia Tsvetkov",cs.CL,story,"Stories are a fundamental aspect of human experience. Engaging deeply with
stories and spotting plot holes -- inconsistencies in a storyline that break
the internal logic or rules of a story's world -- requires nuanced reasoning
skills, including tracking entities and events and their interplay, abstract
thinking, pragmatic narrative understanding, commonsense and social reasoning,
and theory of mind. As Large Language Models (LLMs) increasingly generate,
interpret, and modify text, rigorously assessing their narrative consistency
and deeper language understanding becomes critical. However, existing
benchmarks focus mainly on surface-level comprehension. In this work, we
propose plot hole detection in stories as a proxy to evaluate language
understanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel
algorithm to controllably and carefully synthesize plot holes in human-written
stories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot
hole detection abilities in stories -- FlawedFictions -- , which is robust to
contamination, with human filtering ensuring high quality. We find that
state-of-the-art LLMs struggle in accurately solving FlawedFictions regardless
of the reasoning effort allowed, with performance significantly degrading as
story length increases. Finally, we show that LLM-based story summarization and
story generation are prone to introducing plot holes, with more than 50% and
100% increases in plot hole detection rates with respect to human-written
originals.",2025-04-16
Looking beyond the next token,2025-04-15 16:09:06+00:00,http://arxiv.org/abs/2504.11336v1,"Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk","cs.LG, cs.AI, cs.CL",story,"The structure of causal language model training assumes that each token can
be accurately predicted from the previous context. This contrasts with humans'
natural writing and reasoning process, where goals are typically known before
the exact argument or phrasings. While this mismatch has been well studied in
the literature, the working assumption has been that architectural changes are
needed to address this mismatch. We argue that rearranging and processing the
training data sequences can allow models to more accurately imitate the true
data-generating process, and does not require any other changes to the
architecture or training infrastructure. We demonstrate that this technique,
Trelawney, and the inference algorithms derived from it allow us to improve
performance on several key benchmarks that span planning, algorithmic
reasoning, and story generation tasks. Finally, our method naturally enables
the generation of long-term goals at no additional cost. We investigate how
using the model's goal-generation capability can further improve planning and
reasoning. Additionally, we believe Trelawney could potentially open doors to
new capabilities beyond the current language modeling paradigm.",2025-04-15
"Beyond Memorization: Mapping the Originality-Quality Frontier of
  Language Models",2025-04-13 00:48:58+00:00,http://arxiv.org/abs/2504.09389v1,"Vishakh Padmakumar, Chen Yueh-Han, Jane Pan, Valerie Chen, He He",cs.CL,story,"As large language models (LLMs) are increasingly used for ideation and
scientific discovery, it is important to evaluate their ability to generate
novel output. Prior work evaluates novelty as the originality with respect to
training data, but original outputs can be low quality. In contrast, non-expert
judges may favor high-quality but memorized outputs, limiting the reliability
of human preference as a metric. We propose a new novelty metric for LLM
generations that balances originality and quality -- the harmonic mean of the
fraction of \ngrams unseen during training and a task-specific quality score.
We evaluate the novelty of generations from two families of open-data models
(OLMo and Pythia) on three creative tasks: story completion, poetry writing,
and creative tool use. We find that LLM generated text is less novel than human
written text. To elicit more novel outputs, we experiment with various
inference-time methods, which reveals a trade-off between originality and
quality. While these methods can boost novelty, they do so by increasing
originality at the expense of quality. In contrast, increasing model size or
applying post-training reliably shifts the Pareto frontier, highlighting that
starting with a stronger base model is a more effective way to improve novelty.",2025-04-13
Parameterized Synthetic Text Generation with SimpleStories,2025-04-12 11:44:47+00:00,http://arxiv.org/abs/2504.09184v1,"Lennart Finke, Thomas Dooms, Mat Allen, Juan Diego Rodriguez, Noa Nabeshima, Dan Braun","cs.CL, cs.AI",story,"We present SimpleStories, a large synthetic story dataset in simple language,
consisting of 2 million stories each in English and Japanese. Our method
employs parametrization of prompts with features at multiple levels of
abstraction, allowing for systematic control over story characteristics to
ensure broad syntactic and semantic diversity. Building on and addressing
limitations in the TinyStories dataset, our approach demonstrates that
simplicity and variety can be achieved simultaneously in synthetic text
generation at scale.",2025-04-12
"ELSA: A Style Aligned Dataset for Emotionally Intelligent Language
  Generation",2025-04-11 06:30:16+00:00,http://arxiv.org/abs/2504.08281v1,"Vishal Gandhi, Sagar Gandhi","cs.CL, cs.AI, cs.LG",story,"Advancements in emotion aware language processing increasingly shape vital
NLP applications ranging from conversational AI and affective computing to
computational psychology and creative content generation. Existing emotion
datasets either lack emotional granularity or fail to capture necessary
stylistic diversity, limiting the advancement of effective emotion conditioned
text generation systems. Seeking to bridge this crucial gap between granularity
and style diversity, this paper introduces a novel systematically constructed
dataset named ELSA Emotion and Language Style Alignment Dataset leveraging fine
grained emotion taxonomies adapted from existing sources such as dair ai
emotion dataset and GoEmotions taxonomy. This dataset comprises multiple
emotionally nuanced variations of original sentences regenerated across
distinct contextual styles such as conversational, formal, poetic, and
narrative, using advanced Large Language Models LLMs. Rigorous computational
evaluation using metrics such as perplexity, embedding variance, readability,
lexical diversity, and semantic coherence measures validates the datasets
emotional authenticity, linguistic fluency, and textual diversity.
Comprehensive metric analyses affirm its potential to support deeper
explorations into emotion conditioned style adaptive text generation. By
enabling precision tuned emotionally nuanced language modeling, our dataset
creates fertile ground for research on fine grained emotional control, prompt
driven explanation, interpretability, and style adaptive expressive language
generation with LLMs.",2025-04-11
The Zero Body Problem: Probing LLM Use of Sensory Language,2025-04-08 19:31:37+00:00,http://arxiv.org/abs/2504.06393v1,"Rebecca M. M. Hicke, Sil Hamilton, David Mimno","cs.CL, cs.LG",story,"Sensory language expresses embodied experiences ranging from taste and sound
to excitement and stomachache. This language is of interest to scholars from a
wide range of domains including robotics, narratology, linguistics, and
cognitive science. In this work, we explore whether language models, which are
not embodied, can approximate human use of embodied language. We extend an
existing corpus of parallel human and model responses to short story prompts
with an additional 18,000 stories generated by 18 popular models. We find that
all models generate stories that differ significantly from human usage of
sensory language, but the direction of these differences varies considerably
between model families. Namely, Gemini models use significantly more sensory
language than humans along most axes whereas most models from the remaining
five families use significantly less. Linear probes run on five models suggest
that they are capable of identifying sensory language. However, we find
preliminary evidence suggesting that instruction tuning may discourage usage of
sensory language. Finally, to support further work, we release our expanded
story dataset.",2025-04-08
"Narrative Studio: Visual narrative exploration using LLMs and Monte
  Carlo Tree Search",2025-04-03 09:31:07+00:00,http://arxiv.org/abs/2504.02426v1,"Parsa Ghaffari, Chris Hokamp",cs.AI,story,"Interactive storytelling benefits from planning and exploring multiple 'what
if' scenarios. Modern LLMs are useful tools for ideation and exploration, but
current chat-based user interfaces restrict users to a single linear flow. To
address this limitation, we propose Narrative Studio -- a novel in-browser
narrative exploration environment featuring a tree-like interface that allows
branching exploration from user-defined points in a story. Each branch is
extended via iterative LLM inference guided by system and user-defined prompts.
Additionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand
promising narrative paths based on user-specified criteria, enabling more
diverse and robust story development. We also allow users to enhance narrative
coherence by grounding the generated text in an entity graph that represents
the actors and environment of the story.",2025-04-03
Leveraging LLMs for User Stories in AI Systems: UStAI Dataset,2025-04-01 08:03:40+00:00,http://arxiv.org/abs/2504.00513v1,"Asma Yamani, Malak Baslyman, Moataz Ahmed","cs.SE, cs.AI",story,"AI systems are gaining widespread adoption across various sectors and
domains. Creating high-quality AI system requirements is crucial for aligning
the AI system with business goals and consumer values and for social
responsibility. However, with the uncertain nature of AI systems and the heavy
reliance on sensitive data, more research is needed to address the elicitation
and analysis of AI systems requirements. With the proprietary nature of many AI
systems, there is a lack of open-source requirements artifacts and technical
requirements documents for AI systems, limiting broader research and
investigation. With Large Language Models (LLMs) emerging as a promising
alternative to human-generated text, this paper investigates the potential use
of LLMs to generate user stories for AI systems based on abstracts from
scholarly papers. We conducted an empirical evaluation using three LLMs and
generated $1260$ user stories from $42$ abstracts from $26$ domains. We assess
their quality using the Quality User Story (QUS) framework. Moreover, we
identify relevant non-functional requirements (NFRs) and ethical principles.
Our analysis demonstrates that the investigated LLMs can generate user stories
inspired by the needs of various stakeholders, offering a promising approach
for generating user stories for research purposes and for aiding in the early
requirements elicitation phase of AI systems. We have compiled and curated a
collection of stories generated by various LLMs into a dataset (UStAI), which
is now publicly available for use.",2025-04-01
Learning to Reason for Long-Form Story Generation,2025-03-28 18:48:26+00:00,http://arxiv.org/abs/2503.22828v1,"Alexander Gurung, Mirella Lapata",cs.CL,story,"Generating high-quality stories spanning thousands of tokens requires
competency across a variety of skills, from tracking plot and character arcs to
keeping a consistent and engaging style. Due to the difficulty of sourcing
labeled datasets and precise quality measurements, most work using large
language models (LLMs) for long-form story generation uses combinations of
hand-designed prompting techniques to elicit author-like behavior. This is a
manual process that is highly dependent on the specific story-generation task.
Motivated by the recent success of applying RL with Verifiable Rewards to
domains like math and coding, we propose a general story-generation task
(Next-Chapter Prediction) and a reward formulation (Verified Rewards via
Completion Likelihood Improvement) that allows us to use an unlabeled book
dataset as a learning signal for reasoning. We learn to reason over a story's
condensed information and generate a detailed plan for the next chapter. Our
reasoning is evaluated via the chapters it helps a story-generator create, and
compared against non-trained and supervised finetuning (SFT) baselines.
Pairwise human judgments reveal the chapters our learned reasoning produces are
preferred across almost all metrics, and the effect is more pronounced in Scifi
and Fantasy genres.",2025-03-28
"Evaluating book summaries from internal knowledge in Large Language
  Models: a cross-model and semantic consistency approach",2025-03-27 15:36:24+00:00,http://arxiv.org/abs/2503.21613v1,Javier Coronado-Bl√°zquez,cs.CL,story,"We study the ability of large language models (LLMs) to generate
comprehensive and accurate book summaries solely from their internal knowledge,
without recourse to the original text. Employing a diverse set of books and
multiple LLM architectures, we examine whether these models can synthesize
meaningful narratives that align with established human interpretations.
Evaluation is performed with a LLM-as-a-judge paradigm: each AI-generated
summary is compared against a high-quality, human-written summary via a
cross-model assessment, where all participating LLMs evaluate not only their
own outputs but also those produced by others. This methodology enables the
identification of potential biases, such as the proclivity for models to favor
their own summarization style over others. In addition, alignment between the
human-crafted and LLM-generated summaries is quantified using ROUGE and
BERTScore metrics, assessing the depth of grammatical and semantic
correspondence. The results reveal nuanced variations in content representation
and stylistic preferences among the models, highlighting both strengths and
limitations inherent in relying on internal knowledge for summarization tasks.
These findings contribute to a deeper understanding of LLM internal encodings
of factual information and the dynamics of cross-model evaluation, with
implications for the development of more robust natural language generative
systems.",2025-03-27
"Collaborative Storytelling and LLM: A Linguistic Analysis of
  Automatically-Generated Role-Playing Game Sessions",2025-03-26 15:10:47+00:00,http://arxiv.org/abs/2503.20623v1,Alessandro Maisto,"cs.CL, cs.AI",story,"Role-playing games (RPG) are games in which players interact with one another
to create narratives. The role of players in the RPG is largely based on the
interaction between players and their characters. This emerging form of shared
narrative, primarily oral, is receiving increasing attention. In particular,
many authors investigated the use of an LLM as an actor in the game. In this
paper, we aim to discover to what extent the language of Large Language Models
(LLMs) exhibit oral or written features when asked to generate an RPG session
without human interference. We will conduct a linguistic analysis of the
lexical and syntactic features of the generated texts and compare the results
with analyses of conversations, transcripts of human RPG sessions, and books.
We found that LLMs exhibit a pattern that is distinct from all other text
categories, including oral conversations, human RPG sessions and books. Our
analysis has shown how training influences the way LLMs express themselves and
provides important indications of the narrative capabilities of these tools.",2025-03-26
Accessible Text Descriptions for UpSet Plots,2025-03-21 20:02:21+00:00,http://arxiv.org/abs/2503.17517v1,"Andrew McNutt, Maggie K McCracken, Ishrat Jahan Eliza, Daniel Hajas, Jake Wagoner, Nate Lanza, Jack Wilburn, Sarah Creem-Regehr, Alexander Lex",cs.HC,story,"Data visualizations are typically not accessible to blind and low-vision
(BLV) users. Automatically generating text descriptions offers an enticing
mechanism for democratizing access to the information held in complex
scientific charts, yet appropriate procedures for generating those texts remain
elusive. Pursuing this issue, we study a single complex chart form: UpSet
plots. UpSet Plots are a common way to analyze set data, an area largely
unexplored by prior accessibility literature. By analyzing the patterns present
in real-world examples, we develop a system for automatically captioning any
UpSet plot. We evaluated the utility of our captions via semi-structured
interviews with (N=11) BLV users and found that BLV users find them
informative. In extensions, we find that sighted users can use our texts
similarly to UpSet plots and that they are better than naive LLM usage.",2025-03-21
"VaxGuard: A Multi-Generator, Multi-Type, and Multi-Role Dataset for
  Detecting LLM-Generated Vaccine Misinformation",2025-03-12 06:43:25+00:00,http://arxiv.org/abs/2503.09103v1,"Syed Talal Ahmad, Haohui Lu, Sidong Liu, Annie Lau, Amin Beheshti, Mark Dras, Usman Naseem",cs.CL,story,"Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities. However, they also present challenges,
particularly in generating vaccine-related misinformation, which poses risks to
public health. Despite research on human-authored misinformation, a notable gap
remains in understanding how LLMs contribute to vaccine misinformation and how
best to detect it. Existing benchmarks often overlook vaccine-specific
misinformation and the diverse roles of misinformation spreaders. This paper
introduces VaxGuard, a novel dataset designed to address these challenges.
VaxGuard includes vaccine-related misinformation generated by multiple LLMs and
provides a comprehensive framework for detecting misinformation across various
roles. Our findings show that GPT-3.5 and GPT-4o consistently outperform other
LLMs in detecting misinformation, especially when dealing with subtle or
emotionally charged narratives. On the other hand, PHI3 and Mistral show lower
performance, struggling with precision and recall in fear-driven contexts.
Additionally, detection performance tends to decline as input text length
increases, indicating the need for improved methods to handle larger content.
These results highlight the importance of role-specific detection strategies
and suggest that VaxGuard can serve as a key resource for improving the
detection of LLM-generated vaccine misinformation.",2025-03-12
"Social Bias Benchmark for Generation: A Comparison of Generation and
  QA-Based Evaluations",2025-03-10 07:06:47+00:00,http://arxiv.org/abs/2503.06987v1,"Jiho Jin, Woosung Kang, Junho Myung, Alice Oh","cs.CL, cs.AI",story,"Measuring social bias in large language models (LLMs) is crucial, but
existing bias evaluation methods struggle to assess bias in long-form
generation. We propose a Bias Benchmark for Generation (BBG), an adaptation of
the Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form
generation by having LLMs generate continuations of story prompts. Building our
benchmark in English and Korean, we measure the probability of neutral and
biased generations across ten LLMs. We also compare our long-form story
generation evaluation results with multiple-choice BBQ evaluation, showing that
the two approaches produce inconsistent results.",2025-03-10
"Where is my Glass Slipper? AI, Poetry and Art",2025-02-26 14:57:03+00:00,http://arxiv.org/abs/2503.05781v1,Anastasios P. Pagiaslis,"cs.CY, cs.CL, I.2.7; J.5",story,"This literature review interrogates the intersections between artificial
intelligence, poetry, and art, offering a comprehensive exploration of both
historical evolution and current debates in digital creative practices. It
traces the development of computer-generated poetry from early template-based
systems to generative models, critically assessing evaluative frameworks such
as adaptations of the Turing Test, the FACE model, and ProFTAP. It also
examines how these frameworks endeavour to measure creativity, semantic
coherence, and cultural relevance in AI-generated texts, whilst highlighting
the persistent challenges in replicating the nuance of human poetic expression.
  The review contributes a Marketing Theory discussion that deconstructs the
figurative marketing narratives employed by AI companies, which utilise
sanitised language and anthropomorphic metaphors to humanise their
technologies. This discussion reveals the reductive nature of such narratives
and underscores the tension between algorithmic precision and the realities of
human creativity.The review also incorporates an auto-ethnographic account that
offers a self-reflexive commentary on its own composition. By acknowledging the
use of AI in crafting this review, the auto-ethnographic account destabilises
conventional notions of authorship and objectivity, resonating with
deconstruction and challenging logocentric assumptions in academic discourse.
  Ultimately, the review calls for a re-evaluation of creative processes that
recognises the interdependence of technological innovation and human
subjectivity. It advocates for interdisciplinary dialogue addressing ethical,
cultural, and philosophical concerns, while reimagining the boundaries of
artistic production.",2025-02-26
"FactFlow: Automatic Fact Sheet Generation and Customization from Tabular
  Dataset via AI Chain Design & Implementation",2025-02-25 07:15:41+00:00,http://arxiv.org/abs/2502.17909v1,"Minh Duc Vu, Jieshan Chen, Zhenchang Xing, Qinghua Lu, Xiwei Xu, Qian Fu","cs.HC, cs.AI, I.2; H.4",story,"With the proliferation of data across various domains, there is a critical
demand for tools that enable non-experts to derive meaningful insights without
deep data analysis skills. To address this need, existing automatic fact sheet
generation tools offer heuristic-based solutions to extract facts and generate
stories. However, they inadequately grasp the semantics of data and struggle to
generate narratives that fully capture the semantics of the dataset or align
the fact sheet with specific user needs. Addressing these shortcomings, this
paper introduces \tool, a novel tool designed for the automatic generation and
customisation of fact sheets. \tool applies the concept of collaborative AI
workers to transform raw tabular dataset into comprehensive, visually
compelling fact sheets. We define effective taxonomy to profile AI worker for
specialised tasks. Furthermore, \tool empowers users to refine these fact
sheets through intuitive natural language commands, ensuring the final outputs
align closely with individual preferences and requirements. Our user evaluation
with 18 participants confirms that \tool not only surpasses state-of-the-art
baselines in automated fact sheet production but also provides a positive user
experience during customization tasks.",2025-02-25
"Whose story is it? Personalizing story generation by inferring author
  styles",2025-02-18 16:45:41+00:00,http://arxiv.org/abs/2502.13028v1,"Nischal Ashok Kumar, Chau Minh Pham, Mohit Iyyer, Andrew Lan",cs.CL,story,"Personalization has become essential for improving user experience in
interactive writing and educational applications, yet its potential in story
generation remains largely unexplored. In this work, we propose a novel
two-stage pipeline for personalized story generation. Our approach first infers
an author's implicit story-writing characteristics from their past work and
organizes them into an Author Writing Sheet, inspired by narrative theory. The
second stage uses this sheet to simulate the author's persona through tailored
persona descriptions and personalized story writing rules. To enable and
validate our approach, we construct Mythos, a dataset of 590 stories from 64
authors across five distinct sources that reflect diverse story-writing
settings. A head-to-head comparison with a non-personalized baseline
demonstrates our pipeline's effectiveness in generating high-quality
personalized stories. Our personalized stories achieve a 75 percent win rate
(versus 14 percent for the baseline and 11 percent ties) in capturing authors'
writing style based on their past works. Human evaluation highlights the high
quality of our Author Writing Sheet and provides valuable insights into the
personalized story generation task. Notable takeaways are that writings from
certain sources, such as Reddit, are easier to personalize than others, like
AO3, while narrative aspects, like Creativity and Language Use, are easier to
personalize than others, like Plot.",2025-02-18
"Context-Preserving Gradient Modulation for Large Language Models: A
  Novel Approach to Semantic Consistency in Long-Form Text Generation",2025-02-05 22:13:06+00:00,http://arxiv.org/abs/2502.03643v1,"Nirola Kobanov, Edmund Weatherstone, Zachary Vanderpoel, Orlando Wetherby",cs.CL,story,"Maintaining semantic consistency over extended text sequences remains a
fundamental challenge in long-form text generation, where conventional training
methodologies often struggle to prevent contextual drift and coherence
degradation. A novel gradient modulation approach is introduced, designed to
adjust parameter updates dynamically in response to contextual relevance,
ensuring that generated text remains aligned with prior discourse. By
integrating a modulation function that selectively amplifies or attenuates
gradients based on learned contextual dependencies, the proposed method
enhances the stability of model-generated narratives without imposing
significant computational overhead. Comparative evaluations against baseline
models reveal improvements in coherence, contextual retention, and long-range
dependency tracking, demonstrating the effectiveness of modifying the learning
process at the gradient level. The results indicate that sentence structure
variability and lexical diversity benefit from this approach, mitigating
repetitive phrasing and improving adaptability across diverse linguistic
contexts. Statistical validation of coherence metrics further substantiates the
observed enhancements, with a significant reduction in inconsistencies emerging
as a direct consequence of the modulation mechanism. Computational efficiency
assessments confirm that the framework achieves these gains without requiring
substantial modifications to the underlying architecture, ensuring
compatibility with existing optimization workflows.",2025-02-05
Path Planning for Masked Diffusion Model Sampling,2025-02-05 19:00:52+00:00,http://arxiv.org/abs/2502.03540v2,"Fred Zhangzhi Peng, Zachary Bezemek, Sawan Patel, Jarrid Rector-Brooks, Sherwood Yao, Alexander Tong, Pranam Chatterjee","cs.LG, cs.AI",story,"In this paper, we explore how token unmasking order influences generative
quality in masked diffusion models (MDMs). We derive an expanded evidence lower
bound (ELBO) that introduces a planner to select which tokens to unmask at each
step. Our analysis reveals that alternative unmasking strategies can enhance
generation performance. Building on this, we propose Path Planning (P2), a
sampling framework that uses a pre-trained BERT model or the denoiser itself to
guide unmasking decisions. P2 generalizes all known MDM sampling strategies and
significantly improves performance across diverse domains, including language
generation (in-context learning, code generation, story infilling, mathematical
reasoning, reverse curse correction) and biological sequence generation
(protein and RNA sequences).",2025-02-05
"Classic4Children: Adapting Chinese Literary Classics for Children with
  Large Language Model",2025-02-03 06:23:35+00:00,http://arxiv.org/abs/2502.01090v1,"Jiali Chen, Xusen Hei, Yuqi Xue, Zihan Wu, Jiayuan Xie, Yi Cai","cs.CL, cs.AI",story,"Chinese literary classics hold significant cultural and educational value,
offering deep insights into morality, history, and human nature. These works
often include classical Chinese and complex narratives, making them difficult
for children to read. To bridge this gap, we introduce a child-friendly
literary adaptation (CLA) task to adapt the Chinese literary classic into
engaging and accessible text for children. However, recent large language
models (LLMs) overlook children's reading preferences (\ie, vivid character
portrayals, concise narrative structures, and appropriate readability), which
poses challenges in CLA. In this paper, we propose a method called
InstructChild, which augments the LLM with these preferences for adaptation.
Specifically, we first obtain the characters' personalities and narrative
structure as additional information for fine-grained instruction tuning. Then,
we devise a readability metric as the reward to align the LLM with the
children's reading level. Finally, a lookahead decoding strategy is applied to
improve the readability of the generated text during inference. To support the
evaluation of CLA task, we construct the Classic4Children dataset, which
comprises both the original and child-friendly versions of the Four Great
Classical Novels of Chinese literature. Experimental results show that our
InstructChild significantly improves automatic and human evaluation
performance.",2025-02-03
"Structural Embedding Projection for Contextual Large Language Model
  Inference",2025-01-31 00:46:21+00:00,http://arxiv.org/abs/2501.18826v1,"Vincent Enoasmo, Cedric Featherstonehaugh, Xavier Konstantinopoulos, Zacharias Huntington",cs.CL,story,"Structured embedding transformations offer a promising approach for enhancing
the efficiency and coherence of language model inference. The introduction of
Structural Embedding Projection (SEP) provides a mechanism for refining token
representations through projection matrices that integrate hierarchical and
relational dependencies. The mathematical formulation of SEP enables embedding
spaces to capture structured contextual relationships, thereby improving
semantic fidelity without significantly increasing computational overhead.
Experimental evaluations conducted on a range of linguistic datasets revealed
that SEP contributed to reductions in perplexity and enhanced contextual
coherence, demonstrating its potential to refine language model outputs.
Computational efficiency assessments highlighted variations across different
datasets, suggesting that the integration of structured embeddings introduced
dataset-dependent trade-offs between inference speed and representational
richness. The qualitative analysis of generated responses indicated that SEP
enhanced narrative consistency and topic alignment, leading to improved fluency
in multi-sentence text generation. The modifications to embedding layers
required precise optimization to ensure stable training dynamics, as the
introduction of structured transformations altered the traditional
representation-learning process. The architectural adjustments necessary for
SEP implementation influenced inference latency and memory consumption,
requiring a balance between efficiency gains and additional processing demands.
The impact of SEP on lexical diversity suggested that embedding modifications
influenced the model's vocabulary usage, reflecting a more context-aware
selection of generated tokens.",2025-01-31
Context-Aware Semantic Recomposition Mechanism for Large Language Models,2025-01-29 02:38:28+00:00,http://arxiv.org/abs/2501.17386v1,"Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield","cs.CL, cs.AI",story,"Context-aware processing mechanisms have increasingly become a critical area
of exploration for improving the semantic and contextual capabilities of
language generation models. The Context-Aware Semantic Recomposition Mechanism
(CASRM) was introduced as a novel framework designed to address limitations in
coherence, contextual adaptability, and error propagation in large-scale text
generation tasks. Through the integration of dynamically generated context
vectors and attention modulation layers, CASRM enhances the alignment between
token-level representations and broader contextual dependencies. Experimental
evaluations demonstrated significant improvements in semantic coherence across
multiple domains, including technical, conversational, and narrative text. The
ability to adapt to unseen domains and ambiguous inputs was evaluated using a
diverse set of test scenarios, highlighting the robustness of the proposed
mechanism. A detailed computational analysis revealed that while CASRM
introduces additional processing overhead, the gains in linguistic precision
and contextual relevance outweigh the marginal increase in complexity. The
framework also successfully mitigates error propagation in sequential tasks,
improving performance in dialogue continuation and multi-step text synthesis.
Additional investigations into token-level attention distribution emphasized
the dynamic focus shifts enabled through context-aware enhancements. The
findings suggest that CASRM offers a scalable and flexible solution for
integrating contextual intelligence into existing language model architectures.",2025-01-29
"VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic
  Health Records",2025-01-28 03:13:16+00:00,http://arxiv.org/abs/2501.16672v1,"Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour","cs.AI, cs.CL, cs.IR, cs.LO",story,"Methods to ensure factual accuracy of text generated by large language models
(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence
system that combines retrieval-augmented generation and LLM-as-a-Judge to
verify whether LLM-generated text is factually supported by a patient's medical
history based on their electronic health record (EHR). To evaluate this system,
we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course
narratives from discharge summaries into a set of simple statements with
clinician annotations for whether each statement is supported by the patient's
EHR clinical notes. Whereas highest agreement between clinicians was 88.5%,
VeriFact achieves up to 92.7% agreement when compared to a denoised and
adjudicated average human clinican ground truth, suggesting that VeriFact
exceeds the average clinician's ability to fact-check text against a patient's
medical record. VeriFact may accelerate the development of LLM-based EHR
applications by removing current evaluation bottlenecks.",2025-01-28
"People who frequently use ChatGPT for writing tasks are accurate and
  robust detectors of AI-generated text",2025-01-26 19:31:34+00:00,http://arxiv.org/abs/2501.15654v1,"Jenna Russell, Marzena Karpinska, Mohit Iyyer","cs.CL, cs.AI",story,"In this paper, we study how well humans can detect text generated by
commercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300
non-fiction English articles, label them as either human-written or
AI-generated, and provide paragraph-length explanations for their decisions.
Our experiments show that annotators who frequently use LLMs for writing tasks
excel at detecting AI-generated text, even without any specialized training or
feedback. In fact, the majority vote among five such ""expert"" annotators
misclassifies only 1 of 300 articles, significantly outperforming most
commercial and open-source detectors we evaluated even in the presence of
evasion tactics like paraphrasing and humanization. Qualitative analysis of the
experts' free-form explanations shows that while they rely heavily on specific
lexical clues ('AI vocabulary'), they also pick up on more complex phenomena
within the text (e.g., formality, originality, clarity) that are challenging to
assess for automatic detectors. We release our annotated dataset and code to
spur future research into both human and automated detection of AI-generated
text.",2025-01-26
"Instruction Tuning for Story Understanding and Generation with Weak
  Supervision",2025-01-26 15:59:31+00:00,http://arxiv.org/abs/2501.15574v1,"Yangshu Yuan, Heng Chen, Christian Ng",cs.CL,story,"Story understanding and generation have long been a challenging task in
natural language processing (NLP), especially when dealing with various levels
of instruction specificity. In this paper, we propose a novel approach called
""Weak to Strong Instruction Tuning"" for improving story generation by tuning
models with instructions of varying clarity. We explore the potential of large
language models (LLMs) to adapt to different types of instructions, weak and
strong, and show that our method significantly enhances performance in story
comprehension and generation. By leveraging the strength of instruction tuning,
we train models to understand the nuances of story plots, characters, and
themes while generating coherent and engaging narratives. Through extensive
experiments on several benchmark datasets and comparison with state-of-the-art
baselines, we demonstrate that our method outperforms existing techniques,
yielding substantial improvements in both automatic evaluation metrics and
human evaluations. Our work shows that adaptive instruction tuning can be a
powerful tool in refining generative models for complex narrative tasks.",2025-01-26
"Semantic Layered Embedding Diffusion in Large Language Models for
  Multi-Contextual Consistency",2025-01-26 05:17:04+00:00,http://arxiv.org/abs/2501.15405v1,"Irin Kabakum, Thomas Montgomery, Daniel Ravenwood, Genevieve Harrington","cs.CL, cs.AI",story,"The Semantic Layered Embedding Diffusion (SLED) mechanism redefines the
representation of hierarchical semantics within transformer-based
architectures, enabling enhanced contextual consistency across a wide array of
linguistic tasks. By introducing a multi-layered diffusion process grounded in
spectral analysis, it achieves a complex balance between global and local
semantic coherence. Experimental results demonstrate significant improvements
in perplexity and BLEU scores, emphasizing the mechanism's ability to adapt
effectively across diverse domains, including multilingual and cross-domain
text generation. A rigorous mathematical framework underpins the embedding
diffusion process, incorporating weighted adjacency matrices, kernel-based
refinements, and dynamic layer-wise normalization. Error distribution analysis
reveals that SLED addresses challenges in semantic alignment and coherence,
outperforming baseline approaches across varied benchmarks. Scalability studies
illustrate that its performance gains are maintained consistently across
different model sizes, reflecting a practical balance between computational
efficiency and linguistic precision. The implementation also achieves energy
efficiency, reducing resource consumption during training and inference phases
without compromising accuracy. Qualitative case studies further validate its
adaptability to extended narratives and context-intensive scenarios,
highlighting the mechanism's potential for real-world applications. SLED offers
a different perspective on embedding design and its implications for advancing
language modeling.",2025-01-26
"Toyteller: AI-powered Visual Storytelling Through Toy-Playing with
  Character Symbols",2025-01-23 00:20:38+00:00,http://arxiv.org/abs/2501.13284v1,"John Joon Young Chung, Melissa Roemmele, Max Kreminski","cs.HC, cs.AI, cs.CL",story,"We introduce Toyteller, an AI-powered storytelling system where users
generate a mix of story text and visuals by directly manipulating character
symbols like they are toy-playing. Anthropomorphized symbol motions can convey
rich and nuanced social interactions; Toyteller leverages these motions (1) to
let users steer story text generation and (2) as a visual output format that
accompanies story text. We enabled motion-steered text generation and
text-steered motion generation by mapping motions and text onto a shared
semantic space so that large language models and motion generation models can
use it as a translational layer. Technical evaluations showed that Toyteller
outperforms a competitive baseline, GPT-4o. Our user study identified that
toy-playing helps express intentions difficult to verbalize. However, only
motions could not express all user intentions, suggesting combining it with
other modalities like language. We discuss the design space of toy-playing
interactions and implications for technical HCI research on human-AI
interaction.",2025-01-23
"Neural Contextual Reinforcement Framework for Logical Structure Language
  Generation",2025-01-20 11:34:28+00:00,http://arxiv.org/abs/2501.11417v1,"Marcus Irvin, William Cooper, Edward Hughes, Jessica Morgan, Christopher Hamilton","cs.CL, cs.AI",story,"The Neural Contextual Reinforcement Framework introduces an innovative
approach to enhancing the logical coherence and structural consistency of text
generated by large language models. Leveraging reinforcement learning
principles, the framework integrates custom reward functions and dynamic
context alignment mechanisms to address challenges inherent in maintaining
long-range dependencies across extended sequences. The architecture
incorporates multi-head attention layers and hierarchical encoding modules,
enabling the model to produce outputs that align closely with human
expectations of logical structure and semantic flow. Quantitative evaluations
across diverse datasets demonstrate substantial improvements in coherence
metrics, perplexity reduction, and semantic alignment, showcasing the
framework's ability to outperform baseline models in both general and
domain-specific tasks. Qualitative analyses further highlight the framework's
capacity to generate text with improved narrative clarity and reduced
redundancy, reflecting its effectiveness in balancing fluency with structural
precision. In addition to its performance gains, the framework exhibits
robustness in handling noisy input data and scalability across varying model
sizes, reinforcing its versatility in practical applications. Experimental
results reveal that optimal context window sizes significantly influence
coherence outcomes, showing the importance of architectural flexibility in
adapting to diverse linguistic structures. Cross-lingual performance
evaluations affirm the framework's adaptability to multiple languages,
extending its utility beyond monolingual contexts. Resource efficiency analyses
indicate a reduction in computational overhead compared to traditional
approaches, emphasizing the practicality of the framework for large-scale
deployment.",2025-01-20
"Why are we living the age of AI applications right now? The long
  innovation path from AI's birth to a child's bedtime magic",2025-01-12 20:50:24+00:00,http://arxiv.org/abs/2501.06929v1,Tapio Pitk√§ranta,"cs.CY, cs.AI",story,"Today a four-year-old child who does not know how to read or write can now
create bedtime stories with graphical illustrations and narrated audio, using
AI tools that seamlessly transform speech into text, generate visuals, and
convert text back into speech in a natural and engaging manner. This remarkable
example demonstrates why we are living in the age of AI applications. This
paper examines contemporary leading AI applications and traces their historical
development, highlighting the major advancements that have enabled their
realization. Five key factors are identified: 1) The evolution of computational
hardware (CPUs and GPUs), enabling the training of complex AI models 2) The
vast digital archives provided by the World Wide Web, which serve as a
foundational data resource for AI systems 3) The ubiquity of mobile computing,
with smartphones acting as powerful, accessible small computers in the hands of
billions 4) The rise of industrial-scale cloud infrastructures, offering
elastic computational power for AI training and deployment 5) Breakthroughs in
AI research, including neural networks, backpropagation, and the ""Attention is
All You Need"" framework, which underpin modern AI capabilities. These
innovations have elevated AI from solving narrow tasks to enabling applications
like ChatGPT that are adaptable for numerous use cases, redefining
human-computer interaction. By situating these developments within a historical
context, the paper highlights the critical milestones that have made AI's
current capabilities both possible and widely accessible, offering profound
implications for society.",2025-01-12
"Examining the Robustness of Homogeneity Bias to Hyperparameter
  Adjustments in GPT-4",2025-01-04 06:51:49+00:00,http://arxiv.org/abs/2501.02211v1,Messi H. J. Lee,"cs.CV, cs.CL, cs.LG",story,"Vision-Language Models trained on massive collections of human-generated data
often reproduce and amplify societal stereotypes. One critical form of
stereotyping reproduced by these models is homogeneity bias-the tendency to
represent certain groups as more homogeneous than others. We investigate how
this bias responds to hyperparameter adjustments in GPT-4, specifically
examining sampling temperature and top p which control the randomness of model
outputs. By generating stories about individuals from different racial and
gender groups and comparing their similarities using vector representations, we
assess both bias robustness and its relationship with hyperparameter values. We
find that (1) homogeneity bias persists across most hyperparameter
configurations, with Black Americans and women being represented more
homogeneously than White Americans and men, (2) the relationship between
hyperparameters and group representations shows unexpected non-linear patterns,
particularly at extreme values, and (3) hyperparameter adjustments affect
racial and gender homogeneity bias differently-while increasing temperature or
decreasing top p can reduce racial homogeneity bias, these changes show
different effects on gender homogeneity bias. Our findings suggest that while
hyperparameter tuning may mitigate certain biases to some extent, it cannot
serve as a universal solution for addressing homogeneity bias across different
social group dimensions.",2025-01-04
"An Investigation into Value Misalignment in LLM-Generated Texts for
  Cultural Heritage",2025-01-03 14:35:32+00:00,http://arxiv.org/abs/2501.02039v1,"Fan Bu, Zheng Wang, Siyi Wang, Ziyao Liu","cs.CL, cs.AI",story,"As Large Language Models (LLMs) become increasingly prevalent in tasks
related to cultural heritage, such as generating descriptions of historical
monuments, translating ancient texts, preserving oral traditions, and creating
educational content, their ability to produce accurate and culturally aligned
texts is being increasingly relied upon by users and researchers. However,
cultural value misalignments may exist in generated texts, such as the
misrepresentation of historical facts, the erosion of cultural identity, and
the oversimplification of complex cultural narratives, which may lead to severe
consequences. Therefore, investigating value misalignment in the context of LLM
for cultural heritage is crucial for mitigating these risks, yet there has been
a significant lack of systematic and comprehensive study and investigation in
this area. To fill this gap, we systematically assess the reliability of LLMs
in generating culturally aligned texts for cultural heritage-related tasks. We
conduct a comprehensive evaluation by compiling an extensive set of 1066 query
tasks covering 5 widely recognized categories with 17 aspects within the
knowledge framework of cultural heritage across 5 open-source LLMs, and examine
both the type and rate of cultural value misalignments in the generated texts.
Using both automated and manual approaches, we effectively detect and analyze
the cultural value misalignments in LLM-generated texts. Our findings are
concerning: over 65% of the generated texts exhibit notable cultural
misalignments, with certain tasks demonstrating almost complete misalignment
with key cultural values. Beyond these findings, this paper introduces a
benchmark dataset and a comprehensive evaluation workflow that can serve as a
valuable resource for future research aimed at enhancing the cultural
sensitivity and reliability of LLMs.",2025-01-03
Echoes in AI: Quantifying Lack of Plot Diversity in LLM Outputs,2024-12-31 04:54:48+00:00,http://arxiv.org/abs/2501.00273v1,"Weijia Xu, Nebojsa Jojic, Sudha Rao, Chris Brockett, Bill Dolan",cs.CL,story,"With rapid advances in large language models (LLMs), there has been an
increasing application of LLMs in creative content ideation and generation. A
critical question emerges: can current LLMs provide ideas that are diverse
enough to truly bolster the collective creativity? We examine two
state-of-the-art LLMs, GPT-4 and LLaMA-3, on story generation and discover that
LLM-generated stories often consist of plot elements that are echoed across a
number of generations. To quantify this phenomenon, we introduce the Sui
Generis score, which estimates how unlikely a plot element is to appear in
alternative storylines generated by the same LLM. Evaluating on 100 short
stories, we find that LLM-generated stories often contain combinations of
idiosyncratic plot elements echoed frequently across generations, while the
original human-written stories are rarely recreated or even echoed in pieces.
Moreover, our human evaluation shows that the ranking of Sui Generis scores
among story segments correlates moderately with human judgment of surprise
level, even though score computation is completely automatic without relying on
human judgment.",2024-12-31
"Are We in the AI-Generated Text World Already? Quantifying and
  Monitoring AIGT on Social Media",2024-12-24 04:04:54+00:00,http://arxiv.org/abs/2412.18148v1,"Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He","cs.AI, cs.CL, cs.CR, cs.SI",story,"Social media platforms are experiencing a growing presence of AI-Generated
Texts (AIGTs). However, the misuse of AIGTs could have profound implications
for public opinion, such as spreading misinformation and manipulating
narratives. Despite its importance, a systematic study to assess the prevalence
of AIGTs on social media is still lacking. To address this gap, this paper aims
to quantify, monitor, and analyze the AIGTs on online social media platforms.
We first collect a dataset (SM-D) with around 2.4M posts from 3 major social
media platforms: Medium, Quora, and Reddit. Then, we construct a diverse
dataset (AIGTBench) to train and evaluate AIGT detectors. AIGTBench combines
popular open-source datasets and our AIGT datasets generated from social media
texts by 12 LLMs, serving as a benchmark for evaluating mainstream detectors.
With this setup, we identify the best-performing detector (OSM-Det). We then
apply OSM-Det to SM-D to track AIGTs over time and observe different trends of
AI Attribution Rate (AAR) across social media platforms from January 2022 to
October 2024. Specifically, Medium and Quora exhibit marked increases in AAR,
rising from 1.77% to 37.03% and 2.06% to 38.95%, respectively. In contrast,
Reddit shows slower growth, with AAR increasing from 1.31% to 2.45% over the
same period. Our further analysis indicates that AIGTs differ from
human-written texts across several dimensions, including linguistic patterns,
topic distributions, engagement levels, and the follower distribution of
authors. We envision our analysis and findings on AIGTs in social media can
shed light on future research in this domain.",2024-12-24
"Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small
  Language Models Write Young Students Texts",2024-12-19 15:58:53+00:00,http://arxiv.org/abs/2412.14986v1,"Ioana Buhnila, Georgeta Cislaru, Amalia Todirascu",cs.CL,story,"Large Language Models (LLMs) have been used to generate texts in response to
different writing tasks: reports, essays, story telling. However, language
models do not have a meta-representation of the text writing process, nor
inherent communication learning needs, comparable to those of young human
students. This paper introduces a fine-grained linguistic and textual analysis
of multilingual Small Language Models' (SLMs) writing. With our method,
Chain-of-MetaWriting, SLMs can imitate some steps of the human writing process,
such as planning and evaluation. We mainly focused on short story and essay
writing tasks in French for schoolchildren and undergraduate students
respectively. Our results show that SLMs encounter difficulties in assisting
young students on sensitive topics such as violence in the schoolyard, and they
sometimes use words too complex for the target audience. In particular, the
output is quite different from the human produced texts in term of text
cohesion and coherence regarding temporal connectors, topic progression,
reference.",2024-12-19
"Evaluation of LLM Vulnerabilities to Being Misused for Personalized
  Disinformation Generation",2024-12-18 09:48:53+00:00,http://arxiv.org/abs/2412.13666v1,"Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopal, Katarina Marcincinova, Matus Mesarcik","cs.CL, cs.AI, cs.CY",story,"The capabilities of recent large language models (LLMs) to generate
high-quality content indistinguishable by humans from human-written texts rises
many concerns regarding their misuse. Previous research has shown that LLMs can
be effectively misused for generating disinformation news articles following
predefined narratives. Their capabilities to generate personalized (in various
aspects) content have also been evaluated and mostly found usable. However, a
combination of personalization and disinformation abilities of LLMs has not
been comprehensively studied yet. Such a dangerous combination should trigger
integrated safety filters of the LLMs, if there are some. This study fills this
gap by evaluation of vulnerabilities of recent open and closed LLMs, and their
willingness to generate personalized disinformation news articles in English.
We further explore whether the LLMs can reliably meta-evaluate the
personalization quality and whether the personalization affects the
generated-texts detectability. Our results demonstrate the need for stronger
safety-filters and disclaimers, as those are not properly functioning in most
of the evaluated LLMs. Additionally, our study revealed that the
personalization actually reduces the safety-filter activations; thus
effectively functioning as a jailbreak. Such behavior must be urgently
addressed by LLM developers and service providers.",2024-12-18
"Generating Long-form Story Using Dynamic Hierarchical Outlining with
  Memory-Enhancement",2024-12-18 07:50:54+00:00,http://arxiv.org/abs/2412.13575v1,"Qianyue Wang, Jinwu Hu, Zhengping Li, Yufeng Wang, daiyuan li, Yu Hu, Mingkui Tan",cs.CL,story,"Long-form story generation task aims to produce coherent and sufficiently
lengthy text, essential for applications such as novel writingand interactive
storytelling. However, existing methods, including LLMs, rely on rigid outlines
or lack macro-level planning, making it difficult to achieve both contextual
consistency and coherent plot development in long-form story generation. To
address this issues, we propose Dynamic Hierarchical Outlining with
Memory-Enhancement long-form story generation method, named DOME, to generate
the long-form story with coherent content and plot. Specifically, the Dynamic
Hierarchical Outline(DHO) mechanism incorporates the novel writing theory into
outline planning and fuses the plan and writing stages together, improving the
coherence of the plot by ensuring the plot completeness and adapting to the
uncertainty during story generation. A Memory-Enhancement Module (MEM) based on
temporal knowledge graphs is introduced to store and access the generated
content, reducing contextual conflicts and improving story coherence. Finally,
we propose a Temporal Conflict Analyzer leveraging temporal knowledge graphs to
automatically evaluate the contextual consistency of long-form story.
Experiments demonstrate that DOME significantly improves the fluency,
coherence, and overall quality of generated long stories compared to
state-of-the-art methods.",2024-12-18
"Improving Linguistic Diversity of Large Language Models with Possibility
  Exploration Fine-Tuning",2024-12-04 14:23:16+00:00,http://arxiv.org/abs/2412.03343v1,"Long Mai, Julie Carson-Berndsen","cs.CL, cs.AI",story,"While Large Language Models (LLMs) have made significant strides in
replicating human-like abilities, there are concerns about a reduction in the
linguistic diversity of their outputs. This results in the homogenization of
viewpoints and perspectives, as well as the underrepresentation of specific
demographic groups. Although several fine-tuning and prompting techniques have
been suggested to tackle the issue, they are often tailored to specific tasks
or come with a substantial increase in computational cost and latency. This
makes them challenging to apply to applications that demand very low latency,
such as chatbots and virtual assistants. We propose Possibility Exploration
Fine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity
of LLMs without increasing latency or computational cost. Given the same
prompt, models fine-tuned with PEFT can simultaneously generate multiple
diverse responses, each corresponding with a controllable possibility number.
Experiments on dialogue and story generation tasks demonstrate that PEFT
significantly enhances the diversity of LLM outputs, as evidenced by lower
similarity between candidate responses. Since PEFT emphasizes semantic
diversity over lexical diversity, it can also notably reduce demographic bias
in dialogue systems. The implementations and datasets are available in our
repository: https://github.com/mailong25/peft_diversity",2024-12-04
"MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions
  and Actions",2024-12-03 23:01:21+00:00,http://arxiv.org/abs/2412.02897v1,"Jinming Zhang, Yunfei Long","cs.CL, cs.AI",story,"Narrative understanding and story generation are critical challenges in
natural language processing (NLP), with much of the existing research focused
on summarization and question-answering tasks. While previous studies have
explored predicting plot endings and generating extended narratives, they often
neglect the logical coherence within stories, leaving a significant gap in the
field. To address this, we introduce the Missing Logic Detector by Emotion and
Action (MLD-EA) model, which leverages large language models (LLMs) to identify
narrative gaps and generate coherent sentences that integrate seamlessly with
the story's emotional and logical flow. The experimental results demonstrate
that the MLD-EA model enhances narrative understanding and story generation,
highlighting LLMs' potential as effective logic checkers in story writing with
logical coherence and emotional consistency. This work fills a gap in NLP
research and advances border goals of creating more sophisticated and reliable
story-generation systems.",2024-12-03
"Forma mentis networks predict creativity ratings of short texts via
  interpretable artificial intelligence in human and GPT-simulated raters",2024-11-30 16:33:48+00:00,http://arxiv.org/abs/2412.00530v1,"Edith Haim, Natalie Fischer, Salvatore Citraro, Giulio Rossetti, Massimo Stella","cs.AI, cs.CL, cs.LG",story,"Creativity is a fundamental skill of human cognition. We use textual forma
mentis networks (TFMN) to extract network (semantic/syntactic associations) and
emotional features from approximately one thousand human- and GPT3.5-generated
stories. Using Explainable Artificial Intelligence (XAI), we test whether
features relative to Mednick's associative theory of creativity can explain
creativity ratings assigned by humans and GPT-3.5. Using XGBoost, we examine
three scenarios: (i) human ratings of human stories, (ii) GPT-3.5 ratings of
human stories, and (iii) GPT-3.5 ratings of GPT-generated stories. Our findings
reveal that GPT-3.5 ratings differ significantly from human ratings not only in
terms of correlations but also because of feature patterns identified with XAI
methods. GPT-3.5 favours 'its own' stories and rates human stories differently
from humans. Feature importance analysis with SHAP scores shows that: (i)
network features are more predictive for human creativity ratings but also for
GPT-3.5's ratings of human stories; (ii) emotional features played a greater
role than semantic/syntactic network structure in GPT-3.5 rating its own
stories. These quantitative results underscore key limitations in GPT-3.5's
ability to align with human assessments of creativity. We emphasise the need
for caution when using GPT-3.5 to assess and generate creative content, as it
does not yet capture the nuanced complexity that characterises human
creativity.",2024-11-30
"Richer Output for Richer Countries: Uncovering Geographical Disparities
  in Generated Stories and Travel Recommendations",2024-11-11 19:25:25+00:00,http://arxiv.org/abs/2411.07320v1,"Kirti Bhagat, Kinshuk Vasisht, Danish Pruthi","cs.CL, cs.AI, cs.CY, cs.LG",story,"While a large body of work inspects language models for biases concerning
gender, race, occupation and religion, biases of geographical nature are
relatively less explored. Some recent studies benchmark the degree to which
large language models encode geospatial knowledge. However, the impact of the
encoded geographical knowledge (or lack thereof) on real-world applications has
not been documented. In this work, we examine large language models for two
common scenarios that require geographical knowledge: (a) travel
recommendations and (b) geo-anchored story generation. Specifically, we study
four popular language models, and across about $100$K travel requests, and
$200$K story generations, we observe that travel recommendations corresponding
to poorer countries are less unique with fewer location references, and stories
from these regions more often convey emotions of hardship and sadness compared
to those from wealthier nations.",2024-11-11
Bayesian Calibration of Win Rate Estimation with LLM Evaluators,2024-11-07 04:32:40+00:00,http://arxiv.org/abs/2411.04424v1,"Yicheng Gao, Gonghan Xu, Zhe Wang, Arman Cohan","cs.CL, cs.AI",story,"Recent advances in large language models (LLMs) show the potential of using
LLMs as evaluators for assessing the quality of text generations from LLMs.
However, applying LLM evaluators naively to compare or judge between different
systems can lead to unreliable results due to the intrinsic win rate estimation
bias of LLM evaluators. In order to mitigate this problem, we propose two
calibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian
Dawid-Skene, both of which leverage Bayesian inference to more accurately infer
the true win rate of generative language models. We empirically validate our
methods on six datasets covering story generation, summarization, and
instruction following tasks. We show that both our methods are effective in
improving the accuracy of win rate estimation using LLMs as evaluators,
offering a promising direction for reliable automatic text quality evaluation.",2024-11-07
"Evaluating Creative Short Story Generation in Humans and Large Language
  Models",2024-11-04 17:40:39+00:00,http://arxiv.org/abs/2411.02316v2,"Mete Ismayilzada, Claire Stevenson, Lonneke van der Plas","cs.CL, cs.AI",story,"Storytelling is a fundamental aspect of human communication, relying heavily
on creativity to produce narratives that are novel, appropriate, and
surprising. While large language models (LLMs) have recently demonstrated the
ability to generate high-quality stories, their creative capabilities remain
underexplored. Previous research has either focused on creativity tests
requiring short responses or primarily compared model performance in story
generation to that of professional writers. However, the question of whether
LLMs exhibit creativity in writing short stories on par with the average human
remains unanswered. In this work, we conduct a systematic analysis of
creativity in short story generation across LLMs and everyday people. Using a
five-sentence creative story task, commonly employed in psychology to assess
human creativity, we automatically evaluate model- and human-generated stories
across several dimensions of creativity, including novelty, surprise, and
diversity. Our findings reveal that while LLMs can generate stylistically
complex stories, they tend to fall short in terms of creativity when compared
to average human writers.",2024-11-04
"A Multi-Task Role-Playing Agent Capable of Imitating Character
  Linguistic Styles",2024-11-04 02:26:27+00:00,http://arxiv.org/abs/2411.02457v1,"Siyuan Chen, Qingyi Si, Chenxu Yang, Yunzhi Liang, Zheng Lin, Huan Liu, Weiping Wang","cs.CL, cs.AI",story,"The advent of large language models (LLMs) has significantly propelled the
advancement of Role-Playing Agents (RPAs). However, current Role-Playing Agents
predominantly focus on mimicking a character's fundamental attributes while
neglecting the replication of linguistic style, and they are incapable of
effectively replicating characters when performing tasks beyond multi-turn
dialogues, which results in generated responses that lack authenticity. The
reason current RPAs lack this capability is due to the nature of existing
character datasets, which lack collections of character quotations and are
limited to multi-turn dialogue tasks, constraining the RPA's performance across
other task domains and failing to mimic a character's linguistic style. To
address this gap, we developed a multi-task role-playing dataset named MRstyle,
which encompasses a substantial number of real individuals along with their
quotations and covers seven different tasks. On this basis, we develop
StyleRPA, a Multi-Task Role-Playing Agent (MRPA) that significantly outperforms
recent open-source LLMs and RPAs baselines on 7 tasks including Dialogue,
Dictionary, Composition, Story Generation, Product Description, Music
Commentary, and Open Question Answering. The code and data will be released.",2024-11-04
"KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western
  Cultures",2024-10-25 09:23:24+00:00,http://arxiv.org/abs/2410.19419v2,"Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal",cs.CL,story,"Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated
the ability to generate compelling text and visual stories. However, their
outputs are predominantly aligned with the sensibilities of the Global North,
often resulting in an outsider's gaze on other cultures. As a result,
non-Western communities have to put extra effort into generating culturally
specific stories. To address this challenge, we developed a visual storytelling
pipeline called KAHANI that generates culturally grounded visual stories for
non-Western cultures. Our pipeline leverages off-the-shelf models GPT-4 Turbo
and Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I
prompting techniques, we capture the cultural context from user's prompt and
generate vivid descriptions of the characters and scene compositions. To
evaluate the effectiveness of KAHANI, we conducted a comparative user study
with ChatGPT-4 (with DALL-E3) in which participants from different regions of
India compared the cultural relevance of stories generated by the two tools.
Results from the qualitative and quantitative analysis performed on the user
study showed that KAHANI was able to capture and incorporate more Culturally
Specific Items (CSIs) compared to ChatGPT-4. In terms of both its cultural
competence and visual story generation quality, our pipeline outperformed
ChatGPT-4 in 27 out of the 36 comparisons.",2024-10-25
"Beyond Retrieval: Generating Narratives in Conversational Recommender
  Systems",2024-10-22 07:53:41+00:00,http://arxiv.org/abs/2410.16780v1,"Krishna Sayana, Raghavendra Vasudeva, Yuri Vasilevski, Kun Su, Liam Hebert, Hubert Pham, Ambarish Jash, Sukhdeep Sodhi","cs.CL, cs.AI, cs.IR, cs.LG",story,"The recent advances in Large Language Model's generation and reasoning
capabilities present an opportunity to develop truly conversational
recommendation systems. However, effectively integrating recommender system
knowledge into LLMs for natural language generation which is tailored towards
recommendation tasks remains a challenge. This paper addresses this challenge
by making two key contributions.
  First, we introduce a new dataset (REGEN) for natural language generation
tasks in conversational recommendations. REGEN (Reviews Enhanced with
GEnerative Narratives) extends the Amazon Product Reviews dataset with rich
user narratives, including personalized explanations of product preferences,
product endorsements for recommended items, and summaries of user purchase
history. REGEN is made publicly available to facilitate further research.
Furthermore, we establish benchmarks using well-known generative metrics, and
perform an automated evaluation of the new dataset using a rater LLM. Second,
the paper introduces a fusion architecture (CF model with an LLM) which serves
as a baseline for REGEN. And to the best of our knowledge, represents the first
attempt to analyze the capabilities of LLMs in understanding recommender
signals and generating rich narratives. We demonstrate that LLMs can
effectively learn from simple fusion architectures utilizing interaction-based
CF embeddings, and this can be further enhanced using the metadata and
personalization data associated with items. Our experiments show that combining
CF and content embeddings leads to improvements of 4-12% in key language
metrics compared to using either type of embedding individually. We also
provide an analysis to interpret how CF and content embeddings contribute to
this new generative task.",2024-10-22
With a Grain of SALT: Are LLMs Fair Across Social Dimensions?,2024-10-16 12:22:47+00:00,http://arxiv.org/abs/2410.12499v1,"Samee Arif, Zohaib Khan, Agha Ali Raza, Awais Athar",cs.CL,story,"This paper presents an analysis of biases in open-source Large Language
Models (LLMs) across various genders, religions, and races. We introduce a
methodology for generating a bias detection dataset using seven bias triggers:
General Debate, Positioned Debate, Career Advice, Story Generation,
Problem-Solving, Cover-Letter Writing, and CV Generation. We use GPT-4o to
generate a diverse set of prompts for each trigger across various genders,
religious and racial groups. We evaluate models from Llama and Gemma family on
the generated dataset. We anonymise the LLM-generated text associated with each
group using GPT-4o-mini and do a pairwise comparison using GPT-4o-as-a-Judge.
To quantify bias in the LLM-generated text we use the number of wins and losses
in the pairwise comparison. Our analysis spans three languages, English,
German, and Arabic to explore how language influences bias manifestation. Our
findings reveal that LLMs exhibit strong polarization toward certain groups
across each category, with a notable consistency observed across models.
However, when switching languages, variations and anomalies emerge, often
attributable to cultural cues and contextual differences.",2024-10-16
"Towards More Effective Table-to-Text Generation: Assessing In-Context
  Learning and Self-Evaluation with Open-Source Models",2024-10-15 09:19:42+00:00,http://arxiv.org/abs/2410.12878v1,"Sahar Iravani, Tim . O . F Conrad","cs.CL, cs.AI, cs.LG",story,"Table processing, a key task in natural language processing, has
significantly benefited from recent advancements in language models (LMs).
However, the capabilities of LMs in table-to-text generation, which transforms
structured data into coherent narrative text, require an in-depth
investigation, especially with current open-source models. This study explores
the effectiveness of various in-context learning strategies in LMs across
benchmark datasets, focusing on the impact of providing examples to the model.
More importantly, we examine a real-world use case, offering valuable insights
into practical applications. To complement traditional evaluation metrics, we
employ a large language model (LLM) self-evaluation approach using
chain-of-thought reasoning and assess its correlation with human-aligned
metrics like BERTScore. Our findings highlight the significant impact of
examples in improving table-to-text generation and suggest that, while LLM
self-evaluation has potential, its current alignment with human judgment could
be enhanced. This points to the need for more reliable evaluation methods.",2024-10-15
"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy
  Theories on Telegram",2024-10-11 09:10:26+00:00,http://arxiv.org/abs/2410.08642v1,Elisabeth Steffen,"cs.SI, cs.CL, cs.CV, cs.MM",story,"Research on conspiracy theories and related content online has traditionally
focused on textual data. To address the increasing prevalence of (audio-)visual
data on social media, and to capture the evolving and dynamic nature of this
communication, researchers have begun to explore the potential of unsupervised
approaches for analyzing multimodal online content. Our research contributes to
this field by exploring the potential of multimodal topic modeling for
analyzing conspiracy theories in German-language Telegram channels. Our work
uses the BERTopic topic modeling approach in combination with CLIP for the
analysis of textual and visual data. We analyze a corpus of ~40, 000 Telegram
messages posted in October 2023 in 571 German-language Telegram channels known
for disseminating conspiracy theories and other deceptive content. We explore
the potentials and challenges of this approach for studying a medium-sized
corpus of user-generated, text-image online content. We offer insights into the
dominant topics across modalities, different text and image genres discovered
during the analysis, quantitative inter-modal topic analyses, and a qualitative
case study of textual, visual, and multimodal narrative strategies in the
communication of conspiracy theories.",2024-10-11
Constraint representation towards precise data-driven storytelling,2024-10-10 02:03:46+00:00,http://arxiv.org/abs/2410.07535v1,"Yu-Zhe Shi, Haotian Li, Lecheng Ruan, Huamin Qu",cs.HC,story,"Data-driven storytelling serves as a crucial bridge for communicating ideas
in a persuasive way. However, the manual creation of data stories is a
multifaceted, labor-intensive, and case-specific effort, limiting their broader
application. As a result, automating the creation of data stories has emerged
as a significant research thrust. Despite advances in Artificial Intelligence,
the systematic generation of data stories remains challenging due to their
hybrid nature: they must frame a perspective based on a seed idea in a top-down
manner, similar to traditional storytelling, while coherently grounding
insights of given evidence in a bottom-up fashion, akin to data analysis. These
dual requirements necessitate precise constraints on the permissible space of a
data story. In this viewpoint, we propose integrating constraints into the data
story generation process. Defined upon the hierarchies of interpretation and
articulation, constraints shape both narrations and illustrations to align with
seed ideas and contextualized evidence. We identify the taxonomy and required
functionalities of these constraints. Although constraints can be heterogeneous
and latent, we explore the potential to represent them in a
computation-friendly fashion via Domain-Specific Languages. We believe that
leveraging constraints will facilitate both artistic and scientific aspects of
data story generation.",2024-10-10
"Decoding Decoded: Understanding Hyperparameter Effects in Open-Ended
  Text Generation",2024-10-08 14:51:03+00:00,http://arxiv.org/abs/2410.06097v1,"Esteban Garces Arias, Meimingwei Li, Christian Heumann, Matthias A√üenmacher","cs.CL, cs.LG",story,"Decoding strategies for large language models (LLMs) are a critical but often
underexplored aspect of text generation tasks. Since LLMs produce probability
distributions over the entire vocabulary, various decoding methods have been
developed to transform these probabilities into coherent and fluent text, each
with its own set of hyperparameters. In this study, we present a large-scale,
comprehensive analysis of how hyperparameter selection affects text quality in
open-ended text generation across multiple LLMs, datasets, and evaluation
metrics. Through an extensive sensitivity analysis, we provide practical
guidelines for hyperparameter tuning and demonstrate the substantial influence
of these choices on text quality. Using three established datasets, spanning
factual domains (e.g., news) and creative domains (e.g., fiction), we show that
hyperparameter tuning significantly impacts generation quality, though its
effects vary across models and tasks. We offer in-depth insights into these
effects, supported by both human evaluations and a synthesis of widely-used
automatic evaluation metrics.",2024-10-08
"ACDC: Autoregressive Coherent Multimodal Generation using Diffusion
  Correction",2024-10-07 03:22:51+00:00,http://arxiv.org/abs/2410.04721v1,"Hyungjin Chung, Dohun Lee, Jong Chul Ye","cs.LG, cs.CV",story,"Autoregressive models (ARMs) and diffusion models (DMs) represent two leading
paradigms in generative modeling, each excelling in distinct areas: ARMs in
global context modeling and long-sequence generation, and DMs in generating
high-quality local contexts, especially for continuous data such as images and
short videos. However, ARMs often suffer from exponential error accumulation
over long sequences, leading to physically implausible results, while DMs are
limited by their local context generation capabilities. In this work, we
introduce Autoregressive Coherent multimodal generation with Diffusion
Correction (ACDC), a zero-shot approach that combines the strengths of both
ARMs and DMs at the inference stage without the need for additional
fine-tuning. ACDC leverages ARMs for global context generation and
memory-conditioned DMs for local correction, ensuring high-quality outputs by
correcting artifacts in generated multimodal tokens. In particular, we propose
a memory module based on large language models (LLMs) that dynamically adjusts
the conditioning texts for the DMs, preserving crucial global context
information. Our experiments on multimodal tasks, including coherent
multi-frame story generation and autoregressive video generation, demonstrate
that ACDC effectively mitigates the accumulation of errors and significantly
enhances the quality of generated outputs, achieving superior performance while
remaining agnostic to specific ARM and DM architectures. Project page:
https://acdc2025.github.io/",2024-10-07
"Evaluation of Large Language Models for Summarization Tasks in the
  Medical Domain: A Narrative Review",2024-09-26 17:58:26+00:00,http://arxiv.org/abs/2409.18170v1,"Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Frank J. Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar","cs.CL, cs.AI",story,"Large Language Models have advanced clinical Natural Language Generation,
creating opportunities to manage the volume of medical text. However, the
high-stakes nature of medicine requires reliable evaluation, which remains a
challenge. In this narrative review, we assess the current evaluation state for
clinical summarization tasks and propose future directions to address the
resource constraints of expert human evaluation.",2024-09-26
Counterfactual Token Generation in Large Language Models,2024-09-25 15:30:24+00:00,http://arxiv.org/abs/2409.17027v1,"Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, Manuel Gomez-Rodriguez","cs.LG, cs.AI, cs.CL",story,"""Sure, I am happy to generate a story for you: Captain Lyra stood at the helm
of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]
Lyra's eyes welled up with tears as she realized the bitter truth - she had
sacrificed everything for fleeting riches, and lost the love of her crew, her
family, and herself."" Although this story, generated by a large language model,
is captivating, one may wonder -- how would the story have unfolded if the
model had chosen ""Captain Maeve"" as the protagonist instead? We cannot know.
State-of-the-art large language models are stateless -- they maintain no
internal memory or state. Given a prompt, they generate a sequence of tokens as
an output using an autoregressive process. As a consequence, they cannot reason
about counterfactual alternatives to tokens they have generated in the past. In
this work, our goal is to enhance them with this functionality. To this end, we
develop a causal model of token generation that builds upon the Gumbel-Max
structural causal model. Our model allows any large language model to perform
counterfactual token generation at almost no cost in comparison with vanilla
token generation, it is embarrassingly simple to implement, and it does not
require any fine-tuning nor prompt engineering. We implement our model on Llama
3 8B-instruct and conduct both qualitative and quantitative analyses of
counterfactually generated text. We conclude with a demonstrative application
of counterfactual token generation for bias detection, unveiling interesting
insights about the model of the world constructed by large language models.",2024-09-25
A Character-Centric Creative Story Generation via Imagination,2024-09-25 06:54:29+00:00,http://arxiv.org/abs/2409.16667v1,"Kyeongman Park, Minbeom Kim, Kyomin Jung",cs.CL,story,"Creative story generation with diverse and detailed story elements is a
long-standing goal for large language models. While existing methodologies
generate long and coherent stories, they fall significantly short of human
capabilities in terms of diversity and character detail. To address this, we
introduce a novel story generation framework called CCI (Character-centric
Creative story generation via Imagination). CCI features two innovative modules
for creative story generation: IG (Image-Guided Imagination) and MW
(Multi-Writer model). In the IG module, we utilize DALL-E 3 to create visual
representations of key story elements. The IG generates more novel and concrete
characters, backgrounds, and main plots than text-only methods. The MW module
uses these story elements created by IG to generate multiple description
candidates for the protagonist and select the best one. This method
incorporates vivid and rich character descriptions into the story. We compared
the stories generated by CCI and baseline models through human evaluation and
statistical analysis. The results showed significant improvements in the
creativity. Furthermore, by enabling interactive multi-modal story generation
with users, we have opened up possibilities for human-LLM integration in
cultural development.",2024-09-25
"MirrorStories: Reflecting Diversity through Personalized Narrative
  Generation with Large Language Models",2024-09-20 22:43:13+00:00,http://arxiv.org/abs/2409.13935v2,"Sarfaroz Yunusov, Hamza Sidat, Ali Emami","cs.CL, cs.AI, cs.CY",story,"This study explores the effectiveness of Large Language Models (LLMs) in
creating personalized ""mirror stories"" that reflect and resonate with
individual readers' identities, addressing the significant lack of diversity in
literature. We present MirrorStories, a corpus of 1,500 personalized short
stories generated by integrating elements such as name, gender, age, ethnicity,
reader interest, and story moral. We demonstrate that LLMs can effectively
incorporate diverse identity elements into narratives, with human evaluators
identifying personalized elements in the stories with high accuracy. Through a
comprehensive evaluation involving 26 diverse human judges, we compare the
effectiveness of MirrorStories against generic narratives. We find that
personalized LLM-generated stories not only outscore generic human-written and
LLM-generated ones across all metrics of engagement (with average ratings of
4.22 versus 3.37 on a 5-point scale), but also achieve higher textual diversity
while preserving the intended moral. We also provide analyses that include bias
assessments and a study on the potential for integrating images into
personalized stories.",2024-09-20
Generating Visual Stories with Grounded and Coreferent Characters,2024-09-20 14:56:33+00:00,http://arxiv.org/abs/2409.13555v1,"Danyang Liu, Mirella Lapata, Frank Keller","cs.CL, cs.AI",story,"Characters are important in narratives. They move the plot forward, create
emotional connections, and embody the story's themes. Visual storytelling
methods focus more on the plot and events relating to it, without building the
narrative around specific characters. As a result, the generated stories feel
generic, with character mentions being absent, vague, or incorrect. To mitigate
these issues, we introduce the new task of character-centric story generation
and present the first model capable of predicting visual stories with
consistently grounded and coreferent character mentions. Our model is finetuned
on a new dataset which we build on top of the widely used VIST benchmark.
Specifically, we develop an automated pipeline to enrich VIST with visual and
textual character coreference chains. We also propose new evaluation metrics to
measure the richness of characters and coreference in stories. Experimental
results show that our model generates stories with recurring characters which
are consistent and coreferent to larger extent compared to baselines and
state-of-the-art systems.",2024-09-20
"Small Language Models can Outperform Humans in Short Creative Writing: A
  Study Comparing SLMs with Humans and LLMs",2024-09-17 20:40:02+00:00,http://arxiv.org/abs/2409.11547v1,"Guillermo Marco, Luz Rello, Julio Gonzalo","cs.CL, cs.AI",story,"In this paper, we evaluate the creative fiction writing abilities of a
fine-tuned small language model (SLM), BART Large, and compare its performance
to humans and two large language models (LLMs): GPT-3.5 and GPT-4o. Our
evaluation consists of two experiments: (i) a human evaluation where readers
assess the stories generated by the SLM compared to human-written stories, and
(ii) a qualitative linguistic analysis comparing the textual characteristics of
the stories generated by the different models. In the first experiment, we
asked 68 participants to rate short stories generated by the models and humans
along dimensions such as grammaticality, relevance, creativity, and
attractiveness. BART Large outperformed human writers in most aspects, except
creativity, with an overall score of 2.11 compared to 1.85 for human-written
texts -- a 14% improvement. In the second experiment, the qualitative analysis
revealed that, while GPT-4o exhibited near-perfect internal and external
coherence, it tended to produce more predictable narratives, with only 3% of
its stories seen as novel. In contrast, 15% of BART's stories were considered
novel, indicating a higher degree of creativity despite its smaller model size.
This study provides both quantitative and qualitative insights into how model
size and fine-tuning influence the balance between creativity, fluency, and
coherence in creative writing tasks.",2024-09-17
"The Art of Storytelling: Multi-Agent Generative AI for Dynamic
  Multimodal Narratives",2024-09-17 15:10:23+00:00,http://arxiv.org/abs/2409.11261v3,"Samee Arif, Taimoor Arif, Muhammad Saad Haroon, Aamina Jamal Khan, Agha Ali Raza, Awais Athar",cs.CL,story,"This paper introduces the concept of an education tool that utilizes
Generative Artificial Intelligence (GenAI) to enhance storytelling for
children. The system combines GenAI-driven narrative co-creation,
text-to-speech conversion, and text-to-video generation to produce an engaging
experience for learners. We describe the co-creation process, the adaptation of
narratives into spoken words using text-to-speech models, and the
transformation of these narratives into contextually relevant visuals through
text-to-video technology. Our evaluation covers the linguistics of the
generated stories, the text-to-speech conversion quality, and the accuracy of
the generated visuals.",2024-09-17
Identity-related Speech Suppression in Generative AI Content Moderation,2024-09-09 14:34:51+00:00,http://arxiv.org/abs/2409.13725v1,"Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Dana√´ Metaxa, Sorelle A. Friedler","cs.CL, cs.CY, cs.HC",story,"Automated content moderation has long been used to help identify and filter
undesired user-generated content online. Generative AI systems now use such
filters to keep undesired generated content from being created by or shown to
users. From classrooms to Hollywood, as generative AI is increasingly used for
creative or expressive text generation, whose stories will these technologies
allow to be told, and whose will they suppress? In this paper, we define and
introduce measures of speech suppression, focusing on speech related to
different identity groups incorrectly filtered by a range of content moderation
APIs. Using both short-form, user-generated datasets traditional in content
moderation and longer generative AI-focused data, including two datasets we
introduce in this work, we create a benchmark for measurement of speech
suppression for nine identity groups. Across one traditional and four
generative AI-focused automated content moderation services tested, we find
that identity-related speech is more likely to be incorrectly suppressed than
other speech except in the cases of a few non-marginalized groups.
Additionally, we find differences between APIs in their abilities to correctly
moderate generative AI content.",2024-09-09
CLUE: Concept-Level Uncertainty Estimation for Large Language Models,2024-09-04 18:27:12+00:00,http://arxiv.org/abs/2409.03021v1,"Yu-Hsiang Wang, Andrew Bai, Che-Ping Tsai, Cho-Jui Hsieh","cs.CL, cs.LG",story,"Large Language Models (LLMs) have demonstrated remarkable proficiency in
various natural language generation (NLG) tasks. Previous studies suggest that
LLMs' generation process involves uncertainty. However, existing approaches to
uncertainty estimation mainly focus on sequence-level uncertainty, overlooking
individual pieces of information within sequences. These methods fall short in
separately assessing the uncertainty of each component in a sequence. In
response, we propose a novel framework for Concept-Level Uncertainty Estimation
(CLUE) for LLMs. We leverage LLMs to convert output sequences into
concept-level representations, breaking down sequences into individual concepts
and measuring the uncertainty of each concept separately. We conduct
experiments to demonstrate that CLUE can provide more interpretable uncertainty
estimation results compared with sentence-level uncertainty, and could be a
useful tool for various tasks such as hallucination detection and story
generation.",2024-09-04
"It is Time to Develop an Auditing Framework to Promote Value Aware
  Chatbots",2024-09-03 02:15:34+00:00,http://arxiv.org/abs/2409.01539v1,"Yanchen Wang, Lisa Singh",cs.CL,story,"The launch of ChatGPT in November 2022 marked the beginning of a new era in
AI, the availability of generative AI tools for everyone to use. ChatGPT and
other similar chatbots boast a wide range of capabilities from answering
student homework questions to creating music and art. Given the large amounts
of human data chatbots are built on, it is inevitable that they will inherit
human errors and biases. These biases have the potential to inflict significant
harm or increase inequity on different subpopulations. Because chatbots do not
have an inherent understanding of societal values, they may create new content
that is contrary to established norms. Examples of concerning generated content
includes child pornography, inaccurate facts, and discriminatory posts. In this
position paper, we argue that the speed of advancement of this technology
requires us, as computer and data scientists, to mobilize and develop a
values-based auditing framework containing a community established standard set
of measurements to monitor the health of different chatbots and LLMs. To
support our argument, we use a simple audit template to share the results of
basic audits we conduct that are focused on measuring potential bias in search
engine style tasks, code generation, and story generation. We identify
responses from GPT 3.5 and GPT 4 that are both consistent and not consistent
with values derived from existing law. While the findings come as no surprise,
they do underscore the urgency of developing a robust auditing framework for
openly sharing results in a consistent way so that mitigation strategies can be
developed by the academic community, government agencies, and companies when
our values are not being adhered to. We conclude this paper with
recommendations for value-based strategies for improving the technologies.",2024-09-03
"What Makes a Good Story and How Can We Measure It? A Comprehensive
  Survey of Story Evaluation",2024-08-26 20:35:42+00:00,http://arxiv.org/abs/2408.14622v1,"Dingyi Yang, Qin Jin","cs.CL, A.1; I.2.7; I.2.10",story,"With the development of artificial intelligence, particularly the success of
Large Language Models (LLMs), the quantity and quality of automatically
generated stories have significantly increased. This has led to the need for
automatic story evaluation to assess the generative capabilities of computing
systems and analyze the quality of both automatic-generated and human-written
stories. Evaluating a story can be more challenging than other generation
evaluation tasks. While tasks like machine translation primarily focus on
assessing the aspects of fluency and accuracy, story evaluation demands complex
additional measures such as overall coherence, character development,
interestingness, etc. This requires a thorough review of relevant research. In
this survey, we first summarize existing storytelling tasks, including
text-to-text, visual-to-text, and text-to-visual. We highlight their evaluation
challenges, identify various human criteria to measure stories, and present
existing benchmark datasets. Then, we propose a taxonomy to organize evaluation
metrics that have been developed or can be adopted for story evaluation. We
also provide descriptions of these metrics, along with the discussion of their
merits and limitations. Later, we discuss the human-AI collaboration for story
evaluation and generation. Finally, we suggest potential future research
directions, extending from story evaluation to general evaluations.",2024-08-26
DHP Benchmark: Are LLMs Good NLG Evaluators?,2024-08-25 02:01:38+00:00,http://arxiv.org/abs/2408.13704v1,"Yicheng Wang, Jiayi Yuan, Yu-Neng Chuang, Zhuoer Wang, Yingchi Liu, Mark Cusick, Param Kulkarni, Zhengping Ji, Yasser Ibrahim, Xia Hu","cs.CL, cs.AI",story,"Large Language Models (LLMs) are increasingly serving as evaluators in
Natural Language Generation (NLG) tasks. However, the capabilities of LLMs in
scoring NLG quality remain inadequately explored. Current studies depend on
human assessments and simple metrics that fail to capture the discernment of
LLMs across diverse NLG tasks. To address this gap, we propose the Discernment
of Hierarchical Perturbation (DHP) benchmarking framework, which provides
quantitative discernment scores for LLMs utilizing hierarchically perturbed
text data and statistical tests to measure the NLG evaluation capabilities of
LLMs systematically. We have re-established six evaluation datasets for this
benchmark, covering four NLG tasks: Summarization, Story Completion, Question
Answering, and Translation. Our comprehensive benchmarking of five major LLM
series provides critical insight into their strengths and limitations as NLG
evaluators.",2024-08-25
Xinyu: An Efficient LLM-based System for Commentary Generation,2024-08-21 13:34:29+00:00,http://arxiv.org/abs/2408.11609v2,"Yiquan Wu, Bo Tang, Chenyang Xi, Yu Yu, Pengyu Wang, Yifei Liu, Kun Kuang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Jie Hu, Peng Cheng, Zhonghao Wang, Yi Wang, Yi Luo, Mingchuan Yang","cs.CL, cs.AI, I.2.7",story,"Commentary provides readers with a deep understanding of events by presenting
diverse arguments and evidence. However, creating commentary is a
time-consuming task, even for skilled commentators. Large language models
(LLMs) have simplified the process of natural language generation, but their
direct application in commentary creation still faces challenges due to unique
task requirements. These requirements can be categorized into two levels: 1)
fundamental requirements, which include creating well-structured and logically
consistent narratives, and 2) advanced requirements, which involve generating
quality arguments and providing convincing evidence. In this paper, we
introduce Xinyu, an efficient LLM-based system designed to assist commentators
in generating Chinese commentaries. To meet the fundamental requirements, we
deconstruct the generation process into sequential steps, proposing targeted
strategies and supervised fine-tuning (SFT) for each step. To address the
advanced requirements, we present an argument ranking model for arguments and
establish a comprehensive evidence database that includes up-to-date events and
classic books, thereby strengthening the substantiation of the evidence with
retrieval augmented generation (RAG) technology. To evaluate the generated
commentaries more fairly, corresponding to the two-level requirements, we
introduce a comprehensive evaluation metric that considers five distinct
perspectives in commentary generation. Our experiments confirm the
effectiveness of our proposed system. We also observe a significant increase in
the efficiency of commentators in real-world scenarios, with the average time
spent on creating a commentary dropping from 4 hours to 20 minutes.
Importantly, such an increase in efficiency does not compromise the quality of
the commentaries.",2024-08-21
Imagining from Images with an AI Storytelling Tool,2024-08-21 10:49:15+00:00,http://arxiv.org/abs/2408.11517v1,"Edirlei Soares de Lima, Marco A. Casanova, Antonio L. Furtado",cs.CL,story,"A method for generating narratives by analyzing single images or image
sequences is presented, inspired by the time immemorial tradition of Narrative
Art. The proposed method explores the multimodal capabilities of GPT-4o to
interpret visual content and create engaging stories, which are illustrated by
a Stable Diffusion XL model. The method is supported by a fully implemented
tool, called ImageTeller, which accepts images from diverse sources as input.
Users can guide the narrative's development according to the conventions of
fundamental genres - such as Comedy, Romance, Tragedy, Satire or Mystery -, opt
to generate data-driven stories, or to leave the prototype free to decide how
to handle the narrative structure. User interaction is provided along the
generation process, allowing the user to request alternative chapters or
illustrations, and even reject and restart the story generation based on the
same input. Additionally, users can attach captions to the input images,
influencing the system's interpretation of the visual content. Examples of
generated stories are provided, along with details on how to access the
prototype.",2024-08-21
Assessing Language Models' Worldview for Fiction Generation,2024-08-15 03:19:41+00:00,http://arxiv.org/abs/2408.07904v1,"Aisha Khatun, Daniel G. Brown","cs.CL, cs.AI",story,"The use of Large Language Models (LLMs) has become ubiquitous, with abundant
applications in computational creativity. One such application is fictional
story generation. Fiction is a narrative that occurs in a story world that is
slightly different than ours. With LLMs becoming writing partners, we question
how suitable they are to generate fiction. This study investigates the ability
of LLMs to maintain a state of world essential to generate fiction. Through a
series of questions to nine LLMs, we find that only two models exhibit
consistent worldview, while the rest are self-conflicting. Subsequent analysis
of stories generated by four models revealed a strikingly uniform narrative
pattern. This uniformity across models further suggests a lack of `state'
necessary for fiction. We highlight the limitations of current LLMs in fiction
writing and advocate for future research to test and create story worlds for
LLMs to reside in. All code, dataset, and the generated responses can be found
in https://github.com/tanny411/llm-reliability-and-consistency-evaluation.",2024-08-15
"Context-aware Visual Storytelling with Visual Prefix Tuning and
  Contrastive Learning",2024-08-12 16:15:32+00:00,http://arxiv.org/abs/2408.06259v1,"Yingjin Song, Denis Paperno, Albert Gatt","cs.CL, cs.CV",story,"Visual storytelling systems generate multi-sentence stories from image
sequences. In this task, capturing contextual information and bridging visual
variation bring additional challenges. We propose a simple yet effective
framework that leverages the generalization capabilities of pretrained
foundation models, only training a lightweight vision-language mapping network
to connect modalities, while incorporating context to enhance coherence. We
introduce a multimodal contrastive objective that also improves visual
relevance and story informativeness. Extensive experimental results, across
both automatic metrics and human evaluations, demonstrate that the stories
generated by our framework are diverse, coherent, informative, and interesting.",2024-08-12
"DataNarrative: Automated Data-Driven Storytelling with Visualizations
  and Texts",2024-08-09 21:31:33+00:00,http://arxiv.org/abs/2408.05346v2,"Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty",cs.CL,story,"Data-driven storytelling is a powerful method for conveying insights by
combining narrative techniques with visualizations and text. These stories
integrate visual aids, such as highlighted bars and lines in charts, along with
textual annotations explaining insights. However, creating such stories
requires a deep understanding of the data and meticulous narrative planning,
often necessitating human intervention, which can be time-consuming and
mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks,
their ability to generate coherent and comprehensive data stories remains
underexplored. In this work, we introduce a novel task for data story
generation and a benchmark containing 1,449 stories from diverse sources. To
address the challenges of crafting coherent data stories, we propose a
multiagent framework employing two LLM agents designed to replicate the human
storytelling process: one for understanding and describing the data
(Reflection), generating the outline, and narration, and another for
verification at each intermediary step. While our agentic framework generally
outperforms non-agentic counterparts in both model-based and human evaluations,
the results also reveal unique challenges in data story generation.",2024-08-09
"DASH: A Bimodal Data Exploration Tool for Interactive Text and
  Visualizations",2024-08-02 05:08:48+00:00,http://arxiv.org/abs/2408.01011v2,"Dennis Bromley, Vidya Setlur",cs.HC,story,"Integrating textual content, such as titles, annotations, and captions, with
visualizations facilitates comprehension and takeaways during data exploration.
Yet current tools often lack mechanisms for integrating meaningful long-form
prose with visual data. This paper introduces DASH, a bimodal data exploration
tool that supports integrating semantic levels into the interactive process of
visualization and text-based analysis. DASH operationalizes a modified version
of Lundgard et al.'s semantic hierarchy model that categorizes data
descriptions into four levels ranging from basic encodings to high-level
insights. By leveraging this structured semantic level framework and a large
language model's text generation capabilities, DASH enables the creation of
data-driven narratives via drag-and-drop user interaction. Through a
preliminary user evaluation, we discuss the utility of DASH's text and chart
integration capabilities when participants perform data exploration with the
tool.",2024-08-02
"From Instruction to Insight: Exploring the Functional and Semantic Roles
  of Text in Interactive Dashboards",2024-07-19 16:48:00+00:00,http://arxiv.org/abs/2407.14451v1,"Nicole Sultanum, Vidya Setlur",cs.HC,story,"There is increased interest in the interplay between text and visuals in the
field of data visualization. However, this attention has predominantly been on
the use of text in standalone visualizations or augmenting text stories
supported by a series of independent views. In this paper, we shift from the
traditional focus on single-chart annotations to characterize the nuanced but
crucial communication role of text in the complex environment of interactive
dashboards. Through a survey and analysis of 190 dashboards in the wild, plus
13 expert interview sessions with experienced dashboard authors, we highlight
the distinctive nature of text as an integral component of the dashboard
experience, while delving into the categories, semantic levels, and functional
roles of text, and exploring how these text elements are coalesced by dashboard
authors to guide and inform dashboard users.
  Our contributions are: 1) we distill qualitative and quantitative findings
from our studies to characterize current practices of text use in dashboards,
including a categorization of text-based components and design patterns; 2) we
leverage current practices and existing literature to propose, discuss, and
validate recommended practices for text in dashboards, embodied as 12
heuristics that underscore the semantic and functional role of text in offering
navigational cues, contextualizing data insights, supporting reading order,
etc; 3) we reflect on our findings to identify gaps and propose opportunities
for data visualization researchers to push the boundaries on text usage for
dashboards, from authoring support and interactivity to text generation and
content personalization.
  Our research underscores the significance of elevating text as a first-class
citizen in data visualization, and the need to support the inclusion of textual
components and their interactive affordances in dashboard design.",2024-07-19
"DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject
  Consistent Diffusion",2024-07-17 17:54:12+00:00,http://arxiv.org/abs/2407.12899v1,"Huiguo He, Huan Yang, Zixi Tuo, Yuan Zhou, Qiuyue Wang, Yuhang Zhang, Zeyu Liu, Wenhao Huang, Hongyang Chao, Jian Yin","cs.CV, cs.AI, cs.MM",story,"Story visualization aims to create visually compelling images or videos
corresponding to textual narratives. Despite recent advances in diffusion
models yielding promising results, existing methods still struggle to create a
coherent sequence of subject-consistent frames based solely on a story. To this
end, we propose DreamStory, an automatic open-domain story visualization
framework by leveraging the LLMs and a novel multi-subject consistent diffusion
model. DreamStory consists of (1) an LLM acting as a story director and (2) an
innovative Multi-Subject consistent Diffusion model (MSD) for generating
consistent multi-subject across the images. First, DreamStory employs the LLM
to generate descriptive prompts for subjects and scenes aligned with the story,
annotating each scene's subjects for subsequent subject-consistent generation.
Second, DreamStory utilizes these detailed subject descriptions to create
portraits of the subjects, with these portraits and their corresponding textual
information serving as multimodal anchors (guidance). Finally, the MSD uses
these multimodal anchors to generate story scenes with consistent
multi-subject. Specifically, the MSD includes Masked Mutual Self-Attention
(MMSA) and Masked Mutual Cross-Attention (MMCA) modules. MMSA and MMCA modules
ensure appearance and semantic consistency with reference images and text,
respectively. Both modules employ masking mechanisms to prevent subject
blending. To validate our approach and promote progress in story visualization,
we established a benchmark, DS-500, which can assess the overall performance of
the story visualization framework, subject-identification accuracy, and the
consistency of the generation model. Extensive experiments validate the
effectiveness of DreamStory in both subjective and objective evaluations.
Please visit our project homepage at https://dream-xyz.github.io/dreamstory.",2024-07-17
FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3,2024-07-12 17:46:58+00:00,http://arxiv.org/abs/2407.09467v1,"Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos",cs.AI,story,"In the diverse world of AI-driven storytelling, there is a unique opportunity
to engage young audiences with customized, and personalized narratives. This
paper introduces FairyLandAI an innovative Large Language Model (LLM) developed
through OpenAI's API, specifically crafted to create personalized fairytales
for children. The distinctive feature of FairyLandAI is its dual capability: it
not only generates stories that are engaging, age-appropriate, and reflective
of various traditions but also autonomously produces imaginative prompts
suitable for advanced image generation tools like GenAI and Dalle-3, thereby
enriching the storytelling experience. FairyLandAI is expertly tailored to
resonate with the imaginative worlds of children, providing narratives that are
both educational and entertaining and in alignment with the moral values
inherent in different ages. Its unique strength lies in customizing stories to
match individual children's preferences and cultural backgrounds, heralding a
new era in personalized storytelling. Further, its integration with image
generation technology offers a comprehensive narrative experience that
stimulates both verbal and visual creativity. Empirical evaluations of
FairyLandAI demonstrate its effectiveness in crafting captivating stories for
children, which not only entertain but also embody the values and teachings of
diverse traditions. This model serves as an invaluable tool for parents and
educators, supporting them in imparting meaningful moral lessons through
engaging narratives. FairyLandAI represents a pioneering step in using LLMs,
particularly through OpenAI's API, for educational and cultural enrichment,
making complex moral narratives accessible and enjoyable for young, imaginative
minds.",2024-07-12
Arabic Automatic Story Generation with Large Language Models,2024-07-10 11:26:10+00:00,http://arxiv.org/abs/2407.07551v1,"Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed","cs.CL, cs.AI",story,"Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.",2024-07-10
"Not (yet) the whole story: Evaluating Visual Storytelling Requires More
  than Measuring Coherence, Grounding, and Repetition",2024-07-05 14:48:15+00:00,http://arxiv.org/abs/2407.04559v1,"Aditya K Surikuchi, Raquel Fern√°ndez, Sandro Pezzelle","cs.CL, cs.AI, cs.CV, cs.LG",story,"Visual storytelling consists in generating a natural language story given a
temporally ordered sequence of images. This task is not only challenging for
models, but also very difficult to evaluate with automatic metrics since there
is no consensus about what makes a story 'good'. In this paper, we introduce a
novel method that measures story quality in terms of human likeness regarding
three key aspects highlighted in previous work: visual grounding, coherence,
and repetitiveness. We then use this method to evaluate the stories generated
by several models, showing that the foundation model LLaVA obtains the best
result, but only slightly so compared to TAPM, a 50-times smaller visual
storytelling model. Upgrading the visual and language components of TAPM
results in a model that yields competitive performance with a relatively low
number of parameters. Finally, we carry out a human evaluation study, whose
results suggest that a 'good' story may require more than a human-like level of
visual grounding, coherence, and repetition.",2024-07-05
"Inclusivity in Large Language Models: Personality Traits and Gender Bias
  in Scientific Abstracts",2024-06-27 19:26:11+00:00,http://arxiv.org/abs/2406.19497v1,"Naseela Pervez, Alexander J. Titus","cs.CL, cs.AI",story,"Large language models (LLMs) are increasingly utilized to assist in
scientific and academic writing, helping authors enhance the coherence of their
articles. Previous studies have highlighted stereotypes and biases present in
LLM outputs, emphasizing the need to evaluate these models for their alignment
with human narrative styles and potential gender biases. In this study, we
assess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large,
and Gemini 1.5 Flash - by analyzing their performance on benchmark
text-generation tasks for scientific abstracts. We employ the Linguistic
Inquiry and Word Count (LIWC) framework to extract lexical, psychological, and
social features from the generated texts. Our findings indicate that, while
these models generally produce text closely resembling human authored content,
variations in stylistic features suggest significant gender biases. This
research highlights the importance of developing LLMs that maintain a diversity
of writing styles to promote inclusivity in academic discourse.",2024-06-27
"Human-AI Collaborative Taxonomy Construction: A Case Study in
  Profession-Specific Writing Assistants",2024-06-26 18:25:06+00:00,http://arxiv.org/abs/2406.18675v2,"Minhwa Lee, Zae Myung Kim, Vivek Khetan, Dongyeop Kang","cs.HC, cs.AI, cs.CL",story,"Large Language Models (LLMs) have assisted humans in several writing tasks,
including text revision and story generation. However, their effectiveness in
supporting domain-specific writing, particularly in business contexts, is
relatively less explored. Our formative study with industry professionals
revealed the limitations in current LLMs' understanding of the nuances in such
domain-specific writing. To address this gap, we propose an approach of
human-AI collaborative taxonomy development to perform as a guideline for
domain-specific writing assistants. This method integrates iterative feedback
from domain experts and multiple interactions between these experts and LLMs to
refine the taxonomy. Through larger-scale experiments, we aim to validate this
methodology and thus improve LLM-powered writing assistance, tailoring it to
meet the unique requirements of different stakeholder needs.",2024-06-26
"The GPT-WritingPrompts Dataset: A Comparative Analysis of Character
  Portrayal in Short Stories",2024-06-24 16:24:18+00:00,http://arxiv.org/abs/2406.16767v1,"Xi Yu Huang, Krishnapriya Vishnubhotla, Frank Rudzicz",cs.CL,story,"The improved generative capabilities of large language models have made them
a powerful tool for creative writing and storytelling. It is therefore
important to quantitatively understand the nature of generated stories, and how
they differ from human storytelling. We augment the Reddit WritingPrompts
dataset with short stories generated by GPT-3.5, given the same prompts. We
quantify and compare the emotional and descriptive features of storytelling
from both generative processes, human and machine, along a set of six
dimensions. We find that generated stories differ significantly from human
stories along all six dimensions, and that human and machine generations
display similar biases when grouped according to the narrative point-of-view
and gender of the main protagonist. We release our dataset and code at
https://github.com/KristinHuangg/gpt-writing-prompts.",2024-06-24
"Evaluation of Instruction-Following Ability for Large Language Models on
  Story-Ending Generation",2024-06-24 06:53:36+00:00,http://arxiv.org/abs/2406.16356v1,"Rem Hida, Junki Ohmura, Toshiyuki Sekiya",cs.CL,story,"Instruction-tuned Large Language Models (LLMs) have achieved remarkable
performance across various benchmark tasks. While providing instructions to
LLMs for guiding their generations is user-friendly, assessing their
instruction-following capabilities is still unclarified due to a lack of
evaluation metrics. In this paper, we focus on evaluating the
instruction-following ability of LLMs in the context of story-ending
generation, which requires diverse and context-specific instructions. We
propose an automatic evaluation pipeline that utilizes a machine reading
comprehension (MRC) model to determine whether the generated story-ending
reflects instruction. Our findings demonstrate that our proposed metric aligns
with human evaluation. Furthermore, our experiments confirm that recent
open-source LLMs can achieve instruction-following performance close to
GPT-3.5, as assessed through automatic evaluation.",2024-06-24
SS-Bench: A Benchmark for Social Story Generation and Evaluation,2024-06-22 00:14:48+00:00,http://arxiv.org/abs/2406.15695v1,"Yi Feng, Mingyang Song, Jiaqi Wang, Mao Zheng, Liping Jing, Jian Yu",cs.CL,story,"Children with Autism Spectrum Disorder (ASD) often misunderstand social
situations and struggle to participate in daily routines. Psychology experts
write Social Stories under strict constraints of structural clarity,
descriptive orientation, and situational safety to enhance their abilities in
these regimes. However, Social Stories are costly in creation and often limited
in diversity and timeliness. As Large Language Models (LLMs) become
increasingly powerful, there is a growing need for more automated, affordable,
and accessible methods to generate Social Stories in real-time with broad
coverage. Adapting LLMs to meet the unique and strict constraints of Social
Stories is a challenging issue. To this end, we propose \textbf{SS-Bench}, a
\textbf{S}ocial \textbf{S}tory \textbf{Bench}mark for generating and evaluating
Social Stories. Specifically, we develop a constraint-driven strategy named
\textbf{\textsc{StarSow}} to hierarchically prompt LLMs to generate Social
Stories and build a benchmark, which has been validated through experiments to
fine-tune smaller models for generating qualified Social Stories. Additionally,
we introduce \textbf{Quality Assessment Criteria}, employed in human and GPT
evaluations, to verify the effectiveness of the generated stories. We hope this
work benefits the autism community and catalyzes future research focusing on
particular groups.",2024-06-22
Measuring Psychological Depth in Language Models,2024-06-18 14:51:54+00:00,http://arxiv.org/abs/2406.12680v1,"Fabrice Harel-Canada, Hanyu Zhou, Sreya Mupalla, Zeynep Yildiz, Amit Sahai, Nanyun Peng",cs.CL,story,"Evaluations of creative stories generated by large language models (LLMs)
often focus on objective properties of the text, such as its style, coherence,
and toxicity. While these metrics are indispensable, they do not speak to a
story's subjective, psychological impact from a reader's perspective. We
introduce the Psychological Depth Scale (PDS), a novel framework rooted in
literary theory that measures an LLM's ability to produce authentic and
narratively complex stories that provoke emotion, empathy, and engagement. We
empirically validate our framework by showing that humans can consistently
evaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore
techniques for automating the PDS to easily scale future analyses. GPT-4o,
combined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an
average Spearman correlation of $0.51$ with human judgment while Llama-3-70B
scores as high as 0.68 for empathy. Finally, we compared the depth of stories
authored by both humans and LLMs. Surprisingly, GPT-4 stories either surpassed
or were statistically indistinguishable from highly-rated human-written stories
sourced from Reddit. By shifting the focus from text to reader, the
Psychological Depth Scale is a validated, automated, and systematic means of
measuring the capacity of LLMs to connect with humans through the stories they
tell.",2024-06-18
"Decoding the Narratives: Analyzing Personal Drug Experiences Shared on
  Reddit",2024-06-17 21:56:57+00:00,http://arxiv.org/abs/2406.12117v1,"Layla Bouzoubaa, Elham Aghakhani, Max Song, Minh Trinh, Rezvaneh Rezapour",cs.CL,story,"Online communities such as drug-related subreddits serve as safe spaces for
people who use drugs (PWUD), fostering discussions on substance use
experiences, harm reduction, and addiction recovery. Users' shared narratives
on these forums provide insights into the likelihood of developing a substance
use disorder (SUD) and recovery potential. Our study aims to develop a
multi-level, multi-label classification model to analyze online user-generated
texts about substance use experiences. For this purpose, we first introduce a
novel taxonomy to assess the nature of posts, including their intended
connections (Inquisition or Disclosure), subjects (e.g., Recovery, Dependency),
and specific objectives (e.g., Relapse, Quality, Safety). Using various
multi-label classification algorithms on a set of annotated data, we show that
GPT-4, when prompted with instructions, definitions, and examples, outperformed
all other models. We apply this model to label an additional 1,000 posts and
analyze the categories of linguistic expression used within posts in each
class. Our analysis shows that topics such as Safety, Combination of
Substances, and Mental Health see more disclosure, while discussions about
physiological Effects focus on harm reduction. Our work enriches the
understanding of PWUD's experiences and informs the broader knowledge base on
SUD and drug use.",2024-06-17
Extrinsic Evaluation of Cultural Competence in Large Language Models,2024-06-17 14:03:27+00:00,http://arxiv.org/abs/2406.11565v2,"Shaily Bhatt, Fernando Diaz","cs.CL, cs.CY",story,"Productive interactions between diverse users and language technologies
require outputs from the latter to be culturally relevant and sensitive. Prior
works have evaluated models' knowledge of cultural norms, values, and
artifacts, without considering how this knowledge manifests in downstream
applications. In this work, we focus on extrinsic evaluation of cultural
competence in two text generation tasks, open-ended question answering and
story generation. We quantitatively and qualitatively evaluate model outputs
when an explicit cue of culture, specifically nationality, is perturbed in the
prompts. Although we find that model outputs do vary when varying nationalities
and feature culturally relevant words, we also find weak correlations between
text similarity of outputs for different countries and the cultural values of
these countries. Finally, we discuss important considerations in designing
comprehensive evaluation of cultural competence in user-facing tasks.",2024-06-17
"Confabulation: The Surprising Value of Large Language Model
  Hallucinations",2024-06-06 15:32:29+00:00,http://arxiv.org/abs/2406.04175v2,"Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So","cs.CL, cs.AI",story,"This paper presents a systematic defense of large language model (LLM)
hallucinations or 'confabulations' as a potential resource instead of a
categorically negative pitfall. The standard view is that confabulations are
inherently problematic and AI research should eliminate this flaw. In this
paper, we argue and empirically demonstrate that measurable semantic
characteristics of LLM confabulations mirror a human propensity to utilize
increased narrativity as a cognitive resource for sense-making and
communication. In other words, it has potential value. Specifically, we analyze
popular hallucination benchmarks and reveal that hallucinated outputs display
increased levels of narrativity and semantic coherence relative to veridical
outputs. This finding reveals a tension in our usually dismissive
understandings of confabulation. It suggests, counter-intuitively, that the
tendency for LLMs to confabulate may be intimately associated with a positive
capacity for coherent narrative-text generation.",2024-06-06
"Guiding and Diversifying LLM-Based Story Generation via Answer Set
  Programming",2024-06-01 21:14:25+00:00,http://arxiv.org/abs/2406.00554v2,"Phoebe J. Wang, Max Kreminski","cs.CL, cs.AI",story,"Instruction-tuned large language models (LLMs) are capable of generating
stories in response to open-ended user requests, but the resulting stories tend
to be limited in their diversity. Older, symbolic approaches to story
generation (such as planning) can generate substantially more diverse plot
outlines, but are limited to producing stories that recombine a fixed set of
hand-engineered character action templates. Can we combine the strengths of
these approaches while mitigating their weaknesses? We propose to do so by
using a higher-level and more abstract symbolic specification of high-level
story structure -- implemented via answer set programming (ASP) -- to guide and
diversify LLM-based story generation. Via semantic similarity analysis, we
demonstrate that our approach produces more diverse stories than an unguided
LLM, and via code excerpts, we demonstrate the improved compactness and
flexibility of ASP-based outline generation over full-fledged narrative
planning.",2024-06-01
"Text Generation: A Systematic Literature Review of Tasks, Evaluation,
  and Challenges",2024-05-24 14:38:11+00:00,http://arxiv.org/abs/2405.15604v1,"Jonas Becker, Jan Philip Wahle, Bela Gipp, Terry Ruas","cs.CL, A.1; I.2.7",story,"Text generation has become more accessible than ever, and the increasing
interest in these systems, especially those using large language models, has
spurred an increasing number of related publications. We provide a systematic
literature review comprising 244 selected papers between 2017 and 2024. This
review categorizes works in text generation into five main tasks: open-ended
text generation, summarization, translation, paraphrasing, and question
answering. For each task, we review their relevant characteristics, sub-tasks,
and specific challenges (e.g., missing datasets for multi-document
summarization, coherence in story generation, and complex reasoning for
question answering). Additionally, we assess current approaches for evaluating
text generation systems and ascertain problems with current metrics. Our
investigation shows nine prominent challenges common to all tasks and sub-tasks
in recent text generation publications: bias, reasoning, hallucinations,
misuse, privacy, interpretability, transparency, datasets, and computing. We
provide a detailed analysis of these challenges, their potential solutions, and
which gaps still require further engagement from the community. This systematic
literature review targets two main audiences: early career researchers in
natural language processing looking for an overview of the field and promising
research directions, as well as experienced researchers seeking a detailed view
of tasks, evaluation methodologies, open challenges, and recent mitigation
strategies.",2024-05-24
"Improving Language Models Trained with Translated Data via Continual
  Pre-Training and Dictionary Learning Analysis",2024-05-23 07:53:04+00:00,http://arxiv.org/abs/2405.14277v1,"Sabri Boughorbel, MD Rizwan Parvez, Majd Hawasly",cs.CL,story,"Training LLMs in low resources languages usually utilizes data augmentation
with machine translation (MT) from English language. However, translation
brings a number of challenges: there are large costs attached to translating
and curating huge amounts of content with high-end machine translation
solutions, the translated content carries over cultural biases, and if the
translation is not faithful and accurate, the quality of the data degrades
causing issues in the trained model. In this work we investigate the role of
translation and synthetic data in training language models. We translate
TinyStories, a dataset of 2.2M short stories for 3-4 year old children, from
English to Arabic using the free NLLB-3B MT model. We train a number of story
generation models of sizes 1M-33M parameters using this data. We identify a
number of quality and task-specific issues in the resulting models. To rectify
these issues, we further pre-train the models with a small dataset of
synthesized high-quality stories, representing 1\% of the original training
data, using a capable LLM in Arabic. We show using GPT-4 as a judge and
dictionary learning analysis from mechanistic interpretability that the
suggested approach is a practical means to resolve some of the translation
pitfalls. We illustrate the improvement through case studies of linguistic
issues and cultural bias.",2024-05-23
"Synchronized Video Storytelling: Generating Video Narrations with
  Structured Storyline",2024-05-22 22:22:26+00:00,http://arxiv.org/abs/2405.14040v1,"Dingyi Yang, Chunru Zhan, Ziheng Wang, Biao Wang, Tiezheng Ge, Bo Zheng, Qin Jin",cs.MM,story,"Video storytelling is engaging multimedia content that utilizes video and its
accompanying narration to attract the audience, where a key challenge is
creating narrations for recorded visual scenes. Previous studies on dense video
captioning and video story generation have made some progress. However, in
practical applications, we typically require synchronized narrations for
ongoing visual scenes. In this work, we introduce a new task of Synchronized
Video Storytelling, which aims to generate synchronous and informative
narrations for videos. These narrations, associated with each video clip,
should relate to the visual content, integrate relevant knowledge, and have an
appropriate word count corresponding to the clip's duration. Specifically, a
structured storyline is beneficial to guide the generation process, ensuring
coherence and integrity. To support the exploration of this task, we introduce
a new benchmark dataset E-SyncVidStory with rich annotations. Since existing
Multimodal LLMs are not effective in addressing this task in one-shot or
few-shot settings, we propose a framework named VideoNarrator that can generate
a storyline for input videos and simultaneously generate narrations with the
guidance of the generated or predefined storyline. We further introduce a set
of evaluation metrics to thoroughly assess the generation. Both automatic and
human evaluations validate the effectiveness of our approach. Our dataset,
codes, and evaluations will be released.",2024-05-22
"Narrative Review of Support for Emotional Expressions in Virtual
  Reality: Psychophysiology of speech-to-text interfaces",2024-05-22 18:53:27+00:00,http://arxiv.org/abs/2405.13924v1,"Sunday David Ubur, Denis Gracanin",cs.HC,story,"This narrative review on emotional expression in Speech-to-Text (STT)
interfaces with Virtual Reality (VR) aims to identify advancements,
limitations, and research gaps in incorporating emotional expression into
transcribed text generated by STT systems. Using a rigorous search strategy,
relevant articles published between 2020 and 2024 are extracted and categorized
into themes such as communication enhancement technologies, innovations in
captioning, emotion recognition in AR and VR, and empathic machines. The
findings reveal the evolution of tools and techniques to meet the needs of
individuals with hearing impairments, showcasing innovations in live
transcription, closed captioning, AR, VR, and emotion recognition technologies.
Despite improvements in accessibility, the absence of emotional nuance in
transcribed text remains a significant communication challenge. The study
underscores the urgency for innovations in STT technology to capture emotional
expressions. The research discusses integrating emotional expression into text
through strategies like animated text captions, emojilization tools, and models
associating emotions with animation properties. Extending these efforts into AR
and VR environments opens new possibilities for immersive and emotionally
resonant experiences, especially in educational contexts. The study also
explores empathic applications in healthcare, education, and human-robot
interactions, highlighting the potential for personalized and effective
interactions. The multidisciplinary nature of the literature underscores the
potential for collaborative and interdisciplinary research.",2024-05-22
Exploration of Masked and Causal Language Modelling for Text Generation,2024-05-21 09:33:31+00:00,http://arxiv.org/abs/2405.12630v1,"Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic","cs.CL, cs.AI",story,"Large Language Models (LLMs) have revolutionised the field of Natural
Language Processing (NLP) and have achieved state-of-the-art performance in
practically every task in this field. However, the prevalent approach used in
text generation, Causal Language Modelling (CLM), which generates text
sequentially from left to right, inherently limits the freedom of the model,
which does not decide when and where each token is generated. In contrast,
Masked Language Modelling (MLM), primarily used for language understanding
tasks, can generate tokens anywhere in the text and any order. This paper
conducts an extensive comparison of MLM and CLM approaches for text generation
tasks. To do so, we pre-train several language models of comparable sizes on
three different datasets, namely 1) medical discharge summaries, 2) movie plot
synopses, and 3) authorship verification datasets. To assess the quality of the
generations, we first employ quantitative metrics and then perform a
qualitative human evaluation to analyse coherence and grammatical correctness.
In addition, we evaluate the usefulness of the generated texts by using them in
three different downstream tasks: 1) Entity Recognition, 2) Text
Classification, and 3) Authorship Verification. The results show that MLM
consistently outperforms CLM in text generation across all datasets, with
higher quantitative scores and better coherence in the generated text. The
study also finds \textit{no strong correlation} between the quality of the
generated text and the performance of the models in the downstream tasks. With
this study, we show that MLM for text generation has great potential for future
research and provides direction for future studies in this area.",2024-05-21
"StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character
  Simulation via Narrative Planning",2024-05-17 23:04:51+00:00,http://arxiv.org/abs/2405.13042v1,"Yi Wang, Qian Zhou, David Ledo","cs.HC, cs.AI",story,"Automated plot generation for games enhances the player's experience by
providing rich and immersive narrative experience that adapts to the player's
actions. Traditional approaches adopt a symbolic narrative planning method
which limits the scale and complexity of the generated plot by requiring
extensive knowledge engineering work. Recent advancements use Large Language
Models (LLMs) to drive the behavior of virtual characters, allowing plots to
emerge from interactions between characters and their environments. However,
the emergent nature of such decentralized plot generation makes it difficult
for authors to direct plot progression. We propose a novel plot creation
workflow that mediates between a writer's authorial intent and the emergent
behaviors from LLM-driven character simulation, through a novel authorial
structure called ""abstract acts"". The writers define high-level plot outlines
that are later transformed into concrete character action sequences via an
LLM-based narrative planning process, based on the game world state. The
process creates ""living stories"" that dynamically adapt to various game world
states, resulting in narratives co-created by the author, character simulation,
and player. We present StoryVerse as a proof-of-concept system to demonstrate
this plot creation workflow. We showcase the versatility of our approach with
examples in different stories and game environments.",2024-05-17
Multigenre AI-powered Story Composition,2024-05-06 12:54:41+00:00,http://arxiv.org/abs/2405.06685v1,"Edirlei Soares de Lima, Margot M. E. Neggers, Antonio L. Furtado",cs.CL,story,"This paper shows how to construct genre patterns, whose purpose is to guide
interactive story composition in a way that enforces thematic consistency. To
start the discussion we argue, based on previous seminal works, for the
existence of five fundamental genres, namely comedy, romance - in the sense of
epic plots, flourishing since the twelfth century -, tragedy, satire, and
mystery. To construct the patterns, a simple two-phase process is employed:
first retrieving examples that match our genre characterizations, and then
applying a form of most specific generalization to the groups of examples in
order to find their commonalities. In both phases, AI agents are instrumental,
with our PatternTeller prototype being called to operate the story composition
process, offering the opportunity to generate stories from a given premise of
the user, to be developed under the guidance of the chosen pattern and trying
to accommodate the user's suggestions along the composition stages.",2024-05-06
The Psychosocial Impacts of Generative AI Harms,2024-05-02 21:21:06+00:00,http://arxiv.org/abs/2405.01740v1,"Faye-Marie Vassel, Evan Shieh, Cassidy R. Sugimoto, Thema Monroe-White",cs.CL,story,"The rapid emergence of generative Language Models (LMs) has led to growing
concern about the impacts that their unexamined adoption may have on the social
well-being of diverse user groups. Meanwhile, LMs are increasingly being
adopted in K-20 schools and one-on-one student settings with minimal
investigation of potential harms associated with their deployment. Motivated in
part by real-world/everyday use cases (e.g., an AI writing assistant) this
paper explores the potential psychosocial harms of stories generated by five
leading LMs in response to open-ended prompting. We extend findings of
stereotyping harms analyzing a total of 150K 100-word stories related to
student classroom interactions. Examining patterns in LM-generated character
demographics and representational harms (i.e., erasure, subordination, and
stereotyping) we highlight particularly egregious vignettes, illustrating the
ways LM-generated outputs may influence the experiences of users with
marginalized and minoritized identities, and emphasizing the need for a
critical understanding of the psychosocial impacts of generative AI tools when
deployed and utilized in diverse social contexts.",2024-05-02
"How Well Can LLMs Echo Us? Evaluating AI Chatbots' Role-Play Ability
  with ECHO",2024-04-22 08:00:51+00:00,http://arxiv.org/abs/2404.13957v1,"Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan Wang, Michael R. Lyu",cs.CL,story,"The role-play ability of Large Language Models (LLMs) has emerged as a
popular research direction. However, existing studies focus on imitating
well-known public figures or fictional characters, overlooking the potential
for simulating ordinary individuals. Such an oversight limits the potential for
advancements in digital human clones and non-player characters in video games.
To bridge this gap, we introduce ECHO, an evaluative framework inspired by the
Turing test. This framework engages the acquaintances of the target individuals
to distinguish between human and machine-generated responses. Notably, our
framework focuses on emulating average individuals rather than historical or
fictional figures, presenting a unique advantage to apply the Turing Test. We
evaluated three role-playing LLMs using ECHO, with GPT-3.5 and GPT-4 serving as
foundational models, alongside the online application GPTs from OpenAI. Our
results demonstrate that GPT-4 more effectively deceives human evaluators, and
GPTs achieves a leading success rate of 48.3%. Furthermore, we investigated
whether LLMs could discern between human-generated and machine-generated texts.
While GPT-4 can identify differences, it could not determine which texts were
human-produced. Our code and results of reproducing the role-playing LLMs are
made publicly available via https://github.com/CUHK-ARISE/ECHO.",2024-04-22
Contextual Chart Generation for Cyber Deception,2024-04-07 07:56:14+00:00,http://arxiv.org/abs/2404.04854v1,"David D. Nguyen, David Liebowitz, Surya Nepal, Salil S. Kanhere, Sharif Abuadbba","cs.LG, cs.AI, cs.CR",story,"Honeyfiles are security assets designed to attract and detect intruders on
compromised systems. Honeyfiles are a type of honeypot that mimic real,
sensitive documents, creating the illusion of the presence of valuable data.
Interaction with a honeyfile reveals the presence of an intruder, and can
provide insights into their goals and intentions. Their practical use, however,
is limited by the time, cost and effort associated with manually creating
realistic content. The introduction of large language models has made
high-quality text generation accessible, but honeyfiles contain a variety of
content including charts, tables and images. This content needs to be plausible
and realistic, as well as semantically consistent both within honeyfiles and
with the real documents they mimic, to successfully deceive an intruder.
  In this paper, we focus on an important component of the honeyfile content
generation problem: document charts. Charts are ubiquitous in corporate
documents and are commonly used to communicate quantitative and scientific
data. Existing image generation models, such as DALL-E, are rather prone to
generating charts with incomprehensible text and unconvincing data. We take a
multi-modal approach to this problem by combining two purpose-built generative
models: a multitask Transformer and a specialized multi-head autoencoder. The
Transformer generates realistic captions and plot text, while the autoencoder
generates the underlying tabular data for the plot.
  To advance the field of automated honeyplot generation, we also release a new
document-chart dataset and propose a novel metric Keyword Semantic Matching
(KSM). This metric measures the semantic consistency between keywords of a
corpus and a smaller bag of words. Extensive experiments demonstrate excellent
performance against multiple large language models, including ChatGPT and GPT4.",2024-04-07
Returning to the Start: Generating Narratives with Related Endpoints,2024-03-31 23:48:50+00:00,http://arxiv.org/abs/2404.00829v1,"Anneliese Brei, Chao Zhao, Snigdha Chaturvedi",cs.CL,story,"Human writers often bookend their writing with ending sentences that relate
back to the beginning sentences in order to compose a satisfying narrative that
""closes the loop."" Motivated by this observation, we propose RENarGen, a
controllable story-generation paradigm that generates narratives by ensuring
the first and last sentences are related and then infilling the middle
sentences. Our contributions include an initial exploration of how various
methods of bookending from Narratology affect language modeling for stories.
Automatic and human evaluations indicate RENarGen produces better stories with
more narrative closure than current autoregressive models.",2024-03-31
"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset
  for Scientific News Report Generation",2024-03-26 14:54:48+00:00,http://arxiv.org/abs/2403.17768v1,"Dongqi Pu, Yifan Wang, Jia Loy, Vera Demberg","cs.CL, cs.AI, cs.LG",story,"Scientific news reports serve as a bridge, adeptly translating complex
research articles into reports that resonate with the broader public. The
automated generation of such narratives enhances the accessibility of scholarly
insights. In this paper, we present a new corpus to facilitate this paradigm
development. Our corpus comprises a parallel compilation of academic
publications and their corresponding scientific news reports across nine
disciplines. To demonstrate the utility and reliability of our dataset, we
conduct an extensive analysis, highlighting the divergences in readability and
brevity between scientific news narratives and academic manuscripts. We
benchmark our dataset employing state-of-the-art text generation models. The
evaluation process involves both automatic and human evaluation, which lays the
groundwork for future explorations into the automated generation of scientific
news reports. The dataset and code related to this work are available at
https://dongqi.me/projects/SciNews.",2024-03-26
Protected group bias and stereotypes in Large Language Models,2024-03-21 00:21:38+00:00,http://arxiv.org/abs/2403.14727v1,"Hadas Kotek, David Q. Sun, Zidi Xiu, Margit Bowler, Christopher Klein","cs.CY, cs.CL, cs.LG",story,"As modern Large Language Models (LLMs) shatter many state-of-the-art
benchmarks in a variety of domains, this paper investigates their behavior in
the domains of ethics and fairness, focusing on protected group bias. We
conduct a two-part study: first, we solicit sentence continuations describing
the occupations of individuals from different protected groups, including
gender, sexuality, religion, and race. Second, we have the model generate
stories about individuals who hold different types of occupations. We collect
>10k sentence completions made by a publicly available LLM, which we subject to
human annotation. We find bias across minoritized groups, but in particular in
the domains of gender and sexuality, as well as Western bias, in model
generations. The model not only reflects societal biases, but appears to
amplify them. The model is additionally overly cautious in replies to queries
relating to minoritized groups, providing responses that strongly emphasize
diversity and equity to an extent that other group characteristics are
overshadowed. This suggests that artificially constraining potentially harmful
outputs may itself lead to harm, and should be applied in a careful and
controlled manner.",2024-03-21
Caveat Lector: Large Language Models in Legal Practice,2024-03-14 08:19:41+00:00,http://arxiv.org/abs/2403.09163v1,Eliza Mik,"cs.CL, cs.CY",story,"The current fascination with large language models, or LLMs, derives from the
fact that many users lack the expertise to evaluate the quality of the
generated text. LLMs may therefore appear more capable than they actually are.
The dangerous combination of fluency and superficial plausibility leads to the
temptation to trust the generated text and creates the risk of overreliance.
Who would not trust perfect legalese? Relying recent findings in both technical
and legal scholarship, this Article counterbalances the overly optimistic
predictions as to the role of LLMs in legal practice. Integrating LLMs into
legal workstreams without a better comprehension of their limitations, will
create inefficiencies if not outright risks. Notwithstanding their
unprecedented ability to generate text, LLMs do not understand text. Without
the ability to understand meaning, LLMs will remain unable to use language, to
acquire knowledge and to perform complex reasoning tasks. Trained to model
language on the basis of stochastic word predictions, LLMs cannot distinguish
fact from fiction. Their knowledge of the law is limited to word strings
memorized in their parameters. It is also incomplete and largely incorrect.
LLMs operate at the level of word distributions, not at the level of verified
facts. The resulting propensity to hallucinate, to produce statements that are
incorrect but appear helpful and relevant, is alarming in high-risk areas like
legal services. At present, lawyers should beware of relying on text generated
by LLMs.",2024-03-14
Unfamiliar Finetuning Examples Control How Language Models Hallucinate,2024-03-08 18:28:13+00:00,http://arxiv.org/abs/2403.05612v1,"Katie Kang, Eric Wallace, Claire Tomlin, Aviral Kumar, Sergey Levine","cs.LG, cs.AI, cs.CL",story,"Large language models (LLMs) have a tendency to generate plausible-sounding
yet factually incorrect responses, especially when queried on unfamiliar
concepts. In this work, we explore the underlying mechanisms that govern how
finetuned LLMs hallucinate. Our investigation reveals an interesting pattern:
as inputs become more unfamiliar, LLM outputs tend to default towards a
``hedged'' prediction, whose form is determined by how the unfamiliar examples
in the finetuning data are supervised. Thus, by strategically modifying these
examples' supervision, we can control LLM predictions for unfamiliar inputs
(e.g., teach them to say ``I don't know''). Based on these principles, we
develop an RL approach that more reliably mitigates hallucinations for
long-form generation tasks, by tackling the challenges presented by reward
model hallucinations. We validate our findings with a series of controlled
experiments in multiple-choice QA on MMLU, as well as long-form biography and
book/movie plot generation tasks.",2024-03-08
SARD: A Human-AI Collaborative Story Generation,2024-03-03 17:48:42+00:00,http://arxiv.org/abs/2403.01575v1,"Ahmed Y. Radwan, Khaled M. Alasmari, Omar A. Abdulbagi, Emad A. Alghamdi","cs.HC, cs.AI",story,"Generative artificial intelligence (GenAI) has ushered in a new era for
storytellers, providing a powerful tool to ignite creativity and explore
uncharted narrative territories. As technology continues to advance, the
synergy between human creativity and AI-generated content holds the potential
to redefine the landscape of storytelling. In this work, we propose SARD, a
drag-and-drop visual interface for generating a multi-chapter story using large
language models. Our evaluation of the usability of SARD and its creativity
support shows that while node-based visualization of the narrative may help
writers build a mental model, it exerts unnecessary mental overhead to the
writer and becomes a source of distraction as the story becomes more
elaborated. We also found that AI generates stories that are less lexically
diverse, irrespective of the complexity of the story. We identified some
patterns and limitations of our tool that can guide the development of future
human-AI co-writing tools.",2024-03-03
Improving Open-Ended Text Generation via Adaptive Decoding,2024-02-28 10:38:21+00:00,http://arxiv.org/abs/2402.18223v1,"Wenhong Zhu, Hongkun Hao, Zhiwei He, Yiming Ai, Rui Wang",cs.CL,story,"Current language models decode text token by token according to probabilistic
distribution, and determining the appropriate candidates for the next token is
crucial to ensure generation quality. This study introduces adaptive decoding,
a mechanism that empowers the language models to ascertain a sensible candidate
set during the generation process dynamically. Specifically, we introduce an
entropy-based metric called confidence and conceptualize determining the
optimal candidate set as a confidence-increasing process. The rationality of
including a token in the candidate set is assessed by leveraging the increment
of confidence, enabling the model to determine the most suitable candidate set
adaptively. The experimental results reveal that our method achieves higher
MAUVE and diversity in story generation tasks and maintains certain coherence,
underscoring its superiority over existing algorithms. The code is available at
https://github.com/zwhong714/adaptive_decoding.",2024-02-28
"Creating Suspenseful Stories: Iterative Planning with Large Language
  Models",2024-02-27 01:25:52+00:00,http://arxiv.org/abs/2402.17119v1,"Kaige Xie, Mark Riedl",cs.CL,story,"Automated story generation has been one of the long-standing challenges in
NLP. Among all dimensions of stories, suspense is very common in human-written
stories but relatively under-explored in AI-generated stories. While recent
advances in large language models (LLMs) have greatly promoted language
generation in general, state-of-the-art LLMs are still unreliable when it comes
to suspenseful story generation. We propose a novel iterative-prompting-based
planning method that is grounded in two theoretical foundations of story
suspense from cognitive psychology and narratology. This theory-grounded method
works in a fully zero-shot manner and does not rely on any supervised story
corpora. To the best of our knowledge, this paper is the first attempt at
suspenseful story generation with LLMs. Extensive human evaluations of the
generated suspenseful stories demonstrate the effectiveness of our method.",2024-02-27
"Leveraging Large Language Models for Learning Complex Legal Concepts
  through Storytelling",2024-02-26 20:56:06+00:00,http://arxiv.org/abs/2402.17019v1,"Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel Kessler, Eric Ma, Tal August, Irene Li, Alex 'Sandy' Pentland, Yoon Kim, Jad Kabbara, Deb Roy","cs.CL, cs.HC",story,"Making legal knowledge accessible to non-experts is crucial for enhancing
general legal literacy and encouraging civic participation in democracy.
However, legal documents are often challenging to understand for people without
legal backgrounds. In this paper, we present a novel application of large
language models (LLMs) in legal education to help non-experts learn intricate
legal concepts through storytelling, an effective pedagogical tool in conveying
complex and abstract concepts. We also introduce a new dataset LegalStories,
which consists of 295 complex legal doctrines, each accompanied by a story and
a set of multiple-choice questions generated by LLMs. To construct the dataset,
we experiment with various LLMs to generate legal stories explaining these
concepts. Furthermore, we use an expert-in-the-loop method to iteratively
design multiple-choice questions. Then, we evaluate the effectiveness of
storytelling with LLMs through an RCT experiment with legal novices on 10
samples from the dataset. We find that LLM-generated stories enhance
comprehension of legal concepts and interest in law among non-native speakers
compared to only definitions. Moreover, stories consistently help participants
relate legal concepts to their lives. Finally, we find that learning with
stories shows a higher retention rate for non-native speakers in the follow-up
assessment. Our work has strong implications for using LLMs in promoting
teaching and learning in the legal field and beyond.",2024-02-26
Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation,2024-02-20 01:49:15+00:00,http://arxiv.org/abs/2402.12649v1,"Kristian Lum, Jacy Reese Anthis, Chirag Nagpal, Alexander D'Amour","cs.CL, stat.AP",story,"Bias benchmarks are a popular method for studying the negative impacts of
bias in LLMs, yet there has been little empirical investigation of whether
these benchmarks are actually indicative of how real world harm may manifest in
the real world. In this work, we study the correspondence between such
decontextualized ""trick tests"" and evaluations that are more grounded in
Realistic Use and Tangible {Effects (i.e. RUTEd evaluations). We explore this
correlation in the context of gender-occupation bias--a popular genre of bias
evaluation. We compare three de-contextualized evaluations adapted from the
current literature to three analogous RUTEd evaluations applied to long-form
content generation. We conduct each evaluation for seven instruction-tuned
LLMs. For the RUTEd evaluations, we conduct repeated trials of three text
generation tasks: children's bedtime stories, user personas, and English
language learning exercises. We found no correspondence between trick tests and
RUTEd evaluations. Specifically, selecting the least biased model based on the
de-contextualized results coincides with selecting the model with the best
performance on RUTEd evaluations only as often as random chance. We conclude
that evaluations that are not based in realistic use are likely insufficient to
mitigate and assess bias and real-world harms.",2024-02-20
Neural paraphrasing by automatically crawled and aligned sentence pairs,2024-02-16 10:40:38+00:00,http://arxiv.org/abs/2402.10558v1,"Achille Globo, Antonio Trevisi, Andrea Zugarini, Leonardo Rigutini, Marco Maggini, Stefano Melacci",cs.CL,story,"Paraphrasing is the task of re-writing an input text using other words,
without altering the meaning of the original content. Conversational systems
can exploit automatic paraphrasing to make the conversation more natural, e.g.,
talking about a certain topic using different paraphrases in different time
instants. Recently, the task of automatically generating paraphrases has been
approached in the context of Natural Language Generation (NLG). While many
existing systems simply consist in rule-based models, the recent success of the
Deep Neural Networks in several NLG tasks naturally suggests the possibility of
exploiting such networks for generating paraphrases. However, the main obstacle
toward neural-network-based paraphrasing is the lack of large datasets with
aligned pairs of sentences and paraphrases, that are needed to efficiently
train the neural models. In this paper we present a method for the automatic
generation of large aligned corpora, that is based on the assumption that news
and blog websites talk about the same events using different narrative styles.
We propose a similarity search procedure with linguistic constraints that,
given a reference sentence, is able to locate the most similar candidate
paraphrases out from millions of indexed sentences. The data generation process
is evaluated in the case of the Italian language, performing experiments using
pointer-based deep neural architectures.",2024-02-16
"Examining Gender and Racial Bias in Large Vision-Language Models Using a
  Novel Dataset of Parallel Images",2024-02-08 16:11:23+00:00,http://arxiv.org/abs/2402.05779v1,"Kathleen C. Fraser, Svetlana Kiritchenko","cs.CY, cs.CL, cs.CV",story,"Following on recent advances in large language models (LLMs) and subsequent
chat models, a new wave of large vision-language models (LVLMs) has emerged.
Such models can incorporate images as input in addition to text, and perform
tasks such as visual question answering, image captioning, story generation,
etc. Here, we examine potential gender and racial biases in such systems, based
on the perceived characteristics of the people in the input images. To
accomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday
Scenarios). The PAIRS dataset contains sets of AI-generated images of people,
such that the images are highly similar in terms of background and visual
content, but differ along the dimensions of gender (man, woman) and race
(Black, white). By querying the LVLMs with such images, we observe significant
differences in the responses according to the perceived gender or race of the
person depicted.",2024-02-08
SWAG: Storytelling With Action Guidance,2024-02-05 19:55:06+00:00,http://arxiv.org/abs/2402.03483v1,"Zeeshan Patel, Karim El-Refai, Jonathan Pei, Tianle Li","cs.CL, cs.AI",story,"Automated long-form story generation typically employs long-context large
language models (LLMs) for one-shot creation, which can produce cohesive but
not necessarily engaging content. We introduce Storytelling With Action
Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach
reduces story writing to a search problem through a two-model feedback loop:
one LLM generates story content, and another auxiliary LLM is used to choose
the next best ""action"" to steer the story's future direction. Our results show
that SWAG can substantially outperform previous end-to-end story generation
techniques when evaluated by GPT-4 and through human evaluation, and our SWAG
pipeline using only open-source models surpasses GPT-3.5-Turbo.",2024-02-05
"Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language
  Models",2024-02-05 18:55:53+00:00,http://arxiv.org/abs/2402.06659v1,"Yuancheng Xu, Jiarui Yao, Manli Shu, Yanchao Sun, Zichu Wu, Ning Yu, Tom Goldstein, Furong Huang","cs.CR, cs.AI, cs.LG",story,"Vision-Language Models (VLMs) excel in generating textual responses from
visual inputs, yet their versatility raises significant security concerns. This
study takes the first step in exposing VLMs' susceptibility to data poisoning
attacks that can manipulate responses to innocuous, everyday prompts. We
introduce Shadowcast, a stealthy data poisoning attack method where poison
samples are visually indistinguishable from benign images with matching texts.
Shadowcast demonstrates effectiveness in two attack types. The first is Label
Attack, tricking VLMs into misidentifying class labels, such as confusing
Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages
VLMs' text generation capabilities to craft narratives, such as portraying junk
food as health food, through persuasive and seemingly rational descriptions. We
show that Shadowcast are highly effective in achieving attacker's intentions
using as few as 50 poison samples. Moreover, these poison samples remain
effective across various prompts and are transferable across different VLM
architectures in the black-box setting. This work reveals how poisoned VLMs can
generate convincing yet deceptive misinformation and underscores the importance
of data quality for responsible deployments of VLMs. Our code is available at:
https://github.com/umd-huang-lab/VLM-Poisoning.",2024-02-05
"Towards scalable robotic intervention of children with Autism Spectrum
  Disorder using LLMs",2024-02-01 01:09:00+00:00,http://arxiv.org/abs/2402.00260v1,"Ruchik Mishra, Karla Conn Welch","cs.RO, cs.AI",story,"In this paper, we propose a social robot capable of verbally interacting with
children with Autism Spectrum Disorder (ASD). This communication is meant to
teach perspective-taking using text generated using a Large Language Model
(LLM) pipeline. The social robot NAO acts as a stimulator (verbally describes a
social situation and asks a question), prompter (presents three options to
choose from), and reinforcer (praises when the answer is correct). For the role
of the stimulator, the social situation, questions, and options are generated
using our LLM pipeline. We compare two approaches: GPT-2 + BART and GPT-2 +
GPT-2, where the first GPT-2 common between the pipelines is used for
unsupervised social situation generation. We use the SOCIALIQA dataset to
fine-tune all of our LLM pipelines. We found that the GPT-2 + BART pipeline had
a better BERTscore for generating the questions and the options by combining
their individual loss functions. This observation was also consistent with the
human evaluations. Lastly, the unsupervised generation of social situations was
visualized using T-SNE plots, and the entire pipeline was evaluated for
appropriateness for children with ASD by human experts.",2024-02-01
The Detection and Understanding of Fictional Discourse,2024-01-30 01:57:17+00:00,http://arxiv.org/abs/2401.16678v1,"Andrew Piper, Haiqi Zhou","cs.CL, cs.LG",story,"In this paper, we present a variety of classification experiments related to
the task of fictional discourse detection. We utilize a diverse array of
datasets, including contemporary professionally published fiction, historical
fiction from the Hathi Trust, fanfiction, stories from Reddit, folk tales,
GPT-generated stories, and anglophone world literature. Additionally, we
introduce a new feature set of word ""supersenses"" that facilitate the goal of
semantic generalization. The detection of fictional discourse can help enrich
our knowledge of large cultural heritage archives and assist with the process
of understanding the distinctive qualities of fictional storytelling more
broadly.",2024-01-30
Exploring Automatic Text Simplification of German Narrative Documents,2023-12-15 16:10:44+00:00,http://arxiv.org/abs/2312.09907v1,"Thorben Schomacker, Tillmann D√∂nicke, Marina Tropmann-Frick","cs.CL, cs.AI",story,"In this paper, we apply transformer-based Natural Language Generation (NLG)
techniques to the problem of text simplification. Currently, there are only a
few German datasets available for text simplification, even fewer with larger
and aligned documents, and not a single one with narrative texts. In this
paper, we explore to which degree modern NLG techniques can be applied to
German narrative text simplifications. We use Longformer attention and a
pre-trained mBART model. Our findings indicate that the existing approaches for
German are not able to solve the task properly. We conclude on a few directions
for future research to address this problem.",2023-12-15
"DiffuVST: Narrating Fictional Scenes with Global-History-Guided
  Denoising Models",2023-12-12 08:40:38+00:00,http://arxiv.org/abs/2312.07066v1,"Shengguang Wu, Mei Yuan, Qi Su","cs.CL, cs.CV",story,"Recent advances in image and video creation, especially AI-based image
synthesis, have led to the production of numerous visual scenes that exhibit a
high level of abstractness and diversity. Consequently, Visual Storytelling
(VST), a task that involves generating meaningful and coherent narratives from
a collection of images, has become even more challenging and is increasingly
desired beyond real-world imagery. While existing VST techniques, which
typically use autoregressive decoders, have made significant progress, they
suffer from low inference speed and are not well-suited for synthetic scenes.
To this end, we propose a novel diffusion-based system DiffuVST, which models
the generation of a series of visual descriptions as a single conditional
denoising process. The stochastic and non-autoregressive nature of DiffuVST at
inference time allows it to generate highly diverse narratives more
efficiently. In addition, DiffuVST features a unique design with bi-directional
text history guidance and multimodal adapter modules, which effectively improve
inter-sentence coherence and image-to-text fidelity. Extensive experiments on
the story generation task covering four fictional visual-story datasets
demonstrate the superiority of DiffuVST over traditional autoregressive models
in terms of both text quality and inference speed.",2023-12-12
Assessing LLMs for Moral Value Pluralism,2023-12-08 16:18:15+00:00,http://arxiv.org/abs/2312.10075v1,"Noam Benkler, Drisana Mosaphir, Scott Friedman, Andrew Smart, Sonja Schmer-Galunder","cs.CL, cs.AI",story,"The fields of AI current lacks methods to quantitatively assess and
potentially alter the moral values inherent in the output of large language
models (LLMs). However, decades of social science research has developed and
refined widely-accepted moral value surveys, such as the World Values Survey
(WVS), eliciting value judgments from direct questions in various geographies.
We have turned those questions into value statements and use NLP to compute to
how well popular LLMs are aligned with moral values for various demographics
and cultures. While the WVS is accepted as an explicit assessment of values, we
lack methods for assessing implicit moral and cultural values in media, e.g.,
encountered in social media, political rhetoric, narratives, and generated by
AI systems such as LLMs that are increasingly present in our daily lives. As we
consume online content and utilize LLM outputs, we might ask, which moral
values are being implicitly promoted or undercut, or -- in the case of LLMs --
if they are intending to represent a cultural identity, are they doing so
consistently? In this paper we utilize a Recognizing Value Resonance (RVR) NLP
model to identify WVS values that resonate and conflict with a given passage of
output text. We apply RVR to the text generated by LLMs to characterize
implicit moral values, allowing us to quantify the moral/cultural distance
between LLMs and various demographics that have been surveyed using the WVS. In
line with other work we find that LLMs exhibit several Western-centric value
biases; they overestimate how conservative people in non-Western countries are,
they are less accurate in representing gender for non-Western countries, and
portray older populations as having more traditional values. Our results
highlight value misalignment and age groups, and a need for social science
informed technological solutions addressing value plurality in LLMs.",2023-12-08
"MM-Narrator: Narrating Long-form Videos with Multimodal In-Context
  Learning",2023-11-29 08:27:00+00:00,http://arxiv.org/abs/2311.17435v1,"Chaoyi Zhang, Kevin Lin, Zhengyuan Yang, Jianfeng Wang, Linjie Li, Chung-Ching Lin, Zicheng Liu, Lijuan Wang","cs.CV, cs.AI",story,"We present MM-Narrator, a novel system leveraging GPT-4 with multimodal
in-context learning for the generation of audio descriptions (AD). Unlike
previous methods that primarily focused on downstream fine-tuning with short
video clips, MM-Narrator excels in generating precise audio descriptions for
videos of extensive lengths, even beyond hours, in an autoregressive manner.
This capability is made possible by the proposed memory-augmented generation
process, which effectively utilizes both the short-term textual context and
long-term visual memory through an efficient register-and-recall mechanism.
These contextual memories compile pertinent past information, including
storylines and character identities, ensuring an accurate tracking and
depicting of story-coherent and character-centric audio descriptions.
Maintaining the training-free design of MM-Narrator, we further propose a
complexity-based demonstration selection strategy to largely enhance its
multi-step reasoning capability via few-shot multimodal in-context learning
(MM-ICL). Experimental results on MAD-eval dataset demonstrate that MM-Narrator
consistently outperforms both the existing fine-tuning-based approaches and
LLM-based approaches in most scenarios, as measured by standard evaluation
metrics. Additionally, we introduce the first segment-based evaluator for
recurrent text generation. Empowered by GPT-4, this evaluator comprehensively
reasons and marks AD generation performance in various extendable dimensions.",2023-11-29
"RELIC: Investigating Large Language Model Responses using
  Self-Consistency",2023-11-28 14:55:52+00:00,http://arxiv.org/abs/2311.16842v1,"Furui Cheng, Vil√©m Zouhar, Simran Arora, Mrinmaya Sachan, Hendrik Strobelt, Mennatallah El-Assady","cs.HC, cs.CL",story,"Large Language Models (LLMs) are notorious for blending fact with fiction and
generating non-factual content, known as hallucinations. To tackle this
challenge, we propose an interactive system that helps users obtain insights
into the reliability of the generated text. Our approach is based on the idea
that the self-consistency of multiple samples generated by the same LLM relates
to its confidence in individual claims in the generated texts. Using this idea,
we design RELIC, an interactive system that enables users to investigate and
verify semantic-level variations in multiple long-form responses. This allows
users to recognize potentially inaccurate information in the generated text and
make necessary corrections. From a user study with ten participants, we
demonstrate that our approach helps users better verify the reliability of the
generated text. We further summarize the design implications and lessons
learned from this research for inspiring future studies on reliable human-LLM
interactions.",2023-11-28
"LongStory: Coherent, Complete and Length Controlled Long story
  Generation",2023-11-26 06:24:25+00:00,http://arxiv.org/abs/2311.15208v1,"Kyeongman Park, Nakyeong Yang, Kyomin Jung","cs.CL, cs.AI",story,"A human author can write any length of story without losing coherence. Also,
they always bring the story to a proper ending, an ability that current
language models lack. In this work, we present the LongStory for coherent,
complete, and length-controlled long story generation. LongStory introduces two
novel methodologies: (1) the long and short-term contexts weight calibrator
(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights
for long-term context Memory and short-term context Cheating, acknowledging
their distinct roles. The LSP employs discourse tokens to convey the structural
positions of a long story. Trained on three datasets with varied average story
lengths, LongStory outperforms other baselines, including the strong story
generator Plotmachine, in coherence, completeness, relevance, and
repetitiveness. We also perform zero-shot tests on each dataset to assess the
model's ability to predict outcomes beyond its training data and validate our
methodology by comparing its performance with variants of our model.",2023-11-26
"A Cross-Attention Augmented Model for Event-Triggered Context-Aware
  Story Generation",2023-11-19 08:54:47+00:00,http://arxiv.org/abs/2311.11271v1,"Chen Tang, Tyler Loakman, Chenghua Lin",cs.CL,story,"Despite recent advancements, existing story generation systems continue to
encounter difficulties in effectively incorporating contextual and event
features, which greatly influence the quality of generated narratives. To
tackle these challenges, we introduce a novel neural generation model, EtriCA,
that enhances the relevance and coherence of generated stories by employing a
cross-attention mechanism to map context features onto event sequences through
residual mapping. This feature capturing mechanism enables our model to exploit
logical relationships between events more effectively during the story
generation process. To further enhance our proposed model, we employ a
post-training framework for knowledge enhancement (KeEtriCA) on a large-scale
book corpus. This allows EtriCA to adapt to a wider range of data samples. This
results in approximately 5\% improvement in automatic metrics and over 10\%
improvement in human evaluation. We conduct extensive experiments, including
comparisons with state-of-the-art (SOTA) baseline models, to evaluate the
performance of our framework on story generation. The experimental results,
encompassing both automated metrics and human assessments, demonstrate the
superiority of our model over existing state-of-the-art baselines. These
results underscore the effectiveness of our model in leveraging context and
event features to improve the quality of generated narratives.",2023-11-19
Event Causality Is Key to Computational Story Understanding,2023-11-16 07:59:12+00:00,http://arxiv.org/abs/2311.09648v1,"Yidan Sun, Qin Chao, Boyang Li",cs.CL,story,"Psychological research suggests the central role of event causality in human
story understanding. Further, event causality has been heavily utilized in
symbolic story generation. However, few machine learning systems for story
understanding employ event causality, partially due to the lack of reliable
methods for identifying open-world causal event relations. Leveraging recent
progress in large language models (LLMs), we present the first method for event
causality identification that leads to material improvements in computational
story understanding. We design specific prompts for extracting event causal
relations from GPT. Against human-annotated event causal relations in the
GLUCOSE dataset, our technique performs on par with supervised models, while
being easily generalizable to stories of different types and lengths. The
extracted causal relations lead to 5.7\% improvements on story quality
evaluation and 8.7\% on story video-text alignment. Our findings indicate
enormous untapped potential for event causality in computational story
understanding.",2023-11-16
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,story,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
Improving Pacing in Long-Form Story Planning,2023-11-08 04:58:29+00:00,http://arxiv.org/abs/2311.04459v1,"Yichen Wang, Kevin Yang, Xiaoming Liu, Dan Klein","cs.CL, cs.AI",story,"Existing LLM-based systems for writing long-form stories or story outlines
frequently suffer from unnatural pacing, whether glossing over important events
or over-elaborating on insignificant details, resulting in a jarring experience
for the reader. We propose a CONCrete Outline ConTrol (CONCOCT) system to
improve pacing when automatically generating story outlines. We first train a
concreteness evaluator to judge which of two events is more concrete
(low-level-detailed). This evaluator can then be used to control pacing in
hierarchical outline generation; in this work, we explore a vaguest-first
expansion procedure that aims for uniform pacing. We further use the evaluator
to filter new outline items based on predicted concreteness. Compared to a
baseline hierarchical outline generator, humans judge CONCOCT's pacing to be
more consistent over 57% of the time across multiple outline lengths; the gains
also translate to downstream stories. All code, data, and models are
open-sourced.",2023-11-08
Aspects of human memory and Large Language Models,2023-11-07 09:39:12+00:00,http://arxiv.org/abs/2311.03839v2,Romuald A. Janik,"cs.CL, cs.AI, cs.LG, q-bio.NC",story,"Large Language Models (LLMs) are huge artificial neural networks which
primarily serve to generate text, but also provide a very sophisticated
probabilistic model of language use. Since generating a semantically consistent
text requires a form of effective memory, we investigate the memory properties
of LLMs and find surprising similarities with key characteristics of human
memory. We argue that the human-like memory properties of the Large Language
Model do not follow automatically from the LLM architecture but are rather
learned from the statistics of the training textual data. These results
strongly suggest that the biological features of human memory leave an imprint
on the way that we structure our textual narratives.",2023-11-07
On the Automatic Generation and Simplification of Children's Stories,2023-10-27 21:31:34+00:00,http://arxiv.org/abs/2310.18502v1,"Maria Valentini, Jennifer Weber, Jesus Salcido, T√©a Wright, Eliana Colunga, Katharina Kann",cs.CL,story,"With recent advances in large language models (LLMs), the concept of
automatically generating children's educational materials has become
increasingly realistic. Working toward the goal of age-appropriate simplicity
in generated educational texts, we first examine the ability of several popular
LLMs to generate stories with properly adjusted lexical and readability levels.
We find that, in spite of the growing capabilities of LLMs, they do not yet
possess the ability to limit their vocabulary to levels appropriate for younger
age groups. As a second experiment, we explore the ability of state-of-the-art
lexical simplification models to generalize to the domain of children's stories
and, thus, create an efficient pipeline for their automatic generation. In
order to test these models, we develop a dataset of child-directed lexical
simplification instances, with examples taken from the LLM-generated stories in
our first experiment. We find that, while the strongest-performing current
lexical simplification models do not perform as well on material designed for
children due to their reliance on large language models behind the scenes, some
models that still achieve fairly strong results on general data can mimic or
even improve their performance on children-directed data with proper
fine-tuning, which we conduct using our newly created child-directed
simplification dataset.",2023-10-27
GROOViST: A Metric for Grounding Objects in Visual Storytelling,2023-10-26 20:27:16+00:00,http://arxiv.org/abs/2310.17770v1,"Aditya K Surikuchi, Sandro Pezzelle, Raquel Fern√°ndez","cs.AI, cs.CL, cs.CV, cs.LG",story,"A proper evaluation of stories generated for a sequence of images -- the task
commonly referred to as visual storytelling -- must consider multiple aspects,
such as coherence, grammatical correctness, and visual grounding. In this work,
we focus on evaluating the degree of grounding, that is, the extent to which a
story is about the entities shown in the images. We analyze current metrics,
both designed for this purpose and for general vision-text alignment. Given
their observed shortcomings, we propose a novel evaluation tool, GROOViST, that
accounts for cross-modal dependencies, temporal misalignments (the fact that
the order in which entities appear in the story and the image sequence may not
match), and human intuitions on visual grounding. An additional advantage of
GROOViST is its modular design, where the contribution of each component can be
assessed and interpreted individually.",2023-10-26
"Branch-Solve-Merge Improves Large Language Model Evaluation and
  Generation",2023-10-23 17:29:48+00:00,http://arxiv.org/abs/2310.15123v1,"Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal, Jason Weston, Xian Li","cs.CL, cs.AI, cs.LG",story,"Large Language Models (LLMs) are frequently used for multi-faceted language
generation and evaluation tasks that involve satisfying intricate user
constraints or taking into account multiple aspects and criteria. However,
their performance can fall short, due to the model's lack of coherence and
inability to plan and decompose the problem. We propose Branch-Solve-Merge
(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such
challenging natural language tasks. It consists of branch, solve, and merge
modules that are parameterized with specific prompts to the base LLM. These
three modules plan a decomposition of the task into multiple parallel
sub-tasks, independently solve them, and fuse the solutions to the sub-tasks.
We apply our method to the tasks of LLM response evaluation and constrained
text generation and evaluate its effectiveness with multiple LLMs, including
Vicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and
consistency for each LLM by enhancing human-LLM agreement by up to 26%,
reducing length and pairwise position biases by up to 50%, and allowing
LLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint
story generation task, BSM improves the coherence of the stories while also
improving constraint satisfaction by 12%.",2023-10-23
Affective and Dynamic Beam Search for Story Generation,2023-10-23 16:37:14+00:00,http://arxiv.org/abs/2310.15079v1,"Tenghao Huang, Ehsan Qasemi, Bangzheng Li, He Wang, Faeze Brahman, Muhao Chen, Snigdha Chaturvedi",cs.CL,story,"Storytelling's captivating potential makes it a fascinating research area,
with implications for entertainment, education, therapy, and cognitive studies.
In this paper, we propose Affective Story Generator (AffGen) for generating
interesting narratives. AffGen introduces ""intriguing twists"" in narratives by
employing two novel techniques-Dynamic Beam Sizing and Affective Reranking.
Dynamic Beam Sizing encourages less predictable, more captivating word choices
using a contextual multi-arm bandit model. Affective Reranking prioritizes
sentence candidates based on affect intensity. Our empirical evaluations, both
automatic and human, demonstrate AffGen's superior performance over existing
baselines in generating affectively charged and interesting narratives. Our
ablation study and analysis provide insights into the strengths and weaknesses
of AffGen.",2023-10-23
"Experimental Narratives: A Comparison of Human Crowdsourced Storytelling
  and AI Storytelling",2023-10-19 16:54:38+00:00,http://arxiv.org/abs/2310.12902v1,Nina Begus,"cs.CL, cs.AI",story,"The paper proposes a framework that combines behavioral and computational
experiments employing fictional prompts as a novel tool for investigating
cultural artifacts and social biases in storytelling both by humans and
generative AI. The study analyzes 250 stories authored by crowdworkers in June
2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging
methods from narratology and inferential statistics. Both crowdworkers and
large language models responded to identical prompts about creating and falling
in love with an artificial human. The proposed experimental paradigm allows a
direct comparison between human and LLM-generated storytelling. Responses to
the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth
in the collective imaginary of both humans and large language models. All
solicited narratives present a scientific or technological pursuit. The
analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more
more progressive in terms of gender roles and sexuality than those written by
humans. While AI narratives can occasionally provide innovative plot twists,
they offer less imaginative scenarios and rhetoric than human-authored texts.
The proposed framework argues that fiction can be used as a window into human
and AI-based collective imaginary and social dimensions.",2023-10-19
End-to-end Story Plot Generator,2023-10-13 00:49:59+00:00,http://arxiv.org/abs/2310.08796v1,"Hanlin Zhu, Andrew Cohen, Danqing Wang, Kevin Yang, Xiaomeng Yang, Jiantao Jiao, Yuandong Tian",cs.CL,story,"Story plots, while short, carry most of the essential information of a full
story that may contain tens of thousands of words. We study the problem of
automatic generation of story plots, which includes story premise, character
descriptions, plot outlines, etc. To generate a single engaging plot, existing
plot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands
of calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot,
which is costly and takes at least several minutes. Moreover, the hard-wired
nature of the method makes the pipeline non-differentiable, blocking fast
specialization and personalization of the plot generator. In this paper, we
propose three models, $\texttt{OpenPlot}$, $\texttt{E2EPlot}$ and
$\texttt{RLPlot}$, to address these challenges. $\texttt{OpenPlot}$ replaces
expensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful
prompt designs, which leads to inexpensive generation of high-quality training
datasets of story plots. We then train an end-to-end story plot generator,
$\texttt{E2EPlot}$, by supervised fine-tuning (SFT) using approximately 13000
story plots generated by $\texttt{OpenPlot}$. $\texttt{E2EPlot}$ generates
story plots of comparable quality to $\texttt{OpenPlot}$, and is > 10$\times$
faster (1k tokens in only 30 seconds on average). Finally, we obtain
$\texttt{RLPlot}$ that is further fine-tuned with RLHF on several different
reward models for different aspects of story quality, which yields 60.0$\%$
winning rate against $\texttt{E2EPlot}$ along the aspect of suspense and
surprise.",2023-10-13
"EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form
  Narrative Text Generation",2023-10-12 10:21:37+00:00,http://arxiv.org/abs/2310.08185v1,"Wang You, Wenshan Wu, Yaobo Liang, Shaoguang Mao, Chenfei Wu, Maosong Cao, Yuzhe Cai, Yiduo Guo, Yan Xia, Furu Wei, Nan Duan","cs.CL, cs.AI",story,"Plan-and-Write is a common hierarchical approach in long-form narrative text
generation, which first creates a plan to guide the narrative writing.
Following this approach, several studies rely on simply prompting large
language models for planning, which often yields suboptimal results. In this
paper, we propose a new framework called Evaluation-guided Iterative Plan
Extraction for long-form narrative text generation (EIPE-text), which extracts
plans from the corpus of narratives and utilizes the extracted plans to
construct a better planner. EIPE-text has three stages: plan extraction,
learning, and inference. In the plan extraction stage, it iteratively extracts
and improves plans from the narrative corpus and constructs a plan corpus. We
propose a question answer (QA) based evaluation mechanism to automatically
evaluate the plans and generate detailed plan refinement instructions to guide
the iterative improvement. In the learning stage, we build a better planner by
fine-tuning with the plan corpus or in-context learning with examples in the
plan corpus. Finally, we leverage a hierarchical approach to generate long-form
narratives. We evaluate the effectiveness of EIPE-text in the domains of novels
and storytelling. Both GPT-4-based evaluations and human evaluations
demonstrate that our method can generate more coherent and relevant long-form
narratives. Our code will be released in the future.",2023-10-12
"The Temporal Structure of Language Processing in the Human Brain
  Corresponds to The Layered Hierarchy of Deep Language Models",2023-10-11 01:03:42+00:00,http://arxiv.org/abs/2310.07106v1,"Ariel Goldstein, Eric Ham, Mariano Schain, Samuel Nastase, Zaid Zada, Avigail Dabush, Bobbi Aubrey, Harshvardhan Gazula, Amir Feder, Werner K Doyle, Sasha Devore, Patricia Dugan, Daniel Friedman, Roi Reichart, Michael Brenner, Avinatan Hassidim, Orrin Devinsky, Adeen Flinker, Omer Levy, Uri Hasson","cs.CL, cs.AI, cs.LG, q-bio.NC",story,"Deep Language Models (DLMs) provide a novel computational paradigm for
understanding the mechanisms of natural language processing in the human brain.
Unlike traditional psycholinguistic models, DLMs use layered sequences of
continuous numerical vectors to represent words and context, allowing a
plethora of emerging applications such as human-like text generation. In this
paper we show evidence that the layered hierarchy of DLMs may be used to model
the temporal dynamics of language comprehension in the brain by demonstrating a
strong correlation between DLM layer depth and the time at which layers are
most predictive of the human brain. Our ability to temporally resolve
individual layers benefits from our use of electrocorticography (ECoG) data,
which has a much higher temporal resolution than noninvasive methods like fMRI.
Using ECoG, we record neural activity from participants listening to a
30-minute narrative while also feeding the same narrative to a high-performing
DLM (GPT2-XL). We then extract contextual embeddings from the different layers
of the DLM and use linear encoding models to predict neural activity. We first
focus on the Inferior Frontal Gyrus (IFG, or Broca's area) and then extend our
model to track the increasing temporal receptive window along the linguistic
processing hierarchy from auditory to syntactic and semantic areas. Our results
reveal a connection between human language processing and DLMs, with the DLM's
layer-by-layer accumulation of contextual information mirroring the timing of
neural activity in high-order language areas.",2023-10-11
"RAUCG: Retrieval-Augmented Unsupervised Counter Narrative Generation for
  Hate Speech",2023-10-09 12:01:26+00:00,http://arxiv.org/abs/2310.05650v1,"Shuyu Jiang, Wenyi Tang, Xingshu Chen, Rui Tanga, Haizhou Wang, Wenxian Wang",cs.CL,story,"The Counter Narrative (CN) is a promising approach to combat online hate
speech (HS) without infringing on freedom of speech. In recent years, there has
been a growing interest in automatically generating CNs using natural language
generation techniques. However, current automatic CN generation methods mainly
rely on expert-authored datasets for training, which are time-consuming and
labor-intensive to acquire. Furthermore, these methods cannot directly obtain
and extend counter-knowledge from external statistics, facts, or examples. To
address these limitations, we propose Retrieval-Augmented Unsupervised Counter
Narrative Generation (RAUCG) to automatically expand external counter-knowledge
and map it into CNs in an unsupervised paradigm. Specifically, we first
introduce an SSF retrieval method to retrieve counter-knowledge from the
multiple perspectives of stance consistency, semantic overlap rate, and fitness
for HS. Then we design an energy-based decoding mechanism by quantizing
knowledge injection, countering and fluency constraints into differentiable
functions, to enable the model to build mappings from counter-knowledge to CNs
without expert-authored CN data. Lastly, we comprehensively evaluate model
performance in terms of language quality, toxicity, persuasiveness, relevance,
and success rate of countering HS, etc. Experimental results show that RAUCG
outperforms strong baselines on all metrics and exhibits stronger
generalization capabilities, achieving significant improvements of +2.0% in
relevance and +4.5% in success rate of countering metrics. Moreover, RAUCG
enabled GPT2 to outperform T0 in all metrics, despite the latter being
approximately eight times larger than the former. Warning: This paper may
contain offensive or upsetting content!",2023-10-09
"GROVE: A Retrieval-augmented Complex Story Generation Framework with A
  Forest of Evidence",2023-10-09 03:55:55+00:00,http://arxiv.org/abs/2310.05388v1,"Zhihua Wen, Zhiliang Tian, Wei Wu, Yuxin Yang, Yanqi Shi, Zhen Huang, Dongsheng Li",cs.CL,story,"Conditional story generation is significant in human-machine interaction,
particularly in producing stories with complex plots. While Large language
models (LLMs) perform well on multiple NLP tasks, including story generation,
it is challenging to generate stories with both complex and creative plots.
Existing methods often rely on detailed prompts to guide LLMs to meet target
conditions, which inadvertently restrict the creative potential of the
generated stories. We argue that leveraging information from exemplary
human-written stories facilitates generating more diverse plotlines. Delving
deeper into story details helps build complex and credible plots. In this
paper, we propose a retrieval-au\textbf{G}mented sto\textbf{R}y generation
framework with a f\textbf{O}rest of e\textbf{V}id\textbf{E}nce (GROVE) to
enhance stories' complexity. We build a retrieval repository for target
conditions to produce few-shot examples to prompt LLMs. Additionally, we design
an ``asking-why'' prompting scheme that extracts a forest of evidence,
providing compensation for the ambiguities that may occur in the generated
story. This iterative process uncovers underlying story backgrounds. Finally,
we select the most fitting chains of evidence from the evidence forest and
integrate them into the generated story, thereby enhancing the narrative's
complexity and credibility. Experimental results and numerous examples verify
the effectiveness of our method.",2023-10-09
Visual Storytelling with Question-Answer Plans,2023-10-08 21:45:34+00:00,http://arxiv.org/abs/2310.05295v1,"Danyang Liu, Mirella Lapata, Frank Keller",cs.CL,story,"Visual storytelling aims to generate compelling narratives from image
sequences. Existing models often focus on enhancing the representation of the
image sequence, e.g., with external knowledge sources or advanced graph
structures. Despite recent progress, the stories are often repetitive,
illogical, and lacking in detail. To mitigate these issues, we present a novel
framework which integrates visual representations with pretrained language
models and planning. Our model translates the image sequence into a visual
prefix, a sequence of continuous embeddings which language models can
interpret. It also leverages a sequence of question-answer pairs as a blueprint
plan for selecting salient visual concepts and determining how they should be
assembled into a narrative. Automatic and human evaluation on the VIST
benchmark (Huang et al., 2016) demonstrates that blueprint-based models
generate stories that are more coherent, interesting, and natural compared to
competitive baselines and state-of-the-art systems.",2023-10-08
"Envisioning Narrative Intelligence: A Creative Visual Storytelling
  Anthology",2023-10-06 18:47:20+00:00,http://arxiv.org/abs/2310.04529v1,"Brett A. Halperin, Stephanie M. Lukin","cs.CL, J.5",story,"In this paper, we collect an anthology of 100 visual stories from authors who
participated in our systematic creative process of improvised story-building
based on image sequences. Following close reading and thematic analysis of our
anthology, we present five themes that characterize the variations found in
this creative visual storytelling process: (1) Narrating What is in Vision vs.
Envisioning; (2) Dynamically Characterizing Entities/Objects; (3) Sensing
Experiential Information About the Scenery; (4) Modulating the Mood; (5)
Encoding Narrative Biases. In understanding the varied ways that people derive
stories from images, we offer considerations for collecting story-driven
training data to inform automatic story generation. In correspondence with each
theme, we envision narrative intelligence criteria for computational visual
storytelling as: creative, reliable, expressive, grounded, and responsible.
From these criteria, we discuss how to foreground creative expression, account
for biases, and operate in the bounds of visual storyworlds.",2023-10-06
Automatic and Human-AI Interactive Text Generation,2023-10-05 20:26:15+00:00,http://arxiv.org/abs/2310.03878v1,"Yao Dou, Philippe Laban, Claire Gardent, Wei Xu",cs.CL,story,"In this tutorial, we focus on text-to-text generation, a class of natural
language generation (NLG) tasks, that takes a piece of text as input and then
generates a revision that is improved according to some specific criteria
(e.g., readability or linguistic styles), while largely retaining the original
meaning and the length of the text. This includes many useful applications,
such as text simplification, paraphrase generation, style transfer, etc. In
contrast to text summarization and open-ended text completion (e.g., story),
the text-to-text generation tasks we discuss in this tutorial are more
constrained in terms of semantic consistency and targeted language styles. This
level of control makes these tasks ideal testbeds for studying the ability of
models to generate text that is both semantically adequate and stylistically
appropriate. Moreover, these tasks are interesting from a technical standpoint,
as they require complex combinations of lexical and syntactical
transformations, stylistic control, and adherence to factual knowledge, -- all
at once. With a special focus on text simplification and revision, this
tutorial aims to provide an overview of the state-of-the-art natural language
generation research from four major aspects -- Data, Models, Human-AI
Collaboration, and Evaluation -- and to discuss and showcase a few significant
and recent advances: (1) the use of non-retrogressive approaches; (2) the shift
from fine-tuning to prompting with large language models; (3) the development
of new learnable metric and fine-grained human evaluation framework; (4) a
growing body of studies and datasets on non-English languages; (5) the rise of
HCI+NLP+Accessibility interdisciplinary research to create real-world writing
assistant systems.",2023-10-05
Learning Personalized Story Evaluation,2023-10-05 04:15:48+00:00,http://arxiv.org/abs/2310.03304v3,"Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian",cs.CL,story,"While large language models (LLMs) have shown impressive results for more
objective tasks such as QA and retrieval, it remains nontrivial to evaluate
their performance on open-ended text generation for reasons including (1) data
contamination; (2) multi-dimensional evaluation criteria; and (3)
subjectiveness stemming from reviewers' personal preferences. To address such
issues, we propose to model personalization in an uncontaminated open-ended
generation assessment. We create two new datasets Per-MPST and Per-DOC for
personalized story evaluation, by re-purposing existing datasets with proper
anonymization and new personalized labels. We further develop a personalized
story evaluation model PERSE to infer reviewer preferences and provide a
personalized evaluation. Specifically, given a few exemplary reviews from a
particular reviewer, PERSE predicts either a detailed review or fine-grained
comparison in several aspects (such as interestingness and surprise) for that
reviewer on a new text input. Experimental results show that PERSE outperforms
GPT-4 by 15.8% on Kendall correlation of story ratings, and by 13.7% on
pairwise preference prediction accuracy. Both datasets and code will be
released.",2023-10-05
"Art or Artifice? Large Language Models and the False Promise of
  Creativity",2023-09-25 22:02:46+00:00,http://arxiv.org/abs/2309.14556v1,"Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu","cs.CL, cs.AI, cs.HC",story,"Researchers have argued that large language models (LLMs) exhibit
high-quality writing capabilities from blogs to stories. However, evaluating
objectively the creativity of a piece of writing is challenging. Inspired by
the Torrance Test of Creative Thinking (TTCT), which measures creativity as a
process, we use the Consensual Assessment Technique [3] and propose the
Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product.
TTCW consists of 14 binary tests organized into the original dimensions of
Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative
writers and implement a human assessment of 48 stories written either by
professional authors or LLMs using TTCW. Our analysis shows that LLM-generated
stories pass 3-10X less TTCW tests than stories written by professionals. In
addition, we explore the use of LLMs as assessors to automate the TTCW
evaluation, revealing that none of the LLMs positively correlate with the
expert assessments.",2023-09-25
"What is a Fair Diffusion Model? Designing Generative Text-To-Image
  Models to Incorporate Various Worldviews",2023-09-18 17:04:04+00:00,http://arxiv.org/abs/2309.09944v1,"Zoe De Simone, Angie Boggust, Arvind Satyanarayan, Ashia Wilson","cs.LG, cs.AI, cs.CV, cs.CY",story,"Generative text-to-image (GTI) models produce high-quality images from short
textual descriptions and are widely used in academic and creative domains.
However, GTI models frequently amplify biases from their training data, often
producing prejudiced or stereotypical images. Yet, current bias mitigation
strategies are limited and primarily focus on enforcing gender parity across
occupations. To enhance GTI bias mitigation, we introduce DiffusionWorldViewer,
a tool to analyze and manipulate GTI models' attitudes, values, stories, and
expectations of the world that impact its generated images. Through an
interactive interface deployed as a web-based GUI and Jupyter Notebook plugin,
DiffusionWorldViewer categorizes existing demographics of GTI-generated images
and provides interactive methods to align image demographics with user
worldviews. In a study with 13 GTI users, we find that DiffusionWorldViewer
allows users to represent their varied viewpoints about what GTI outputs are
fair and, in doing so, challenges current notions of fairness that assume a
universal worldview.",2023-09-18
"Causal-Story: Local Causal Attention Utilizing Parameter-Efficient
  Tuning For Visual Story Synthesis",2023-09-18 08:06:06+00:00,http://arxiv.org/abs/2309.09553v3,"Tianyi Song, Jiuxin Cao, Kun Wang, Bo Liu, Xiaofeng Zhang","cs.CV, cs.AI, cs.MM",story,"The excellent text-to-image synthesis capability of diffusion models has
driven progress in synthesizing coherent visual stories. The current
state-of-the-art method combines the features of historical captions,
historical frames, and the current captions as conditions for generating the
current frame. However, this method treats each historical frame and caption as
the same contribution. It connects them in order with equal weights, ignoring
that not all historical conditions are associated with the generation of the
current frame. To address this issue, we propose Causal-Story. This model
incorporates a local causal attention mechanism that considers the causal
relationship between previous captions, frames, and current captions. By
assigning weights based on this relationship, Causal-Story generates the
current frame, thereby improving the global consistency of story generation. We
evaluated our model on the PororoSV and FlintstonesSV datasets and obtained
state-of-the-art FID scores, and the generated frames also demonstrate better
storytelling in visuals.",2023-09-18
1.5 million materials narratives generated by chatbots,2023-08-25 22:00:53+00:00,http://arxiv.org/abs/2308.13687v1,"Yang Jeong Park, Sung Eun Jerng, Jin-Sung Park, Choah Kwon, Chia-Wei Hsu, Zhichu Ren, Sungroh Yoon, Ju Li","cond-mat.mtrl-sci, cs.CL",story,"The advent of artificial intelligence (AI) has enabled a comprehensive
exploration of materials for various applications. However, AI models often
prioritize frequently encountered materials in the scientific literature,
limiting the selection of suitable candidates based on inherent physical and
chemical properties. To address this imbalance, we have generated a dataset of
1,494,017 natural language-material paragraphs based on combined OQMD,
Materials Project, JARVIS, COD and AFLOW2 databases, which are dominated by ab
initio calculations and tend to be much more evenly distributed on the periodic
table. The generated text narratives were then polled and scored by both human
experts and ChatGPT-4, based on three rubrics: technical accuracy, language and
structure, and relevance and depth of content, showing similar scores but with
human-scored depth of content being the most lagging. The merger of
multi-modality data sources and large language model (LLM) holds immense
potential for AI frameworks to help the exploration and discovery of
solid-state materials for specific applications.",2023-08-25
StoryBench: A Multifaceted Benchmark for Continuous Story Visualization,2023-08-22 17:53:55+00:00,http://arxiv.org/abs/2308.11606v1,"Emanuele Bugliarello, Hernan Moraldo, Ruben Villegas, Mohammad Babaeizadeh, Mohammad Taghi Saffar, Han Zhang, Dumitru Erhan, Vittorio Ferrari, Pieter-Jan Kindermans, Paul Voigtlaender","cs.CV, cs.CL",story,"Generating video stories from text prompts is a complex task. In addition to
having high visual quality, videos need to realistically adhere to a sequence
of text prompts whilst being consistent throughout the frames. Creating a
benchmark for video generation requires data annotated over time, which
contrasts with the single caption used often in video datasets. To fill this
gap, we collect comprehensive human annotations on three existing datasets, and
introduce StoryBench: a new, challenging multi-task benchmark to reliably
evaluate forthcoming text-to-video models. Our benchmark includes three video
generation tasks of increasing difficulty: action execution, where the next
action must be generated starting from a conditioning video; story
continuation, where a sequence of actions must be executed starting from a
conditioning video; and story generation, where a video must be generated from
only text prompts. We evaluate small yet strong text-to-video baselines, and
show the benefits of training on story-like data algorithmically generated from
existing video captions. Finally, we establish guidelines for human evaluation
of video stories, and reaffirm the need of better automatic metrics for video
generation. StoryBench aims at encouraging future research efforts in this
exciting new area.",2023-08-22
"DataTales: Investigating the use of Large Language Models for Authoring
  Data-Driven Articles",2023-08-08 06:21:58+00:00,http://arxiv.org/abs/2308.04076v1,"Nicole Sultanum, Arjun Srinivasan","cs.HC, cs.CL",story,"Authoring data-driven articles is a complex process requiring authors to not
only analyze data for insights but also craft a cohesive narrative that
effectively communicates the insights. Text generation capabilities of
contemporary large language models (LLMs) present an opportunity to assist the
authoring of data-driven articles and expedite the writing process. In this
work, we investigate the feasibility and perceived value of leveraging LLMs to
support authors of data-driven articles. We designed a prototype system,
DataTales, that leverages a LLM to generate textual narratives accompanying a
given chart. Using DataTales as a design probe, we conducted a qualitative
study with 11 professionals to evaluate the concept, from which we distilled
affordances and opportunities to further integrate LLMs as valuable data-driven
article authoring assistants.",2023-08-08
"Storyfier: Exploring Vocabulary Learning Support with Text Generation
  Models",2023-08-07 18:25:00+00:00,http://arxiv.org/abs/2308.03864v1,"Zhenhui Peng, Xingbo Wang, Qiushi Han, Junkai Zhu, Xiaojuan Ma, Huamin Qu","cs.HC, cs.CL",story,"Vocabulary learning support tools have widely exploited existing materials,
e.g., stories or video clips, as contexts to help users memorize each target
word. However, these tools could not provide a coherent context for any target
words of learners' interests, and they seldom help practice word usage. In this
paper, we work with teachers and students to iteratively develop Storyfier,
which leverages text generation models to enable learners to read a generated
story that covers any target words, conduct a story cloze test, and use these
words to write a new story with adaptive AI assistance. Our within-subjects
study (N=28) shows that learners generally favor the generated stories for
connecting target words and writing assistance for easing their learning
workload. However, in the read-cloze-write learning sessions, participants
using Storyfier perform worse in recalling and using target words than learning
with a baseline tool without our AI features. We discuss insights into
supporting learning tasks with generative models.",2023-08-07
"""Kurosawa"": A Script Writer's Assistant",2023-08-06 14:09:02+00:00,http://arxiv.org/abs/2308.03122v1,"Prerak Gandhi, Vishal Pramanik, Pushpak Bhattacharyya",cs.CL,story,"Storytelling is the lifeline of the entertainment industry -- movies, TV
shows, and stand-up comedies, all need stories. A good and gripping script is
the lifeline of storytelling and demands creativity and resource investment.
Good scriptwriters are rare to find and often work under severe time pressure.
Consequently, entertainment media are actively looking for automation. In this
paper, we present an AI-based script-writing workbench called KUROSAWA which
addresses the tasks of plot generation and script generation. Plot generation
aims to generate a coherent and creative plot (600-800 words) given a prompt
(15-40 words). Script generation, on the other hand, generates a scene (200-500
words) in a screenplay format from a brief description (15-40 words). Kurosawa
needs data to train. We use a 4-act structure of storytelling to annotate the
plot dataset manually. We create a dataset of 1000 manually annotated plots and
their corresponding prompts/storylines and a gold-standard dataset of 1000
scenes with four main elements -- scene headings, action lines, dialogues, and
character names -- tagged individually. We fine-tune GPT-3 with the above
datasets to generate plots and scenes. These plots and scenes are first
evaluated and then used by the scriptwriters of a large and famous media
platform ErosNow. We release the annotated datasets and the models trained on
these datasets as a working benchmark for automatic movie plot and script
generation.",2023-08-06
Ambient Adventures: Teaching ChatGPT on Developing Complex Stories,2023-08-03 12:52:49+00:00,http://arxiv.org/abs/2308.01734v1,"Zexin Chen, Eric Zhou, Kenneth Eaton, Xiangyu Peng, Mark Riedl","cs.CL, cs.HC",story,"Imaginative play is an area of creativity that could allow robots to engage
with the world around them in a much more personified way. Imaginary play can
be seen as taking real objects and locations and using them as imaginary
objects and locations in virtual scenarios. We adopted the story generation
capability of large language models (LLMs) to obtain the stories used for
imaginary play with human-written prompts. Those generated stories will be
simplified and mapped into action sequences that can guide the agent in
imaginary play. To evaluate whether the agent can successfully finish the
imaginary play, we also designed a text adventure game to simulate a house as
the playground for the agent to interact.",2023-08-03
Trustworthiness of Children Stories Generated by Large Language Models,2023-07-25 22:55:51+00:00,http://arxiv.org/abs/2308.00073v1,"Prabin Bhandari, Hannah Marie Brennan",cs.CL,story,"Large Language Models (LLMs) have shown a tremendous capacity for generating
literary text. However, their effectiveness in generating children's stories
has yet to be thoroughly examined. In this study, we evaluate the
trustworthiness of children's stories generated by LLMs using various measures,
and we compare and contrast our results with both old and new children's
stories to better assess their significance. Our findings suggest that LLMs
still struggle to generate children's stories at the level of quality and
nuance found in actual stories",2023-07-25
"The Imitation Game: Detecting Human and AI-Generated Texts in the Era of
  Large Language Models",2023-07-22 21:00:14+00:00,http://arxiv.org/abs/2307.12166v1,"Kadhim Hayawi, Sakib Shahriar, Sujith Samuel Mathew","cs.CL, cs.AI",story,"The potential of artificial intelligence (AI)-based large language models
(LLMs) holds considerable promise in revolutionizing education, research, and
practice. However, distinguishing between human-written and AI-generated text
has become a significant task. This paper presents a comparative study,
introducing a novel dataset of human-written and LLM-generated texts in
different genres: essays, stories, poetry, and Python code. We employ several
machine learning models to classify the texts. Results demonstrate the efficacy
of these models in discerning between human and AI-generated text, despite the
dataset's limited sample size. However, the task becomes more challenging when
classifying GPT-generated text, particularly in story writing. The results
indicate that the models exhibit superior performance in binary classification
tasks, such as distinguishing human-generated text from a specific LLM,
compared to the more complex multiclass tasks that involve discerning among
human-generated and multiple LLMs. Our findings provide insightful implications
for AI text detection while our dataset paves the way for future research in
this evolving area.",2023-07-22
"On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large
  Language Models",2023-07-19 07:17:43+00:00,http://arxiv.org/abs/2307.09793v1,"Sarah Gao, Andrew Kean Gao","cs.DL, cs.CL, I.2.1; H.5.0",story,"Since late 2022, Large Language Models (LLMs) have become very prominent with
LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs
are announced each week, many of which are deposited to Hugging Face, a
repository of machine learning models and datasets. To date, nearly 16,000 Text
Generation models have been uploaded to the site. Given the huge influx of
LLMs, it is of interest to know which LLM backbones, settings, training
methods, and families are popular or trending. However, there is no
comprehensive index of LLMs available. We take advantage of the relatively
systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering
and identify communities amongst LLMs using n-grams and term frequency-inverse
document frequency. Our methods successfully identify families of LLMs and
accurately cluster LLMs into meaningful subgroups. We present a public web
application to navigate and explore Constellation, our atlas of 15,821 LLMs.
Constellation rapidly generates a variety of visualizations, namely
dendrograms, graphs, word clouds, and scatter plots. Constellation is available
at the following link: https://constellation.sites.stanford.edu/.",2023-07-19
"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and
  Addressing Sociological Implications",2023-07-18 11:38:45+00:00,http://arxiv.org/abs/2307.09162v1,Vishesh Thakur,cs.CL,story,"Gender bias in artificial intelligence (AI) and natural language processing
has garnered significant attention due to its potential impact on societal
perceptions and biases. This research paper aims to analyze gender bias in
Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2
and GPT-3.5, some prominent language models, to better understand its
implications. Through a comprehensive literature review, the study examines
existing research on gender bias in AI language models and identifies gaps in
the current knowledge. The methodology involves collecting and preprocessing
data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis
techniques to evaluate gender bias in the generated text. The findings shed
light on gendered word associations, language usage, and biased narratives
present in the outputs of these Large Language Models. The discussion explores
the ethical implications of gender bias and its potential consequences on
social perceptions and marginalized communities. Additionally, the paper
presents strategies for reducing gender bias in LLMs, including algorithmic
approaches and data augmentation techniques. The research highlights the
importance of interdisciplinary collaborations and the role of sociological
studies in mitigating gender bias in AI models. By addressing these issues, we
can pave the way for more inclusive and unbiased AI systems that have a
positive impact on society.",2023-07-18
"Using Large Language Models for Zero-Shot Natural Language Generation
  from Knowledge Graphs",2023-07-14 12:45:03+00:00,http://arxiv.org/abs/2307.07312v1,"Agnes Axelsson, Gabriel Skantze","cs.CL, 68T50, I.2.7; I.2.4",story,"In any system that uses structured knowledge graph (KG) data as its
underlying knowledge representation, KG-to-text generation is a useful tool for
turning parts of the graph data into text that can be understood by humans.
Recent work has shown that models that make use of pretraining on large amounts
of text data can perform well on the KG-to-text task even with relatively small
sets of training data on the specific graph-to-text task. In this paper, we
build on this concept by using large language models to perform zero-shot
generation based on nothing but the model's understanding of the triple
structure from what it can read. We show that ChatGPT achieves near
state-of-the-art performance on some measures of the WebNLG 2020 challenge, but
falls behind on others. Additionally, we compare factual, counter-factual and
fictional statements, and show that there is a significant connection between
what the LLM already knows about the data it is parsing and the quality of the
output text.",2023-07-14
Designing Mixed-Initiative Video Games,2023-07-08 01:45:25+00:00,http://arxiv.org/abs/2307.03877v1,Daijin Yang,"cs.HC, cs.AI, J.5",story,"The development of Artificial Intelligence (AI) enables humans to co-create
content with machines. The unexpectedness of AI-generated content can bring
inspiration and entertainment to users. However, the co-creation interactions
are always designed for content creators and have poor accessibility. To
explore gamification of mixed-initiative co-creation and make human-AI
interactions accessible and fun for players, I prototyped Snake Story, a
mixed-initiative game where players can select AI-generated texts to write a
story of a snake by playing a ""Snake"" like game. A controlled experiment was
conducted to investigate the dynamics of player-AI interactions with and
without the game component in the designed interface. As a result of a study
with 11 players (n=11), I found that players utilized different strategies when
playing with the two versions, game mechanics significantly affected the output
stories, players' creative process, as well as role perceptions, and players
with different backgrounds showed different preferences for the two versions.
Based on these results, I further discussed considerations for mixed-initiative
game design. This work aims to inspire the design of engaging co-creation
experiences.",2023-07-08
"ScoNe: Benchmarking Negation Reasoning in Language Models With
  Fine-Tuning and In-Context Learning",2023-05-30 21:43:11+00:00,http://arxiv.org/abs/2305.19426v1,"Jingyuan Selena She, Christopher Potts, Samuel R. Bowman, Atticus Geiger","cs.CL, cs.LG",story,"A number of recent benchmarks seek to assess how well models handle natural
language negation. However, these benchmarks lack the controlled example
paradigms that would allow us to infer whether a model had learned how negation
morphemes semantically scope. To fill these analytical gaps, we present the
Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six
examples with up to two negations where either zero, one, or both negative
morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and
in-context learning strategies. We find that RoBERTa and DeBERTa models solve
ScoNe-NLI after many shot fine-tuning. For in-context learning, we test
InstructGPT models and find that most prompt strategies are not successful,
including those using step-by-step reasoning. To better understand this result,
we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds
negation reasoning in short narratives. Here, InstructGPT is successful, which
reveals the model can correctly reason about negation, but struggles to do so
on prompt-adapted NLI examples outside of its core pretraining regime.",2023-05-30
"Marked Personas: Using Natural Language Prompts to Measure Stereotypes
  in Language Models",2023-05-29 16:29:22+00:00,http://arxiv.org/abs/2305.18189v1,"Myra Cheng, Esin Durmus, Dan Jurafsky","cs.CL, cs.AI, cs.CY",story,"To recognize and mitigate harms from large language models (LLMs), we need to
understand the prevalence and nuances of stereotypes in LLM outputs. Toward
this end, we present Marked Personas, a prompt-based method to measure
stereotypes in LLMs for intersectional demographic groups without any lexicon
or data labeling. Grounded in the sociolinguistic concept of markedness (which
characterizes explicitly linguistically marked categories versus unmarked
defaults), our proposed method is twofold: 1) prompting an LLM to generate
personas, i.e., natural language descriptions, of the target demographic group
alongside personas of unmarked, default groups; 2) identifying the words that
significantly distinguish personas of the target group from corresponding
unmarked ones. We find that the portrayals generated by GPT-3.5 and GPT-4
contain higher rates of racial stereotypes than human-written portrayals using
the same prompts. The words distinguishing personas of marked (non-white,
non-male) groups reflect patterns of othering and exoticizing these
demographics. An intersectional lens further reveals tropes that dominate
portrayals of marginalized groups, such as tropicalism and the
hypersexualization of minoritized women. These representational harms have
concerning implications for downstream applications like story generation.",2023-05-29
Improved Visual Story Generation with Adaptive Context Modeling,2023-05-26 10:43:42+00:00,http://arxiv.org/abs/2305.16811v1,"Zhangyin Feng, Yuchen Ren, Xinmiao Yu, Xiaocheng Feng, Duyu Tang, Shuming Shi, Bing Qin","cs.CV, cs.CL",story,"Diffusion models developed on top of powerful text-to-image generation models
like Stable Diffusion achieve remarkable success in visual story generation.
However, the best-performing approach considers historically generated results
as flattened memory cells, ignoring the fact that not all preceding images
contribute equally to the generation of the characters and scenes at the
current stage. To address this, we present a simple method that improves the
leading system with adaptive context modeling, which is not only incorporated
in the encoder but also adopted as additional guidance in the sampling stage to
boost the global consistency of the generated story. We evaluate our model on
PororoSV and FlintstonesSV datasets and show that our approach achieves
state-of-the-art FID scores on both story visualization and continuation
scenarios. We conduct detailed model analysis and show that our model excels at
generating semantically consistent images for stories.",2023-05-26
Ghostbuster: Detecting Text Ghostwritten by Large Language Models,2023-05-24 11:37:10+00:00,http://arxiv.org/abs/2305.15047v1,"Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein","cs.CL, cs.AI",story,"We introduce Ghostbuster, a state-of-the-art system for detecting
AI-generated text. Our method works by passing documents through a series of
weaker language models and running a structured search over possible
combinations of their features, then training a classifier on the selected
features to determine if the target document was AI-generated. Crucially,
Ghostbuster does not require access to token probabilities from the target
model, making it useful for detecting text generated by black-box models or
unknown model versions. In conjunction with our model, we release three new
datasets of human and AI-generated text as detection benchmarks that cover
multiple domains (student essays, creative fiction, and news) and task setups:
document-level detection, author identification, and a challenge task of
paragraph-level detection. Ghostbuster averages 99.1 F1 across all three
datasets on document-level detection, outperforming previous approaches such as
GPTZero and DetectGPT by up to 32.7 F1.",2023-05-24
"Enhancing Generation through Summarization Duality and Explicit Outline
  Control",2023-05-23 18:33:52+00:00,http://arxiv.org/abs/2305.14459v1,"Yunzhe Li, Qian Chen, Weixiang Yan, Wen Wang, Qinglin Zhang, Hari Sundaram","cs.CL, cs.AI",story,"Automatically open-ended long text generation poses significant challenges
due to semantic incoherence and plot implausibility. Previous works usually
alleviate this problem through outlines in the form of short phrases or
abstractive signals by designing unsupervised tasks, which tend to be unstable
and weakly interpretable.
  Assuming that a summary serves as a mature outline, we introduce a two-stage,
summary-enhanced outline supervised generation framework. This framework
leverages the dual characteristics of the summarization task to improve outline
prediction, resulting in more explicit and plausible outlines. Furthermore, we
identify an underutilization issue in outline-based generation with both
standard pretrained language models (e.g., GPT-2, BART) and large language
models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit
outline control method for more effective utilization of generated outlines.",2023-05-23
Look-back Decoding for Open-Ended Text Generation,2023-05-22 20:42:37+00:00,http://arxiv.org/abs/2305.13477v1,"Nan Xu, Chunting Zhou, Asli Celikyilmaz, Xuezhe Ma",cs.CL,story,"Given a prefix (context), open-ended generation aims to decode texts that are
coherent, which don't abruptly drift from previous topics, and informative,
which don't suffer from undesired repetitions. In this paper, we propose
Look-back, an improved decoding algorithm that leverages the Kullback-Leibler
divergence to track the distribution distance between current and historical
decoding steps. Thus Look-back can automatically predict potential repetitive
phrase and topic drift, and remove tokens that may cause the failure modes,
restricting the next token probability distribution within a plausible distance
to the history. We perform decoding experiments on document continuation and
story generation, and demonstrate that Look-back is able to generate more
fluent and coherent text, outperforming other strong decoding methods
significantly in both automatic and human evaluations.",2023-05-22
RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text,2023-05-22 17:58:10+00:00,http://arxiv.org/abs/2305.13304v1,"Wangchunshu Zhou, Yuchen Eleanor Jiang, Peng Cui, Tiannan Wang, Zhenxin Xiao, Yifan Hou, Ryan Cotterell, Mrinmaya Sachan","cs.CL, cs.LG",story,"The fixed-size context of Transformer makes GPT models incapable of
generating arbitrarily long text. In this paper, we introduce RecurrentGPT, a
language-based simulacrum of the recurrence mechanism in RNNs. RecurrentGPT is
built upon a large language model (LLM) such as ChatGPT and uses natural
language to simulate the Long Short-Term Memory mechanism in an LSTM. At each
timestep, RecurrentGPT generates a paragraph of text and updates its
language-based long-short term memory stored on the hard drive and the prompt,
respectively. This recurrence mechanism enables RecurrentGPT to generate texts
of arbitrary length without forgetting. Since human users can easily observe
and edit the natural language memories, RecurrentGPT is interpretable and
enables interactive generation of long text. RecurrentGPT is an initial step
towards next-generation computer-assisted writing systems beyond local editing
suggestions. In addition to producing AI-generated content (AIGC), we also
demonstrate the possibility of using RecurrentGPT as an interactive fiction
that directly interacts with consumers. We call this usage of generative models
by ``AI As Contents'' (AIAC), which we believe is the next form of conventional
AIGC. We further demonstrate the possibility of using RecurrentGPT to create
personalized interactive fiction that directly interacts with readers instead
of interacting with writers. More broadly, RecurrentGPT demonstrates the
utility of borrowing ideas from popular model designs in cognitive science and
deep learning for prompting LLMs. Our code is available at
https://github.com/aiwaves-cn/RecurrentGPT and an online demo is available at
https://www.aiwaves.org/recurrentgpt.",2023-05-22
Deepfake Text Detection in the Wild,2023-05-22 17:13:29+00:00,http://arxiv.org/abs/2305.13242v1,"Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue Wang, Linyi Yang, Shuming Shi, Yue Zhang",cs.CL,story,"Recent advances in large language models have enabled them to reach a level
of text generation comparable to that of humans. These models show powerful
capabilities across a wide range of content, including news article writing,
story generation, and scientific writing. Such capability further narrows the
gap between human-authored and machine-generated texts, highlighting the
importance of deepfake text detection to avoid potential risks such as fake
news propagation and plagiarism. However, previous work has been limited in
that they testify methods on testbed of specific domains or certain language
models. In practical scenarios, the detector faces texts from various domains
or LLMs without knowing their sources. To this end, we build a wild testbed by
gathering texts from various human writings and deepfake texts generated by
different LLMs. Human annotators are only slightly better than random guessing
at identifying machine-generated texts. Empirical results on automatic
detection methods further showcase the challenges of deepfake text detection in
a wild testbed. In addition, out-of-distribution poses a greater challenge for
a detector to be employed in realistic application scenarios. We release our
resources at https://github.com/yafuly/DeepfakeTextDetect.",2023-05-22
"Extrapolating Multilingual Understanding Models as Multilingual
  Generators",2023-05-22 15:33:21+00:00,http://arxiv.org/abs/2305.13140v1,"Bohong Wu, Fei Yuan, Hai Zhao, Lei Li, Jingjing Xu",cs.CL,story,"Multilingual understanding models (or encoder-based), pre-trained via masked
language modeling, have achieved promising results on many language
understanding tasks (e.g., mBERT). However, these non-autoregressive (NAR)
models still struggle to generate high-quality texts compared with
autoregressive (AR) models. Considering that encoder-based models have the
advantage of efficient generation and self-correction abilities, this paper
explores methods to empower multilingual understanding models the generation
abilities to get a unified model. Specifically, we start from a multilingual
encoder (XLM-R) and propose a \textbf{S}emantic-\textbf{G}uided
\textbf{A}lignment-then-Denoising (SGA) approach to adapt an encoder to a
multilingual generator with a small number of new parameters. Experiments show
that the proposed approach is an effective adaption method, outperforming
widely-used initialization-based methods with gains of 9.4 BLEU on machine
translation, 8.1 Rouge-L on question generation, and 5.5 METEOR on story
generation on XLM-R$_{large}$. On the other hand, we observe that XLM-R is
still inferior to mBART in supervised settings despite better results on
zero-shot settings, indicating that more exploration is required to make
understanding models strong generators.",2023-05-22
"A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them
  In Zero Shot",2023-05-16 19:13:11+00:00,http://arxiv.org/abs/2305.09758v1,"Aanisha Bhattacharya, Yaman K Singla, Balaji Krishnamurthy, Rajiv Ratn Shah, Changyou Chen","cs.CV, cs.CL",story,"Multimedia content, such as advertisements and story videos, exhibit a rich
blend of creativity and multiple modalities. They incorporate elements like
text, visuals, audio, and storytelling techniques, employing devices like
emotions, symbolism, and slogans to convey meaning. While previous research in
multimedia understanding has focused mainly on videos with specific actions
like cooking, there is a dearth of large annotated training datasets, hindering
the development of supervised learning models with satisfactory performance for
real-world applications. However, the rise of large language models (LLMs) has
witnessed remarkable zero-shot performance in various natural language
processing (NLP) tasks, such as emotion classification, question-answering, and
topic classification. To bridge this performance gap in multimedia
understanding, we propose verbalizing story videos to generate their
descriptions in natural language and then performing video-understanding tasks
on the generated story as opposed to the original video. Through extensive
experiments on five video-understanding tasks, we demonstrate that our method,
despite being zero-shot, achieves significantly better results than supervised
baselines for video understanding. Further, alleviating a lack of story
understanding benchmarks, we publicly release the first dataset on a crucial
task in computational social science, persuasion strategy identification.",2023-05-16
"Generating coherent comic with rich story using ChatGPT and Stable
  Diffusion",2023-05-16 13:11:45+00:00,http://arxiv.org/abs/2305.11067v2,"Ze Jin, Zorina Song","cs.CV, cs.AI, cs.LG",story,"Past work demonstrated that using neural networks, we can extend unfinished
music pieces while maintaining the music style of the musician. With recent
advancements in large language models and diffusion models, we are now capable
of generating comics with an interesting storyline while maintaining the art
style of the artist. In this paper, we used ChatGPT to generate storylines and
dialogue and then generated the comic using stable diffusion. We introduced a
novel way to evaluate AI-generated stories, and we achieved SOTA performance on
character fidelity and art style by fine-tuning stable diffusion using LoRA,
ControlNet, etc.",2023-05-16
Can Large Language Models Be an Alternative to Human Evaluations?,2023-05-03 07:28:50+00:00,http://arxiv.org/abs/2305.01937v1,"Cheng-Han Chiang, Hung-yi Lee","cs.CL, cs.HC",story,"Human evaluation is indispensable and inevitable for assessing the quality of
texts generated by machine learning models or written by humans. However, human
evaluation is very difficult to reproduce and its quality is notoriously
unstable, hindering fair comparisons among different natural language
processing (NLP) models and algorithms. Recently, large language models (LLMs)
have demonstrated exceptional performance on unseen tasks when only the task
instructions are provided. In this paper, we explore if such an ability of the
LLMs can be used as an alternative to human evaluation. We present the LLMs
with the exact same instructions, samples to be evaluated, and questions used
to conduct human evaluation, and then ask the LLMs to generate responses to
those questions; we dub this LLM evaluation. We use human evaluation and LLM
evaluation to evaluate the texts in two NLP tasks: open-ended story generation
and adversarial attacks. We show that the result of LLM evaluation is
consistent with the results obtained by expert human evaluation: the texts
rated higher by human experts are also rated higher by the LLMs. We also find
that the results of LLM evaluation are stable over different formatting of the
task instructions and the sampling algorithm used to generate the answer. We
are the first to show the potential of using LLMs to assess the quality of
texts and discuss the limitations and ethical considerations of LLM evaluation.",2023-05-03
Controlling keywords and their positions in text generation,2023-04-19 09:11:45+00:00,http://arxiv.org/abs/2304.09516v1,"Yuichi Sasazawa, Terufumi Morishita, Hiroaki Ozaki, Osamu Imaichi, Yasuhiro Sogawa",cs.CL,story,"One of the challenges in text generation is to control generation as intended
by a user. Previous studies have proposed to specify the keywords that should
be included in the generated text. However, this is insufficient to generate
text which reflect the user intent. For example, placing the important keyword
beginning of the text would helps attract the reader's attention, but existing
methods do not enable such flexible control. In this paper, we tackle a novel
task of controlling not only keywords but also the position of each keyword in
the text generation. To this end, we show that a method using special tokens
can control the relative position of keywords. Experimental results on
summarization and story generation tasks show that the proposed method can
control keywords and their positions. We also demonstrate that controlling the
keyword positions can generate summary texts that are closer to the user's
intent than baseline. We release our code.",2023-04-19
"LongForm: Optimizing Instruction Tuning for Long Text Generation with
  Corpus Extraction",2023-04-17 17:36:35+00:00,http://arxiv.org/abs/2304.08460v1,"Abdullatif K√∂ksal, Timo Schick, Anna Korhonen, Hinrich Sch√ºtze","cs.CL, cs.AI, cs.LG",story,"Instruction tuning enables language models to generalize more effectively and
better follow user intent. However, obtaining instruction data can be costly
and challenging. Prior works employ methods such as expensive human annotation,
crowd-sourced datasets with alignment issues, or generating noisy examples via
LLMs. We introduce the LongForm dataset, which is created by leveraging English
corpus examples with augmented instructions. We select a diverse set of
human-written documents from existing corpora such as C4 and Wikipedia and
generate instructions for the given documents via LLMs. This approach provides
a cheaper and cleaner instruction-tuning dataset and one suitable for long text
generation. We finetune T5, OPT, and LLaMA models on our dataset and show that
even smaller LongForm models have good generalization capabilities for text
generation. Our models outperform 10x larger language models without
instruction tuning on various tasks such as story/recipe generation and
long-form question answering. Moreover, LongForm models outperform prior
instruction-tuned models such as FLAN-T5 and Alpaca by a large margin. Finally,
our models can effectively follow and answer multilingual instructions; we
demonstrate this for news generation. We publicly release our data and models:
https://github.com/akoksal/LongForm.",2023-04-17
"Rolling the Dice: Imagining Generative AI as a Dungeons & Dragons
  Storytelling Companion",2023-04-04 15:09:00+00:00,http://arxiv.org/abs/2304.01860v1,"Jose Ma. Santiago III, Richard Lance Parayno, Jordan Aiko Deja, Briane Paul V. Samson","cs.HC, I.2.7",story,"AI Advancements have augmented casual writing and story generation, but their
usage poses challenges in collaborative storytelling. In role-playing games
such as Dungeons & Dragons (D&D), composing prompts using generative AI
requires a technical understanding to generate ideal results, which is
difficult for novices. Thus, emergent narratives organically developed based on
player actions and decisions have yet to be fully utilized. This paper
envisions the use of generative AI in transforming storytelling into an
interactive drama using dynamic and immersive narratives. First, we describe
scenarios where narratives are created and character conversations are designed
within an overarching fantasy disposition. Then, we recommend design guidelines
to help create tools using generative AI in interactive storytelling. Lastly,
we raise questions on its potential impact on player immersion and cognitive
load. Our contributions may be expanded within the broader interactive
storytelling domain, such as speech-conversational AI and persona-driven
chatbots.",2023-04-04
Detecting and Grounding Important Characters in Visual Stories,2023-03-30 18:24:06+00:00,http://arxiv.org/abs/2303.17647v1,"Danyang Liu, Frank Keller","cs.CL, cs.CV",story,"Characters are essential to the plot of any story. Establishing the
characters before writing a story can improve the clarity of the plot and the
overall flow of the narrative. However, previous work on visual storytelling
tends to focus on detecting objects in images and discovering relationships
between them. In this approach, characters are not distinguished from other
objects when they are fed into the generation pipeline. The result is a
coherent sequence of events rather than a character-centric story. In order to
address this limitation, we introduce the VIST-Character dataset, which
provides rich character-centric annotations, including visual and textual
co-reference chains and importance ratings for characters. Based on this
dataset, we propose two new tasks: important character detection and character
grounding in visual stories. For both tasks, we develop simple, unsupervised
models based on distributional similarity and pre-trained vision-and-language
models. Our new dataset, together with these models, can serve as the
foundation for subsequent work on analysing and generating stories from a
character-centric perspective.",2023-03-30
"Chinese Intermediate English Learners outdid ChatGPT in deep cohesion:
  Evidence from English narrative writing",2023-03-21 12:55:54+00:00,http://arxiv.org/abs/2303.11812v1,"Tongquan Zhou, Siyi Cao, Siruo Zhou, Yao Zhang, Aijing He",cs.CL,story,"ChatGPT is a publicly available chatbot that can quickly generate texts on
given topics, but it is unknown whether the chatbot is really superior to human
writers in all aspects of writing and whether its writing quality can be
prominently improved on the basis of updating commands. Consequently, this
study compared the writing performance on a narrative topic by ChatGPT and
Chinese intermediate English (CIE) learners so as to reveal the chatbot's
advantage and disadvantage in writing. The data were analyzed in terms of five
discourse components using Coh-Metrix (a special instrument for analyzing
language discourses), and the results revealed that ChatGPT performed better
than human writers in narrativity, word concreteness, and referential cohesion,
but worse in syntactic simplicity and deep cohesion in its initial version.
After more revision commands were updated, while the resulting version was
facilitated in syntactic simplicity, yet it is still lagged far behind CIE
learners' writing in deep cohesion. In addition, the correlation analysis of
the discourse components suggests that narrativity was correlated with
referential cohesion in both ChatGPT and human writers, but the correlations
varied within each group.",2023-03-21
"DeltaScore: Evaluating Story Generation with Differentiating
  Perturbations",2023-03-15 23:45:54+00:00,http://arxiv.org/abs/2303.08991v1,"Zhuohan Xie, Miao Li, Trevor Cohn, Jey Han Lau",cs.CL,story,"Various evaluation metrics exist for natural language generation tasks, but
they have limited utility for story generation since they generally do not
correlate well with human judgments and do not measure fine-grained story
aspects, such as fluency versus relatedness, as they are intended to assess
overall generation quality. In this paper, we propose deltascore, an approach
that utilizes perturbation to evaluate fine-grained story aspects. Our core
idea is based on the hypothesis that the better the story performs in a
specific aspect (e.g., fluency), the more it will be affected by a particular
perturbation (e.g., introducing typos). To measure the impact, we calculate the
likelihood difference between the pre- and post-perturbation stories using a
language model. We evaluate deltascore against state-of-the-art model-based and
traditional similarity-based metrics across multiple story domains, and
investigate its correlation with human judgments on five fine-grained story
aspects: fluency, coherence, relatedness, logicality, and interestingness. Our
results demonstrate that deltascore performs impressively in evaluating
fine-grained story aspects, and we discovered a striking outcome where a
specific perturbation appears to be highly effective in measuring most aspects.",2023-03-15
Is ChatGPT a Good NLG Evaluator? A Preliminary Study,2023-03-07 16:57:20+00:00,http://arxiv.org/abs/2303.04048v1,"Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, Jie Zhou","cs.CL, cs.AI",story,"Recently, the emergence of ChatGPT has attracted wide attention from the
computational linguistics community. Many prior studies have shown that ChatGPT
achieves remarkable performance on various NLP tasks in terms of automatic
evaluation metrics. However, the ability of ChatGPT to serve as an evaluation
metric is still underexplored. Considering assessing the quality of NLG models
is an arduous task and previous statistical metrics notoriously show their poor
correlation with human judgments, we wonder whether ChatGPT is a good NLG
evaluation metric. In this report, we provide a preliminary meta-evaluation on
ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT
as a human evaluator and give task-specific (e.g., summarization) and
aspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the
generation of NLG models. We conduct experiments on three widely-used NLG
meta-evaluation datasets (including summarization, story generation and
data-to-text tasks). Experimental results show that compared with previous
automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation
with golden human judgments. We hope our preliminary study could prompt the
emergence of a general-purposed reliable NLG metric.",2023-03-07
"LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations
  and Infographics using Large Language Models",2023-03-06 06:47:22+00:00,http://arxiv.org/abs/2303.02927v1,Victor Dibia,"cs.AI, cs.HC, cs.PL",story,"Systems that support users in the automatic creation of visualizations must
address several subtasks - understand the semantics of data, enumerate relevant
visualization goals and generate visualization specifications. In this work, we
pose visualization generation as a multi-stage generation problem and argue
that well-orchestrated pipelines based on large language models (LLMs) and
image generation models (IGMs) are suitable to addressing these tasks. We
present LIDA, a novel tool for generating grammar-agnostic visualizations and
infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data
into a rich but compact natural language summary, a GOAL EXPLORER that
enumerates visualization goals given the data, a VISGENERATOR that generates,
refines, executes and filters visualization code and an INFOGRAPHER module that
yields data-faithful stylized graphics using IGMs. LIDA provides a python api,
and a hybrid user interface (direct manipulation and natural language) for
interactive chart, infographics and data story generation.",2023-03-06
"A Plot is Worth a Thousand Words: Model Information Stealing Attacks via
  Scientific Plots",2023-02-23 12:57:34+00:00,http://arxiv.org/abs/2302.11982v1,"Boyang Zhang, Xinlei He, Yun Shen, Tianhao Wang, Yang Zhang","cs.CR, cs.LG",story,"Building advanced machine learning (ML) models requires expert knowledge and
many trials to discover the best architecture and hyperparameter settings.
Previous work demonstrates that model information can be leveraged to assist
other attacks, such as membership inference, generating adversarial examples.
Therefore, such information, e.g., hyperparameters, should be kept
confidential. It is well known that an adversary can leverage a target ML
model's output to steal the model's information. In this paper, we discover a
new side channel for model information stealing attacks, i.e., models'
scientific plots which are extensively used to demonstrate model performance
and are easily accessible. Our attack is simple and straightforward. We
leverage the shadow model training techniques to generate training data for the
attack model which is essentially an image classifier. Extensive evaluation on
three benchmark datasets shows that our proposed attack can effectively infer
the architecture/hyperparameters of image classifiers based on convolutional
neural network (CNN) given the scientific plot generated from it. We also
reveal that the attack's success is mainly caused by the shape of the
scientific plots, and further demonstrate that the attacks are robust in
various scenarios. Given the simplicity and effectiveness of the attack method,
our study indicates scientific plots indeed constitute a valid side channel for
model information stealing attacks. To mitigate the attacks, we propose several
defense mechanisms that can reduce the original attacks' accuracy while
maintaining the plot utility. However, such defenses can still be bypassed by
adaptive attacks.",2023-02-23
"Conveying the Predicted Future to Users: A Case Study of Story Plot
  Prediction",2023-02-17 20:10:55+00:00,http://arxiv.org/abs/2302.09122v1,"Chieh-Yang Huang, Saniya Naphade, Kavya Laalasa Karanam, Ting-Hao 'Kenneth' Huang","cs.CL, cs.HC",story,"Creative writing is hard: Novelists struggle with writer's block daily. While
automatic story generation has advanced recently, it is treated as a ""toy task""
for advancing artificial intelligence rather than helping people. In this
paper, we create a system that produces a short description that narrates a
predicted plot using existing story generation approaches. Our goal is to
assist writers in crafting a consistent and compelling story arc. We conducted
experiments on Amazon Mechanical Turk (AMT) to examine the quality of the
generated story plots in terms of consistency and storiability. The results
show that short descriptions produced by our frame-enhanced GPT-2 (FGPT-2) were
rated as the most consistent and storiable among all models; FGPT-2's outputs
even beat some random story snippets written by humans. Next, we conducted a
preliminary user study using a story continuation task where AMT workers were
given access to machine-generated story plots and asked to write a follow-up
story. FGPT-2 could positively affect the writing process, though people favor
other baselines more. Our study shed some light on the possibilities of future
creative writing support systems beyond the scope of completing sentences. Our
code is available at: https://github.com/appleternity/Story-Plot-Generation.",2023-02-17
"Foundation Models for Natural Language Processing -- Pre-trained
  Language Models Integrating Media",2023-02-16 20:42:04+00:00,http://arxiv.org/abs/2302.08575v1,"Gerhard Paa√ü, Sven Giesselbach","cs.CL, cs.CV, cs.LG, cs.MM, 68W20, 68W25, I.2.6; I.2.7; I.2.8; I.2.10; I.4.8; I.4.10; I.5.2; I.5.4; I.7.0;
  J.1; J.3; K.4.1; K.4.2; K.5.0",story,"This open access book provides a comprehensive overview of the state of the
art in research and applications of Foundation Models and is intended for
readers familiar with basic Natural Language Processing (NLP) concepts. Over
the recent years, a revolutionary new paradigm has been developed for training
models for NLP. These models are first pre-trained on large collections of text
documents to acquire general syntactic knowledge and semantic information.
Then, they are fine-tuned for specific tasks, which they can often solve with
superhuman accuracy. When the models are large enough, they can be instructed
by prompts to solve new tasks without any fine-tuning. Moreover, they can be
applied to a wide range of different media and problem domains, ranging from
image and video processing to robot control learning. Because they provide a
blueprint for solving many tasks in artificial intelligence, they have been
called Foundation Models. After a brief introduction to basic NLP models the
main pre-trained language models BERT, GPT and sequence-to-sequence transformer
are described, as well as the concepts of self-attention and context-sensitive
embedding. Then, different approaches to improving these models are discussed,
such as expanding the pre-training criteria, increasing the length of input
texts, or including extra knowledge. An overview of the best-performing models
for about twenty application areas is then presented, e.g., question answering,
translation, story generation, dialog systems, generating images from text,
etc. For each application area, the strengths and weaknesses of current models
are discussed, and an outlook on further developments is given. In addition,
links are provided to freely available program code. A concluding chapter
summarizes the economic opportunities, mitigation of risks, and potential
developments of AI.",2023-02-16
"The Stable Entropy Hypothesis and Entropy-Aware Decoding: An Analysis
  and Algorithm for Robust Natural Language Generation",2023-02-14 02:02:33+00:00,http://arxiv.org/abs/2302.06784v1,"Kushal Arora, Timothy J. O'Donnell, Doina Precup, Jason Weston, Jackie C. K. Cheung",cs.CL,story,"State-of-the-art language generation models can degenerate when applied to
open-ended generation problems such as text completion, story generation, or
dialog modeling. This degeneration usually shows up in the form of incoherence,
lack of vocabulary diversity, and self-repetition or copying from the context.
In this paper, we postulate that ``human-like'' generations usually lie in a
narrow and nearly flat entropy band, and violation of these entropy bounds
correlates with degenerate behavior. Our experiments show that this stable
narrow entropy zone exists across models, tasks, and domains and confirm the
hypothesis that violations of this zone correlate with degeneration. We then
use this insight to propose an entropy-aware decoding algorithm that respects
these entropy bounds resulting in less degenerate, more contextual, and
""human-like"" language generation in open-ended text generation settings.",2023-02-14
"""Nice to meet you!"": Expressing Emotions with Movement Gestures and
  Textual Content in Automatic Handwriting Robots",2023-02-12 17:13:25+00:00,http://arxiv.org/abs/2302.05959v1,"Yanheng Li, Lin Luoying, Xinyan Li, Yaxuan Mao, Ray Lc","cs.HC, cs.RO",story,"Text-writing robots have been used in assistive writing and drawing
applications. However, robots do not convey emotional tones in the writing
process due to the lack of behaviors humans typically adopt. To examine how
people interpret designed robotic expressions of emotion through both movements
and textual output, we used a pen-plotting robot to generate texts by
performing human-like behaviors like stop-and-go, speed, and pressure
variation. We examined how people convey emotion in the writing process by
observing how they wrote in different emotional contexts. We then mapped these
human expressions during writing to the handwriting robot and measured how well
other participants understood the robot's affective expression. We found that
textual output was the strongest determinant of participants' ability to
perceive the robot's emotions, whereas parameters of gestural movements of the
robots like speed, fluency, pressure, size, and acceleration could be useful
for understanding the context of the writing expression.",2023-02-12
Level Generation Through Large Language Models,2023-02-11 23:34:42+00:00,http://arxiv.org/abs/2302.05817v1,"Graham Todd, Sam Earle, Muhammad Umair Nasir, Michael Cerny Green, Julian Togelius","cs.AI, cs.CL, cs.NE",story,"Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.",2023-02-11
Nationality Bias in Text Generation,2023-02-05 19:15:33+00:00,http://arxiv.org/abs/2302.02463v1,"Pranav Narayanan Venkit, Sanjana Gautam, Ruchi Panchanadikar, Ting-Hao, Huang, Shomir Wilson","cs.CL, cs.AI",story,"Little attention is placed on analyzing nationality bias in language models,
especially when nationality is highly used as a factor in increasing the
performance of social NLP models. This paper examines how a text generation
model, GPT-2, accentuates pre-existing societal biases about country-based
demonyms. We generate stories using GPT-2 for various nationalities and use
sensitivity analysis to explore how the number of internet users and the
country's economic status impacts the sentiment of the stories. To reduce the
propagation of biases through large language models (LLM), we explore the
debiasing method of adversarial triggering. Our results show that GPT-2
demonstrates significant bias against countries with lower internet users, and
adversarial triggering effectively reduces the same.",2023-02-05
"Can Very Large Pretrained Language Models Learn Storytelling With A Few
  Examples?",2023-01-24 02:44:02+00:00,http://arxiv.org/abs/2301.09790v1,"Zhuohan Xie, Trevor Cohn, Jey Han Lau",cs.CL,story,"While pre-trained language models can generate individually fluent sentences
for automatic story generation, they struggle to generate stories that are
coherent, sensible and interesting. Current state-of-the-art (SOTA) story
generation models explore using higher-level features such as plots or
commonsense knowledge to improve the quality of generated stories. Prompt-based
learning using very large pre-trained language models (VLPLMs) such as GPT3 has
demonstrated impressive performance even across various NLP tasks. In this
paper, we present an extensive study using automatic and human evaluation to
compare the story generation capability of VLPLMs to those SOTA models in three
different datasets where stories differ in style, register and length. Our
results show that VLPLMs generate much higher quality stories than other story
generation models, and to a certain extent rival human authors, although
preliminary investigation also reveals that they tend to ``plagiarise'' real
stories in scenarios that involve world knowledge.",2023-01-24
"Visual Writing Prompts: Character-Grounded Story Generation with Curated
  Image Sequences",2023-01-20 13:38:24+00:00,http://arxiv.org/abs/2301.08571v1,"Xudong Hong, Asad Sayeed, Khushboo Mehra, Vera Demberg, Bernt Schiele","cs.CL, cs.CV, cs.LG",story,"Current work on image-based story generation suffers from the fact that the
existing image sequence collections do not have coherent plots behind them. We
improve visual story generation by producing a new image-grounded dataset,
Visual Writing Prompts (VWP). VWP contains almost 2K selected sequences of
movie shots, each including 5-10 images. The image sequences are aligned with a
total of 12K stories which were collected via crowdsourcing given the image
sequences and a set of grounded characters from the corresponding image
sequence. Our new image sequence collection and filtering process has allowed
us to obtain stories that are more coherent and have more narrativity compared
to previous work. We also propose a character-based story generation model
driven by coherence as a strong baseline. Evaluations show that our generated
stories are more coherent, visually grounded, and have more narrativity than
stories generated with the current state-of-the-art model.",2023-01-20
Visual Story Generation Based on Emotion and Keywords,2023-01-07 03:56:49+00:00,http://arxiv.org/abs/2301.02777v1,"Yuetian Chen, Ruohua Li, Bowen Shi, Peiru Liu, Mei Si","cs.AI, cs.CL, cs.LG",story,"Automated visual story generation aims to produce stories with corresponding
illustrations that exhibit coherence, progression, and adherence to characters'
emotional development. This work proposes a story generation pipeline to
co-create visual stories with the users. The pipeline allows the user to
control events and emotions on the generated content. The pipeline includes two
parts: narrative and image generation. For narrative generation, the system
generates the next sentence using user-specified keywords and emotion labels.
For image generation, diffusion models are used to create a visually appealing
image corresponding to each generated sentence. Further, object recognition is
applied to the generated images to allow objects in these images to be
mentioned in future story development.",2023-01-07
"A Comprehensive Gold Standard and Benchmark for Comics Text Detection
  and Recognition",2022-12-27 12:05:23+00:00,http://arxiv.org/abs/2212.14674v1,"G√ºrkan Soykan, Deniz Yuret, Tevfik Metin Sezgin","cs.CL, cs.AI",story,"This study focuses on improving the optical character recognition (OCR) data
for panels in the COMICS dataset, the largest dataset containing text and
images from comic books. To do this, we developed a pipeline for OCR processing
and labeling of comic books and created the first text detection and
recognition datasets for western comics, called ""COMICS Text+: Detection"" and
""COMICS Text+: Recognition"". We evaluated the performance of state-of-the-art
text detection and recognition models on these datasets and found significant
improvement in word accuracy and normalized edit distance compared to the text
in COMICS. We also created a new dataset called ""COMICS Text+"", which contains
the extracted text from the textboxes in the COMICS dataset. Using the improved
text data of COMICS Text+ in the comics processing model from resulted in
state-of-the-art performance on cloze-style tasks without changing the model
architecture. The COMICS Text+ dataset can be a valuable resource for
researchers working on tasks including text detection, recognition, and
high-level processing of comics, such as narrative understanding, character
relations, and story generation. All the data and inference instructions can be
accessed in https://github.com/gsoykan/comics_text_plus.",2022-12-27
"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped
  Neurosymbolic Reasoning",2022-12-21 04:21:35+00:00,http://arxiv.org/abs/2212.10754v1,"Yijiang River Dong, Lara J. Martin, Chris Callison-Burch",cs.CL,story,"Story generation and understanding -- as with all NLG/NLU tasks -- has seen a
surge in neurosymbolic work. Researchers have recognized that, while large
language models (LLMs) have tremendous utility, they can be augmented with
symbolic means to be even better and to make up for any flaws that the neural
networks might have. However, symbolic methods are extremely costly in terms of
the amount of time and expertise needed to create them. In this work, we
capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use
of symbolic methods for tracking the state of stories and aiding in story
understanding. We show that our CoRRPUS system and abstracted prompting
procedures can beat current state-of-the-art structured LLM techniques on
pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand
engineering. We hope that this work can help highlight the importance of
symbolic representations and specialized prompting for LLMs as these models
require some guidance for performing reasoning tasks properly.",2022-12-21
"Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning
  and Generation with Large Language Models",2022-12-20 17:42:16+00:00,http://arxiv.org/abs/2212.10471v1,"Evgeniia Razumovskaia, Joshua Maynez, Annie Louis, Mirella Lapata, Shashi Narayan",cs.CL,story,"We consider the problem of automatically generating stories in multiple
languages. Compared to prior work in monolingual story generation, crosslingual
story generation allows for more universal research on story planning. We
propose to use Prompting Large Language Models with Plans to study which plan
is optimal for story generation. We consider 4 types of plans and
systematically analyse how the outputs differ for different planning
strategies. The study demonstrates that formulating the plans as
question-answer pairs leads to more coherent generated stories while the plan
gives more control to the story creators.",2022-12-20
DOC: Improving Long Story Coherence With Detailed Outline Control,2022-12-20 08:30:58+00:00,http://arxiv.org/abs/2212.10077v1,"Kevin Yang, Dan Klein, Nanyun Peng, Yuandong Tian","cs.CL, cs.AI",story,"We propose the Detailed Outline Control (DOC) framework for improving
long-range plot coherence when automatically generating
several-thousand-word-long stories. DOC consists of two complementary
components: a detailed outliner and a detailed controller. The detailed
outliner creates a more detailed, hierarchically structured outline, shifting
creative burden from the main drafting procedure to the planning stage. The
detailed controller ensures the more detailed outline is still respected during
generation by controlling story passages to align with outline details. In
human evaluations of automatically generated stories, DOC substantially
outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%
absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans
also judged DOC to be much more controllable in an interactive generation
setting.",2022-12-20
"Future Sight: Dynamic Story Generation with Large Pretrained Language
  Models",2022-12-20 01:53:26+00:00,http://arxiv.org/abs/2212.09947v1,"Brian D. Zimmerman, Gaurav Sahu, Olga Vechtomova","cs.CL, cs.AI, cs.LG",story,"Recent advances in deep learning research, such as transformers, have
bolstered the ability for automated agents to generate creative texts similar
to those that a human would write. By default, transformer decoders can only
generate new text with respect to previously generated text. The output
distribution of candidate tokens at any position is conditioned on previously
selected tokens using a self-attention mechanism to emulate the property of
autoregression. This is inherently limiting for tasks such as controllable
story generation where it may be necessary to condition on future plot events
when writing a story. In this work, we propose Future Sight, a method for
finetuning a pretrained generative transformer on the task of future
conditioning. Transformer decoders are typically pretrained on the task of
completing a context, one token at a time, by means of self-attention. Future
Sight additionally enables a decoder to attend to an encoded future plot event.
This motivates the decoder to expand on the context in a way that logically
concludes with the provided future. During inference, the future plot event can
be written by a human author to steer the narrative being generated in a
certain direction. We evaluate the efficacy of our approach on a story
generation task with human evaluators.",2022-12-20
Neural Story Planning,2022-12-16 21:29:41+00:00,http://arxiv.org/abs/2212.08718v1,"Anbang Ye, Christopher Cui, Taiwei Shi, Mark O. Riedl","cs.CL, cs.AI",story,"Automated plot generation is the challenge of generating a sequence of events
that will be perceived by readers as the plot of a coherent story. Traditional
symbolic planners plan a story from a goal state and guarantee logical causal
plot coherence but rely on a library of hand-crafted actions with their
preconditions and effects. This closed world setting limits the length and
diversity of what symbolic planners can generate. On the other hand,
pre-trained neural language models can generate stories with great diversity,
while being generally incapable of ending a story in a specified manner and can
have trouble maintaining coherence. In this paper, we present an approach to
story plot generation that unifies causal planning with neural language models.
We propose to use commonsense knowledge extracted from large language models to
recursively expand a story plot in a backward chaining fashion. Specifically,
our system infers the preconditions for events in the story and then events
that will cause those conditions to become true. We performed automatic
evaluation to measure narrative coherence as indicated by the ability to answer
questions about whether different events in the story are causally related to
other events. Results indicate that our proposed method produces more coherent
plotlines than several strong baselines.",2022-12-16
"Open-world Story Generation with Structured Knowledge Enhancement: A
  Comprehensive Survey",2022-12-09 02:19:07+00:00,http://arxiv.org/abs/2212.04634v1,"Yuxin Wang, Jieru Lin, Zhiwei Yu, Wei Hu, B√∂rje F. Karlsson","cs.CL, cs.AI",story,"Storytelling and narrative are fundamental to human experience, intertwined
with our social and cultural engagement. As such, researchers have long
attempted to create systems that can generate stories automatically. In recent
years, powered by deep learning and massive data resources, automatic story
generation has shown significant advances. However, considerable challenges,
like the need for global coherence in generated stories, still hamper
generative models from reaching the same storytelling ability as human
narrators. To tackle these challenges, many studies seek to inject structured
knowledge into the generation process, which is referred to as structure
knowledge-enhanced story generation. Incorporating external knowledge can
enhance the logical coherence among story events, achieve better knowledge
grounding, and alleviate over-generalization and repetition problems in
stories. This survey provides the latest and comprehensive review of this
research field: (i) we present a systematical taxonomy regarding how existing
methods integrate structured knowledge into story generation; (ii) we summarize
involved story corpora, structured knowledge datasets, and evaluation metrics;
(iii) we give multidimensional insights into the challenges of
knowledge-enhanced story generation and cast light on promising directions for
future study.",2022-12-09
An FNet based Auto Encoder for Long Sequence News Story Generation,2022-11-15 16:48:09+00:00,http://arxiv.org/abs/2211.08295v2,"Paul K. Mandal, Rakeshkumar Mahto","cs.CL, cs.AI, cs.LG, 68T07, 68T50, I.2.6; I.2.7",story,"In this paper, we design an auto encoder based off of Google's FNet
Architecture in order to generate text from a subset of news stories contained
in Google's C4 dataset. We discuss previous attempts and methods to generate
text from autoencoders and non LLM Models. FNET poses multiple advantages to
BERT based encoders in the realm of efficiency which train 80% faster on GPUs
and 70% faster on TPUs. We then compare outputs of how this autencoder perfroms
on different epochs. Finally, we analyze what outputs the encoder produces with
different seed text.",2022-11-15
"Creative Writing with an AI-Powered Writing Assistant: Perspectives from
  Professional Writers",2022-11-09 17:00:56+00:00,http://arxiv.org/abs/2211.05030v1,"Daphne Ippolito, Ann Yuan, Andy Coenen, Sehmon Burnam","cs.HC, cs.CL",story,"Recent developments in natural language generation (NLG) using neural
language models have brought us closer than ever to the goal of building
AI-powered creative writing tools. However, most prior work on human-AI
collaboration in the creative writing domain has evaluated new systems with
amateur writers, typically in contrived user studies of limited scope. In this
work, we commissioned 13 professional, published writers from a diverse set of
creative writing backgrounds to craft stories using Wordcraft, a text editor
with built-in AI-powered writing assistance tools. Using interviews and
participant journals, we discuss the potential of NLG to have significant
impact in the creative writing domain--especially with respect to
brainstorming, generation of story details, world-building, and research
assistance. Experienced writers, more so than amateurs, typically have
well-developed systems and methodologies for writing, as well as distinctive
voices and target audiences. Our work highlights the challenges in building for
these writers; NLG technologies struggle to preserve style and authorial voice,
and they lack deep understanding of story contents. In order for AI-powered
writing assistants to realize their full potential, it is essential that they
take into account the diverse goals and expertise of human writers.",2022-11-09
"Human-Machine Collaboration Approaches to Build a Dialogue Dataset for
  Hate Speech Countering",2022-11-07 10:37:13+00:00,http://arxiv.org/abs/2211.03433v1,"Helena Bonaldi, Sara Dellantonio, Serra Sinem Tekiroglu, Marco Guerini","cs.CL, cs.CY",story,"Fighting online hate speech is a challenge that is usually addressed using
Natural Language Processing via automatic detection and removal of hate
content. Besides this approach, counter narratives have emerged as an effective
tool employed by NGOs to respond to online hate on social media platforms. For
this reason, Natural Language Generation is currently being studied as a way to
automatize counter narrative writing. However, the existing resources necessary
to train NLG models are limited to 2-turn interactions (a hate speech and a
counter narrative as response), while in real life, interactions can consist of
multiple turns. In this paper, we present a hybrid approach for dialogical data
collection, which combines the intervention of human expert annotators over
machine generated dialogues obtained using 19 different configurations. The
result of this work is DIALOCONAN, the first dataset comprising over 3000
fictitious multi-turn dialogues between a hater and an NGO operator, covering 6
targets of hate.",2022-11-07
Towards Inter-character Relationship-driven Story Generation,2022-11-01 18:04:29+00:00,http://arxiv.org/abs/2211.00676v1,"Anvesh Rao Vijjini, Faeze Brahman, Snigdha Chaturvedi",cs.CL,story,"In this paper, we introduce the task of modeling interpersonal relationships
for story generation. For addressing this task, we propose Relationships as
Latent Variables for Story Generation, (ReLiSt). ReLiSt generates stories
sentence by sentence and has two major components - a relationship selector and
a story continuer. The relationship selector specifies a latent variable to
pick the relationship to exhibit in the next sentence and the story continuer
generates the next sentence while expressing the selected relationship in a
coherent way. Our automatic and human evaluations demonstrate that ReLiSt is
able to generate stories with relationships that are more faithful to desired
relationships while maintaining the content quality. The relationship
assignments to sentences during inference bring interpretability to ReLiSt.",2022-11-01
"MOCHA: A Multi-Task Training Approach for Coherent Text Generation from
  Cognitive Perspective",2022-10-26 11:55:41+00:00,http://arxiv.org/abs/2210.14650v1,"Zhe Hu, Hou Pong Chan, Lifu Huang",cs.CL,story,"Teaching neural models to generate narrative coherent texts is a critical
problem. Recent pre-trained language models have achieved promising results,
but there is still a gap between human written texts and machine-generated
outputs. In this work, we propose a novel multi-task training strategy for
coherent text generation grounded on the cognitive theory of writing, which
empowers the model to learn essential subskills needed for writing including
planning and reviewing besides end-to-end generation. We extensively evaluate
our model on three open-ended generation tasks including story generation, news
article writing and argument generation. Experiments show that our model
achieves better results on both few-shot and fully-supervised settings than
strong baselines, and human evaluations confirm that our model can generate
more coherent outputs.",2022-10-26
"EtriCA: Event-Triggered Context-Aware Story Generation Augmented by
  Cross Attention",2022-10-22 14:51:12+00:00,http://arxiv.org/abs/2210.12463v1,"Chen Tang, Chenghua Lin, Henglin Huang, Frank Guerin, Zhihao Zhang","cs.CL, cs.AI",story,"One of the key challenges of automatic story generation is how to generate a
long narrative that can maintain fluency, relevance, and coherence. Despite
recent progress, current story generation systems still face the challenge of
how to effectively capture contextual and event features, which has a profound
impact on a model's generation performance. To address these challenges, we
present EtriCA, a novel neural generation model, which improves the relevance
and coherence of the generated stories through residually mapping context
features to event sequences with a cross-attention mechanism. Such a feature
capturing mechanism allows our model to better exploit the logical relatedness
between events when generating stories. Extensive experiments based on both
automatic and human evaluations show that our model significantly outperforms
state-of-the-art baselines, demonstrating the effectiveness of our model in
leveraging context and event features.",2022-10-22
"A Continuum of Generation Tasks for Investigating Length Bias and
  Degenerate Repetition",2022-10-19 18:09:51+00:00,http://arxiv.org/abs/2210.10817v1,"Darcey Riley, David Chiang","cs.CL, cs.AI",story,"Language models suffer from various degenerate behaviors. These differ
between tasks: machine translation (MT) exhibits length bias, while tasks like
story generation exhibit excessive repetition. Recent work has attributed the
difference to task constrainedness, but evidence for this claim has always
involved many confounding variables. To study this question directly, we
introduce a new experimental framework that allows us to smoothly vary task
constrainedness, from MT at one end to fully open-ended generation at the
other, while keeping all other aspects fixed. We find that: (1) repetition
decreases smoothly with constrainedness, explaining the difference in
repetition across tasks; (2) length bias surprisingly also decreases with
constrainedness, suggesting some other cause for the difference in length bias;
(3) across the board, these problems affect the mode, not the whole
distribution; (4) the differences cannot be attributed to a change in the
entropy of the distribution, since another method of changing the entropy,
label smoothing, does not produce the same effect.",2022-10-19
"Improving Chinese Story Generation via Awareness of Syntactic
  Dependencies and Semantics",2022-10-19 15:01:52+00:00,http://arxiv.org/abs/2210.10618v1,"Henglin Huang, Chen Tang, Tyler Loakman, Frank Guerin, Chenghua Lin","cs.CL, cs.AI",story,"Story generation aims to generate a long narrative conditioned on a given
input. In spite of the success of prior works with the application of
pre-trained models, current neural models for Chinese stories still struggle to
generate high-quality long text narratives. We hypothesise that this stems from
ambiguity in syntactically parsing the Chinese language, which does not have
explicit delimiters for word segmentation. Consequently, neural models suffer
from the inefficient capturing of features in Chinese narratives. In this
paper, we present a new generation framework that enhances the feature
capturing mechanism by informing the generation model of dependencies between
words and additionally augmenting the semantic representation learning through
synonym denoising training. We conduct a range of experiments, and the results
demonstrate that our framework outperforms the state-of-the-art Chinese
generation models on all evaluation metrics, demonstrating the benefits of
enhanced dependency and semantic representation learning.",2022-10-19
NGEP: A Graph-based Event Planning Framework for Story Generation,2022-10-19 14:49:27+00:00,http://arxiv.org/abs/2210.10602v1,"Chen Tang, Zhihao Zhang, Tyler Loakman, Chenghua Lin, Frank Guerin","cs.CL, cs.AI",story,"To improve the performance of long text generation, recent studies have
leveraged automatically planned event structures (i.e. storylines) to guide
story generation. Such prior works mostly employ end-to-end neural generation
models to predict event sequences for a story. However, such generation models
struggle to guarantee the narrative coherence of separate events due to the
hallucination problem, and additionally the generated event sequences are often
hard to control due to the end-to-end nature of the models. To address these
challenges, we propose NGEP, an novel event planning framework which generates
an event sequence by performing inference on an automatically constructed event
graph and enhances generalisation ability through a neural event advisor. We
conduct a range of experiments on multiple criteria, and the results
demonstrate that our graph-based neural framework outperforms the
state-of-the-art (SOTA) event planning approaches, considering both the
performance of event sequence generation and the effectiveness on the
downstream task of story generation.",2022-10-19
Model Criticism for Long-Form Text Generation,2022-10-16 04:35:58+00:00,http://arxiv.org/abs/2210.08444v1,"Yuntian Deng, Volodymyr Kuleshov, Alexander M. Rush","cs.CL, cs.LG, stat.ML",story,"Language models have demonstrated the ability to generate highly fluent text;
however, it remains unclear whether their output retains coherent high-level
structure (e.g., story progression). Here, we propose to apply a statistical
tool, model criticism in latent space, to evaluate the high-level structure of
the generated text. Model criticism compares the distributions between real and
generated data in a latent space obtained according to an assumptive generative
process. Different generative processes identify specific failure modes of the
underlying model. We perform experiments on three representative aspects of
high-level discourse -- coherence, coreference, and topicality -- and find that
transformer-based language models are able to capture topical structures but
have a harder time maintaining structural coherence or modeling coreference.",2022-10-16
"Robust Preference Learning for Storytelling via Contrastive
  Reinforcement Learning",2022-10-14 13:21:33+00:00,http://arxiv.org/abs/2210.07792v1,"Louis Castricato, Alexander Havrilla, Shahbuland Matiana, Michael Pieler, Anbang Ye, Ian Yang, Spencer Frazier, Mark Riedl",cs.CL,story,"Controlled automated story generation seeks to generate natural language
stories satisfying constraints from natural language critiques or preferences.
Existing methods to control for story preference utilize prompt engineering
which is labor intensive and often inconsistent. They may also use
logit-manipulation methods which require annotated datasets to exist for the
desired attributes. To address these issues, we first train a contrastive
bi-encoder model to align stories with corresponding human critiques, named
CARP, building a general purpose preference model. This is subsequently used as
a reward function to fine-tune a generative language model via reinforcement
learning. However, simply fine-tuning a generative language model with a
contrastive reward model does not always reliably result in a story generation
system capable of generating stories that meet user preferences. To increase
story generation robustness we further fine-tune the contrastive reward model
using a prompt-learning technique. A human participant study is then conducted
comparing generations from our full system, ablations, and two baselines. We
show that the full fine-tuning pipeline results in a story generator preferred
over a LLM 20x as large as well as logit-based methods. This motivates the use
of contrastive learning for general purpose human preference modeling.",2022-10-14
Psychology-guided Controllable Story Generation,2022-10-14 03:40:53+00:00,http://arxiv.org/abs/2210.07493v1,"Yuqiang Xie, Yue Hu, Yunpeng Li, Guanqun Bi, Luxi Xing, Wei Peng","cs.CL, cs.AI",story,"Controllable story generation is a challenging task in the field of NLP,
which has attracted increasing research interest in recent years. However, most
existing works generate a whole story conditioned on the appointed keywords or
emotions, ignoring the psychological changes of the protagonist. Inspired by
psychology theories, we introduce global psychological state chains, which
include the needs and emotions of the protagonists, to help a story generation
system create more controllable and well-planned stories. In this paper, we
propose a Psychology-guIded Controllable Story Generation System (PICS) to
generate stories that adhere to the given leading context and desired
psychological state chains for the protagonist. Specifically, psychological
state trackers are employed to memorize the protagonist's local psychological
states to capture their inner temporal relationships. In addition,
psychological state planners are adopted to gain the protagonist's global
psychological states for story planning. Eventually, a psychology controller is
designed to integrate the local and global psychological states into the story
context representation for composing psychology-guided stories. Automatic and
manual evaluations demonstrate that PICS outperforms baselines, and each part
of PICS shows effectiveness for writing stories with more consistent
psychological changes.",2022-10-14
Re3: Generating Longer Stories With Recursive Reprompting and Revision,2022-10-13 06:29:57+00:00,http://arxiv.org/abs/2210.06774v2,"Kevin Yang, Yuandong Tian, Nanyun Peng, Dan Klein","cs.CL, cs.AI",story,"We consider the problem of automatically generating longer stories of over
two thousand words. Compared to prior work on shorter stories, long-range plot
coherence and relevance are more central challenges here. We propose the
Recursive Reprompting and Revision framework (Re3) to address these challenges
by (a) prompting a general-purpose language model to construct a structured
overarching plan, and (b) generating story passages by repeatedly injecting
contextual information from both the plan and current story state into a
language model prompt. We then revise by (c) reranking different continuations
for plot coherence and premise relevance, and finally (d) editing the best
continuation for factual consistency. Compared to similar-length stories
generated directly from the same base model, human evaluators judged
substantially more of Re3's stories as having a coherent overarching plot (by
14% absolute increase), and relevant to the given initial premise (by 20%).",2022-10-13
"CHAE: Fine-Grained Controllable Story Generation with Characters,
  Actions and Emotions",2022-10-11 07:37:50+00:00,http://arxiv.org/abs/2210.05221v1,"Xinpeng Wang, Han Jiang, Zhihua Wei, Shanlin Zhou","cs.CL, cs.AI",story,"Story generation has emerged as an interesting yet challenging NLP task in
recent years. Some existing studies aim at generating fluent and coherent
stories from keywords and outlines; while others attempt to control the global
features of the story, such as emotion, style and topic. However, these works
focus on coarse-grained control on the story, neglecting control on the details
of the story, which is also crucial for the task. To fill the gap, this paper
proposes a model for fine-grained control on the story, which allows the
generation of customized stories with characters, corresponding actions and
emotions arbitrarily assigned. Extensive experimental results on both automatic
and human manual evaluations show the superiority of our method. It has strong
controllability to generate stories according to the fine-grained personalized
guidance, unveiling the effectiveness of our methodology. Our code is available
at https://github.com/victorup/CHAE.",2022-10-11
"Visualize Before You Write: Imagination-Guided Open-Ended Text
  Generation",2022-10-07 18:01:09+00:00,http://arxiv.org/abs/2210.03765v1,"Wanrong Zhu, An Yan, Yujie Lu, Wenda Xu, Xin Eric Wang, Miguel Eckstein, William Yang Wang","cs.CL, cs.AI",story,"Recent advances in text-to-image synthesis make it possible to visualize
machine imaginations for a given context. On the other hand, when generating
text, human writers are gifted at creative visualization, which enhances their
writings by forming imaginations as blueprints before putting down the stories
in words. Inspired by such a cognitive process, we ask the natural question of
whether we can endow machines with the same ability to utilize visual
information and construct a general picture of the context to guide text
generation. In this work, we propose iNLG that uses machine-generated images to
guide language models (LM) in open-ended text generation. The experiments and
analyses demonstrate the effectiveness of iNLG on open-ended text generation
tasks, including text completion, story generation, and concept-to-text
generation in few-shot scenarios. Both automatic metrics and human evaluations
verify that the text snippets generated by our iNLG are coherent and
informative while displaying minor degeneration.",2022-10-07
"Unsupervised Neural Stylistic Text Generation using Transfer learning
  and Adapters",2022-10-07 00:09:22+00:00,http://arxiv.org/abs/2210.03264v1,"Vinayshekhar Bannihatti Kumar, Rashmi Gangadharaiah, Dan Roth",cs.CL,story,"Research has shown that personality is a key driver to improve engagement and
user experience in conversational systems. Conversational agents should also
maintain a consistent persona to have an engaging conversation with a user.
However, text generation datasets are often crowd sourced and thereby have an
averaging effect where the style of the generation model is an average style of
all the crowd workers that have contributed to the dataset. While one can
collect persona-specific datasets for each task, it would be an expensive and
time consuming annotation effort. In this work, we propose a novel transfer
learning framework which updates only $0.3\%$ of model parameters to learn
style specific attributes for response generation. For the purpose of this
study, we tackle the problem of stylistic story ending generation using the ROC
stories Corpus. We learn style specific attributes from the
PERSONALITY-CAPTIONS dataset. Through extensive experiments and evaluation
metrics we show that our novel training procedure can improve the style
generation by 200 over Encoder-Decoder baselines while maintaining on-par
content relevance metrics with",2022-10-07
"Dancing with the Unexpected and Beyond: The Use of AI Assistance in
  Design Fiction Creation",2022-10-03 11:26:39+00:00,http://arxiv.org/abs/2210.00829v1,"Yiying Wu, Yunye Yu, Pengcheng An",cs.HC,story,"The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology.",2022-10-03
"Co-Writing Screenplays and Theatre Scripts with Language Models: An
  Evaluation by Industry Professionals",2022-09-29 17:26:22+00:00,http://arxiv.org/abs/2209.14958v1,"Piotr Mirowski, Kory W. Mathewson, Jaylen Pittman, Richard Evans","cs.HC, cs.CL",story,"Language models are increasingly attracting interest from writers. However,
such models lack long-range semantic coherence, limiting their usefulness for
longform creative writing. We address this limitation by applying language
models hierarchically, in a system we call Dramatron. By building structural
context via prompt chaining, Dramatron can generate coherent scripts and
screenplays complete with title, characters, story beats, location
descriptions, and dialogue. We illustrate Dramatron's usefulness as an
interactive co-creative system with a user study of 15 theatre and film
industry professionals. Participants co-wrote theatre scripts and screenplays
with Dramatron and engaged in open-ended interviews. We report critical
reflections both from our interviewees and from independent reviewers who
watched stagings of the works to illustrate how both Dramatron and hierarchical
text generation could be useful for human-machine co-creativity. Finally, we
discuss the suitability of Dramatron for co-creativity, ethical considerations
-- including plagiarism and bias -- and participatory models for the design and
deployment of such tools.",2022-09-29
Controllable Text Generation for Open-Domain Creativity and Fairness,2022-09-24 22:40:01+00:00,http://arxiv.org/abs/2209.12099v1,Nanyun Peng,"cs.CL, cs.AI",story,"Recent advances in large pre-trained language models have demonstrated strong
results in generating natural languages and significantly improved performances
for many natural language generation (NLG) applications such as machine
translation and text summarization. However, when the generation tasks are more
open-ended and the content is under-specified, existing techniques struggle to
generate long-term coherent and creative content. Moreover, the models exhibit
and even amplify social biases that are learned from the training corpora. This
happens because the generation models are trained to capture the surface
patterns (i.e. sequences of words), instead of capturing underlying semantics
and discourse structures, as well as background knowledge including social
norms. In this paper, I introduce our recent works on controllable text
generation to enhance the creativity and fairness of language generation
models. We explore hierarchical generation and constrained decoding, with
applications to creative language generation including story, poetry, and
figurative languages, and bias mitigation for generation models.",2022-09-24
LibertyMFD: A Lexicon to Assess the Moral Foundation of Liberty,2022-09-14 16:14:54+00:00,http://arxiv.org/abs/2209.06750v1,"Oscar Araque, Lorenzo Gatti, Kyriaki Kalimeri",cs.CL,story,"Quantifying the moral narratives expressed in the user-generated text, news,
or public discourses is fundamental for understanding individuals' concerns and
viewpoints and preventing violent protests and social polarisation. The Moral
Foundation Theory (MFT) was developed to operationalise morality in a
five-dimensional scale system. Recent developments of the theory urged for the
introduction of a new foundation, the Liberty Foundation. Being only recently
added to the theory, there are no available linguistic resources to assess
whether liberty is present in text corpora. Given its importance to current
social issues such as the vaccination debate, we propose two data-driven
approaches, deriving two candidate lexicons generated based on aligned
documents from online news sources with different worldviews. After extensive
experimentation, we contribute to the research community a novel lexicon that
assesses the liberty moral foundation in the way individuals with contrasting
viewpoints express themselves through written text. The LibertyMFD dictionary
can be a valuable tool for policymakers to understand diverse viewpoints on
controversial social issues such as vaccination, abortion, or even uprisings,
as they happen and on a large scale.",2022-09-14
"Every picture tells a story: Image-grounded controllable stylistic story
  generation",2022-09-04 15:07:53+00:00,http://arxiv.org/abs/2209.01638v1,"Holy Lovenia, Bryan Wilie, Romain Barraud, Samuel Cahyawijaya, Willy Chung, Pascale Fung",cs.CL,story,"Generating a short story out of an image is arduous. Unlike image captioning,
story generation from an image poses multiple challenges: preserving the story
coherence, appropriately assessing the quality of the story, steering the
generated story into a certain style, and addressing the scarcity of
image-story pair reference datasets limiting supervision during training. In
this work, we introduce Plug-and-Play Story Teller (PPST) and improve
image-to-story generation by: 1) alleviating the data scarcity problem by
incorporating large pre-trained models, namely CLIP and GPT-2, to facilitate a
fluent image-to-text generation with minimal supervision, and 2) enabling a
more style-relevant generation by incorporating stylistic adapters to control
the story generation. We conduct image-to-story generation experiments with
non-styled, romance-styled, and action-styled PPST approaches and compare our
generated stories with those of previous work over three aspects, i.e., story
coherence, image-story relevance, and style fitness, using both automatic and
human evaluation. The results show that PPST improves story coherence and has
better image-story relevance, but has yet to be adequately stylistic.",2022-09-04
"StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse
  Representations and Content Enhancing",2022-08-29 08:47:49+00:00,http://arxiv.org/abs/2208.13423v1,"Xuekai Zhu, Jian Guan, Minlie Huang, Juan Liu",cs.CL,story,"Non-parallel text style transfer is an important task in natural language
generation. However, previous studies concentrate on the token or sentence
level, such as sentence sentiment and formality transfer, but neglect long
style transfer at the discourse level. Long texts usually involve more
complicated author linguistic preferences such as discourse structures than
sentences. In this paper, we formulate the task of non-parallel story
author-style transfer, which requires transferring an input story into a
specified author style while maintaining source semantics. To tackle this
problem, we propose a generation model, named StoryTrans, which leverages
discourse representations to capture source content information and transfer
them to target styles with learnable style embeddings. We use an additional
training objective to disentangle stylistic features from the learned discourse
representation to prevent the model from degenerating to an auto-encoder.
Moreover, to enhance content preservation, we design a mask-and-fill framework
to explicitly fuse style-specific keywords of source texts into generation.
Furthermore, we constructed new datasets for this task in Chinese and English,
respectively. Extensive experiments show that our model outperforms strong
baselines in overall performance of style transfer and content preservation.",2022-08-29
"Of Human Criteria and Automatic Metrics: A Benchmark of the Evaluation
  of Story Generation",2022-08-24 16:35:32+00:00,http://arxiv.org/abs/2208.11646v1,"Cyril Chhun, Pierre Colombo, Chlo√© Clavel, Fabian M. Suchanek",cs.CL,story,"Research on Automatic Story Generation (ASG) relies heavily on human and
automatic evaluation. However, there is no consensus on which human evaluation
criteria to use, and no analysis of how well automatic criteria correlate with
them. In this paper, we propose to re-evaluate ASG evaluation. We introduce a
set of 6 orthogonal and comprehensive human criteria, carefully motivated by
the social sciences literature. We also present HANNA, an annotated dataset of
1,056 stories produced by 10 different ASG systems. HANNA allows us to
quantitatively evaluate the correlations of 72 automatic metrics with human
criteria. Our analysis highlights the weaknesses of current metrics for ASG and
allows us to formulate practical recommendations for ASG evaluation.",2022-08-24
"Leveraging Natural Supervision for Language Representation Learning and
  Generation",2022-07-21 17:26:03+00:00,http://arxiv.org/abs/2207.10617v1,Mingda Chen,cs.CL,story,"Recent breakthroughs in Natural Language Processing (NLP) have been driven by
language models trained on a massive amount of plain text. While powerful,
deriving supervision from textual resources is still an open question. For
example, language model pretraining often neglects the rich, freely-available
structures in textual data. In this thesis, we describe three lines of work
that seek to improve the training and evaluation of neural models using
naturally-occurring supervision.
  We first investigate self-supervised training losses to help enhance the
performance of pretrained language models for various NLP tasks. Specifically,
we alter the sentence prediction loss to make it better suited to other
pretraining losses and more challenging to solve. We design an intermediate
finetuning step that uses self-supervised training to promote models' ability
in cross-task generalization.
  Then we describe methods to leverage the structures in Wikipedia and
paraphrases. In particular, we propose training losses to exploit hyperlinks,
article structures, and article category graphs for entity-, discourse-,
entailment-related knowledge. We propose a framework that uses paraphrase pairs
to disentangle semantics and syntax in sentence representations. We extend the
framework for a novel generation task that controls the syntax of output text
with a sentential exemplar.
  Lastly, we discuss our work on tailoring textual resources for establishing
challenging evaluation tasks. We introduce three datasets by defining novel
tasks using various fan-contributed websites, including a long-form
data-to-text generation dataset, a screenplay summarization dataset, and a
long-form story generation dataset. These datasets have unique characteristics
offering challenges to future work in their respective task settings.",2022-07-21
"Collocation2Text: Controllable Text Generation from Guide Phrases in
  Russian",2022-06-18 17:10:08+00:00,http://arxiv.org/abs/2206.09248v1,"Sergey Vychegzhanin, Evgeny Kotelnikov",cs.CL,story,"Large pre-trained language models are capable of generating varied and fluent
texts. Starting from the prompt, these models generate a narrative that can
develop unpredictably. The existing methods of controllable text generation,
which guide the narrative in the text in the user-specified direction, require
creating a training corpus and an additional time-consuming training procedure.
The paper proposes and investigates Collocation2Text, a plug-and-play method
for automatic controllable text generation in Russian, which does not require
fine-tuning. The method is based on two interacting models: the autoregressive
language ruGPT-3 model and the autoencoding language ruRoBERTa model. The idea
of the method is to shift the output distribution of the autoregressive model
according to the output distribution of the autoencoding model in order to
ensure a coherent transition of the narrative in the text towards the guide
phrase, which can contain single words or collocations. The autoencoding model,
which is able to take into account the left and right contexts of the token,
""tells"" the autoregressive model which tokens are the most and least logical at
the current generation step, increasing or decreasing the probabilities of the
corresponding tokens. The experiments on generating news articles using the
proposed method showed its effectiveness for automatically generated fluent
texts which contain coherent transitions between user-specified phrases.",2022-06-18
Plot Writing From Pre-Trained Language Models,2022-06-07 05:30:46+00:00,http://arxiv.org/abs/2206.03021v1,"Yiping Jin, Vishakha Kadam, Dittaya Wanvarie",cs.CL,story,"Pre-trained language models (PLMs) fail to generate long-form narrative text
because they do not consider global structure. As a result, the generated texts
are often incohesive, repetitive, or lack content. Recent work in story
generation reintroduced explicit content planning in the form of prompts,
keywords, or semantic frames. Trained on large parallel corpora, these models
can generate more logical event sequences and thus more contentful stories.
However, these intermediate representations are often not in natural language
and cannot be utilized by PLMs without fine-tuning. We propose generating story
plots using off-the-shelf PLMs while maintaining the benefit of content
planning to generate cohesive and contentful stories. Our proposed method,
ScratchPlot, first prompts a PLM to compose a content plan. Then, we generate
the story's body and ending conditioned on the content plan. Furthermore, we
take a generate-and-rank approach by using additional PLMs to rank the
generated (story, ending) pairs. We benchmark our method with various baselines
and achieved superior results in both human and automatic evaluation.",2022-06-07
"RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText
  Generators",2022-05-25 09:06:04+00:00,http://arxiv.org/abs/2205.12590v1,"Rilwan A. Adewoyin, Ritabrata Dutta, Yulan He",cs.CL,story,"In this paper, we study the task of improving the cohesion and coherence of
long-form text generated by language models. To this end, we propose RSTGen, a
framework that utilises Rhetorical Structure Theory (RST), a classical language
theory, to control the discourse structure, semantics and topics of generated
text. Firstly, we demonstrate our model's ability to control structural
discourse and semantic features of generated text in open generation
evaluation. Then we experiment on the two challenging long-form text tasks of
argument generation and story generation. Evaluation using automated metrics
and a metric with high correlation to human evaluation, shows that our model
performs competitively against existing models, while offering significantly
more controls over generated text than alternative methods.",2022-05-25
"How Human is Human Evaluation? Improving the Gold Standard for NLG with
  Utility Theory",2022-05-24 09:51:27+00:00,http://arxiv.org/abs/2205.11930v1,"Kawin Ethayarajh, Dan Jurafsky","cs.CL, cs.AI, cs.LG",story,"Human ratings are treated as the gold standard in NLG evaluation. The
standard protocol is to collect ratings of generated text, average across
annotators, and then rank NLG systems by their average scores. However, little
consideration has been given as to whether this approach faithfully captures
human preferences. In this work, we analyze this standard protocol through the
lens of utility theory in economics. We first identify the implicit assumptions
it makes about annotators and find that these assumptions are often violated in
practice, in which case annotator ratings become an unfaithful reflection of
their preferences. The most egregious violations come from using Likert scales,
which provably reverse the direction of the true preference in certain cases.
We suggest improvements to the standard protocol to make it more theoretically
sound, but even in its improved form, it cannot be used to evaluate open-ended
tasks like story generation. For the latter, we propose a new evaluation
protocol called $\textit{system-level probabilistic assessment}$ (SPA). In our
experiments, we find that according to SPA, annotators prefer larger GPT-3
variants to smaller ones -- as expected -- with all comparisons being
statistically significant. In contrast, the standard protocol only yields
significant results half the time.",2022-05-24
RoViST:Learning Robust Metrics for Visual Storytelling,2022-05-08 03:51:22+00:00,http://arxiv.org/abs/2205.03774v1,"Eileen Wang, Caren Han, Josiah Poon","cs.CV, cs.AI",story,"Visual storytelling (VST) is the task of generating a story paragraph that
describes a given image sequence. Most existing storytelling approaches have
evaluated their models using traditional natural language generation metrics
like BLEU or CIDEr. However, such metrics based on n-gram matching tend to have
poor correlation with human evaluation scores and do not explicitly consider
other criteria necessary for storytelling such as sentence structure or topic
coherence. Moreover, a single score is not enough to assess a story as it does
not inform us about what specific errors were made by the model. In this paper,
we propose 3 evaluation metrics sets that analyses which aspects we would look
for in a good story: 1) visual grounding, 2) coherence, and 3) non-redundancy.
We measure the reliability of our metric sets by analysing its correlation with
human judgement scores on a sample of machine stories obtained from 4
state-of-the-arts models trained on the Visual Storytelling Dataset (VIST). Our
metric sets outperforms other metrics on human correlation, and could be served
as a learning based evaluation metric set that is complementary to existing
rule-based metrics.",2022-05-08
Language Models Can See: Plugging Visual Controls in Text Generation,2022-05-05 13:56:18+00:00,http://arxiv.org/abs/2205.02655v1,"Yixuan Su, Tian Lan, Yahui Liu, Fangyu Liu, Dani Yogatama, Yan Wang, Lingpeng Kong, Nigel Collier","cs.CV, cs.CL",story,"Generative language models (LMs) such as GPT-2/3 can be prompted to generate
text with remarkable quality. While they are designed for text-prompted
generation, it remains an open question how the generation process could be
guided by modalities beyond text such as images. In this work, we propose a
training-free framework, called MAGIC (iMAge-Guided text generatIon with CLIP),
for plugging in visual controls in the generation process and enabling LMs to
perform multimodal tasks (e.g., image captioning) in a zero-shot manner. MAGIC
is a simple yet efficient plug-and-play framework, which directly combines an
off-the-shelf LM (i.e., GPT-2) and an image-text matching model (i.e., CLIP)
for image-grounded text generation. During decoding, MAGIC influences the
generation of the LM by introducing a CLIP-induced score, called magic score,
which regularizes the generated result to be semantically related to a given
image while being coherent to the previously generated context. Notably, the
proposed decoding scheme does not involve any gradient update operation,
therefore being computationally efficient. On the challenging task of zero-shot
image captioning, MAGIC outperforms the state-of-the-art method by notable
margins with a nearly 27 times decoding speedup. MAGIC is a flexible framework
and is theoretically compatible with any text generation tasks that incorporate
image grounding. In the experiments, we showcase that it is also capable of
performing visually grounded story generation given both an image and a text
prompt.",2022-05-05
"Persona-Guided Planning for Controlling the Protagonist's Persona in
  Story Generation",2022-04-22 13:45:02+00:00,http://arxiv.org/abs/2204.10703v1,"Zhexin Zhang, Jiaxin Wen, Jian Guan, Minlie Huang",cs.CL,story,"Endowing the protagonist with a specific personality is essential for writing
an engaging story. In this paper, we aim to control the protagonist's persona
in story generation, i.e., generating a story from a leading context and a
persona description, where the protagonist should exhibit the specified
personality through a coherent event sequence. Considering that personas are
usually embodied implicitly and sparsely in stories, we propose a
planning-based generation model named CONPER to explicitly model the
relationship between personas and events. CONPER first plans events of the
protagonist's behavior which are motivated by the specified persona through
predicting one target sentence, then plans the plot as a sequence of keywords
with the guidance of the predicted persona-related events and commonsense
knowledge, and finally generates the whole story. Both automatic and manual
evaluation results demonstrate that CONPER outperforms state-of-the-art
baselines for generating more coherent and persona-controllable stories.",2022-04-22
"Recovering Patient Journeys: A Corpus of Biomedical Entities and
  Relations on Twitter (BEAR)",2022-04-21 08:18:44+00:00,http://arxiv.org/abs/2204.09952v1,"Amelie W√ºhrl, Roman Klinger","cs.CL, cs.IR",story,"Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.",2022-04-21
Event Transition Planning for Open-ended Text Generation,2022-04-20 13:37:51+00:00,http://arxiv.org/abs/2204.09453v1,"Qintong Li, Piji Li, Wei Bi, Zhaochun Ren, Yuxuan Lai, Lingpeng Kong",cs.CL,story,"Open-ended text generation tasks, such as dialogue generation and story
completion, require models to generate a coherent continuation given limited
preceding context. The open-ended nature of these tasks brings new challenges
to the neural auto-regressive text generators nowadays. Despite these neural
models are good at producing human-like text, it is difficult for them to
arrange causalities and relations between given facts and possible ensuing
events. To bridge this gap, we propose a novel two-stage method which
explicitly arranges the ensuing events in open-ended text generation. Our
approach can be understood as a specially-trained coarse-to-fine algorithm,
where an event transition planner provides a ""coarse"" plot skeleton and a text
generator in the second stage refines the skeleton. Experiments on two
open-ended text generation tasks demonstrate that our proposed method
effectively improves the quality of the generated text, especially in coherence
and diversity. The code is available at:
\url{https://github.com/qtli/EventPlanforTextGen}.",2022-04-20
Probing Script Knowledge from Pre-Trained Models,2022-04-16 05:13:39+00:00,http://arxiv.org/abs/2204.10176v1,"Zijian Jin, Xingyu Zhang, Mo Yu, Lifu Huang","cs.CL, cs.AI",story,"Script knowledge is critical for humans to understand the broad daily tasks
and routine activities in the world. Recently researchers have explored the
large-scale pre-trained language models (PLMs) to perform various script
related tasks, such as story generation, temporal ordering of event, future
event prediction and so on. However, it's still not well studied in terms of
how well the PLMs capture the script knowledge. To answer this question, we
design three probing tasks: inclusive sub-event selection, starting sub-event
selection and temporal ordering to investigate the capabilities of PLMs with
and without fine-tuning. The three probing tasks can be further used to
automatically induce a script for each main event given all the possible
sub-events. Taking BERT as a case study, by analyzing its performance on script
induction as well as each individual probing task, we conclude that the
stereotypical temporal knowledge among the sub-events is well captured in BERT,
however the inclusive or starting sub-event knowledge is barely encoded.",2022-04-16
Uniform Complexity for Text Generation,2022-04-11 15:19:47+00:00,http://arxiv.org/abs/2204.05185v1,Joseph Marvin Imperial,"cs.CL, cs.LG",story,"Powerful language models such as GPT-2 have shown promising results in tasks
such as narrative generation which can be useful in an educational setup. These
models, however, should be consistent with the linguistic properties of
triggers used. For example, if the reading level of an input text prompt is
appropriate for low-leveled learners (ex. A2 in the CEFR), then the generated
continuation should also assume this particular level. Thus, we propose the
task of uniform complexity for text generation which serves as a call to make
existing language generators uniformly complex with respect to prompts used.
Our study surveyed over 160 linguistic properties for evaluating text
complexity and found out that both humans and GPT-2 models struggle in
preserving the complexity of prompts in a narrative generation setting.",2022-04-11
On Decoding Strategies for Neural Text Generators,2022-03-29 16:25:30+00:00,http://arxiv.org/abs/2203.15721v1,"Gian Wiher, Clara Meister, Ryan Cotterell","cs.CL, cs.AI",story,"When generating text from probabilistic models, the chosen decoding strategy
has a profound effect on the resulting text. Yet the properties elicited by
various decoding strategies do not always transfer across natural language
generation tasks. For example, while mode-seeking methods like beam search
perform remarkably well for machine translation, they have been observed to
lead to incoherent and repetitive text in story generation. Despite such
observations, the effectiveness of decoding strategies is often assessed with
respect to only a single task. This work -- in contrast -- provides a
comprehensive analysis of the interaction between language generation tasks and
decoding strategies. Specifically, we measure changes in attributes of
generated text as a function of both decoding strategy and task using human and
automatic evaluation. Our results reveal both previously-observed and
surprising findings. For example, the nature of the diversity-quality trade-off
in language generation is very task-specific; the length bias often attributed
to beam search is not constant across tasks.",2022-03-29
Immersive Text Game and Personality Classification,2022-03-20 18:37:03+00:00,http://arxiv.org/abs/2203.10621v1,"Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi","cs.CL, cs.AI, cs.LG",story,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",2022-03-20
Pruned Graph Neural Network for Short Story Ordering,2022-03-13 22:25:17+00:00,http://arxiv.org/abs/2203.06778v1,"Melika Golestani, Zeinab Borhanifard, Farnaz Tahmasebian, Heshaam Faili",cs.CL,story,"Text coherence is a fundamental problem in natural language generation and
understanding. Organizing sentences into an order that maximizes coherence is
known as sentence ordering. This paper is proposing a new approach based on the
graph neural network approach to encode a set of sentences and learn orderings
of short stories. We propose a new method for constructing sentence-entity
graphs of short stories to create the edges between sentences and reduce noise
in our graph by replacing the pronouns with their referring entities. We
improve the sentence ordering by introducing an aggregation method based on
majority voting of state-of-the-art methods and our proposed one. Our approach
employs a BERT-based model to learn semantic representations of the sentences.
The results demonstrate that the proposed method significantly outperforms
existing baselines on a corpus of short stories with a new state-of-the-art
performance in terms of Perfect Match Ratio (PMR) and Kendall's Tau (Tau)
metrics. More precisely, our method increases PMR and Tau criteria by more than
5% and 4.3%, respectively. These outcomes highlight the benefit of forming the
edges between sentences based on their cosine similarity. We also observe that
replacing pronouns with their referring entities effectively encodes sentences
in sentence-entity graphs.",2022-03-13
"Knowledge-enriched Attention Network with Group-wise Semantic for Visual
  Storytelling",2022-03-10 12:55:47+00:00,http://arxiv.org/abs/2203.05346v1,"Tengpeng Li, Hanli Wang, Bin He, Chang Wen Chen","cs.CV, cs.CL",story,"As a technically challenging topic, visual storytelling aims at generating an
imaginary and coherent story with narrative multi-sentences from a group of
relevant images. Existing methods often generate direct and rigid descriptions
of apparent image-based contents, because they are not capable of exploring
implicit information beyond images. Hence, these schemes could not capture
consistent dependencies from holistic representation, impairing the generation
of reasonable and fluent story. To address these problems, a novel
knowledge-enriched attention network with group-wise semantic model is
proposed. Three main novel components are designed and supported by substantial
experiments to reveal practical advantages. First, a knowledge-enriched
attention network is designed to extract implicit concepts from external
knowledge system, and these concepts are followed by a cascade cross-modal
attention mechanism to characterize imaginative and concrete representations.
Second, a group-wise semantic module with second-order pooling is developed to
explore the globally consistent guidance. Third, a unified one-stage story
generation model with encoder-decoder structure is proposed to simultaneously
train and infer the knowledge-enriched attention network, group-wise semantic
module and multi-modal story generation decoder in an end-to-end fashion.
Substantial experiments on the popular Visual Storytelling dataset with both
objective and subjective evaluation metrics demonstrate the superior
performance of the proposed scheme as compared with other state-of-the-art
methods.",2022-03-10
CLSEG: Contrastive Learning of Story Ending Generation,2022-02-18 07:11:04+00:00,http://arxiv.org/abs/2202.09049v1,"Yuqiang Xie, Yue Hu, Luxi Xing, Yunpeng Li, Wei Peng, Ping Guo",cs.CL,story,"Story Ending Generation (SEG) is a challenging task in natural language
generation. Recently, methods based on Pre-trained Language Models (PLM) have
achieved great prosperity, which can produce fluent and coherent story endings.
However, the pre-training objective of PLM-based methods is unable to model the
consistency between story context and ending. The goal of this paper is to
adopt contrastive learning to generate endings more consistent with story
context, while there are two main challenges in contrastive learning of SEG.
First is the negative sampling of wrong endings inconsistent with story
contexts. The second challenge is the adaptation of contrastive learning for
SEG. To address these two issues, we propose a novel Contrastive Learning
framework for Story Ending Generation (CLSEG), which has two steps:
multi-aspect sampling and story-specific contrastive learning. Particularly,
for the first issue, we utilize novel multi-aspect sampling mechanisms to
obtain wrong endings considering the consistency of order, causality, and
sentiment. To solve the second issue, we well-design a story-specific
contrastive training strategy that is adapted for SEG. Experiments show that
CLSEG outperforms baselines and can produce story endings with stronger
consistency and rationality.",2022-02-18
"Inferring Commonsense Explanations as Prompts for Future Event
  Generation",2022-01-18 16:21:23+00:00,http://arxiv.org/abs/2201.07099v1,"Li Lin, Yixin Cao, Lifu Huang, Shuang Li, Xuming Hu, Lijie Wen, Jianmin Wang","cs.CL, cs.LG, I.2.7; I.2.4",story,"Future Event Generation aims to generate fluent and reasonable future event
descriptions given preceding events. It requires not only fluent text
generation but also commonsense reasoning to maintain the coherence of the
entire event story. However, existing FEG methods are easily trapped into
repeated or general events without imposing any logical constraint to the
generation process. In this paper, we propose a novel explainable FEG framework
that consists of a commonsense inference model (IM) and an event generation
model (GM). The IM, which is pre-trained on a commonsense knowledge graph
ATOMIC, learns to interpret the preceding events and conducts commonsense
reasoning to reveal the characters psychology such as intent, reaction, and
needs as latent variables. GM further takes the commonsense knowledge as
prompts to guide and enforce the generation of logistically coherent future
events. As unique merit, the commonsense prompts can be further decoded into
textual descriptions, yielding explanations for the future event. Automatic and
human evaluation demonstrate that our approach can generate more coherent,
specific, and logical future events than the strong baselines.",2022-01-18
Guiding Neural Story Generation with Reader Models,2021-12-16 03:44:01+00:00,http://arxiv.org/abs/2112.08596v1,"Xiangyu Peng, Kaige Xie, Amal Alabdulkarim, Harshith Kayam, Samihan Dani, Mark O. Riedl",cs.CL,story,"Automated storytelling has long captured the attention of researchers for the
ubiquity of narratives in everyday life. However, it is challenging to maintain
coherence and stay on-topic toward a specific ending when generating narratives
with neural language models. In this paper, we introduce Story generation with
Reader Models (StoRM), a framework in which a reader model is used to reason
about the story should progress. A reader model infers what a human reader
believes about the concepts, entities, and relations about the fictional story
world. We show how an explicit reader model represented as a knowledge graph
affords story coherence and provides controllability in the form of achieving a
given story world state goal. Experiments show that our model produces
significantly more coherent and on-topic stories, outperforming baselines in
dimensions including plot plausibility and staying on topic. Our system also
outperforms outline-guided story generation baselines in composing given
concepts without ordering.",2021-12-16
"Goal-Directed Story Generation: Augmenting Generative Language Models
  with Reinforcement Learning",2021-12-16 03:34:14+00:00,http://arxiv.org/abs/2112.08593v1,"Amal Alabdulkarim, Winston Li, Lara J. Martin, Mark O. Riedl","cs.CL, cs.AI",story,"The advent of large pre-trained generative language models has provided a
common framework for AI story generation via sampling the model to create
sequences that continue the story. However, sampling alone is insufficient for
story generation. In particular, it is hard to direct a language model to
create stories to reach a specific goal event. We present two automated
techniques grounded in deep reinforcement learning and reward shaping to
control the plot of computer-generated stories. The first utilizes proximal
policy optimization to fine-tune an existing transformer-based language model
to generate text continuations but also be goal-seeking. The second extracts a
knowledge graph from the unfolding story, which is used by a policy network
with graph attention to select a candidate continuation generated by a language
model. We report on automated metrics pertaining to how often stories achieve a
given goal event as well as human participant rankings of coherence and overall
story quality compared to baselines and ablations.",2021-12-16
TopNet: Learning from Neural Topic Model to Generate Long Stories,2021-12-14 09:47:53+00:00,http://arxiv.org/abs/2112.07259v1,"Yazheng Yang, Boyuan Pan, Deng Cai, Huan Sun","cs.LG, cs.CL",story,"Long story generation (LSG) is one of the coveted goals in natural language
processing. Different from most text generation tasks, LSG requires to output a
long story of rich content based on a much shorter text input, and often
suffers from information sparsity. In this paper, we propose \emph{TopNet} to
alleviate this problem, by leveraging the recent advances in neural topic
modeling to obtain high-quality skeleton words to complement the short input.
In particular, instead of directly generating a story, we first learn to map
the short text input to a low-dimensional topic distribution (which is
pre-assigned by a topic model). Based on this latent topic distribution, we can
use the reconstruction decoder of the topic model to sample a sequence of
inter-related words as a skeleton for the story. Experiments on two benchmark
datasets show that our proposed framework is highly effective in skeleton word
selection and significantly outperforms the state-of-the-art models in both
automatic evaluation and human evaluation.",2021-12-14
Contextualized Scene Imagination for Generative Commonsense Reasoning,2021-12-12 20:38:08+00:00,http://arxiv.org/abs/2112.06318v1,"PeiFeng Wang, Jonathan Zamora, Junfeng Liu, Filip Ilievski, Muhao Chen, Xiang Ren",cs.CL,story,"Humans use natural language to compose common concepts from their environment
into plausible, day-to-day scene descriptions. However, such generative
commonsense reasoning (GCSR) skills are lacking in state-of-the-art text
generation methods. Descriptive sentences about arbitrary concepts generated by
neural text generation models (e.g., pre-trained text-to-text Transformers) are
often grammatically fluent but may not correspond to human common sense,
largely due to their lack of mechanisms to capture concept relations, to
identify implicit concepts, and to perform generalizable reasoning about unseen
concept compositions. In this paper, we propose an Imagine-and-Verbalize (I&V)
method, which learns to imagine a relational scene knowledge graph (SKG) with
relations between the input concepts, and leverage the SKG as a constraint when
generating a plausible scene description. We collect and harmonize a set of
knowledge resources from different domains and modalities, providing a rich
auxiliary supervision signal for I&V. The experiments demonstrate the
effectiveness of I&V in improving language models on both concept-to-sentence
and concept-to-story generation tasks, while enabling the model to learn well
from fewer task examples and generate SKGs that make common sense to human
annotators.",2021-12-12
Show and Write: Entity-aware News Generation with Image Information,2021-12-11 05:32:09+00:00,http://arxiv.org/abs/2112.05917v1,"Zhongping Zhang, Yiwen Gu, Bryan A. Plummer",cs.CL,story,"Automatically writing long articles is a complex and challenging language
generation task. Prior work has primarily focused on generating these articles
using human-written prompt to provide some topical context and some metadata
about the article. That said, for many applications, such as generating news
stories, these articles are often paired with images and their captions or
alt-text, which in turn are based on real-world events and may reference many
different named entities that are difficult to be correctly recognized and
predicted by language models. To address these two problems, this paper
introduces an Entity-aware News Generation method with Image iNformation,
Engin, to incorporate news image information into language models. Engin
produces news articles conditioned on both metadata and information such as
captions and named entities extracted from images. We also propose an
Entity-aware mechanism to help our model better recognize and predict the
entity names in news. We perform experiments on two public large-scale news
datasets, GoodNews and VisualNews. Quantitative results show that our approach
improves article perplexity by 4-5 points over the base models. Qualitative
results demonstrate the text generated by Engin is more consistent with news
images. We also perform article quality annotation experiment on the generated
articles to validate that our model produces higher-quality articles. Finally,
we investigate the effect Engin has on methods that automatically detect
machine-generated articles.",2021-12-11
Automated Story Generation as Question-Answering,2021-12-07 16:32:30+00:00,http://arxiv.org/abs/2112.03808v1,"Louis Castricato, Spencer Frazier, Jonathan Balloch, Nitya Tarakad, Mark Riedl",cs.CL,story,"Neural language model-based approaches to automated story generation suffer
from two important limitations. First, language model-based story generators
generally do not work toward a given goal or ending. Second, they often lose
coherence as the story gets longer. We propose a novel approach to automated
story generation that treats the problem as one of generative
question-answering. Our proposed story generation system starts with sentences
encapsulating the final event of the story. The system then iteratively (1)
analyzes the text describing the most recent event, (2) generates a question
about ""why"" a character is doing the thing they are doing in the event, and
then (3) attempts to generate another, preceding event that answers this
question.",2021-12-07
Mutltimodal AI Companion for Interactive Fairytale Co-creation,2021-12-01 07:53:38+00:00,http://arxiv.org/abs/2112.00331v1,"Ruiyang Liu, Predrag K. Nikolic",cs.MM,story,"AI fairy tale companions play an important role in early childhood education
as an augmentation for parents' efforts to close the participation gap and
boost kids' mental and language development. Existing systems are generally
designed to provide vivid materials as unidirectional entertaining reading
environments, e.g, visualizing inputting texts. However, due to the limited
vocabulary of kids, these systems failed to afford effective interaction to
motivate kids to write their own fairy tales. In this work, we propose AI.R
Taletorium, an illustrative, immersive, and inclusive multimodal AI companion,
for interactive fairy tale co-creation that actively involves kids to create
fairy tales with both the AI agent and their normal peers. AI.R Taletorium
consists a neural story generator and a doodler-based fairy tale visualizer. We
design a character-centric bidirectional connection mechanism between the story
generator and visualizer equipped with Contrastive Language Image Pretraining
(CLIP), thus enabling kids to participant in the story generation process by
simple sketching. Extensive experiments and user studies show that our system
was able to generate and visualize meaningful and vivid fairy tales with
limited training data and complete the full interaction cycle under various
inputs (text, doodler) through the bidirectional connection.",2021-12-01
"Exploring Story Generation with Multi-task Objectives in Variational
  Autoencoders",2021-11-15 23:07:19+00:00,http://arxiv.org/abs/2111.08133v1,"Zhuohan Xie, Trevor Cohn, Jey Han Lau","cs.CL, cs.LG",story,"GPT-2 has been frequently adapted in story generation models as it provides
powerful generative capability. However, it still fails to generate consistent
stories and lacks diversity. Current story generation models leverage
additional information such as plots or commonsense into GPT-2 to guide the
generation process. These approaches focus on improving generation quality of
stories while our work look at both quality and diversity. We explore combining
BERT and GPT-2 to build a variational autoencoder (VAE), and extend it by
adding additional objectives to learn global features such as story topic and
discourse relations. Our evaluations show our enhanced VAE can provide better
quality and diversity trade off, generate less repetitive story content and
learn a more informative latent variable.",2021-11-15
A Novel Corpus of Discourse Structure in Humans and Computers,2021-11-10 20:56:08+00:00,http://arxiv.org/abs/2111.05940v1,"Babak Hemmatian, Sheridan Feucht, Rachel Avram, Alexander Wey, Muskaan Garg, Kate Spitalnic, Carsten Eickhoff, Ellie Pavlick, Bjorn Sandstede, Steven Sloman",cs.CL,story,"We present a novel corpus of 445 human- and computer-generated documents,
comprising about 27,000 clauses, annotated for semantic clause types and
coherence relations that allow for nuanced comparison of artificial and natural
discourse modes. The corpus covers both formal and informal discourse, and
contains documents generated using fine-tuned GPT-2 (Zellers et al., 2019) and
GPT-3(Brown et al., 2020). We showcase the usefulness of this corpus for
detailed discourse analysis of text generation by providing preliminary
evidence that less numerous, shorter and more often incoherent clause relations
are associated with lower perceived quality of computer-generated narratives
and arguments.",2021-11-10
"DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational
  Transformer",2021-10-12 13:41:06+00:00,http://arxiv.org/abs/2110.05999v1,"Haozhe Ji, Minlie Huang",cs.CL,story,"Despite the recent advances in applying pre-trained language models to
generate high-quality texts, generating long passages that maintain long-range
coherence is yet challenging for these models. In this paper, we propose
DiscoDVT, a discourse-aware discrete variational Transformer to tackle the
incoherence issue. DiscoDVT learns a discrete variable sequence that summarizes
the global structure of the text and then applies it to guide the generation
process at each decoding step. To further embed discourse-aware information
into the discrete latent representations, we introduce an auxiliary objective
to model the discourse relations within the text. We conduct extensive
experiments on two open story generation datasets and demonstrate that the
latent codes learn meaningful correspondence to the discourse structures that
guide the model to generate long texts with better long-range coherence.",2021-10-12
A guided journey through non-interactive automatic story generation,2021-10-08 10:01:36+00:00,http://arxiv.org/abs/2110.11167v1,Luis Miguel Botelho,"cs.CL, cs.AI",story,"We present a literature survey on non-interactive computational story
generation. The article starts with the presentation of requirements for
creative systems, three types of models of creativity (computational,
socio-cultural, and individual), and models of human creative writing. Then it
reviews each class of story generation approach depending on the used
technology: story-schemas, analogy, rules, planning, evolutionary algorithms,
implicit knowledge learning, and explicit knowledge learning. Before the
concluding section, the article analyses the contributions of the reviewed work
to improve the quality of the generated stories. This analysis addresses the
description of the story characters, the use of narrative knowledge including
about character believability, and the possible lack of more comprehensive or
more detailed knowledge or creativity models. Finally, the article presents
concluding remarks in the form of suggestions of research topics that might
have a significant impact on the advancement of the state of the art on
autonomous non-interactive story generation systems. The article concludes that
the autonomous generation and adoption of the main idea to be conveyed and the
autonomous design of the creativity ensuring criteria are possibly two of most
important topics for future research.",2021-10-08
Cut the CARP: Fishing for zero-shot story evaluation,2021-10-06 23:50:46+00:00,http://arxiv.org/abs/2110.03111v1,"Shahbuland Matiana, JR Smith, Ryan Teehan, Louis Castricato, Stella Biderman, Leo Gao, Spencer Frazier",cs.CL,story,"Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
  Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.",2021-10-06
A Plug-and-Play Method for Controlled Text Generation,2021-09-20 17:27:03+00:00,http://arxiv.org/abs/2109.09707v1,"Damian Pascual, Beni Egressy, Clara Meister, Ryan Cotterell, Roger Wattenhofer","cs.CL, cs.AI",story,"Large pre-trained language models have repeatedly shown their ability to
produce fluent text. Yet even when starting from a prompt, generation can
continue in many plausible directions. Current decoding methods with the goal
of controlling generation, e.g., to ensure specific words are included, either
require additional models or fine-tuning, or work poorly when the task at hand
is semantically unconstrained, e.g., story generation. In this work, we present
a plug-and-play decoding method for controlled language generation that is so
simple and intuitive, it can be described in a single sentence: given a topic
or keyword, we add a shift to the probability distribution over our vocabulary
towards semantically similar words. We show how annealing this distribution can
be used to impose hard constraints on language generation, something no other
plug-and-play method is currently able to do with SOTA language generators.
Despite the simplicity of this approach, we see it works incredibly well in
practice: decoding from GPT-2 leads to diverse and fluent sentences while
guaranteeing the appearance of given guide words. We perform two user studies,
revealing that (1) our method outperforms competing methods in human
evaluations; and (2) forcing the guide words to appear in the generated text
has no impact on the fluency of the generated text.",2021-09-20
TVRecap: A Dataset for Generating Stories with Character Descriptions,2021-09-18 05:02:29+00:00,http://arxiv.org/abs/2109.08833v1,"Mingda Chen, Kevin Gimpel",cs.CL,story,"We introduce TVRecap, a story generation dataset that requires generating
detailed TV show episode recaps from a brief summary and a set of documents
describing the characters involved. Unlike other story generation datasets,
TVRecap contains stories that are authored by professional screenwriters and
that feature complex interactions among multiple characters. Generating stories
in TVRecap requires drawing relevant information from the lengthy provided
documents about characters based on the brief summary. In addition, by swapping
the input and output, TVRecap can serve as a challenging testbed for
abstractive summarization. We create TVRecap from fan-contributed websites,
which allows us to collect 26k episode recaps with 1868.7 tokens on average.
Empirically, we take a hierarchical story generation approach and find that the
neural model that uses oracle content selectors for character descriptions
demonstrates the best performance on automatic metrics, showing the potential
of our dataset to inspire future research on story generation with constraints.
Qualitative analysis shows that the best-performing model sometimes generates
content that is unfaithful to the short summaries, suggesting promising
directions for future work.",2021-09-18
"The Perils of Using Mechanical Turk to Evaluate Open-Ended Text
  Generation",2021-09-14 17:20:30+00:00,http://arxiv.org/abs/2109.06835v1,"Marzena Karpinska, Nader Akoury, Mohit Iyyer",cs.CL,story,"Recent text generation research has increasingly focused on open-ended
domains such as story and poetry generation. Because models built for such
tasks are difficult to evaluate automatically, most researchers in the space
justify their modeling choices by collecting crowdsourced human judgments of
text quality (e.g., Likert scores of coherence or grammaticality) from Amazon
Mechanical Turk (AMT). In this paper, we first conduct a survey of 45
open-ended text generation papers and find that the vast majority of them fail
to report crucial details about their AMT tasks, hindering reproducibility. We
then run a series of story evaluation experiments with both AMT workers and
English teachers and discover that even with strict qualification filters, AMT
workers (unlike teachers) fail to distinguish between model-generated text and
human-generated references. We show that AMT worker judgments improve when they
are shown model-generated output alongside human-generated references, which
enables the workers to better calibrate their ratings. Finally, interviews with
the English teachers provide deeper insights into the challenges of the
evaluation process, particularly when rating model-generated text.",2021-09-14
A Temporal Variational Model for Story Generation,2021-09-14 16:36:12+00:00,http://arxiv.org/abs/2109.06807v1,"David Wilmot, Frank Keller","cs.CL, cs.AI",story,"Recent language models can generate interesting and grammatically correct
text in story generation but often lack plot development and long-term
coherence. This paper experiments with a latent vector planning approach based
on a TD-VAE (Temporal Difference Variational Autoencoder), using the model for
conditioning and reranking for text generation. The results demonstrate strong
performance in automatic cloze and swapping evaluations. The human judgments
show stories generated with TD-VAE reranking improve on a GPT-2 medium baseline
and show comparable performance to a hierarchical LSTM reranking model.
Conditioning on the latent vectors proves disappointing and deteriorates
performance in human evaluation because it reduces the diversity of generation,
and the models don't learn to progress the narrative. This highlights an
important difference between technical task performance (e.g. cloze) and
generating interesting stories.",2021-09-14
"Implicit Premise Generation with Discourse-aware Commonsense Knowledge
  Models",2021-09-11 19:54:39+00:00,http://arxiv.org/abs/2109.05358v1,"Tuhin Chakrabarty, Aadit Trivedi, Smaranda Muresan",cs.CL,story,"Enthymemes are defined as arguments where a premise or conclusion is left
implicit. We tackle the task of generating the implicit premise in an
enthymeme, which requires not only an understanding of the stated conclusion
and premise but also additional inferences that could depend on commonsense
knowledge. The largest available dataset for enthymemes (Habernal et al., 2018)
consists of 1.7k samples, which is not large enough to train a neural text
generation model. To address this issue, we take advantage of a similar task
and dataset: Abductive reasoning in narrative text (Bhagavatula et al., 2020).
However, we show that simply using a state-of-the-art seq2seq model fine-tuned
on this data might not generate meaningful implicit premises associated with
the given enthymemes. We demonstrate that encoding discourse-aware commonsense
during fine-tuning improves the quality of the generated implicit premises and
outperforms all other baselines both in automatic and human evaluations on
three different datasets.",2021-09-11
"Using BERT Encoding and Sentence-Level Language Model for Sentence
  Ordering",2021-08-24 23:03:36+00:00,http://arxiv.org/abs/2108.10986v1,"Melika Golestani, Seyedeh Zahra Razavi, Zeinab Borhanifard, Farnaz Tahmasebian, Hesham Faili",cs.CL,story,"Discovering the logical sequence of events is one of the cornerstones in
Natural Language Understanding. One approach to learn the sequence of events is
to study the order of sentences in a coherent text. Sentence ordering can be
applied in various tasks such as retrieval-based Question Answering, document
summarization, storytelling, text generation, and dialogue systems.
Furthermore, we can learn to model text coherence by learning how to order a
set of shuffled sentences. Previous research has relied on RNN, LSTM, and
BiLSTM architecture for learning text language models. However, these networks
have performed poorly due to the lack of attention mechanisms. We propose an
algorithm for sentence ordering in a corpus of short stories. Our proposed
method uses a language model based on Universal Transformers (UT) that captures
sentences' dependencies by employing an attention mechanism. Our method
improves the previous state-of-the-art in terms of Perfect Match Ratio (PMR)
score in the ROCStories dataset, a corpus of nearly 100K short human-made
stories. The proposed model includes three components: Sentence Encoder,
Language Model, and Sentence Arrangement with Brute Force Search. The first
component generates sentence embeddings using SBERT-WK pre-trained model
fine-tuned on the ROCStories data. Then a Universal Transformer network
generates a sentence-level language model. For decoding, the network generates
a candidate sentence as the following sentence of the current sentence. We use
cosine similarity as a scoring function to assign scores to the candidate
embedding and the embeddings of other sentences in the shuffled set. Then a
Brute Force Search is employed to maximize the sum of similarities between
pairs of consecutive sentences.",2021-08-24
"GGP: A Graph-based Grouping Planner for Explicit Control of Long Text
  Generation",2021-08-18 06:55:55+00:00,http://arxiv.org/abs/2108.07998v1,"Xuming Lin, Shaobo Cui, Zhongzhou Zhao, Wei Zhou, Ji Zhang, Haiqing Chen",cs.CL,story,"Existing data-driven methods can well handle short text generation. However,
when applied to the long-text generation scenarios such as story generation or
advertising text generation in the commercial scenario, these methods may
generate illogical and uncontrollable texts. To address these aforementioned
issues, we propose a graph-based grouping planner(GGP) following the idea of
first-plan-then-generate. Specifically, given a collection of key phrases, GGP
firstly encodes these phrases into an instance-level sequential representation
and a corpus-level graph-based representation separately. With these two
synergic representations, we then regroup these phrases into a fine-grained
plan, based on which we generate the final long text. We conduct our
experiments on three long text generation datasets and the experimental results
reveal that GGP significantly outperforms baselines, which proves that GGP can
control the long text generation by knowing how to say and in what order.",2021-08-18
MTG: A Benchmarking Suite for Multilingual Text Generation,2021-08-13 13:25:08+00:00,http://arxiv.org/abs/2108.07140v1,"Yiran Chen, Zhenqiao Song, Xianze Wu, Danqing Wang, Jingjing Xu, Jiaze Chen, Hao Zhou, Lei Li",cs.CL,story,"We introduce MTG, a new benchmark suite for training and evaluating
multilingual text generation. It is the first and largest text generation
benchmark with 120k human-annotated multi-way parallel data for three tasks
(story generation, question generation, and title generation) across four
languages (English, German, French, and Spanish). Based on it, we set various
evaluation scenarios and make a deep analysis of several popular multilingual
generation models from different aspects. Our benchmark suite will encourage
the multilingualism for text generation community with more human-annotated
parallel data and more diverse generation scenarios.",2021-08-13
Sentence Semantic Regression for Text Generation,2021-08-06 07:35:59+00:00,http://arxiv.org/abs/2108.02984v1,"Wei Wang, Piji Li, Hai-Tao Zheng",cs.CL,story,"Recall the classical text generation works, the generation framework can be
briefly divided into two phases: \textbf{idea reasoning} and \textbf{surface
realization}. The target of idea reasoning is to figure out the main idea which
will be presented in the following talking/writing periods. Surface realization
aims to arrange the most appropriate sentence to depict and convey the
information distilled from the main idea. However, the current popular
token-by-token text generation methods ignore this crucial process and suffer
from many serious issues, such as idea/topic drift. To tackle the problems and
realize this two-phase paradigm, we propose a new framework named Sentence
Semantic Regression (\textbf{SSR}) based on sentence-level language modeling.
For idea reasoning, two architectures \textbf{SSR-AR} and \textbf{SSR-NonAR}
are designed to conduct sentence semantic regression autoregressively (like
GPT2/3) and bidirectionally (like BERT). In the phase of surface realization, a
mixed-granularity sentence decoder is designed to generate text with better
consistency by jointly incorporating the predicted sentence-level main idea as
well as the preceding contextual token-level information. We conduct
experiments on four tasks of story ending prediction, story ending generation,
dialogue generation, and sentence infilling. The results show that SSR can
obtain better performance in terms of automatic metrics and human evaluation.",2021-08-06
"Inspiration through Observation: Demonstrating the Influence of
  Automatically Generated Text on Creative Writing",2021-07-08 17:53:22+00:00,http://arxiv.org/abs/2107.04007v1,Melissa Roemmele,"cs.CL, cs.AI, cs.HC",story,"Getting machines to generate text perceived as creative is a long-pursued
goal. A growing body of research directs this goal towards augmenting the
creative writing abilities of human authors. In this paper, we pursue this
objective by analyzing how observing examples of automatically generated text
influences writing. In particular, we examine a task referred to as sentence
infilling, which involves transforming a list of words into a complete
sentence. We emphasize ""storiability"" as a desirable feature of the resulting
sentences, where ""storiable"" sentences are those that suggest a story a reader
would be curious to hear about. Both humans and an automated system (based on a
neural language model) performed this sentence infilling task. In one setting,
people wrote sentences on their own; in a different setting, people observed
the sentences produced by the model while writing their own sentences. Readers
then assigned storiability preferences to the resulting sentences in a
subsequent evaluation. We find that human-authored sentences were judged as
more storiable when authors observed the generated examples, and that
storiability increased as authors derived more semantic content from the
examples. This result gives evidence of an ""inspiration through observation""
paradigm for human-computer collaborative writing, through which human writing
can be enhanced by text generation models without directly copying their
output.",2021-07-08
"Improving Coherence and Consistency in Neural Sequence Models with
  Dual-System, Neuro-Symbolic Reasoning",2021-07-06 17:59:49+00:00,http://arxiv.org/abs/2107.02794v1,"Maxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, Brenden M. Lake","cs.AI, cs.CL, cs.LG",story,"Human reasoning can often be understood as an interplay between two systems:
the intuitive and associative (""System 1"") and the deliberative and logical
(""System 2""). Neural sequence models -- which have been increasingly successful
at performing complex, structured tasks -- exhibit the advantages and failure
modes of System 1: they are fast and learn patterns from data, but are often
inconsistent and incoherent. In this work, we seek a lightweight, training-free
means of improving existing System 1-like sequence models by adding System
2-inspired logical reasoning. We explore several variations on this theme in
which candidate generations from a neural sequence model are examined for
logical consistency by a symbolic reasoning module, which can either accept or
reject the generations. Our approach uses neural inference to mediate between
the neural System 1 and the logical System 2. Results in robust story
generation and grounded instruction-following show that this approach can
increase the coherence and accuracy of neurally-based generations.",2021-07-06
Scarecrow: A Framework for Scrutinizing Machine Text,2021-07-02 22:37:03+00:00,http://arxiv.org/abs/2107.01294v2,"Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, Yejin Choi",cs.CL,story,"Modern neural text generation systems can produce remarkably fluent and
grammatical texts. While earlier language models suffered from repetition and
syntactic errors, the errors made by contemporary models are often semantic,
narrative, or discourse failures.
  To facilitate research of these complex error types, we introduce a new
structured, crowdsourced error annotation schema called Scarecrow. The error
categories used in Scarecrow -- such as redundancy, commonsense errors, and
incoherence -- were identified by combining expert analysis with several pilot
rounds of ontology-free crowd annotation to arrive at a schema which covers the
error phenomena found in real machine generated text.
  We use Scarecrow to collect 13k annotations of 1.3k human and machine
generate paragraphs of English language news text, amounting to over 41k spans
each labeled with its error category, severity, a natural language explanation,
and antecedent span (where relevant). We collect annotations for text generated
by state-of-the-art systems with varying known performance levels, from GPT-2
Small through the largest GPT-3. We isolate several factors for detailed
analysis, including parameter count, training data, and decoding technique. Our
results show both expected and surprising differences across these settings.
These findings demonstrate the value of Scarecrow annotations in the assessment
of current and future text generation systems. We release our complete
annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.",2021-07-02
"All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated
  Text",2021-06-30 19:00:25+00:00,http://arxiv.org/abs/2107.00061v1,"Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, Noah A. Smith",cs.CL,story,"Human evaluations are typically considered the gold standard in natural
language generation, but as models' fluency improves, how well can evaluators
detect and judge machine-generated text? We run a study assessing non-experts'
ability to distinguish between human- and machine-authored text (GPT2 and GPT3)
in three domains (stories, news articles, and recipes). We find that, without
training, evaluators distinguished between GPT3- and human-authored text at
random chance level. We explore three approaches for quickly training
evaluators to better identify GPT3-authored text (detailed instructions,
annotated examples, and paired examples) and find that while evaluators'
accuracy improved up to 55%, it did not significantly improve across the three
domains. Given the inconsistent results across text domains and the often
contradictory reasons evaluators gave for their judgments, we examine the role
untrained human evaluations play in NLG evaluation and provide recommendations
to NLG researchers for improving human evaluations of text generated from
state-of-the-art models.",2021-06-30
"Graph-based Trajectory Visualization for Text Mining of COVID-19
  Biomedical Literature",2021-06-07 06:01:17+00:00,http://arxiv.org/abs/2106.07374v1,"Yeseul Jeon, Dongjun Chung, Jina Park, Ick Hoon Jin","cs.IR, stat.AP",story,"Since the emergence of the worldwide pandemic of COVID-19, relevant research
has been published at a dazzling pace, which makes it hard to follow the
research in this area without dedicated efforts. It is practically impossible
to implement this task manually due to the high volume of the relevant
literature. Text mining has been considered to be a powerful approach to
address this challenge, especially the topic modeling, a well-known
unsupervised method that aims to reveal latent topics from the literature.
However, in spite of its potential utility, the results generated from this
approach are often investigated manually. Hence, its application to the
COVID-19 literature is not straightforward and expert knowledge is needed to
make meaningful interpretations. In order to address these challenges, we
propose a novel analytical framework for effective visualization and mining of
topic modeling results. Here we assumed that topics constituting a paper can be
positioned on an interaction map, which belongs to a high-dimensional Euclidean
space. Based on this assumption, after summarizing topics with their topic-word
distributions using the biterm topic model, we mapped these latent topics on
networks to visualize relationships among the topics. Moreover, in the proposed
approach, the change of relationships among topics can be traced using a
trajectory plot generated with different levels of word richness. These results
together provide a deeply mined and intuitive representation of relationships
among topics related to a specific research area. The application of this
proposed framework to the PubMed literature shows that our approach facilitates
understanding of the topics constituting the COVID-19 knowledge.",2021-06-07
"Long Text Generation by Modeling Sentence-Level and Discourse-Level
  Coherence",2021-05-19 07:29:08+00:00,http://arxiv.org/abs/2105.08963v1,"Jian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wenbiao Ding, Minlie Huang",cs.CL,story,"Generating long and coherent text is an important but challenging task,
particularly for open-ended language generation tasks such as story generation.
Despite the success in modeling intra-sentence coherence, existing generation
models (e.g., BART) still struggle to maintain a coherent event sequence
throughout the generated text. We conjecture that this is because of the
difficulty for the decoder to capture the high-level semantics and discourse
structures in the context beyond token-level co-occurrence. In this paper, we
propose a long text generation model, which can represent the prefix sentences
at sentence level and discourse level in the decoding process. To this end, we
propose two pretraining objectives to learn the representations by predicting
inter-sentence semantic similarity and distinguishing between normal and
shuffled sentence orders. Extensive experiments show that our model can
generate more coherent texts than state-of-the-art baselines.",2021-05-19
OpenMEVA: A Benchmark for Evaluating Open-ended Story Generation Metrics,2021-05-19 04:45:07+00:00,http://arxiv.org/abs/2105.08920v1,"Jian Guan, Zhexin Zhang, Zhuoer Feng, Zitao Liu, Wenbiao Ding, Xiaoxi Mao, Changjie Fan, Minlie Huang",cs.CL,story,"Automatic metrics are essential for developing natural language generation
(NLG) models, particularly for open-ended language generation tasks such as
story generation. However, existing automatic metrics are observed to correlate
poorly with human evaluation. The lack of standardized benchmark datasets makes
it difficult to fully evaluate the capabilities of a metric and fairly compare
different metrics. Therefore, we propose OpenMEVA, a benchmark for evaluating
open-ended story generation metrics. OpenMEVA provides a comprehensive test
suite to assess the capabilities of metrics, including (a) the correlation with
human judgments, (b) the generalization to different model outputs and
datasets, (c) the ability to judge story coherence, and (d) the robustness to
perturbations. To this end, OpenMEVA includes both manually annotated stories
and auto-constructed test examples. We evaluate existing metrics on OpenMEVA
and observe that they have poor correlation with human judgments, fail to
recognize discourse-level incoherence, and lack inferential knowledge (e.g.,
causal order between events), the generalization ability and robustness. Our
study presents insights for developing NLG models and metrics in further
research.",2021-05-19
Stylized Story Generation with Style-Guided Planning,2021-05-18 15:55:38+00:00,http://arxiv.org/abs/2105.08625v2,"Xiangzhe Kong, Jialiang Huang, Ziquan Tung, Jian Guan, Minlie Huang","cs.CL, cs.AI",story,"Current storytelling systems focus more ongenerating stories with coherent
plots regard-less of the narration style, which is impor-tant for controllable
text generation. There-fore, we propose a new task, stylized story gen-eration,
namely generating stories with speci-fied style given a leading context. To
tacklethe problem, we propose a novel generationmodel that first plans the
stylized keywordsand then generates the whole story with theguidance of the
keywords. Besides, we pro-pose two automatic metrics to evaluate theconsistency
between the generated story andthe specified style. Experiments
demonstratesthat our model can controllably generateemo-tion-driven
orevent-driven stories based onthe ROCStories dataset (Mostafazadeh et
al.,2016). Our study presents insights for stylizedstory generation in further
research.",2021-05-18
"Inferring the Reader: Guiding Automated Story Generation with
  Commonsense Reasoning",2021-05-04 06:40:33+00:00,http://arxiv.org/abs/2105.01311v1,"Xiangyu Peng, Siyan Li, Sarah Wiegreffe, Mark Riedl",cs.CL,story,"Transformer-based language model approaches to automated story generation
currently provide state-of-the-art results. However, they still suffer from
plot incoherence when generating narratives over time, and critically lack
basic commonsense reasoning. Furthermore, existing methods generally focus only
on single-character stories, or fail to track characters at all. To improve the
coherence of generated narratives and to expand the scope of character-centric
narrative generation, we introduce Commonsense-inference Augmented neural
StoryTelling (CAST), a framework for introducing commonsense reasoning into the
generation process while modeling the interaction between multiple characters.
We find that our CAST method produces significantly more coherent and on-topic
two-character stories, outperforming baselines in dimensions including plot
plausibility and staying on topic. We also show how the CAST method can be used
to further train language models that generate more coherent stories and reduce
computation cost.",2021-05-04
"Plot-guided Adversarial Example Construction for Evaluating Open-domain
  Story Generation",2021-04-12 20:19:24+00:00,http://arxiv.org/abs/2104.05801v1,"Sarik Ghazarian, Zixi Liu, Akash SM, Ralph Weischedel, Aram Galstyan, Nanyun Peng","cs.CL, cs.LG",story,"With the recent advances of open-domain story generation, the lack of
reliable automatic evaluation metrics becomes an increasingly imperative issue
that hinders the fast development of story generation. According to conducted
researches in this regard, learnable evaluation metrics have promised more
accurate assessments by having higher correlations with human judgments. A
critical bottleneck of obtaining a reliable learnable evaluation metric is the
lack of high-quality training data for classifiers to efficiently distinguish
plausible and implausible machine-generated stories. Previous works relied on
\textit{heuristically manipulated} plausible examples to mimic possible system
drawbacks such as repetition, contradiction, or irrelevant content in the text
level, which can be \textit{unnatural} and \textit{oversimplify} the
characteristics of implausible machine-generated stories. We propose to tackle
these issues by generating a more comprehensive set of implausible stories
using {\em plots}, which are structured representations of controllable factors
used to generate stories. Since these plots are compact and structured, it is
easier to manipulate them to generate text with targeted undesirable
properties, while at the same time maintain the grammatical correctness and
naturalness of the generated sentences. To improve the quality of generated
implausible stories, we further apply the adversarial filtering procedure
presented by \citet{zellers2018swag} to select a more nuanced set of
implausible texts. Experiments show that the evaluation metrics trained on our
generated data result in more reliable automatic assessments that correlate
remarkably better with human judgments compared to the baselines.",2021-04-12
Semantic Frame Forecast,2021-04-12 16:23:17+00:00,http://arxiv.org/abs/2104.05604v1,"Chieh-Yang Huang, Ting-Hao 'Kenneth' Huang",cs.CL,story,"This paper introduces semantic frame forecast, a task that predicts the
semantic frames that will occur in the next 10, 100, or even 1,000 sentences in
a running story. Prior work focused on predicting the immediate future of a
story, such as one to a few sentences ahead. However, when novelists write long
stories, generating a few sentences is not enough to help them gain high-level
insight to develop the follow-up story. In this paper, we formulate a long
story as a sequence of ""story blocks,"" where each block contains a fixed number
of sentences (e.g., 10, 100, or 200). This formulation allows us to predict the
follow-up story arc beyond the scope of a few sentences. We represent a story
block using the term frequencies (TF) of semantic frames in it, normalized by
each frame's inverse document frequency (IDF). We conduct semantic frame
forecast experiments on 4,794 books from the Bookcorpus and 7,962 scientific
abstracts from CODA-19, with block sizes ranging from 5 to 1,000 sentences. The
results show that automated models can forecast the follow-up story blocks
better than the random, prior, and replay baselines, indicating the task's
feasibility. We also learn that the models using the frame representation as
features outperform all the existing approaches when the block size is over 150
sentences. The human evaluation also shows that the proposed frame
representation, when visualized as word clouds, is comprehensible,
representative, and specific to humans. Our code is available at
https://github.com/appleternity/FrameForecasting.",2021-04-12
Sketch and Customize: A Counterfactual Story Generator,2021-04-02 08:14:22+00:00,http://arxiv.org/abs/2104.00929v1,"Changying Hao, Liang Pang, Yanyan Lan, Yan Wang, Jiafeng Guo, Xueqi Cheng","cs.CL, cs.AI",story,"Recent text generation models are easy to generate relevant and fluent text
for the given text, while lack of causal reasoning ability when we change some
parts of the given text. Counterfactual story rewriting is a recently proposed
task to test the causal reasoning ability for text generation models, which
requires a model to predict the corresponding story ending when the condition
is modified to a counterfactual one. Previous works have shown that the
traditional sequence-to-sequence model cannot well handle this problem, as it
often captures some spurious correlations between the original and
counterfactual endings, instead of the causal relations between conditions and
endings. To address this issue, we propose a sketch-and-customize generation
model guided by the causality implicated in the conditions and endings. In the
sketch stage, a skeleton is extracted by removing words which are conflict to
the counterfactual condition, from the original ending. In the customize stage,
a generation model is used to fill proper words in the skeleton under the
guidance of the counterfactual condition. In this way, the obtained
counterfactual ending is both relevant to the original ending and consistent
with the counterfactual condition. Experimental results show that the proposed
model generates much better endings, as compared with the traditional
sequence-to-sequence model.",2021-04-02
AfriKI: Machine-in-the-Loop Afrikaans Poetry Generation,2021-03-30 09:17:56+00:00,http://arxiv.org/abs/2103.16190v1,"Imke van Heerden, Anil Bas","cs.CL, cs.LG",story,"This paper proposes a generative language model called AfriKI. Our approach
is based on an LSTM architecture trained on a small corpus of contemporary
fiction. With the aim of promoting human creativity, we use the model as an
authoring tool to explore machine-in-the-loop Afrikaans poetry generation. To
our knowledge, this is the first study to attempt creative text generation in
Afrikaans.",2021-03-30
Automatic Story Generation: Challenges and Attempts,2021-02-25 02:03:35+00:00,http://arxiv.org/abs/2102.12634v1,"Amal Alabdulkarim, Siyan Li, Xiangyu Peng",cs.CL,story,"The scope of this survey paper is to explore the challenges in automatic
story generation. We hope to contribute in the following ways: 1. Explore how
previous research in story generation addressed those challenges. 2. Discuss
future research directions and new technologies that may aid more advancements.
3. Shed light on emerging and often overlooked challenges such as creativity
and discourse.",2021-02-25
"On Efficient Training, Controllability and Compositional Generalization
  of Insertion-based Language Generators",2021-02-12 11:05:02+00:00,http://arxiv.org/abs/2102.11008v1,"Sidi Lu, Nanyun Peng",cs.CL,story,"Auto-regressive language models with the left-to-right generation order have
been a predominant paradigm for language generation. Recently, out-of-order
text generation beyond the traditional left-to-right paradigm has attracted
extensive attention, with a notable variation of insertion-based generation,
where a model is used to gradually extend the context into a complete sentence
purely with insertion operations. However, since insertion operations disturb
the position information of each token, it is often believed that each step of
the insertion-based likelihood estimation requires a bi-directional
\textit{re-encoding} of the whole generated sequence. This computational
overhead prohibits the model from scaling up to generate long, diverse texts
such as stories, news articles, and reports. To address this issue, we propose
InsNet, an insertion-based sequence model that can be trained as efficiently as
traditional transformer decoders while maintaining the same performance as that
with a bi-directional context encoder. We evaluate InsNet on story generation
and CleVR-CoGENT captioning, showing the advantages of InsNet in several
dimensions, including computational costs, generation quality, the ability to
perfectly incorporate lexical controls, and better compositional
generalization.",2021-02-12
GraphPlan: Story Generation by Planning with Event Graph,2021-02-05 03:18:55+00:00,http://arxiv.org/abs/2102.02977v1,"Hong Chen, Raphael Shu, Hiroya Takamura, Hideki Nakayama",cs.CL,story,"Story generation is a task that aims to automatically produce multiple
sentences to make up a meaningful story. This task is challenging because it
requires high-level understanding of semantic meaning of sentences and
causality of story events. Naive sequence-to-sequence models generally fail to
acquire such knowledge, as the logical correctness can hardly be guaranteed in
a text generation model without the strategic planning. In this paper, we focus
on planning a sequence of events assisted by event graphs, and use the events
to guide the generator. Instead of using a sequence-to-sequence model to output
a storyline as in some existing works, we propose to generate an event sequence
by walking on an event graph. The event graphs are built automatically based on
the corpus. To evaluate the proposed approach, we conduct human evaluation both
on event planning and story generation. Based on large-scale human annotation
results, our proposed approach is shown to produce more logically correct event
sequences and stories.",2021-02-05
"MAUVE: Human-Machine Divergence Curves for Evaluating Open-Ended Text
  Generation",2021-02-02 11:59:28+00:00,http://arxiv.org/abs/2102.01454v1,"Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Yejin Choi, Zaid Harchaoui",cs.CL,story,"Despite major advances in open-ended text generation, there has been limited
progress in designing evaluation metrics for this task. We propose MAUVE -- a
metric for open-ended text generation, which directly compares the distribution
of machine-generated text to that of human language. MAUVE measures the mean
area under the divergence curve for the two distributions, exploring the
trade-off between two types of errors: those arising from parts of the human
distribution that the model distribution approximates well, and those it does
not. We present experiments across two open-ended generation tasks in the web
text domain and the story domain, and a variety of decoding algorithms and
model sizes. Our results show that evaluation under MAUVE indeed reflects the
more natural behavior with respect to model size, compared to prior metrics.
MAUVE's ordering of the decoding algorithms also agrees with that of generation
perplexity, the most widely used metric in open-ended text generation; however,
MAUVE presents a more principled evaluation metric for the task as it considers
both model and human text.",2021-02-02
Persistent Anti-Muslim Bias in Large Language Models,2021-01-14 18:41:55+00:00,http://arxiv.org/abs/2101.05783v2,"Abubakar Abid, Maheen Farooqi, James Zou","cs.CL, cs.LG",story,"It has been observed that large-scale language models capture undesirable
societal biases, e.g. relating to race and gender; yet religious bias has been
relatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual
language model, captures persistent Muslim-violence bias. We probe GPT-3 in
various ways, including prompt completion, analogical reasoning, and story
generation, to understand this anti-Muslim bias, demonstrating that it appears
consistently and creatively in different uses of the model and that it is
severe even compared to biases about other religious groups. For instance,
""Muslim"" is analogized to ""terrorist"" in 23% of test cases, while ""Jewish"" is
mapped to ""money"" in 5% of test cases. We quantify the positive distraction
needed to overcome this bias with adversarial text prompts, and find that use
of the most positive 6 adjectives reduces violent completions for ""Muslims""
from 66% to 20%, but which is still higher than for other religious groups.",2021-01-14
"Political Depolarization of News Articles Using Attribute-aware Word
  Embeddings",2021-01-05 07:39:12+00:00,http://arxiv.org/abs/2101.01391v1,"Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vosoughi","cs.CL, cs.AI",story,"Political polarization in the US is on the rise. This polarization negatively
affects the public sphere by contributing to the creation of ideological echo
chambers. In this paper, we focus on addressing one of the factors that
contributes to this polarity, polarized media. We introduce a framework for
depolarizing news articles. Given an article on a certain topic with a
particular ideological slant (eg., liberal or conservative), the framework
first detects polar language in the article and then generates a new article
with the polar language replaced with neutral expressions. To detect polar
words, we train a multi-attribute-aware word embedding model that is aware of
ideology and topics on 360k full-length media articles. Then, for text
generation, we propose a new algorithm called Text Annealing Depolarization
Algorithm (TADA). TADA retrieves neutral expressions from the word embedding
model that not only decrease ideological polarity but also preserve the
original argument of the text, while maintaining grammatical correctness. We
evaluate our framework by comparing the depolarized output of our model in two
modes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics.
Based on feedback from 161 human testers, our framework successfully
depolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs
in fully-automatic mode. Furthermore, 81.2% of the testers agree that the
non-polar content information is well-preserved and 79% agree that
depolarization does not harm semantic correctness when they compare the
original text and the depolarized text. Our work shows that data-driven methods
can help to locate political polarity and aid in the depolarization of
articles.",2021-01-05
"Outline to Story: Fine-grained Controllable Story Generation from
  Cascaded Events",2021-01-04 08:16:21+00:00,http://arxiv.org/abs/2101.00822v1,"Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong, Changyou Chen","cs.CL, cs.AI, cs.LG",story,"Large-scale pretrained language models have shown thrilling generation
capabilities, especially when they generate consistent long text in thousands
of words with ease. However, users of these models can only control the prefix
of sentences or certain global aspects of generated text. It is challenging to
simultaneously achieve fine-grained controllability and preserve the
state-of-the-art unconditional text generation capability. In this paper, we
first propose a new task named ""Outline to Story"" (O2S) as a test bed for
fine-grained controllable generation of long text, which generates a
multi-paragraph story from cascaded events, i.e. a sequence of outline events
that guide subsequent paragraph generation. We then create dedicate datasets
for future benchmarks, built by state-of-the-art keyword extraction techniques.
Finally, we propose an extremely simple yet strong baseline method for the O2S
task, which fine tunes pre-trained language models on augmented sequences of
outline-story pairs with simple language modeling objective. Our method does
not introduce any new parameters or perform any architecture modification,
except several special tokens as delimiters to build augmented sequences.
Extensive experiments on various datasets demonstrate state-of-the-art
conditional story generation performance with our model, achieving better
fine-grained controllability and user flexibility. Our paper is among the first
ones by our knowledge to propose a model and to create datasets for the task of
""outline to story"". Our work also instantiates research interest of
fine-grained controllable generation of open-domain long text, where
controlling inputs are represented by short text.",2021-01-04
Facts2Story: Controlling Text Generation by Key Facts,2020-12-08 10:14:29+00:00,http://arxiv.org/abs/2012.04332v1,"Eyal Orbach, Yoav Goldberg",cs.CL,story,"Recent advancements in self-attention neural network architectures have
raised the bar for open-ended text generation. Yet, while current methods are
capable of producing a coherent text which is several hundred words long,
attaining control over the content that is being generated -- as well as
evaluating it -- are still open questions. We propose a controlled generation
task which is based on expanding a sequence of facts, expressed in natural
language, into a longer narrative. We introduce human-based evaluation metrics
for this task, as well as a method for deriving a large training dataset. We
evaluate three methods on this task, based on fine-tuning pre-trained models.
We show that while auto-regressive, unidirectional Language Models such as GPT2
produce better fluency, they struggle to adhere to the requested facts. We
propose a plan-and-cloze model (using fine-tuned XLNet) which produces
competitive fluency while adhering to the requested content.",2020-12-08
Machine Generation and Detection of Arabic Manipulated and Fake News,2020-11-05 20:50:22+00:00,http://arxiv.org/abs/2011.03092v1,"El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed, Tariq Alhindi, Hasan Cavusoglu","cs.CL, cs.LG",story,"Fake news and deceptive machine-generated text are serious problems
threatening modern societies, including in the Arab world. This motivates work
on detecting false and manipulated stories online. However, a bottleneck for
this research is lack of sufficient data to train detection models. We present
a novel method for automatically generating Arabic manipulated (and potentially
fake) news stories. Our method is simple and only depends on availability of
true stories, which are abundant online, and a part of speech tagger (POS). To
facilitate future work, we dispense with both of these requirements altogether
by providing AraNews, a novel and large POS-tagged news dataset that can be
used off-the-shelf. Using stories generated based on AraNews, we carry out a
human annotation study that casts light on the effects of machine manipulation
on text veracity. The study also measures human ability to detect Arabic
machine manipulated text generated by our method. Finally, we develop the first
models for detecting manipulated Arabic news and achieve state-of-the-art
results on Arabic fake news detection (macro F1=70.06). Our models and data are
publicly available.",2020-11-05
Dissecting the components and factors of Neural Text Generation,2020-10-14 17:54:42+00:00,http://arxiv.org/abs/2010.07279v1,"Khyathi Raghavi Chandu, Alan W Black",cs.CL,story,"Neural text generation metamorphosed into several critical natural language
applications ranging from text completion to free form narrative generation.
Generating natural language has fundamentally been a human attribute and the
advent of ubiquitous NLP applications and virtual agents marks the need to
impart this skill to machines. There has been a colossal research effort in
various frontiers of neural text generation including machine translation,
summarization, image captioning, storytelling etc., We believe that this is an
excellent juncture to retrospect on the directions of the field. Specifically,
this paper surveys the fundamental factors and components relaying task
agnostic impacts across various generation tasks such as storytelling,
summarization, translation etc., In specific, we present an abstraction of the
imperative techniques with respect to learning paradigms, pretraining, modeling
approaches, decoding and the key challenges. Thereby, we hope to deliver a
one-stop destination for researchers in the field to facilitate a perspective
on where to situate their work and how it impacts other closely related tasks.",2020-10-14
"Back to the Future: Unsupervised Backprop-based Decoding for
  Counterfactual and Abductive Commonsense Reasoning",2020-10-12 17:58:43+00:00,http://arxiv.org/abs/2010.05906v3,"Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena Hwang, Ronan Le Bras, Antoine Bosselut, Yejin Choi","cs.CL, cs.AI, cs.LG",story,"Abductive and counterfactual reasoning, core abilities of everyday human
cognition, require reasoning about what might have happened at time t, while
conditioning on multiple contexts from the relative past and future. However,
simultaneous incorporation of past and future contexts using generative
language models (LMs) can be challenging, as they are trained either to
condition only on the past context or to perform narrowly scoped
text-infilling. In this paper, we propose DeLorean, a new unsupervised decoding
algorithm that can flexibly incorporate both the past and future contexts using
only off-the-shelf, left-to-right language models and no supervision. The key
intuition of our algorithm is incorporating the future through
back-propagation, during which, we only update the internal representation of
the output while fixing the model parameters. By alternating between forward
and backward propagation, DeLorean can decode the output representation that
reflects both the left and right contexts. We demonstrate that our approach is
general and applicable to two nonmonotonic reasoning tasks: abductive text
generation and counterfactual story revision, where DeLorean outperforms a
range of unsupervised and some supervised methods, based on automatic and human
evaluation.",2020-10-12
Controllable Multi-Character Psychology-Oriented Story Generation,2020-10-11 12:05:00+00:00,http://arxiv.org/abs/2010.05230v1,"Feifei Xu, Xinpeng Wang, Yunpu Ma, Volker Tresp, Yuyi Wang, Shanlin Zhou, Haizhou Du",cs.CL,story,"Story generation, which aims to generate a long and coherent story
automatically based on the title or an input sentence, is an important research
area in the field of natural language generation. There is relatively little
work on story generation with appointed emotions. Most existing works focus on
using only one specific emotion to control the generation of a whole story and
ignore the emotional changes in the characters in the course of the story. In
our work, we aim to design an emotional line for each character that considers
multiple emotions common in psychological theories, with the goal of generating
stories with richer emotional changes in the characters. To the best of our
knowledge, this work is first to focuses on characters' emotional lines in
story generation. We present a novel model-based attention mechanism that we
call SoCP (Storytelling of multi-Character Psychology). We show that the
proposed model can generate stories considering the changes in the
psychological state of different characters. To take into account the
particularity of the model, in addition to commonly used evaluation
indicators(BLEU, ROUGE, etc.), we introduce the accuracy rate of psychological
state control as a novel evaluation metric. The new indicator reflects the
effect of the model on the psychological state control of story characters.
Experiments show that with SoCP, the generated stories follow the psychological
state for each character according to both automatic and human evaluations.",2020-10-11
"MEGATRON-CNTRL: Controllable Story Generation with External Knowledge
  Using Large-Scale Language Models",2020-10-02 08:07:12+00:00,http://arxiv.org/abs/2010.00840v1,"Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Raul Puri, Pascale Fung, Anima Anandkumar, Bryan Catanzaro",cs.CL,story,"Existing pre-trained large language models have shown unparalleled generative
capabilities. However, they are not controllable. In this paper, we propose
MEGATRON-CNTRL, a novel framework that uses large-scale language models and
adds control to text generation by incorporating an external knowledge base.
Our framework consists of a keyword predictor, a knowledge retriever, a
contextual knowledge ranker, and a conditional text generator. As we do not
have access to ground-truth supervision for the knowledge ranker, we make use
of weak supervision from sentence embedding. The empirical results show that
our model generates more fluent, consistent, and coherent stories with less
repetition and higher diversity compared to prior work on the ROC story
dataset. We showcase the controllability of our model by replacing the keywords
used to generate stories and re-running the generation process. Human
evaluation results show that 77.5% of these stories are successfully controlled
by the new keywords. Furthermore, by scaling our model from 124 million to 8.3
billion parameters we demonstrate that larger models improve both the quality
of generation (from 74.5% to 93.0% for consistency) and controllability (from
77.5% to 91.5%).",2020-10-02
Graph-based Multi-hop Reasoning for Long Text Generation,2020-09-28 12:47:59+00:00,http://arxiv.org/abs/2009.13282v1,"Liang Zhao, Jingjing Xu, Junyang Lin, Yichang Zhang, Hongxia Yang, Xu Sun",cs.CL,story,"Long text generation is an important but challenging task.The main problem
lies in learning sentence-level semantic dependencies which traditional
generative models often suffer from. To address this problem, we propose a
Multi-hop Reasoning Generation (MRG) approach that incorporates multi-hop
reasoning over a knowledge graph to learn semantic dependencies among
sentences. MRG consists of twoparts, a graph-based multi-hop reasoning module
and a path-aware sentence realization module. The reasoning module is
responsible for searching skeleton paths from a knowledge graph to imitate the
imagination process in the human writing for semantic transfer. Based on the
inferred paths, the sentence realization module then generates a complete
sentence. Unlike previous black-box models, MRG explicitly infers the skeleton
path, which provides explanatory views tounderstand how the proposed model
works. We conduct experiments on three representative tasks, including story
generation, review generation, and product description generation. Automatic
and manual evaluation show that our proposed method can generate more
informative and coherentlong text than strong baselines, such as pre-trained
models(e.g. GPT-2) and knowledge-enhanced models.",2020-09-28
Content Planning for Neural Story Generation with Aristotelian Rescoring,2020-09-21 13:41:32+00:00,http://arxiv.org/abs/2009.09870v2,"Seraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph Weischedel, Nanyun Peng","cs.CL, cs.AI",story,"Long-form narrative text generated from large language models manages a
fluent impersonation of human writing, but only at the local sentence level,
and lacks structure or global cohesion. We posit that many of the problems of
story generation can be addressed via high-quality content planning, and
present a system that focuses on how to learn good plot structures to guide
story generation. We utilize a plot-generation language model along with an
ensemble of rescoring models that each implement an aspect of good
story-writing as detailed in Aristotle's Poetics. We find that stories written
with our more principled plot-structure are both more relevant to a given
prompt and higher quality than baselines that do not content plan, or that plan
in an unprincipled way.",2020-09-21
UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation,2020-09-16 11:01:46+00:00,http://arxiv.org/abs/2009.07602v1,"Jian Guan, Minlie Huang",cs.CL,story,"Despite the success of existing referenced metrics (e.g., BLEU and
MoverScore), they correlate poorly with human judgments for open-ended text
generation including story or dialog generation because of the notorious
one-to-many issue: there are many plausible outputs for the same input, which
may differ substantially in literal or semantics from the limited number of
given references. To alleviate this issue, we propose UNION, a learnable
unreferenced metric for evaluating open-ended story generation, which measures
the quality of a generated story without any reference. Built on top of BERT,
UNION is trained to distinguish human-written stories from negative samples and
recover the perturbation in negative stories. We propose an approach of
constructing negative samples by mimicking the errors commonly observed in
existing NLG models, including repeated plots, conflicting logic, and
long-range incoherence. Experiments on two story datasets demonstrate that
UNION is a reliable measure for evaluating the quality of generated stories,
which correlates better with human judgments and is more generalizable than
existing state-of-the-art metrics.",2020-09-16
A Comparison of LSTM and BERT for Small Corpus,2020-09-11 14:01:14+00:00,http://arxiv.org/abs/2009.05451v1,Aysu Ezen-Can,"cs.CL, cs.LG",story,"Recent advancements in the NLP field showed that transfer learning helps with
achieving state-of-the-art results for new tasks by tuning pre-trained models
instead of starting from scratch. Transformers have made a significant
improvement in creating new state-of-the-art results for many NLP tasks
including but not limited to text classification, text generation, and sequence
labeling. Most of these success stories were based on large datasets. In this
paper we focus on a real-life scenario that scientists in academia and industry
face frequently: given a small dataset, can we use a large pre-trained model
like BERT and get better results than simple models? To answer this question,
we use a small dataset for intent classification collected for building
chatbots and compare the performance of a simple bidirectional LSTM model with
a pre-trained BERT model. Our experimental results show that bidirectional LSTM
models can achieve significantly higher results than a BERT model for a small
dataset and these simple models get trained in much less time than tuning the
pre-trained counterparts. We conclude that the performance of a model is
dependent on the task and the data, and therefore before making a model choice,
these factors should be taken into consideration instead of directly choosing
the most popular model.",2020-09-11
Navigating Human Language Models with Synthetic Agents,2020-08-10 14:39:53+00:00,http://arxiv.org/abs/2008.04162v7,"Philip Feldman, Antonio Bucchiarone","cs.AI, cs.CL, cs.MA, I.2; I.6; J.4",story,"Modern natural language models such as the GPT-2/GPT-3 contain tremendous
amounts of information about human belief in a consistently testable form. If
these models could be shown to accurately reflect the underlying beliefs of the
human beings that produced the data used to train these models, then such
models become a powerful sociological tool in ways that are distinct from
traditional methods, such as interviews and surveys. In this study, We train a
version of the GPT-2 on a corpora of historical chess games, and then ""launch""
clusters of synthetic agents into the model, using text strings to create
context and orientation. We compare the trajectories contained in the text
generated by the agents/model and compare that to the known ground truth of the
chess board, move legality, and historical patterns of play. We find that the
percentages of moves by piece using the model are substantially similar from
human patterns. We further find that the model creates an accurate latent
representation of the chessboard, and that it is possible to plot trajectories
of legal moves across the board using this knowledge.",2020-08-10
"Paranoid Transformer: Reading Narrative of Madness as Computational
  Approach to Creativity",2020-07-13 10:18:24+00:00,http://arxiv.org/abs/2007.06290v1,"Yana Agafonova, Alexey Tikhonov, Ivan P. Yamshchikov","cs.CL, cs.AI, cs.CY, 68T50, 68T07, 91F20, 68T42, H.1.2; J.5; K.4",story,"This papers revisits the receptive theory in context of computational
creativity. It presents a case study of a Paranoid Transformer - a fully
autonomous text generation engine with raw output that could be read as the
narrative of a mad digital persona without any additional human post-filtering.
We describe technical details of the generative system, provide examples of
output and discuss the impact of receptive theory, chance discovery and
simulation of fringe mental state on the understanding of computational
creativity.",2020-07-13
On Faithfulness and Factuality in Abstractive Summarization,2020-05-02 00:09:16+00:00,http://arxiv.org/abs/2005.00661v1,"Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan McDonald",cs.CL,story,"It is well known that the standard likelihood training and approximate
decoding objectives in neural text generation models lead to less human-like
responses for open-ended tasks such as language modeling and story generation.
In this paper we have analyzed limitations of these models for abstractive
document summarization and found that these models are highly prone to
hallucinate content that is unfaithful to the input document. We conducted a
large scale human evaluation of several neural abstractive summarization
systems to better understand the types of hallucinations they produce. Our
human annotators found substantial amounts of hallucinated content in all model
generated summaries. However, our analysis does show that pretrained models are
better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in
generating faithful and factual summaries as evaluated by humans. Furthermore,
we show that textual entailment measures better correlate with faithfulness
than standard metrics, potentially leading the way to automatic evaluation
metrics as well as training and decoding criteria.",2020-05-02
Sparse Text Generation,2020-04-06 13:09:10+00:00,http://arxiv.org/abs/2004.02644v3,"Pedro Henrique Martins, Zita Marinho, Andr√© F. T. Martins",cs.CL,story,"Current state-of-the-art text generators build on powerful language models
such as GPT-2, achieving impressive performance. However, to avoid degenerate
text, they require sampling from a modified softmax, via temperature parameters
or ad-hoc truncation techniques, as in top-$k$ or nucleus sampling. This
creates a mismatch between training and testing conditions. In this paper, we
use the recently introduced entmax transformation to train and sample from a
natively sparse language model, avoiding this mismatch. The result is a text
generator with favorable performance in terms of fluency and consistency, fewer
repetitions, and n-gram diversity closer to human text. In order to evaluate
our model, we propose three new metrics for comparing sparse or truncated
distributions: $\epsilon$-perplexity, sparsemax score, and Jensen-Shannon
divergence. Human-evaluated experiments in story completion and dialogue
generation show that entmax sampling leads to more engaging and coherent
stories and conversations.",2020-04-06
Semantics of the Unwritten,2020-04-05 16:55:09+00:00,http://arxiv.org/abs/2004.02251v1,"He Bai, Peng Shi, Jimmy Lin, Luchen Tan, Kun Xiong, Wen Gao, Jie Liu, Ming Li",cs.CL,story,"The semantics of a text is manifested not only by what is read, but also by
what is not read. In this article, we will study how those implicit ""not read""
information such as end-of-paragraph (EOP) and end-of-sequence (EOS) affect the
quality of text generation. Transformer-based pretrained language models (LMs)
have demonstrated the ability to generate long continuations with good quality.
This model gives us a platform for the first time to demonstrate that paragraph
layouts and text endings are also important components of human writing.
Specifically, we find that pretrained LMs can generate better continuations by
learning to generate the end of the paragraph (EOP) in the fine-tuning stage.
Experimental results on English story generation show that EOP can lead to
higher BLEU score and lower EOS perplexity. To further investigate the
relationship between text ending and EOP, we conduct experiments with a
self-collected Chinese essay dataset on Chinese-GPT2, a character level LM
without paragraph breaker or EOS during pre-training. Experimental results show
that the Chinese GPT2 can generate better essay endings with paragraph
information. Experiments on both English stories and Chinese essays demonstrate
that learning to end paragraphs can benefit the continuation generation with
pretrained LMs.",2020-04-05
Counterfactual Story Reasoning and Generation,2019-09-09 18:08:35+00:00,http://arxiv.org/abs/1909.04076v2,"Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chandra Bhagavatula, Elizabeth Clark, Yejin Choi","cs.CL, cs.AI",story,"Counterfactual reasoning requires predicting how alternative events, contrary
to what actually happened, might have resulted in different outcomes. Despite
being considered a necessary component of AI-complete systems, few resources
have been developed for evaluating counterfactual reasoning in narratives.
  In this paper, we propose Counterfactual Story Rewriting: given an original
story and an intervening counterfactual event, the task is to minimally revise
the story to make it compatible with the given counterfactual event. Solving
this task will require deep understanding of causal narrative chains and
counterfactual invariance, and integration of such story reasoning capabilities
into conditional language generation models.
  We present TimeTravel, a new dataset of 29,849 counterfactual rewritings,
each with the original story, a counterfactual event, and human-generated
revision of the original story compatible with the counterfactual event.
Additionally, we include 80,115 counterfactual ""branches"" without a rewritten
storyline to support future work on semi- or un-supervised approaches to
counterfactual story rewriting.
  Finally, we evaluate the counterfactual rewriting capacities of several
competitive baselines based on pretrained language models, and assess whether
common overlap and model-based automatic metrics for text generation correlate
well with human scores for counterfactual rewriting.",2019-09-09
WriterForcing: Generating more interesting story endings,2019-07-18 19:29:29+00:00,http://arxiv.org/abs/1907.08259v1,"Prakhar Gupta, Vinayshekhar Bannihatti Kumar, Mukul Bhutani, Alan W Black","cs.LG, cs.CL, stat.ML",story,"We study the problem of generating interesting endings for stories. Neural
generative models have shown promising results for various text generation
problems. Sequence to Sequence (Seq2Seq) models are typically trained to
generate a single output sequence for a given input sequence. However, in the
context of a story, multiple endings are possible. Seq2Seq models tend to
ignore the context and generate generic and dull responses. Very few works have
studied generating diverse and interesting story endings for a given story
context. In this paper, we propose models which generate more diverse and
interesting outputs by 1) training models to focus attention on important
keyphrases of the story, and 2) promoting generation of non-generic words. We
show that the combination of the two leads to more diverse and interesting
endings.",2019-07-18
Towards Content Transfer through Grounded Text Generation,2019-05-13 21:36:43+00:00,http://arxiv.org/abs/1905.05293v1,"Shrimai Prabhumoye, Chris Quirk, Michel Galley",cs.CL,story,"Recent work in neural generation has attracted significant interest in
controlling the form of text, such as style, persona, and politeness. However,
there has been less work on controlling neural text generation for content.
This paper introduces the notion of Content Transfer for long-form text
generation, where the task is to generate a next sentence in a document that
both fits its context and is grounded in a content-rich external textual source
such as a news story. Our experiments on Wikipedia data show significant
improvements against competitive baselines. As another contribution of this
paper, we release a benchmark dataset of 640k Wikipedia referenced sentences
paired with the source articles to encourage exploration of this new task.",2019-05-13
Strategies for Structuring Story Generation,2019-02-04 10:23:39+00:00,http://arxiv.org/abs/1902.01109v2,"Angela Fan, Mike Lewis, Yann Dauphin",cs.CL,story,"Writers generally rely on plans or sketches to write long stories, but most
current language models generate word by word from left to right. We explore
coarse-to-fine models for creating narrative texts of several hundred words,
and introduce new models which decompose stories by abstracting over actions
and entities. The model first generates the predicate-argument structure of the
text, where different mentions of the same entity are marked with placeholder
tokens. It then generates a surface realization of the predicate-argument
structure, and finally replaces the entity placeholders with context-sensitive
names and references. Human judges prefer the stories from our models to a wide
range of previous approaches to hierarchical text generation. Extensive
analysis shows that our methods can help improve the diversity and coherence of
events and entities in generated stories.",2019-02-04
"Co-occurrence of the Benford-like and Zipf Laws Arising from the Texts
  Representing Human and Artificial Languages",2018-03-06 12:24:42+00:00,http://arxiv.org/abs/1803.03667v1,"Evgeny Shulzinger, Irina Legchenkova, Edward Bormashenko","cs.CL, physics.soc-ph, stat.OT",story,"We demonstrate that large texts, representing human (English, Russian,
Ukrainian) and artificial (C++, Java) languages, display quantitative patterns
characterized by the Benford-like and Zipf laws. The frequency of a word
following the Zipf law is inversely proportional to its rank, whereas the total
numbers of a certain word appearing in the text generate the uneven
Benford-like distribution of leading numbers. Excluding the most popular words
essentially improves the correlation of actual textual data with the Zipfian
distribution, whereas the Benford distribution of leading numbers (arising from
the overall amount of a certain word) is insensitive to the same elimination
procedure. The calculated values of the moduli of slopes of double
logarithmical plots for artificial languages (C++, Java) are markedly larger
than those for human ones.",2018-03-06
Story Generation from Sequence of Independent Short Descriptions,2017-07-18 07:08:31+00:00,http://arxiv.org/abs/1707.05501v2,"Parag Jain, Priyanka Agrawal, Abhijit Mishra, Mohak Sukhwani, Anirban Laha, Karthik Sankaranarayanan",cs.CL,story,"Existing Natural Language Generation (NLG) systems are weak AI systems and
exhibit limited capabilities when language generation tasks demand higher
levels of creativity, originality and brevity. Effective solutions or, at least
evaluations of modern NLG paradigms for such creative tasks have been elusive,
unfortunately. This paper introduces and addresses the task of coherent story
generation from independent descriptions, describing a scene or an event.
Towards this, we explore along two popular text-generation paradigms -- (1)
Statistical Machine Translation (SMT), posing story generation as a translation
problem and (2) Deep Learning, posing story generation as a sequence to
sequence learning problem. In SMT, we chose two popular methods such as phrase
based SMT (PB-SMT) and syntax based SMT (SYNTAX-SMT) to `translate' the
incoherent input text into stories. We then implement a deep recurrent neural
network (RNN) architecture that encodes sequence of variable length input
descriptions to corresponding latent representations and decodes them to
produce well formed comprehensive story like summaries. The efficacy of the
suggested approaches is demonstrated on a publicly available dataset with the
help of popular machine translation and summarization evaluation metrics.",2017-07-18
A Theme-Rewriting Approach for Generating Algebra Word Problems,2016-10-19 20:49:23+00:00,http://arxiv.org/abs/1610.06210v1,"Rik Koncel-Kedziorski, Ioannis Konstas, Luke Zettlemoyer, Hannaneh Hajishirzi",cs.CL,story,"Texts present coherent stories that have a particular theme or overall
setting, for example science fiction or western. In this paper, we present a
text generation method called {\it rewriting} that edits existing
human-authored narratives to change their theme without changing the underlying
story. We apply the approach to math word problems, where it might help
students stay more engaged by quickly transforming all of their homework
assignments to the theme of their favorite movie without changing the math
concepts that are being taught. Our rewriting method uses a two-stage decoding
process, which proposes new words from the target theme and scores the
resulting stories according to a number of factors defining aspects of
syntactic, semantic, and thematic coherence. Experiments demonstrate that the
final stories typically represent the new theme well while still testing the
original math concepts, outperforming a number of baselines. We also release a
new dataset of human-authored rewrites of math word problems in several themes.",2016-10-19
