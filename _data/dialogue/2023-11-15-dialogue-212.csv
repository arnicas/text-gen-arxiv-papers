title,pubdate,id,authors,categories,search,abstract,displaydate
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,dialogue,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
"X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented
  Instruction Tuning with Auxiliary Evaluation Aspects",2023-11-15 09:01:55+00:00,http://arxiv.org/abs/2311.08788v1,"Minqian Liu, Ying Shen, Zhiyang Xu, Yixin Cao, Eunah Cho, Vaibhav Kumar, Reza Ghanadan, Lifu Huang","cs.CL, cs.AI, cs.LG",dialogue,"Natural Language Generation (NLG) typically involves evaluating the generated
text in various aspects (e.g., consistency and naturalness) to obtain a
comprehensive assessment. However, multi-aspect evaluation remains challenging
as it may require the evaluator to generalize to any given evaluation aspect
even if it's absent during training. In this paper, we introduce X-Eval, a
two-stage instruction tuning framework to evaluate the text in both seen and
unseen aspects customized by end users. X-Eval consists of two learning stages:
the vanilla instruction tuning stage that improves the model's ability to
follow evaluation instructions, and an enhanced instruction tuning stage that
exploits the connections between fine-grained evaluation aspects to better
assess text quality. To support the training of X-Eval, we collect
AspectInstruct, the first instruction tuning dataset tailored for multi-aspect
NLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance
task diversity, we devise an augmentation strategy that converts human rating
annotations into diverse forms of NLG evaluation tasks, including scoring,
comparison, ranking, and Boolean question answering. Extensive experiments
across three essential categories of NLG tasks: dialogue generation,
summarization, and data-to-text coupled with 21 aspects in meta-evaluation,
demonstrate that our X-Eval enables even a lightweight language model to
achieve a comparable if not higher correlation with human judgments compared to
the state-of-the-art NLG evaluators, such as GPT-4.",2023-11-15
Workflow-Guided Response Generation for Task-Oriented Dialogue,2023-11-14 16:44:33+00:00,http://arxiv.org/abs/2311.08300v1,"Do June Min, Paloma Sodhi, Ramya Ramakrishnan","cs.CL, cs.AI",dialogue,"Task-oriented dialogue (TOD) systems aim to achieve specific goals through
interactive dialogue. Such tasks usually involve following specific workflows,
i.e. executing a sequence of actions in a particular order. While prior work
has focused on supervised learning methods to condition on past actions, they
do not explicitly optimize for compliance to a desired workflow. In this paper,
we propose a novel framework based on reinforcement learning (RL) to generate
dialogue responses that are aligned with a given workflow. Our framework
consists of ComplianceScorer, a metric designed to evaluate how well a
generated response executes the specified action, combined with an RL
opimization process that utilizes an interactive sampling technique. We
evaluate our approach on two TOD datasets, Action-Based Conversations Dataset
(ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of
automated and human evaluation metrics. Our findings indicate that our RL-based
framework outperforms baselines and is effective at enerating responses that
both comply with the intended workflows while being expressed in a natural and
fluent manner.",2023-11-14
Measuring Entrainment in Spontaneous Code-switched Speech,2023-11-13 19:41:34+00:00,http://arxiv.org/abs/2311.07703v1,"Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg","cs.CL, cs.SD, eess.AS",dialogue,"It is well-known that interlocutors who entrain to one another have more
successful conversations than those who do not. Previous research has shown
that interlocutors entrain on linguistic features in both written and spoken
monolingual domains. More recent work on code-switched communication has also
shown preliminary evidence of entrainment on certain aspects of code-switching
(CSW). However, such studies of entrainment in code-switched domains have been
extremely few and restricted to human-machine textual interactions. Our work
studies code-switched spontaneous speech between humans by answering the
following questions: 1) Do patterns of written and spoken entrainment in
monolingual settings generalize to code-switched settings? 2) Do patterns of
entrainment on code-switching in generated text generalize to spontaneous
code-switched speech? We find evidence of affirmative answers to both of these
questions, with important implications for the potentially ""universal"" nature
of entrainment as a communication phenomenon, and potential applications in
inclusive and interactive speech technology.",2023-11-13
"TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for
  Human-Aligned LLMs",2023-11-09 13:58:59+00:00,http://arxiv.org/abs/2311.05374v1,"Shuyi Xie, Wenlin Yao, Yong Dai, Shaobo Wang, Donlin Zhou, Lifeng Jin, Xinhua Feng, Pengzhi Wei, Yujie Lin, Zhichao Hu, Dong Yu, Zhengyou Zhang, Jing Nie, Yuhong Liu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) have shown impressive capabilities across
various natural language tasks. However, evaluating their alignment with human
preferences remains a challenge. To this end, we propose a comprehensive human
evaluation framework to assess LLMs' proficiency in following instructions on
diverse real-world tasks. We construct a hierarchical task tree encompassing 7
major areas covering over 200 categories and over 800 tasks, which covers
diverse capabilities such as question answering, reasoning, multiturn dialogue,
and text generation, to evaluate LLMs in a comprehensive and in-depth manner.
We also design detailed evaluation standards and processes to facilitate
consistent, unbiased judgments from human evaluators. A test set of over 3,000
instances is released, spanning different difficulty levels and knowledge
domains. Our work provides a standardized methodology to evaluate human
alignment in LLMs for both English and Chinese. We also analyze the feasibility
of automating parts of evaluation with a strong LLM (GPT-4). Our framework
supports a thorough assessment of LLMs as they are integrated into real-world
applications. We have made publicly available the task tree, TencentLLMEval
dataset, and evaluation methodology which have been demonstrated as effective
in assessing the performance of Tencent Hunyuan LLMs. By doing so, we aim to
facilitate the benchmarking of advances in the development of safe and
human-aligned LLMs.",2023-11-09
"Multitask Multimodal Prompted Training for Interactive Embodied Task
  Completion",2023-11-07 15:27:52+00:00,http://arxiv.org/abs/2311.04067v1,"Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia","cs.LG, cs.AI, cs.CV",dialogue,"Interactive and embodied tasks pose at least two fundamental challenges to
existing Vision & Language (VL) models, including 1) grounding language in
trajectories of actions and observations, and 2) referential disambiguation. To
tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a
unified encoder-decoder model that reasons over images and trajectories, and
casts action prediction as multimodal text generation. By unifying all tasks as
text generation, EMMA learns a language of actions which facilitates transfer
across tasks. Different to previous modular approaches with independently
trained components, we use a single multitask model where each task contributes
to goal completion. EMMA performs on par with similar models on several VL
benchmarks and sets a new state-of-the-art performance (36.81% success rate) on
the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided
agents in the Alexa Arena",2023-11-07
"LitCab: Lightweight Calibration of Language Models on Outputs of Varied
  Lengths",2023-10-30 00:30:34+00:00,http://arxiv.org/abs/2310.19208v1,"Xin Liu, Muhammad Khalifa, Lu Wang",cs.CL,dialogue,"A model is considered well-calibrated when its probability estimate aligns
with the actual likelihood of the output being correct. Calibrating language
models (LMs) is crucial, as it plays a vital role in detecting and mitigating
hallucinations, a common issue of LMs, as well as building more trustworthy
models. Yet, popular neural model calibration techniques are not well-suited
for LMs due to their lack of flexibility in discerning answer correctness and
their high computational costs. For instance, post-processing methods like
temperature scaling are often unable to reorder the candidate generations.
Moreover, training-based methods require finetuning the entire model, which is
impractical due to the increasing sizes of modern LMs. In this paper, we
present LitCab, a lightweight calibration mechanism consisting of a single
linear layer taking the input text representation and manipulateing the LM
output logits. LitCab improves model calibration by only adding < 2% of the
original model parameters. For evaluation, we construct CaT, a benchmark
consisting of 7 text generation tasks, covering responses ranging from short
phrases to paragraphs. We test LitCab with Llama2-7B, where it improves
calibration across all tasks, by reducing the average ECE score by 20%. We
further conduct a comprehensive evaluation with 7 popular open-sourced LMs from
GPT and LLaMA families, yielding the following key findings: (1) Larger models
within the same family exhibit better calibration on tasks with short
generation tasks, but not necessarily for longer ones. (2) GPT-family models
show superior calibration compared to LLaMA, Llama2 and Vicuna models despite
having much fewer parameters. (3) Finetuning pretrained model (e.g., LLaMA)
with samples of limited purpose (e.g., conversations) may lead to worse
calibration, highlighting the importance of finetuning setups for calibrating
LMs.",2023-10-30
"Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded
  Dialogue Generation",2023-10-28 19:42:28+00:00,http://arxiv.org/abs/2310.18794v1,"Yixin Wan, Fanyou Wu, Weijie Xu, Srinivasan H. Sengamedu","cs.CL, cs.AI",dialogue,"Model hallucination has been a crucial interest of research in Natural
Language Generation (NLG). In this work, we propose sequence-level certainty as
a common theme over hallucination in NLG, and explore the correlation between
sequence-level certainty and the level of hallucination in model responses. We
categorize sequence-level certainty into two aspects: probabilistic certainty
and semantic certainty, and reveal through experiments on Knowledge-Grounded
Dialogue Generation (KGDG) task that both a higher level of probabilistic
certainty and a higher level of semantic certainty in model responses are
significantly correlated with a lower level of hallucination. What's more, we
provide theoretical proof and analysis to show that semantic certainty is a
good estimator of probabilistic certainty, and therefore has the potential as
an alternative to probability-based certainty estimation in black-box
scenarios. Based on the observation on the relationship between certainty and
hallucination, we further propose Certainty-based Response Ranking (CRR), a
decoding-time method for mitigating hallucination in NLG. Based on our
categorization of sequence-level certainty, we propose 2 types of CRR approach:
Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually
sampled model responses using their arithmetic mean log-probability of the
entire sequence. S-CRR approaches certainty estimation from meaning-space, and
ranks a number of model response candidates based on their semantic certainty
level, which is estimated by the entailment-based Agreement Score (AS). Through
extensive experiments across 3 KGDG datasets, 3 decoding methods, and on 4
different models, we validate the effectiveness of our 2 proposed CRR methods
to reduce model hallucination.",2023-10-28
"INA: An Integrative Approach for Enhancing Negotiation Strategies with
  Reward-Based Dialogue System",2023-10-27 15:31:16+00:00,http://arxiv.org/abs/2310.18207v1,"Zishan Ahmad, Suman Saurabh, Vaishakh Sreekanth Menon, Asif Ekbal, Roshni Ramnani, Anutosh Maitra",cs.CL,dialogue,"In this paper, we propose a novel negotiation dialogue agent designed for the
online marketplace. Our agent is integrative in nature i.e, it possesses the
capability to negotiate on price as well as other factors, such as the addition
or removal of items from a deal bundle, thereby offering a more flexible and
comprehensive negotiation experience. We create a new dataset called
Integrative Negotiation Dataset (IND) to enable this functionality. For this
dataset creation, we introduce a new semi-automated data creation method, which
combines defining negotiation intents, actions, and intent-action simulation
between users and the agent to generate potential dialogue flows. Finally, the
prompting of GPT-J, a state-of-the-art language model, is done to generate
dialogues for a given intent, with a human-in-the-loop process for post-editing
and refining minor errors to ensure high data quality. We employ a set of novel
rewards, specifically tailored for the negotiation task to train our
Negotiation Agent, termed as the Integrative Negotiation Agent (INA). These
rewards incentivize the chatbot to learn effective negotiation strategies that
can adapt to various contextual requirements and price proposals. By leveraging
the IND, we train our model and conduct experiments to evaluate the
effectiveness of our reward-based dialogue system for negotiation. Our results
demonstrate that the proposed approach and reward system significantly enhance
the agent's negotiation capabilities. The INA successfully engages in
integrative negotiations, displaying the ability to dynamically adjust prices
and negotiate the inclusion or exclusion of items in a bundle deal",2023-10-27
"Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based
  Constructive Communication to Improve Communicative Competence for EFL
  earners",2023-10-27 14:29:36+00:00,http://arxiv.org/abs/2311.00718v1,Wei Zhou,cs.HC,dialogue,"Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)
language models, which have received specialized training to produce text based
on natural language inputs. Its purpose is to imitate human-like conversation
and can be implemented in multiple applications, such as chatbots, virtual
assistants, and language translation systems, starting with an introduction to
the new trends and differences between artificial intelligence, machine
learning, and artificial neural networks, and highlighting the rigorous
language logic and powerful text generation capabilities of Chat GPT. This
paper delves into how advances in artificial intelligence will shape e-learning
in the coming decades, particularly in terms of Chat- GPT's ability to improve
learners' Communicative Competence when English is a second language. The
combination of new trends in artificial intelligence, mainly in the particular
case of English as a second language, and, at the academic level, chatbot
technology, will be the next step in the replacement of the human academic
community by virtual assistants, apparently until a certain point. Despite the
controversy, this very innovative solution will be able to bridge the gap
between technology and education. Moreover, such innovative practices
facilitate communication by enabling its inclusion in various applications,
including virtual assistants, chatbots, and language education. Keyword: Chat
GPT, artificial intelligence, Communicative Competence, Communicative Language
Teaching (CLT)",2023-10-27
"""Honey, Tell Me What's Wrong"", Global Explanation of Textual
  Discriminative Models through Cooperative Generation",2023-10-27 11:26:27+00:00,http://arxiv.org/abs/2310.18063v1,"Antoine Chaffin, Julien Delaunay","cs.CL, cs.LG, I.2.7",dialogue,"The ubiquity of complex machine learning has raised the importance of
model-agnostic explanation algorithms. These methods create artificial
instances by slightly perturbing real instances, capturing shifts in model
decisions. However, such methods rely on initial data and only provide
explanations of the decision for these. To tackle these problems, we propose
Therapy, the first global and model-agnostic explanation method adapted to text
which requires no input dataset. Therapy generates texts following the
distribution learned by a classifier through cooperative generation. Because it
does not rely on initial samples, it allows to generate explanations even when
data is absent (e.g., for confidentiality reasons). Moreover, conversely to
existing methods that combine multiple local explanations into a global one,
Therapy offers a global overview of the model behavior on the input space. Our
experiments show that although using no input data to generate samples, Therapy
provides insightful information about features used by the classifier that is
competitive with the ones from methods relying on input samples and outperforms
them when input samples are not specific to the studied model.",2023-10-27
"Fidelity-Enriched Contrastive Search: Reconciling the
  Faithfulness-Diversity Trade-Off in Text Generation",2023-10-23 14:27:45+00:00,http://arxiv.org/abs/2310.14981v1,"Wei-Lin Chen, Cheng-Kuang Wu, Hsin-Hsi Chen, Chung-Chi Chen",cs.CL,dialogue,"In this paper, we address the hallucination problem commonly found in natural
language generation tasks. Language models often generate fluent and convincing
content but can lack consistency with the provided source, resulting in
potential inaccuracies. We propose a new decoding method called
Fidelity-Enriched Contrastive Search (FECS), which augments the contrastive
search framework with context-aware regularization terms. FECS promotes tokens
that are semantically similar to the provided source while penalizing
repetitiveness in the generated text. We demonstrate its effectiveness across
two tasks prone to hallucination: abstractive summarization and dialogue
generation. Results show that FECS consistently enhances faithfulness across
various language model sizes while maintaining output diversity comparable to
well-performing decoding algorithms.",2023-10-23
"NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling
  Social Norm Adherence and Violation",2023-10-23 04:38:34+00:00,http://arxiv.org/abs/2310.14563v2,"Oliver Li, Mallika Subramanian, Arkadiy Saakyan, Sky CH-Wang, Smaranda Muresan","cs.CL, cs.CY",dialogue,"Social norms fundamentally shape interpersonal communication. We present
NormDial, a high-quality dyadic dialogue dataset with turn-by-turn annotations
of social norm adherences and violations for Chinese and American cultures.
Introducing the task of social norm observance detection, our dataset is
synthetically generated in both Chinese and English using a human-in-the-loop
pipeline by prompting large language models with a small collection of
expert-annotated social norms. We show that our generated dialogues are of high
quality through human evaluation and further evaluate the performance of
existing large language models on this task. Our findings point towards new
directions for understanding the nuances of social norms as they manifest in
conversational contexts that span across languages and cultures.",2023-10-23
"Information Value: Measuring Utterance Predictability as Distance from
  Plausible Alternatives",2023-10-20 17:25:36+00:00,http://arxiv.org/abs/2310.13676v1,"Mario Giulianelli, Sarenne Wallbridge, Raquel Fernández",cs.CL,dialogue,"We present information value, a measure which quantifies the predictability
of an utterance relative to a set of plausible alternatives. We introduce a
method to obtain interpretable estimates of information value using neural text
generators, and exploit their psychometric predictive power to investigate the
dimensions of predictability that drive human comprehension behaviour.
Information value is a stronger predictor of utterance acceptability in written
and spoken dialogue than aggregates of token-level surprisal and it is
complementary to surprisal for predicting eye-tracked reading times.",2023-10-20
BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues,2023-10-20 16:53:51+00:00,http://arxiv.org/abs/2310.13650v1,"Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, Kai Chen",cs.CL,dialogue,"Interacting with human via high-quality multi-turn dialogues is a key feature
of large language models (LLMs). However, human-based evaluation of such
capability involves intensive manual labor. This report provides a preliminary
evaluation of existing large language models for human-style multi-turn
chatting, through an LLM-based approach. We start from real-world human
dialogues and keep the very first utterances as the ChatSEED. Then we prompt
LLMs to generate a full multi-turn dialogue (tens of utterances) based on the
ChatSEED, utterance by utterance. Finally, we adopt state-of-the-art LLMs
(GPT-4, \etc) as the judge to evaluate the generated dialogues. With different
evaluation protocols, we come to substantially identical conclusions. We find
that GPT-4 can generate human-style multi-turn dialogues with impressive
quality, significantly outperforms its counterparts. It's difficult for a
discriminator to distinguish between GPT-4 generated dialogues and human
dialogues. In contrast, other LLMs struggle to generate multi-turn dialogues of
satisfactory quality due to poor instruction-following capability, tendency to
generate lengthy utterances, or limited general capability. All data and codes
will be provided in https://github.com/open-compass/BotChat/ and we hope they
can serve as a valuable resource for evaluating multi-turn chatting
capabilities of LLMs.",2023-10-20
"DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for
  Emotion Recognition in Conversations",2023-10-17 16:15:34+00:00,http://arxiv.org/abs/2310.11374v1,"Yazhou Zhang, Mengyao Wang, Prayag Tiwari, Qiuchi Li, Benyou Wang, Jing Qin",cs.CL,dialogue,"Large language models (LLMs) and their variants have shown extraordinary
efficacy across numerous downstream natural language processing (NLP) tasks,
which has presented a new vision for the development of NLP. Despite their
remarkable performance in natural language generating (NLG), LLMs lack a
distinct focus on the emotion understanding domain. As a result, using LLMs for
emotion recognition may lead to suboptimal and inadequate precision. Another
limitation of LLMs is that they are typical trained without leveraging
multi-modal information. To overcome these limitations, we propose DialogueLLM,
a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA
models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.
The visual information is considered as the supplementary knowledge to
construct high-quality instructions. We offer a comprehensive evaluation of our
proposed model on three benchmarking emotion recognition in conversations (ERC)
datasets and compare the results against the SOTA baselines and other SOTA
LLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB
A100 GPU in 5 hours, facilitating reproducibility for other researchers.",2023-10-17
"BiLL-VTG: Bridging Large Language Models and Lightweight Visual Tools
  for Video-based Texts Generation",2023-10-16 17:05:56+00:00,http://arxiv.org/abs/2310.10586v1,"Ji Qi, Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, Lei Hou, Juanzi Li","cs.CV, cs.CL",dialogue,"Building models that generate textual responses to user instructions for
videos is a practical and challenging topic, as it requires both vision
understanding and knowledge reasoning. Compared to language and image
modalities, training efficiency remains a serious problem as existing studies
train models on massive sparse videos aligned with brief descriptions. In this
paper, we introduce BiLL-VTG, a fast adaptive framework that leverages large
language models (LLMs) to reasoning on videos based on essential lightweight
visual tools. Specifically, we reveal the key to response specific instructions
is the concentration on relevant video events, and utilize two visual tools of
structured scene graph generation and descriptive image caption generation to
gather and represent the events information. Thus, a LLM equipped with world
knowledge is adopted as the reasoning agent to achieve the response by
performing multiple reasoning steps on specified video events.To address the
difficulty of specifying events from agent, we further propose an
Instruction-oriented Video Events Recognition (InsOVER) algorithm based on the
efficient Hungarian matching to localize corresponding video events using
linguistic instructions, enabling LLMs to interact with long videos. Extensive
experiments on two typical video-based texts generations tasks show that our
tuning-free framework outperforms the pre-trained models including
Flamingo-80B, to achieve the state-of-the-art performance.",2023-10-16
Character-LLM: A Trainable Agent for Role-Playing,2023-10-16 07:58:56+00:00,http://arxiv.org/abs/2310.10158v1,"Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) can be used to serve as agents to simulate human
behaviors, given the powerful ability to understand human instructions and
provide high-quality generated texts. Such ability stimulates us to wonder
whether LLMs can simulate a person in a higher form than simple human
behaviors. Therefore, we aim to train an agent with the profile, experience,
and emotional states of a specific person instead of using limited prompts to
instruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs
to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,
etc. Our method focuses on editing profiles as experiences of a certain
character and training models to be personal simulacra with these experiences.
To assess the effectiveness of our approach, we build a test playground that
interviews trained agents and evaluates whether the agents \textit{memorize}
their characters and experiences. Experimental results show interesting
observations that help build future simulacra of humankind.",2023-10-16
"KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level
  Hallucination Detection",2023-10-13 12:12:34+00:00,http://arxiv.org/abs/2310.09044v1,"Sehyun Choi, Tianqing Fang, Zhaowei Wang, Yangqiu Song","cs.CL, cs.AI, cs.LG",dialogue,"Large Language Models (LLMs) have demonstrated remarkable human-level natural
language generation capabilities. However, their potential to generate
misinformation, often called the hallucination problem, poses a significant
risk to their deployment. A common approach to address this issue is to
retrieve relevant knowledge and fine-tune the LLM with the knowledge in its
input. Unfortunately, this method incurs high training costs and may cause
catastrophic forgetting for multi-tasking models. To overcome these
limitations, we propose a knowledge-constrained decoding method called KCTS
(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text
aligned with the reference knowledge at each decoding step using a knowledge
classifier score and MCTS (Monte-Carlo Tree Search). To adapt the
sequence-level knowledge classifier to token-level guidance, we also propose a
novel token-level hallucination detection method called RIPA (Reward Inflection
Point Approximation). Our empirical results on knowledge-grounded dialogue and
abstractive summarization demonstrate the strength of KCTS as a plug-and-play,
model-agnostic decoding method that can effectively reduce hallucinations in
natural language generation.",2023-10-13
"Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task
  Instruction Tuning",2023-10-12 09:39:17+00:00,http://arxiv.org/abs/2310.08166v1,"Junyu Lu, Dixiang Zhang, Xiaojun Wu, Xinyu Gao, Ruyi Gan, Jiaxing Zhang, Yan Song, Pingjian Zhang",cs.CL,dialogue,"Recent advancements enlarge the capabilities of large language models (LLMs)
in zero-shot image-to-text generation and understanding by integrating
multi-modal inputs. However, such success is typically limited to English
scenarios due to the lack of large-scale and high-quality non-English
multi-modal resources, making it extremely difficult to establish competitive
counterparts in other languages. In this paper, we introduce the Ziya-VL
series, a set of bilingual large-scale vision-language models (LVLMs) designed
to incorporate visual semantics into LLM for multi-modal dialogue. Composed of
Ziya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from
BLIP-2, further exploring the assistance of optimization schemes such as
instruction tuning, multi-stage training and low-rank adaptation module for
visual-language alignment. In addition, we stimulate the understanding ability
of GPT-4 in multi-modal scenarios, translating our gathered English image-text
datasets into Chinese and generating instruction-response through the
in-context learning method. The experiment results demonstrate that compared to
the existing LVLMs, Ziya-VL achieves competitive performance across a wide
range of English-only tasks including zero-shot image-text retrieval, image
captioning, and visual question answering. The evaluation leaderboard accessed
by GPT-4 also indicates that our models possess satisfactory image-text
understanding and generation capabilities in Chinese multi-modal scenario
dialogues. Code, demo and models are available at
~\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.",2023-10-12
"Harnessing Large Language Models' Empathetic Response Generation
  Capabilities for Online Mental Health Counselling Support",2023-10-12 03:33:06+00:00,http://arxiv.org/abs/2310.08017v1,"Siyuan Brandon Loh, Aravind Sesagiri Raamkumar","cs.CL, I.2",dialogue,"Large Language Models (LLMs) have demonstrated remarkable performance across
various information-seeking and reasoning tasks. These computational systems
drive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also
carry substantial promise in meeting the growing demands of mental health care,
albeit relatively unexplored. As such, this study sought to examine LLMs'
capability to generate empathetic responses in conversations that emulate those
in a mental health counselling setting. We selected five LLMs: version 3.5 and
version 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways
Language Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple
instructional prompt, these models responded to utterances derived from the
EmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we
compared their responses to those from traditional response generation dialogue
systems, which were fine-tuned on the ED dataset, along with human-generated
responses. Notably, we discovered that responses from the LLMs were remarkably
more empathetic in most scenarios. We position our findings in light of
catapulting advancements in creating empathetic conversational systems.",2023-10-12
Dobby: A Conversational Service Robot Driven by GPT-4,2023-10-10 04:34:00+00:00,http://arxiv.org/abs/2310.06303v1,"Carson Stark, Bohkyung Chun, Casey Charleston, Varsha Ravi, Luis Pabon, Surya Sunkari, Tarun Mohan, Peter Stone, Justin Hart","cs.RO, cs.AI",dialogue,"This work introduces a robotics platform which embeds a conversational AI
agent in an embodied system for natural language understanding and intelligent
decision-making for service tasks; integrating task planning and human-like
conversation. The agent is derived from a large language model, which has
learned from a vast corpus of general knowledge. In addition to generating
dialogue, this agent can interface with the physical world by invoking commands
on the robot; seamlessly merging communication and behavior. This system is
demonstrated in a free-form tour-guide scenario, in an HRI study combining
robots with and without conversational AI capabilities. Performance is measured
along five dimensions: overall effectiveness, exploration abilities,
scrutinization abilities, receptiveness to personification, and adaptability.",2023-10-10
Aligning Language Models with Human Preferences via a Bayesian Approach,2023-10-09 15:15:05+00:00,http://arxiv.org/abs/2310.05782v1,"Jiashuo Wang, Haozhao Wang, Shichao Sun, Wenjie Li",cs.CL,dialogue,"In the quest to advance human-centric natural language generation (NLG)
systems, ensuring alignment between NLG models and human preferences is
crucial. For this alignment, current popular methods leverage a reinforcement
learning (RL) approach with a reward model trained on feedback from humans.
However, inherent disagreements due to the subjective nature of human
preferences pose a significant challenge for training the reward model,
resulting in a deterioration of the NLG performance. To tackle this issue,
previous approaches typically rely on majority voting or averaging to
consolidate multiple inconsistent preferences into a merged one. Although
straightforward to understand and execute, such methods suffer from an
inability to capture the nuanced degrees of disaggregation among humans and may
only represent a specialized subset of individuals, thereby lacking the ability
to quantitatively disclose the universality of human preferences. To address
this challenge, this paper proposes a novel approach, which employs a Bayesian
framework to account for the distribution of disagreements among human
preferences as training a preference model, and names it as d-PM. Besides,
considering the RL strategy's inefficient and complex training process over the
training efficiency, we further propose utilizing the contrastive learning
strategy to train the NLG model with the preference scores derived from the
d-PM model. Extensive experiments on two human-centric NLG tasks, i.e.,
emotional support conversation and integrity ""Rule-of-Thumb"" generation, show
that our method consistently exceeds previous SOTA models in both automatic and
human evaluations.",2023-10-09
"Improving the Reliability of Large Language Models by Leveraging
  Uncertainty-Aware In-Context Learning",2023-10-07 12:06:53+00:00,http://arxiv.org/abs/2310.04782v1,"Yuchen Yang, Houqiang Li, Yanfeng Wang, Yu Wang",cs.CL,dialogue,"In recent years, large-scale language models (LLMs) have gained attention for
their impressive text generation capabilities. However, these models often face
the challenge of ""hallucination,"" which undermines their reliability. In this
study, we introduce an uncertainty-aware in-context learning framework to
empower the model to enhance or reject its output in response to uncertainty.
Human-defined methods for estimating uncertainty typically assume that
""uncertainty is lower when the model's response is correct compared to when it
is incorrect."" However, setting a precise threshold to distinguish correctness
is challenging. Therefore, we introduce uncertainty information as an
intermediary variable that implicitly influences the model's behavior. Our
innovative uncertainty-aware in-context learning framework involves fine-tuning
the LLM using a calibration dataset. Our aim is to improve the model's
responses by filtering out answers with high uncertainty while considering the
model's knowledge limitations. We evaluate the model's knowledge by examining
multiple responses to the same question for the presence of a correct answer.
When the model lacks relevant knowledge, the response should indicate that the
question cannot be answered. Conversely, when the model has relevant knowledge,
the response should provide the correct answer. Extensive experiments confirm
the effectiveness of our framework, leading to two key findings. First, the
logit output values of the LLM partly reflect inherent uncertainty. Second, our
model autonomously recognizes uncertainty, resulting in improved responses.",2023-10-07
"Controlling Topic-Focus Articulation in Meaning-to-Text Generation using
  Graph Neural Networks",2023-10-03 13:51:01+00:00,http://arxiv.org/abs/2310.02053v1,"Chunliu Wang, Rik van Noord, Johan Bos",cs.CL,dialogue,"A bare meaning representation can be expressed in various ways using natural
language, depending on how the information is structured on the surface level.
We are interested in finding ways to control topic-focus articulation when
generating text from meaning. We focus on distinguishing active and passive
voice for sentences with transitive verbs. The idea is to add pragmatic
information such as topic to the meaning representation, thereby forcing either
active or passive voice when given to a natural language generation system. We
use graph neural models because there is no explicit information about word
order in a meaning represented by a graph. We try three different methods for
topic-focus articulation (TFA) employing graph neural models for a
meaning-to-text generation task. We propose a novel encoding strategy about
node aggregation in graph neural models, which instead of traditional encoding
by aggregating adjacent node information, learns node representations by using
depth-first search. The results show our approach can get competitive
performance with state-of-art graph models on general text generation, and lead
to significant improvements on the task of active-passive conversion compared
to traditional adjacency-based aggregation strategies. Different types of TFA
can have a huge impact on the performance of the graph models.",2023-10-03
"Curriculum-Driven Edubot: A Framework for Developing Language Learning
  Chatbots Through Synthesizing Conversational Data",2023-09-28 19:14:18+00:00,http://arxiv.org/abs/2309.16804v1,"Yu Li, Shang Qu, Jili Shen, Shangchao Min, Zhou Yu",cs.CL,dialogue,"Chatbots have become popular in educational settings, revolutionizing how
students interact with material and how teachers teach. We present
Curriculum-Driven EduBot, a framework for developing a chatbot that combines
the interactive features of chatbots with the systematic material of English
textbooks to assist students in enhancing their conversational skills. We begin
by extracting pertinent topics from textbooks and then using large language
models to generate dialogues related to these topics. We then fine-tune an
open-source LLM using our generated conversational data to create our
curriculum-driven chatbot. User studies demonstrate that our chatbot
outperforms ChatGPT in leading curriculum-based dialogues and adapting its
dialogue to match the user's English proficiency level. By combining
traditional textbook methodologies with conversational AI, our approach offers
learners an interactive tool that aligns with their curriculum and provides
user-tailored conversation practice. This facilitates meaningful student-bot
dialogues and enriches the overall learning experience within the curriculum's
pedagogical framework.",2023-09-28
"When Automated Assessment Meets Automated Content Generation: Examining
  Text Quality in the Era of GPTs",2023-09-25 19:32:18+00:00,http://arxiv.org/abs/2309.14488v1,"Marialena Bevilacqua, Kezia Oketch, Ruiyang Qin, Will Stamey, Xinyuan Zhang, Yi Gan, Kai Yang, Ahmed Abbasi","cs.CL, cs.AI",dialogue,"The use of machine learning (ML) models to assess and score textual data has
become increasingly pervasive in an array of contexts including natural
language processing, information retrieval, search and recommendation, and
credibility assessment of online content. A significant disruption at the
intersection of ML and text are text-generating large-language models such as
generative pre-trained transformers (GPTs). We empirically assess the
differences in how ML-based scoring models trained on human content assess the
quality of content generated by humans versus GPTs. To do so, we propose an
analysis framework that encompasses essay scoring ML-models, human and
ML-generated essays, and a statistical model that parsimoniously considers the
impact of type of respondent, prompt genre, and the ML model used for
assessment model. A rich testbed is utilized that encompasses 18,460
human-generated and GPT-based essays. Results of our benchmark analysis reveal
that transformer pretrained language models (PLMs) more accurately score human
essay quality as compared to CNN/RNN and feature-based ML methods.
Interestingly, we find that the transformer PLMs tend to score GPT-generated
text 10-15\% higher on average, relative to human-authored documents.
Conversely, traditional deep learning and feature-based ML models score human
text considerably higher. Further analysis reveals that although the
transformer PLMs are exclusively fine-tuned on human text, they more
prominently attend to certain tokens appearing only in GPT-generated text,
possibly due to familiarity/overlap in pre-training. Our framework and results
have implications for text classification settings where automated scoring of
text is likely to be disrupted by generative AI.",2023-09-25
"BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment
  of Continuation Writing",2023-09-02 11:46:05+00:00,http://arxiv.org/abs/2309.00916v1,"Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang","cs.CL, cs.SD, eess.AS",dialogue,"The emergence of large language models (LLMs) has sparked significant
interest in extending their remarkable language capabilities to speech.
However, modality alignment between speech and text still remains an open
problem. Current solutions can be categorized into two strategies. One is a
cascaded approach where outputs (tokens or states) of a separately trained
speech recognition system are used as inputs for LLMs, which limits their
potential in modeling alignment between speech and text. The other is an
end-to-end approach that relies on speech instruction data, which is very
difficult to collect in large quantities. In this paper, we address these
issues and propose the BLSP approach that Bootstraps Language-Speech
Pre-training via behavior alignment of continuation writing. We achieve this by
learning a lightweight modality adapter between a frozen speech encoder and an
LLM, ensuring that the LLM exhibits the same generation behavior regardless of
the modality of input: a speech segment or its transcript. The training process
can be divided into two steps. The first step prompts an LLM to generate texts
with speech transcripts as prefixes, obtaining text continuations. In the
second step, these continuations are used as supervised signals to train the
modality adapter in an end-to-end manner. We demonstrate that this
straightforward process can extend the capabilities of LLMs to speech, enabling
speech recognition, speech translation, spoken language understanding, and
speech conversation, even in zero-shot cross-lingual scenarios.",2023-09-02
"Sparkles: Unlocking Chats Across Multiple Images for Multimodal
  Instruction-Following Models",2023-08-31 05:15:27+00:00,http://arxiv.org/abs/2308.16463v1,"Yupan Huang, Zaiqiao Meng, Fangyu Liu, Yixuan Su, Nigel Collier, Yutong Lu","cs.CV, cs.CL",dialogue,"Large language models exhibit enhanced zero-shot performance on various tasks
when fine-tuned with instruction-following data. Multimodal
instruction-following models extend these capabilities by integrating both text
and images. However, existing models such as MiniGPT-4 face challenges in
maintaining dialogue coherence in scenarios involving multiple images. A
primary reason is the lack of a specialized dataset for this critical
application. To bridge these gaps, we present SparklesChat, a multimodal
instruction-following model for open-ended dialogues across multiple images. To
support the training, we introduce SparklesDialogue, the first
machine-generated dialogue dataset tailored for word-level interleaved
multi-image and text interactions. Furthermore, we construct SparklesEval, a
GPT-assisted benchmark for quantitatively assessing a model's conversational
competence across multiple images and dialogue turns. Our experiments validate
the effectiveness of SparklesChat in understanding and reasoning across
multiple images and dialogue turns. Specifically, SparklesChat outperformed
MiniGPT-4 on established vision-and-language benchmarks, including the BISON
binary image selection task and the NLVR2 visual reasoning task. Moreover,
SparklesChat scored 8.56 out of 10 on SparklesEval, substantially exceeding
MiniGPT-4's score of 3.91 and nearing GPT-4's score of 9.26. Qualitative
evaluations further demonstrate SparklesChat's generality in handling
real-world applications. All resources will be available at
https://github.com/HYPJUDY/Sparkles.",2023-08-31
"Out of the Cage: How Stochastic Parrots Win in Cyber Security
  Environments",2023-08-23 12:11:27+00:00,http://arxiv.org/abs/2308.12086v2,"Maria Rigaki, Ondřej Lukáš, Carlos A. Catania, Sebastian Garcia","cs.CR, cs.AI, cs.CL",dialogue,"Large Language Models (LLMs) have gained widespread popularity across diverse
domains involving text generation, summarization, and various natural language
processing tasks. Despite their inherent limitations, LLM-based designs have
shown promising capabilities in planning and navigating open-world scenarios.
This paper introduces a novel application of pre-trained LLMs as agents within
cybersecurity network environments, focusing on their utility for sequential
decision-making processes.
  We present an approach wherein pre-trained LLMs are leveraged as attacking
agents in two reinforcement learning environments. Our proposed agents
demonstrate similar or better performance against state-of-the-art agents
trained for thousands of episodes in most scenarios and configurations. In
addition, the best LLM agents perform similarly to human testers of the
environment without any additional training process. This design highlights the
potential of LLMs to efficiently address complex decision-making tasks within
cybersecurity.
  Furthermore, we introduce a new network security environment named
NetSecGame. The environment is designed to eventually support complex
multi-agent scenarios within the network security domain. The proposed
environment mimics real network attacks and is designed to be highly modular
and adaptable for various scenarios.",2023-08-23
"Enhancing Performance on Seen and Unseen Dialogue Scenarios using
  Retrieval-Augmented End-to-End Task-Oriented System",2023-08-16 06:52:10+00:00,http://arxiv.org/abs/2308.08169v1,"Jianguo Zhang, Stephen Roller, Kun Qian, Zhiwei Liu, Rui Meng, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong","cs.CL, cs.AI",dialogue,"End-to-end task-oriented dialogue (TOD) systems have achieved promising
performance by leveraging sophisticated natural language understanding and
natural language generation capabilities of pre-trained models. This work
enables the TOD systems with more flexibility through a simple cache. The cache
provides the flexibility to dynamically update the TOD systems and handle both
existing and unseen dialogue scenarios. Towards this end, we first fine-tune a
retrieval module to effectively retrieve the most relevant information entries
from the cache. We then train end-to-end TOD models that can refer to and
ground on both dialogue history and retrieved information during TOD
generation. The cache is straightforward to construct, and the backbone models
of TOD systems are compatible with existing pre-trained generative models.
Extensive experiments demonstrate the superior performance of our framework,
with a notable improvement in non-empty joint goal accuracy by 6.7% compared to
strong baselines.",2023-08-16
ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,2023-08-14 15:13:04+00:00,http://arxiv.org/abs/2308.07201v1,"Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu",cs.CL,dialogue,"Text evaluation has historically posed significant challenges, often
demanding substantial labor and time cost. With the emergence of large language
models (LLMs), researchers have explored LLMs' potential as alternatives for
human evaluation. While these single-agent-based approaches show promise,
experimental results suggest that further advancements are needed to bridge the
gap between their current effectiveness and human-level evaluation quality.
Recognizing that best practices of human evaluation processes often involve
multiple human annotators collaborating in the evaluation, we resort to a
multi-agent debate framework, moving beyond single-agent prompting strategies.
The multi-agent-based approach enables a group of LLMs to synergize with an
array of intelligent counterparts, harnessing their distinct capabilities and
expertise to enhance efficiency and effectiveness in handling intricate tasks.
In this paper, we construct a multi-agent referee team called ChatEval to
autonomously discuss and evaluate the quality of generated responses from
different models on open-ended questions and traditional natural language
generation (NLG) tasks. Our analysis shows that ChatEval transcends mere
textual scoring, offering a human-mimicking evaluation process for reliable
assessments. Our code is available at https://github.com/chanchimin/ChatEval.",2023-08-14
Dataflow Dialogue Generation,2023-08-04 13:40:54+00:00,http://arxiv.org/abs/2308.02323v1,"Joram Meron, Victor Guimarães",cs.CL,dialogue,"We demonstrate task-oriented dialogue generation within the dataflow dialogue
paradigm. We show an example of agenda driven dialogue generation for the
MultiWOZ domain, and an example of generation without an agenda for the
SMCalFlow domain, where we show an improvement in the accuracy of the
translation of user requests to dataflow expressions when the generated
dialogues are used to augment the translation training dataset.",2023-08-04
"Controllable Generation of Dialogue Acts for Dialogue Systems via
  Few-Shot Response Generation and Ranking",2023-07-26 18:16:45+00:00,http://arxiv.org/abs/2307.14440v1,"Angela Ramirez, Karik Agarwal, Juraj Juraska, Utkarsh Garg, Marilyn A. Walker",cs.CL,dialogue,"Dialogue systems need to produce responses that realize multiple types of
dialogue acts (DAs) with high semantic fidelity. In the past, natural language
generators (NLGs) for dialogue were trained on large parallel corpora that map
from a domain-specific DA and its semantic attributes to an output utterance.
Recent work shows that pretrained language models (LLMs) offer new
possibilities for controllable NLG using prompt-based learning. Here we develop
a novel few-shot overgenerate-and-rank approach that achieves the controlled
generation of DAs. We compare eight few-shot prompt styles that include a novel
method of generating from textual pseudo-references using a textual style
transfer approach. We develop six automatic ranking functions that identify
outputs with both the correct DA and high semantic accuracy at generation time.
We test our approach on three domains and four LLMs. To our knowledge, this is
the first work on NLG for dialogue that automatically ranks outputs using both
DA and attribute accuracy. For completeness, we compare our results to
fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results
show that several prompt settings achieve perfect DA accuracy, and near perfect
semantic accuracy (99.81%) and perform better than few-shot fine-tuning.",2023-07-26
Adversarial Conversational Shaping for Intelligent Agents,2023-07-20 12:44:47+00:00,http://arxiv.org/abs/2307.11785v1,"Piotr Tarasiewicz, Sultan Kenjeyev, Ilana Sebag, Shehab Alshehabi","cs.CL, cs.LG",dialogue,"The recent emergence of deep learning methods has enabled the research
community to achieve state-of-the art results in several domains including
natural language processing. However, the current robocall system remains
unstable and inaccurate: text generator and chat-bots can be tedious and
misunderstand human-like dialogue. In this work, we study the performance of
two models able to enhance an intelligent conversational agent through
adversarial conversational shaping: a generative adversarial network with
policy gradient (GANPG) and a generative adversarial network with reward for
every generation step (REGS) based on the REGS model presented in Li et al.
[18] . This model is able to assign rewards to both partially and fully
generated text sequences. We discuss performance with different training
details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning
framework.",2023-07-20
"A Dialogue System for Assessing Activities of Daily Living: Improving
  Consistency with Grounded Knowledge",2023-07-15 22:41:59+00:00,http://arxiv.org/abs/2307.07544v1,"Zhecheng Sheng, Raymond Finzel, Michael Lucke, Sheena Dufresne, Maria Gini, Serguei Pakhomov","cs.CL, cs.AI",dialogue,"In healthcare, the ability to care for oneself is reflected in the
""Activities of Daily Living (ADL),"" which serve as a measure of functional
ability (functioning). A lack of functioning may lead to poor living conditions
requiring personal care and assistance. To accurately identify those in need of
support, assistance programs continuously evaluate participants' functioning
across various domains. However, the assessment process may encounter
consistency issues when multiple assessors with varying levels of expertise are
involved. Novice assessors, in particular, may lack the necessary preparation
for real-world interactions with participants. To address this issue, we
developed a dialogue system that simulates interactions between assessors and
individuals of varying functioning in a natural and reproducible way. The
dialogue system consists of two major modules, one for natural language
understanding (NLU) and one for natural language generation (NLG),
respectively. In order to generate responses consistent with the underlying
knowledge base, the dialogue system requires both an understanding of the
user's query and of biographical details of an individual being simulated. To
fulfill this requirement, we experimented with query classification and
generated responses based on those biographical details using some recently
released InstructGPT-like models.",2023-07-15
Zero-shot NLG evaluation through Pairware Comparisons with LLMs,2023-07-15 22:02:12+00:00,http://arxiv.org/abs/2307.07889v1,"Adian Liusie, Potsawee Manakul, Mark J. F. Gales",cs.CL,dialogue,"Evaluating Natural Language Generation (NLG) outputs is crucial but laborious
and expensive. While various automatic NLG assessment methods have been
proposed, they often are quite task-specific and have to be engineered with a
particular domain and attribute in mind. In this work, we propose a robust
zero-shot approach to NLG evaluation using pairwise comparative judgment with
open-source Large Language Models (LLMs). The motivation for this approach is
that even as humans, it is easier to determine which of two options are better,
than it is to independently objectively score each option. We use this insight
and leverage the emergent abilities of LLMs, where we probe FlanT5 to determine
which of two candidate responses is better, rather than assigning absolute
scores. Our results demonstrate that comparative assessment is a more effective
approach than absolute scoring, enabling smaller open-source LLMs to achieve
comparable performance to larger public access APIs. We evaluate systems on
both summary evaluation and dialogue response generation, and show that
opensource LLMs can lead to good correlations with human scores for a range of
different attributes.",2023-07-15
"DIALGEN: Collaborative Human-LM Generated Dialogues for Improved
  Understanding of Human-Human Conversations",2023-07-13 20:02:50+00:00,http://arxiv.org/abs/2307.07047v1,"Bo-Ru Lu, Nikita Haduong, Chia-Hsuan Lee, Zeqiu Wu, Hao Cheng, Paul Koester, Jean Utke, Tao Yu, Noah A. Smith, Mari Ostendorf",cs.CL,dialogue,"Applications that could benefit from automatic understanding of human-human
conversations often come with challenges associated with private information in
real-world data such as call center or clinical conversations. Working with
protected data also increases costs of annotation, which limits technology
development. To address these challenges, we propose DIALGEN, a
human-in-the-loop semi-automated dialogue generation framework. DIALGEN uses a
language model (ChatGPT) that can follow schema and style specifications to
produce fluent conversational text, generating a complex conversation through
iteratively generating subdialogues and using human feedback to correct
inconsistencies or redirect the flow. In experiments on structured
summarization of agent-client information gathering calls, framed as dialogue
state tracking, we show that DIALGEN data enables significant improvement in
model performance.",2023-07-13
"DecompEval: Evaluating Generated Texts as Unsupervised Decomposed
  Question Answering",2023-07-13 16:16:51+00:00,http://arxiv.org/abs/2307.06869v1,"Pei Ke, Fei Huang, Fei Mi, Yasheng Wang, Qun Liu, Xiaoyan Zhu, Minlie Huang","cs.CL, cs.AI",dialogue,"Existing evaluation metrics for natural language generation (NLG) tasks face
the challenges on generalization ability and interpretability. Specifically,
most of the well-performed metrics are required to train on evaluation datasets
of specific NLG tasks and evaluation dimensions, which may cause over-fitting
to task-specific datasets. Furthermore, existing metrics only provide an
evaluation score for each dimension without revealing the evidence to interpret
how this score is obtained. To deal with these challenges, we propose a simple
yet effective metric called DecompEval. This metric formulates NLG evaluation
as an instruction-style question answering task and utilizes instruction-tuned
pre-trained language models (PLMs) without training on evaluation datasets,
aiming to enhance the generalization ability. To make the evaluation process
more interpretable, we decompose our devised instruction-style question about
the quality of generated texts into the subquestions that measure the quality
of each sentence. The subquestions with their answers generated by PLMs are
then recomposed as evidence to obtain the evaluation result. Experimental
results show that DecompEval achieves state-of-the-art performance in untrained
metrics for evaluating text summarization and dialogue generation, which also
exhibits strong dimension-level / task-level generalization ability and
interpretability.",2023-07-13
"Learning to Generate Equitable Text in Dialogue from Biased Training
  Data",2023-07-10 01:44:13+00:00,http://arxiv.org/abs/2307.04303v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.AI",dialogue,"The ingrained principles of fairness in a dialogue system's decision-making
process and generated responses are crucial for user engagement, satisfaction,
and task achievement. Absence of equitable and inclusive principles can hinder
the formation of common ground, which in turn negatively impacts the overall
performance of the system. For example, misusing pronouns in a user interaction
may cause ambiguity about the intended subject. Yet, there is no comprehensive
study of equitable text generation in dialogue. Aptly, in this work, we use
theories of computational learning to study this problem. We provide formal
definitions of equity in text generation, and further, prove formal connections
between learning human-likeness and learning equity: algorithms for improving
equity ultimately reduce to algorithms for improving human-likeness (on
augmented data). With this insight, we also formulate reasonable conditions
under which text generation algorithms can learn to generate equitable text
without any modifications to the biased training data on which they learn. To
exemplify our theory in practice, we look at a group of algorithms for the
GuessWhat?! visual dialogue game and, using this example, test our theory
empirically. Our theory accurately predicts relative-performance of multiple
algorithms in generating equitable text as measured by both human and automated
evaluation.",2023-07-10
"Opening up ChatGPT: Tracking openness, transparency, and accountability
  in instruction-tuned text generators",2023-07-08 07:08:20+00:00,http://arxiv.org/abs/2307.05532v1,"Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse",cs.CL,dialogue,"Large language models that exhibit instruction-following behaviour represent
one of the biggest recent upheavals in conversational interfaces, a trend in
large part fuelled by the release of OpenAI's ChatGPT, a proprietary large
language model for text generation fine-tuned through reinforcement learning
from human feedback (LLM+RLHF). We review the risks of relying on proprietary
software and survey the first crop of open-source projects of comparable
architecture and functionality. The main contribution of this paper is to show
that openness is differentiated, and to offer scientific documentation of
degrees of openness in this fast-moving field. We evaluate projects in terms of
openness of code, training data, model weights, RLHF data, licensing,
scientific documentation, and access methods. We find that while there is a
fast-growing list of projects billing themselves as 'open source', many inherit
undocumented data of dubious legality, few share the all-important
instruction-tuning (a key site where human annotation labour is involved), and
careful scientific documentation is exceedingly rare. Degrees of openness are
relevant to fairness and accountability at all points, from data collection and
curation to model architecture, and from training and fine-tuning to release
and deployment.",2023-07-08
"Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement
  Learning",2023-07-05 19:48:03+00:00,http://arxiv.org/abs/2307.02620v1,"Colin Bellinger, Mark Crowley, Isaac Tamblyn","cs.LG, cs.AI, 68T01, I.2.0",dialogue,"Reinforcement learning (RL) has been shown to learn sophisticated control
policies for complex tasks including games, robotics, heating and cooling
systems and text generation. The action-perception cycle in RL, however,
generally assumes that a measurement of the state of the environment is
available at each time step without a cost. In applications such as deep-sea
and planetary robot exploration, materials design and medicine, however, there
can be a high cost associated with measuring, or even approximating, the state
of the environment. In this paper, we survey the recently growing literature
that adopts the perspective that an RL agent might not need, or even want, a
costly measurement at each time step. Within this context, we propose the Deep
Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the
literature and empirically evaluate it on OpenAI gym and Atari Pong
environments. Our results, show that DMSOA learns a better policy with fewer
decision steps and measurements than the considered alternative from the
literature.",2023-07-05
"Knowledge-Aware Audio-Grounded Generative Slot Filling for Limited
  Annotated Data",2023-07-04 15:05:42+00:00,http://arxiv.org/abs/2307.01764v1,"Guangzhi Sun, Chao Zhang, Ivan Vulić, Paweł Budzianowski, Philip C. Woodland",cs.CL,dialogue,"Manually annotating fine-grained slot-value labels for task-oriented dialogue
(ToD) systems is an expensive and time-consuming endeavour. This motivates
research into slot-filling methods that operate with limited amounts of
labelled data. Moreover, the majority of current work on ToD is based solely on
text as the input modality, neglecting the additional challenges of imperfect
automatic speech recognition (ASR) when working with spoken language. In this
work, we propose a Knowledge-Aware Audio-Grounded generative slot-filling
framework, termed KA2G, that focuses on few-shot and zero-shot slot filling for
ToD with speech input. KA2G achieves robust and data-efficient slot filling for
speech-based ToD by 1) framing it as a text generation task, 2) grounding text
generation additionally in the audio modality, and 3) conditioning on available
external knowledge (e.g. a predefined list of possible slot values). We show
that combining both modalities within the KA2G framework improves the
robustness against ASR errors. Further, the knowledge-aware slot-value
generator in KA2G, implemented via a pointer generator mechanism, particularly
benefits few-shot and zero-shot learning. Experiments, conducted on the
standard speech-based single-turn SLURP dataset and a multi-turn dataset
extracted from a commercial ToD system, display strong and consistent gains
over prior work, especially in few-shot and zero-shot setups.",2023-07-04
Knowledge Graph for NLG in the context of conversational agents,2023-07-04 08:03:33+00:00,http://arxiv.org/abs/2307.01548v1,"Hussam Ghanem, Massinissa Atmani, Christophe Cruz",cs.AI,dialogue,"The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness
of the responses provided by a conversational agent. While generating answers
during conversations consists in generating text from these KGs, it is still
regarded as a challenging task that has gained significant attention in recent
years. In this document, we provide a review of different architectures used
for knowledge graph-to-text generation including: Graph Neural Networks, the
Graph Transformer, and linearization with seq2seq models. We discuss the
advantages and limitations of each architecture and conclude that the choice of
architecture will depend on the specific requirements of the task at hand. We
also highlight the importance of considering constraints such as execution time
and model validity, particularly in the context of conversational agents. Based
on these constraints and the availability of labeled data for the domains of
DAVI, we choose to use seq2seq Transformer-based models (PLMs) for the
Knowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of
kg-to-text generation on PLMs and to explore the emotional and multilingual
dimensions in our future work. Overall, this review provides insights into the
different approaches for knowledge graph-to-text generation and outlines future
directions for research in this area.",2023-07-04
"PatternGPT :A Pattern-Driven Framework for Large Language Model Text
  Generation",2023-07-02 04:32:41+00:00,http://arxiv.org/abs/2307.00470v4,"Le Xiao, Xin Shan","cs.CL, cs.AI",dialogue,"Large language models(LLMS)have shown excellent text generation capabilities,
capable of generating fluent human-like responses for many downstream tasks.
However, applying large language models to real-world critical tasks remains
challenging due to their susceptibility to hallucinations and inability to
directly use external knowledge. To cope with the above challenges, this paper
proposes PatternGPT, a pattern-driven text generation framework for Large
Language Models. Firstly, the framework utilizes the extraction capability of
Large Language Models to generate rich and diversified structured and
formalized patterns, which facilitates the introduction of external knowledge
to do the computation, and then draws on the idea of federated learning to use
multiple agents to achieve the sharing in order to obtain more diversified
patterns, and finally uses judgment criteria and optimization algorithm to
search for high-quality patterns to guide the generation of models. Finally,
external knowledge such as judgment criteria and optimization algorithms are
used to search for high-quality patterns, and the searched patterns are used to
guide model generation. This framework has the advantages of generating
diversified patterns, protecting data privacy, combining external knowledge,
and improving the quality of generation, which provides an effective method to
optimize the text generation capability of large language models, and make it
better applied to the field of intelligent dialogue and content generation.",2023-07-02
Personality Traits in Large Language Models,2023-07-01 00:58:51+00:00,http://arxiv.org/abs/2307.00184v1,"Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, Maja Matarić","cs.CL, cs.AI, cs.CY, cs.HC, 68T35, I.2.7",dialogue,"The advent of large language models (LLMs) has revolutionized natural
language processing, enabling the generation of coherent and contextually
relevant text. As LLMs increasingly power conversational agents, the
synthesized personality embedded in these models by virtue of their training on
large amounts of human-generated data draws attention. Since personality is an
important factor determining the effectiveness of communication, we present a
comprehensive method for administering validated psychometric tests and
quantifying, analyzing, and shaping personality traits exhibited in text
generated from widely-used LLMs. We find that: 1) personality simulated in the
outputs of some LLMs (under specific prompting configurations) is reliable and
valid; 2) evidence of reliability and validity of LLM-simulated personality is
stronger for larger and instruction fine-tuned models; and 3) personality in
LLM outputs can be shaped along desired dimensions to mimic specific
personality profiles. We also discuss potential applications and ethical
implications of our measurement and shaping framework, especially regarding
responsible use of LLMs.",2023-07-01
Open-Domain Text Evaluation via Meta Distribution Modeling,2023-06-20 20:37:54+00:00,http://arxiv.org/abs/2306.11879v1,"Sidi Lu, Asli Celikyilmaz, Tianlu Wang, Nanyun Peng",cs.CL,dialogue,"Recent advances in open-domain text generation models powered by large
pre-trained language models (LLMs) have achieved remarkable performance.
However, evaluating and controlling these models for desired attributes remains
a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and
METEOR are insufficient for open-ended generation tasks. Similarly, while
trainable discriminator-based evaluation metrics show promise, obtaining
high-quality training data is a non-trivial task. In this paper, we introduce a
novel approach to evaluate open-domain generation - the Meta-Distribution
Methods (MDM). Drawing on the correlation between the rising parameter counts
and the improving performance of LLMs, MDM creates a mapping from the contrast
of two probabilistic distributions -- one known to be superior to the other --
to quality measures, which can be viewed as a distribution of distributions
i.e. Meta-Distribution. We investigate MDM for open-domain text generation
evaluation under two paradigms: 1) \emph{Generative} MDM, which leverages the
Meta-Distribution Methods to generate in-domain negative samples for training
discriminator-based metrics; 2) \emph{Discriminative} MDM, which directly uses
distribution discrepancies between two language models for evaluation. Our
experiments on multi-turn dialogue and factuality in abstractive summarization
demonstrate that MDMs correlate better with human judgment than existing
automatic evaluation metrics on both tasks, highlighting the strong performance
and generalizability of such methods.",2023-06-20
Learning to Generate Better Than Your LLM,2023-06-20 18:19:17+00:00,http://arxiv.org/abs/2306.11816v1,"Jonathan D. Chang, Kiante Brantley, Rajkumar Ramamurthy, Dipendra Misra, Wen Sun","cs.LG, cs.AI, cs.CL",dialogue,"Reinforcement learning (RL) has emerged as a powerful paradigm for
fine-tuning Large Language Models (LLMs) for conditional text generation. In
particular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent
conversations with users by incorporating RL and feedback from humans. Inspired
by learning-to-search algorithms and capitalizing on key properties of text
generation, we seek to investigate reinforcement learning algorithms beyond
general purpose algorithms such as Proximal policy optimization (PPO). In
particular, we extend RL algorithms to allow them to interact with a dynamic
black-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a
suite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive
review and CommonGen text generation task from the GRUE benchmark. We show that
our RL algorithms achieve higher performance than supervised learning (SL) and
default PPO baselines, demonstrating the benefit of interaction with the guide
LLM. On CommonGen, we not only outperform our SL baselines but also improve
beyond PPO across a variety of lexical and semantic metrics beyond the one we
optimized for. Notably, on the IMDB dataset, we show that our GPT-2 based
policy outperforms the zero-shot GPT-3 oracle, indicating that our algorithms
can learn from a powerful, black-box GPT-3 oracle with a simpler, cheaper, and
publicly available GPT-2 model while gaining performance.",2023-06-20
"ChatGPT is not Enough: Enhancing Large Language Models with Knowledge
  Graphs for Fact-aware Language Modeling",2023-06-20 12:21:06+00:00,http://arxiv.org/abs/2306.11489v1,"Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, Xindong Wu","cs.CL, cs.AI",dialogue,"Recently, ChatGPT, a representative large language model (LLM), has gained
considerable attention due to its powerful emergent abilities. Some researchers
suggest that LLMs could potentially replace structured knowledge bases like
knowledge graphs (KGs) and function as parameterized knowledge bases. However,
while LLMs are proficient at learning probabilistic language patterns based on
large corpus and engaging in conversations with humans, they, like previous
smaller pre-trained language models (PLMs), still have difficulty in recalling
facts while generating knowledge-grounded contents. To overcome these
limitations, researchers have proposed enhancing data-driven PLMs with
knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus
improving their performance to generate texts requiring factual knowledge and
providing more informed responses to user queries. This paper reviews the
studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced
pre-trained language models (KGPLMs) as well as their applications. Inspired by
existing studies on KGPLM, this paper proposes to enhance LLMs with KGs by
developing knowledge graph-enhanced large language models (KGLLMs). KGLLM
provides a solution to enhance LLMs' factual reasoning ability, opening up new
avenues for LLM research.",2023-06-20
"FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for
  Task-Oriented Dialogue",2023-06-17 10:40:07+00:00,http://arxiv.org/abs/2306.10315v1,"Weihao Zeng, Keqing He, Yejie Wang, Chen Zeng, Jingang Wang, Yunsen Xian, Weiran Xu",cs.CL,dialogue,"Pre-trained language models based on general text enable huge success in the
NLP scenario. But the intrinsical difference of linguistic patterns between
general text and task-oriented dialogues makes existing pre-trained language
models less useful in practice. Current dialogue pre-training methods rely on a
contrastive framework and face the challenges of both selecting true positives
and hard negatives. In this paper, we propose a novel dialogue pre-training
model, FutureTOD, which distills future knowledge to the representation of the
previous dialogue context using a self-training framework. Our intuition is
that a good dialogue representation both learns local context information and
predicts future information. Extensive experiments on diverse downstream
dialogue tasks demonstrate the effectiveness of our model, especially the
generalization, robustness, and learning discriminative dialogue
representations capabilities.",2023-06-17
On the N-gram Approximation of Pre-trained Language Models,2023-06-12 06:42:08+00:00,http://arxiv.org/abs/2306.06892v1,"Aravind Krishnan, Jesujoba Alabi, Dietrich Klakow",cs.CL,dialogue,"Large pre-trained language models (PLMs) have shown remarkable performance
across various natural language understanding (NLU) tasks, particularly in
low-resource settings. Nevertheless, their potential in Automatic Speech
Recognition (ASR) remains largely unexplored. This study investigates the
potential usage of PLMs for language modelling in ASR. We compare the
application of large-scale text sampling and probability conversion for
approximating GPT-2 into an n-gram model. Furthermore, we introduce a
vocabulary-restricted decoding method for random sampling, and evaluate the
effects of domain difficulty and data size on the usability of generated text.
Our findings across eight domain-specific corpora support the use of
sampling-based approximation and show that interpolating with a large sampled
corpus improves test perplexity over a baseline trigram by 15%. Our
vocabulary-restricted decoding method pushes this improvement further by 5% in
domain-specific settings.",2023-06-12
Emotion and Sentiment Guided Paraphrasing,2023-06-08 20:59:40+00:00,http://arxiv.org/abs/2306.05556v1,"Justin J. Xie, Ameeta Agrawal","cs.CL, cs.LG",dialogue,"Paraphrase generation, a.k.a. paraphrasing, is a common and important task in
natural language processing. Emotional paraphrasing, which changes the emotion
embodied in a piece of text while preserving its meaning, has many potential
applications, including moderating online dialogues and preventing
cyberbullying. We introduce a new task of fine-grained emotional paraphrasing
along emotion gradients, that is, altering the emotional intensities of the
paraphrases in fine-grained settings following smooth variations in affective
dimensions while preserving the meaning of the original text. We reconstruct
several widely used paraphrasing datasets by augmenting the input and target
texts with their fine-grained emotion labels. Then, we propose a framework for
emotion and sentiment guided paraphrasing by leveraging pre-trained language
models for conditioned text generation. Extensive evaluation of the fine-tuned
models suggests that including fine-grained emotion labels in the paraphrase
task significantly improves the likelihood of obtaining high-quality
paraphrases that reflect the desired emotions while achieving consistently
better scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.",2023-06-08
"IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for
  multilayer summarization of clinical conversations?",2023-06-07 10:47:33+00:00,http://arxiv.org/abs/2306.04328v1,Dhananjay Srivastava,cs.CL,dialogue,"Clinical conversation summarization has become an important application of
Natural language Processing. In this work, we intend to analyze summarization
model ensembling approaches, that can be utilized to improve the overall
accuracy of the generated medical report called chart note. The work starts
with a single summarization model creating the baseline. Then leads to an
ensemble of summarization models trained on a separate section of the chart
note. This leads to the final approach of passing the generated results to
another summarization model in a multi-layer/stage fashion for better coherency
of the generated text. Our results indicate that although an ensemble of models
specialized in each section produces better results, the multi-layer/stage
approach does not improve accuracy. The code for the above paper is available
at https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git",2023-06-07
"Correction of Errors in Preference Ratings from Automated Metrics for
  Text Generation",2023-06-06 17:09:29+00:00,http://arxiv.org/abs/2306.03866v1,"Jan Deriu, Pius von Däniken, Don Tuggener, Mark Cieliebak","cs.CL, cs.AI",dialogue,"A major challenge in the field of Text Generation is evaluation: Human
evaluations are cost-intensive, and automated metrics often display
considerable disagreement with human judgments. In this paper, we propose a
statistical model of Text Generation evaluation that accounts for the
error-proneness of automated metrics when used to generate preference rankings
between system outputs. We show that existing automated metrics are generally
over-confident in assigning significant differences between systems in this
setting. However, our model enables an efficient combination of human and
automated ratings to remedy the error-proneness of the automated metrics. We
show that using this combination, we only require about 50% of the human
annotations typically used in evaluations to arrive at robust and statistically
significant results while yielding the same evaluation outcome as the pure
human evaluation in 95% of cases. We showcase the benefits of approach for
three text generation tasks: dialogue systems, machine translation, and text
summarization.",2023-06-06
"Injecting knowledge into language generation: a case study in
  auto-charting after-visit care instructions from medical dialogue",2023-06-06 13:13:27+00:00,http://arxiv.org/abs/2306.03652v1,"Maksim Eremeev, Ilya Valmianski, Xavier Amatriain, Anitha Kannan",cs.CL,dialogue,"Factual correctness is often the limiting factor in practical applications of
natural language generation in high-stakes domains such as healthcare. An
essential requirement for maintaining factuality is the ability to deal with
rare tokens. This paper focuses on rare tokens that appear in both the source
and the reference sequences, and which, when missed during generation, decrease
the factual correctness of the output text. For high-stake domains that are
also knowledge-rich, we show how to use knowledge to (a) identify which rare
tokens that appear in both source and reference are important and (b) uplift
their conditional probability. We introduce the ``utilization rate'' that
encodes knowledge and serves as a regularizer by maximizing the marginal
probability of selected tokens. We present a study in a knowledge-rich domain
of healthcare, where we tackle the problem of generating after-visit care
instructions based on patient-doctor dialogues. We verify that, in our dataset,
specific medical concepts with high utilization rates are underestimated by
conventionally trained sequence-to-sequence models. We observe that correcting
this with our approach to knowledge injection reduces the uncertainty of the
model as well as improves factuality and coherence without negatively impacting
fluency.",2023-06-06
"Diverse and Faithful Knowledge-Grounded Dialogue Generation via
  Sequential Posterior Inference",2023-06-01 21:23:13+00:00,http://arxiv.org/abs/2306.01153v1,"Yan Xu, Deqian Kong, Dehong Xu, Ziwei Ji, Bo Pang, Pascale Fung, Ying Nian Wu",cs.CL,dialogue,"The capability to generate responses with diversity and faithfulness using
factual knowledge is paramount for creating a human-like, trustworthy dialogue
system. Common strategies either adopt a two-step paradigm, which optimizes
knowledge selection and response generation separately, and may overlook the
inherent correlation between these two tasks, or leverage conditional
variational method to jointly optimize knowledge selection and response
generation by employing an inference network. In this paper, we present an
end-to-end learning framework, termed Sequential Posterior Inference (SPI),
capable of selecting knowledge and generating dialogues by approximately
sampling from the posterior distribution. Unlike other methods, SPI does not
require the inference network or assume a simple geometry of the posterior
distribution. This straightforward and intuitive inference procedure of SPI
directly queries the response generation model, allowing for accurate knowledge
selection and generation of faithful responses. In addition to modeling
contributions, our experimental results on two common dialogue datasets (Wizard
of Wikipedia and Holl-E) demonstrate that SPI outperforms previous strong
baselines according to both automatic and human evaluation metrics.",2023-06-01
"Deliberate then Generate: Enhanced Prompting Framework for Text
  Generation",2023-05-31 13:23:04+00:00,http://arxiv.org/abs/2305.19835v1,"Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan, Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian, JingBo Zhu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) have shown remarkable success across a wide
range of natural language generation tasks, where proper prompt designs make
great impacts. While existing prompting methods are normally restricted to
providing correct information, in this paper, we encourage the model to
deliberate by proposing a novel Deliberate then Generate (DTG) prompting
framework, which consists of error detection instructions and candidates that
may contain errors. DTG is a simple yet effective technique that can be applied
to various text generation tasks with minimal modifications. We conduct
extensive experiments on 20+ datasets across 7 text generation tasks, including
summarization, translation, dialogue, and more. We show that DTG consistently
outperforms existing prompting methods and achieves state-of-the-art
performance on multiple text generation tasks. We also provide in-depth
analyses to reveal the underlying mechanisms of DTG, which may inspire future
research on prompting for LLMs.",2023-05-31
"Knowledge Graph-Augmented Language Models for Knowledge-Grounded
  Dialogue Generation",2023-05-30 08:36:45+00:00,http://arxiv.org/abs/2305.18846v1,"Minki Kang, Jin Myung Kwak, Jinheon Baek, Sung Ju Hwang","cs.CL, cs.AI, cs.LG",dialogue,"Language models have achieved impressive performances on dialogue generation
tasks. However, when generating responses for a conversation that requires
factual knowledge, they are far from perfect, due to an absence of mechanisms
to retrieve, encode, and reflect the knowledge in the generated responses. Some
knowledge-grounded dialogue generation methods tackle this problem by
leveraging facts from Knowledge Graphs (KGs); however, they do not guarantee
that the model utilizes a relevant piece of knowledge from the KG. To overcome
this limitation, we propose SUbgraph Retrieval-augmented GEneration (SURGE), a
framework for generating context-relevant and knowledge-grounded dialogues with
the KG. Specifically, our SURGE framework first retrieves the relevant subgraph
from the KG, and then enforces consistency across facts by perturbing their
word embeddings conditioned by the retrieved subgraph. Then, we utilize
contrastive learning to ensure that the generated texts have high similarity to
the retrieved subgraphs. We validate our SURGE framework on OpendialKG and
KOMODIS datasets, showing that it generates high-quality dialogues that
faithfully reflect the knowledge from KG.",2023-05-30
Perceived Trustworthiness of Natural Language Generators,2023-05-29 16:09:58+00:00,http://arxiv.org/abs/2305.18176v1,"Beatriz Cabrero-Daniel, Andrea Sanagustín Cabrero","cs.HC, cs.AI, cs.CL",dialogue,"Natural Language Generation tools, such as chatbots that can generate
human-like conversational text, are becoming more common both for personal and
professional use. However, there are concerns about their trustworthiness and
ethical implications. The paper addresses the problem of understanding how
different users (e.g., linguists, engineers) perceive and adopt these tools and
their perception of machine-generated text quality. It also discusses the
perceived advantages and limitations of Natural Language Generation tools, as
well as users' beliefs on governance strategies. The main findings of this
study include the impact of users' field and level of expertise on the
perceived trust and adoption of Natural Language Generation tools, the users'
assessment of the accuracy, fluency, and potential biases of machine-generated
text in comparison to human-written text, and an analysis of the advantages and
ethical risks associated with these tools as identified by the participants.
Moreover, this paper discusses the potential implications of these findings for
enhancing the AI development process. The paper sheds light on how different
user characteristics shape their beliefs on the quality and overall
trustworthiness of machine-generated text. Furthermore, it examines the
benefits and risks of these tools from the perspectives of different users.",2023-05-29
"GripRank: Bridging the Gap between Retrieval and Generation via the
  Generative Knowledge Improved Passage Ranking",2023-05-29 15:15:53+00:00,http://arxiv.org/abs/2305.18144v1,"Jiaqi Bai, Hongcheng Guo, Jiaheng Liu, Jian Yang, Xinnian Liang, Zhao Yan, Zhoujun Li","cs.CL, cs.AI",dialogue,"Retrieval-enhanced text generation, which aims to leverage passages retrieved
from a large passage corpus for delivering a proper answer given the input
query, has shown remarkable progress on knowledge-intensive language tasks such
as open-domain question answering and knowledge-enhanced dialogue generation.
However, the retrieved passages are not ideal for guiding answer generation
because of the discrepancy between retrieval and generation, i.e., the
candidate passages are all treated equally during the retrieval procedure
without considering their potential to generate the proper answers. This
discrepancy makes a passage retriever deliver a sub-optimal collection of
candidate passages to generate answers. In this paper, we propose the
GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing
the above challenge by distilling knowledge from a generative passage estimator
(GPE) to a passage ranker, where the GPE is a generative language model used to
measure how likely the candidate passages can generate the proper answer. We
realize the distillation procedure by teaching the passage ranker learning to
rank the passages ordered by the GPE. Furthermore, we improve the distillation
quality by devising a curriculum knowledge distillation mechanism, which allows
the knowledge provided by the GPE can be progressively distilled to the ranker
through an easy-to-hard curriculum, enabling the passage ranker to correctly
recognize the provenance of the answer from many plausible candidates. We
conduct extensive experiments on four datasets across three knowledge-intensive
language tasks. Experimental results show advantages over the state-of-the-art
methods for both passage ranking and answer generation on the KILT benchmark.",2023-05-29
"A Unified Framework for Slot based Response Generation in a Multimodal
  Dialogue System",2023-05-27 10:06:03+00:00,http://arxiv.org/abs/2305.17433v1,"Mauajama Firdaus, Avinash Madasu, Asif Ekbal","cs.CV, cs.CL",dialogue,"Natural Language Understanding (NLU) and Natural Language Generation (NLG)
are the two critical components of every conversational system that handles the
task of understanding the user by capturing the necessary information in the
form of slots and generating an appropriate response in accordance with the
extracted information. Recently, dialogue systems integrated with complementary
information such as images, audio, or video have gained immense popularity. In
this work, we propose an end-to-end framework with the capability to extract
necessary slot values from the utterance and generate a coherent response,
thereby assisting the user to achieve their desired goals in a multimodal
dialogue system having both textual and visual information. The task of
extracting the necessary information is dependent not only on the text but also
on the visual cues present in the dialogue. Similarly, for the generation, the
previous dialog context comprising multimodal information is significant for
providing coherent and informative responses. We employ a multimodal
hierarchical encoder using pre-trained DialoGPT and also exploit the knowledge
base (Kb) to provide a stronger context for both the tasks. Finally, we design
a slot attention mechanism to focus on the necessary information in a given
utterance. Lastly, a decoder generates the corresponding response for the given
dialogue context and the extracted slot values. Experimental results on the
Multimodal Dialogue Dataset (MMD) show that the proposed framework outperforms
the baselines approaches in both the tasks. The code is available at
https://github.com/avinashsai/slot-gpt.",2023-05-27
Generating Images with Multimodal Language Models,2023-05-26 19:22:03+00:00,http://arxiv.org/abs/2305.17216v1,"Jing Yu Koh, Daniel Fried, Ruslan Salakhutdinov","cs.CL, cs.CV, cs.LG",dialogue,"We propose a method to fuse frozen text-only large language models (LLMs)
with pre-trained image encoder and decoder models, by mapping between their
embedding spaces. Our model demonstrates a wide suite of multimodal
capabilities: image retrieval, novel image generation, and multimodal dialogue.
Ours is the first approach capable of conditioning on arbitrarily interleaved
image and text inputs to generate coherent image (and text) outputs. To achieve
strong performance on image generation, we propose an efficient mapping network
to ground the LLM to an off-the-shelf text-to-image generation model. This
mapping network translates hidden representations of text into the embedding
space of the visual models, enabling us to leverage the strong text
representations of the LLM for visual outputs. Our approach outperforms
baseline generation models on tasks with longer and more complex language. In
addition to novel image generation, our model is also capable of image
retrieval from a prespecified dataset, and decides whether to retrieve or
generate at inference time. This is done with a learnt decision module which
conditions on the hidden representations of the LLM. Our model exhibits a wider
range of capabilities compared to prior multimodal language models. It can
process image-and-text inputs, and produce retrieved images, generated images,
and generated text -- outperforming non-LLM based generation models across
several text-to-image tasks that measure context dependence.",2023-05-26
"Distinguishing Human Generated Text From ChatGPT Generated Text Using
  Machine Learning",2023-05-26 09:27:43+00:00,http://arxiv.org/abs/2306.01761v1,"Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya, Monowara Tabassum Maisha, Dewan Md Farid","cs.CL, cs.AI, cs.LG",dialogue,"ChatGPT is a conversational artificial intelligence that is a member of the
generative pre-trained transformer of the large language model family. This
text generative model was fine-tuned by both supervised learning and
reinforcement learning so that it can produce text documents that seem to be
written by natural intelligence. Although there are numerous advantages of this
generative model, it comes with some reasonable concerns as well. This paper
presents a machine learning-based solution that can identify the ChatGPT
delivered text from the human written text along with the comparative analysis
of a total of 11 machine learning and deep learning algorithms in the
classification process. We have tested the proposed model on a Kaggle dataset
consisting of 10,000 texts out of which 5,204 texts were written by humans and
collected from news and social media. On the corpus generated by GPT-3.5, the
proposed algorithm presents an accuracy of 77%.",2023-05-26
"Response Generation in Longitudinal Dialogues: Which Knowledge
  Representation Helps?",2023-05-25 10:13:53+00:00,http://arxiv.org/abs/2305.15908v1,"Seyed Mahed Mousavi, Simone Caldarella, Giuseppe Riccardi",cs.CL,dialogue,"Longitudinal Dialogues (LD) are the most challenging type of conversation for
human-machine dialogue systems. LDs include the recollections of events,
personal thoughts, and emotions specific to each individual in a sparse
sequence of dialogue sessions. Dialogue systems designed for LDs should
uniquely interact with the users over multiple sessions and long periods of
time (e.g. weeks), and engage them in personal dialogues to elaborate on their
feelings, thoughts, and real-life events. In this paper, we study the task of
response generation in LDs. We evaluate whether general-purpose Pre-trained
Language Models (PLM) are appropriate for this purpose. We fine-tune two PLMs,
GePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different
representations of the personal knowledge extracted from LDs for grounded
response generation, including the graph representation of the mentioned events
and participants. We evaluate the performance of the models via automatic
metrics and the contribution of the knowledge via the Integrated Gradients
technique. We categorize the natural language generation errors via human
evaluations of contextualization, appropriateness and engagement of the user.",2023-05-25
MERGE: Fast Private Text Generation,2023-05-25 06:27:19+00:00,http://arxiv.org/abs/2305.15769v1,"Zi Liang, Pinghui Wang, Ruofei Zhang, Nuo Xu, Shuo Zhang","cs.CL, cs.AI",dialogue,"Recent years have seen increasing concerns about the private inference of NLP
services and Transformer models. However, existing two-party privacy-preserving
methods solely consider NLU scenarios, while the private inference of text
generation such as translation, dialogue, and code completion remains unsolved.
Besides, while migrated to NLG models, existing privacy-preserving methods
perform poorly in terms of inference speed, and suffer from the convergence
problem during the training stage. To address these issues, we propose MERGE, a
fast private text generation framework for Transformer-based language models.
Specifically, MERGE reuse the output hidden state as the word embedding to
bypass the embedding computation, and reorganize the linear operations in the
Transformer module to accelerate the forward procedure. Based on these two
optimizations, extensive experiments show that MERGE can achieve a 26.5x
speedup under the sequence length 512, and reduce 80\% communication bytes,
with an up to 10x speedup to existing state-of-art models.",2023-05-25
Revisiting Sentence Union Generation as a Testbed for Text Consolidation,2023-05-24 22:34:01+00:00,http://arxiv.org/abs/2305.15605v1,"Eran Hirsch, Valentina Pyatkin, Ruben Wolhandler, Avi Caciularu, Asi Shefer, Ido Dagan",cs.CL,dialogue,"Tasks involving text generation based on multiple input texts, such as
multi-document summarization, long-form question answering and contemporary
dialogue applications, challenge models for their ability to properly
consolidate partly-overlapping multi-text information. However, these tasks
entangle the consolidation phase with the often subjective and ill-defined
content selection requirement, impeding proper assessment of models'
consolidation capabilities. In this paper, we suggest revisiting the sentence
union generation task as an effective well-defined testbed for assessing text
consolidation capabilities, decoupling the consolidation challenge from
subjective content selection. To support research on this task, we present
refined annotation methodology and tools for crowdsourcing sentence union,
create the largest union dataset to date and provide an analysis of its rich
coverage of various consolidation aspects. We then propose a comprehensive
evaluation protocol for union generation, including both human and automatic
evaluation. Finally, as baselines, we evaluate state-of-the-art language models
on the task, along with a detailed analysis of their capacity to address
multi-text consolidation challenges and their limitations.",2023-05-24
"RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs
  and for GPTs",2023-05-24 10:30:42+00:00,http://arxiv.org/abs/2305.14994v2,"Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, Zili Wang, Shusen Wang, Hai Zhao",cs.CL,dialogue,"General chat models, like ChatGPT, have attained impressive capability to
resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with
high-quality instruction data. However, collecting human-written high-quality
data, especially multi-turn dialogues, is expensive and unattainable for most
people. Though previous studies have used powerful LLMs to generate the
dialogues automatically, but they all suffer from generating untruthful
dialogues because of the LLMs hallucination. Therefore, we propose a method
called RefGPT to generate enormous truthful and customized dialogues without
worrying about factual errors caused by the model hallucination. RefGPT solves
the model hallucination in dialogue generation by restricting the LLMs to
leverage the given reference instead of reciting their own knowledge to
generate dialogues. Additionally, RefGPT adds detailed controls on every
utterances to enable highly customization capability, which previous studies
have ignored. On the basis of RefGPT, we also propose two high-quality dialogue
datasets generated by GPT-4, namely RefGPT-Fact and RefGPT-Code. RefGPT-Fact is
100k multi-turn dialogue datasets based on factual knowledge and RefGPT-Code is
76k multi-turn dialogue dataset covering a wide range of coding scenarios. Our
code and datasets are released in https://github.com/ziliwangnlp/RefGPT",2023-05-24
Dolphin: A Challenging and Diverse Benchmark for Arabic NLG,2023-05-24 10:24:10+00:00,http://arxiv.org/abs/2305.14989v1,"El Moatez Billah Nagoudi, Ahmed El-Shangiti, AbdelRahim Elmadany, Muhammad Abdul-Mageed",cs.CL,dialogue,"We present Dolphin, a novel benchmark that addresses the need for an
evaluation framework for the wide collection of Arabic languages and varieties.
The proposed benchmark encompasses a broad range of 13 different NLG tasks,
including text summarization, machine translation, question answering, and
dialogue generation, among others. Dolphin comprises a substantial corpus of 40
diverse and representative public datasets across 50 test splits, carefully
curated to reflect real-world scenarios and the linguistic richness of Arabic.
It sets a new standard for evaluating the performance and generalization
capabilities of Arabic and multilingual models, promising to enable researchers
to push the boundaries of current methodologies. We provide an extensive
analysis of Dolphin, highlighting its diversity and identifying gaps in current
Arabic NLG research. We also evaluate several Arabic and multilingual models on
our benchmark, allowing us to set strong baselines against which researchers
can compare.",2023-05-24
"In-Context Impersonation Reveals Large Language Models' Strengths and
  Biases",2023-05-24 09:13:15+00:00,http://arxiv.org/abs/2305.14930v1,"Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, Zeynep Akata","cs.AI, cs.CL, cs.LG",dialogue,"In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.",2023-05-24
"Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented
  Dialogues and Annotations",2023-05-23 22:31:01+00:00,http://arxiv.org/abs/2305.14556v1,"Tiziano Labruna, Sofia Brenna, Andrea Zaninello, Bernardo Magnini","cs.CL, cs.AI",dialogue,"Large pre-trained language models have exhibited unprecedented capabilities
in producing high-quality text via prompting techniques. This fact introduces
new possibilities for data collection and annotation, particularly in
situations where such data is scarce, complex to gather, expensive, or even
sensitive. In this paper, we explore the potential of these models to generate
and annotate goal-oriented dialogues, and conduct an in-depth analysis to
evaluate their quality. Our experiments employ ChatGPT, and encompass three
categories of goal-oriented dialogues (task-oriented, collaborative, and
explanatory), two generation modes (interactive and one-shot), and two
languages (English and Italian). Based on extensive human-based evaluations, we
demonstrate that the quality of generated dialogues and annotations is on par
with those generated by humans.",2023-05-23
Reducing Sensitivity on Speaker Names for Text Generation from Dialogues,2023-05-23 08:53:33+00:00,http://arxiv.org/abs/2305.13833v1,"Qi Jia, Haifeng Tang, Kenny Q. Zhu",cs.CL,dialogue,"Changing speaker names consistently throughout a dialogue should not affect
its meaning and corresponding outputs for text generation from dialogues.
However, pre-trained language models, serving as the backbone for
dialogue-processing tasks, have shown to be sensitive to nuances. This may
result in unfairness in real-world applications. No comprehensive analysis of
this problem has been done in the past. In this work, we propose to
quantitatively measure a model's sensitivity on speaker names, and
comprehensively evaluate a number of known methods for reducing speaker name
sensitivity, including a novel approach of our own. Extensive experiments on
multiple datasets provide a benchmark for this problem and show the favorable
performance of our approach in sensitivity reduction and quality of generation.",2023-05-23
"DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text
  Diffusion",2023-05-19 08:30:11+00:00,http://arxiv.org/abs/2305.11517v1,"Chao-Hong Tan, Jia-Chen Gu, Zhen-Hua Ling","cs.CL, cs.AI",dialogue,"Diffusion models have emerged as the new state-of-the-art family of deep
generative models, and their promising potentials for text generation have
recently attracted increasing attention. Existing studies mostly adopt a single
encoder architecture with partially noising processes for conditional text
generation, but its degree of flexibility for conditional modeling is limited.
In fact, the encoder-decoder architecture is naturally more flexible for its
detachable encoder and decoder modules, which is extensible to multilingual and
multimodal generation tasks for conditions and target texts. However, the
encoding process of conditional texts lacks the understanding of target texts.
To this end, a spiral interaction architecture for encoder-decoder text
diffusion (DiffuSIA) is proposed. Concretely, the conditional information from
encoder is designed to be captured by the diffusion decoder, while the target
information from decoder is designed to be captured by the conditional encoder.
These two types of information flow run through multilayer interaction spirally
for deep fusion and understanding. DiffuSIA is evaluated on four text
generation tasks, including paraphrase, text simplification, question
generation, and open-domain dialogue generation. Experimental results show that
DiffuSIA achieves competitive performance among previous methods on all four
tasks, demonstrating the effectiveness and generalization ability of the
proposed method.",2023-05-19
TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks,2023-05-19 04:59:34+00:00,http://arxiv.org/abs/2305.11430v1,"Shubhra Kanti Karmaker Santu, Dongji Feng","cs.AI, cs.CL, cs.IR, cs.LG, I.2.7",dialogue,"While LLMs have shown great success in understanding and generating text in
traditional conversational settings, their potential for performing ill-defined
complex tasks is largely under-studied. Indeed, we are yet to conduct
comprehensive benchmarking studies with multiple LLMs that are exclusively
focused on a complex task. However, conducting such benchmarking studies is
challenging because of the large variations in LLMs' performance when different
prompt types/styles are used and different degrees of detail are provided in
the prompts. To address this issue, the paper proposes a general taxonomy that
can be used to design prompts with specific properties in order to perform a
wide range of complex tasks. This taxonomy will allow future benchmarking
studies to report the specific categories of prompts used as part of the study,
enabling meaningful comparisons across different studies. Also, by establishing
a common standard through this taxonomy, researchers will be able to draw more
accurate conclusions about LLMs' performance on a specific complex task.",2023-05-19
"CHBias: Bias Evaluation and Mitigation of Chinese Conversational
  Language Models",2023-05-18 18:58:30+00:00,http://arxiv.org/abs/2305.11262v1,"Jiaxu Zhao, Meng Fang, Zijing Shi, Yitong Li, Ling Chen, Mykola Pechenizkiy",cs.CL,dialogue,"\textit{\textbf{\textcolor{red}{Warning}:} This paper contains content that
may be offensive or upsetting.} Pretrained conversational agents have been
exposed to safety issues, exhibiting a range of stereotypical human biases such
as gender bias. However, there are still limited bias categories in current
research, and most of them only focus on English. In this paper, we introduce a
new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese
conversational language models. Apart from those previous well-explored bias
categories, CHBias includes under-explored bias categories, such as ageism and
appearance biases, which received less attention. We evaluate two popular
pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias.
Furthermore, to mitigate different biases, we apply several debiasing methods
to the Chinese pretrained models. Experimental results show that these Chinese
pretrained models are potentially risky for generating texts that contain
social biases, and debiasing methods using the proposed dataset can make
response generation less biased while preserving the models' conversational
capabilities.",2023-05-18
Boosting Event Extraction with Denoised Structure-to-Text Augmentation,2023-05-16 16:52:07+00:00,http://arxiv.org/abs/2305.09598v1,"bo wang, Heyan Huang, Xiaochi Wei, Ge Shi, Xiao Liu, Chong Feng, Tong Zhou, Shuaiqiang Wang, Dawei Yin",cs.CL,dialogue,"Event extraction aims to recognize pre-defined event triggers and arguments
from texts, which suffer from the lack of high-quality annotations. In most NLP
applications, involving a large scale of synthetic training data is a practical
and effective approach to alleviate the problem of data scarcity. However, when
applying to the task of event extraction, recent data augmentation methods
often neglect the problem of grammatical incorrectness, structure misalignment,
and semantic drifting, leading to unsatisfactory performances. In order to
solve these problems, we propose a denoised structure-to-text augmentation
framework for event extraction DAEE, which generates additional training data
through the knowledge-based structure-to-text generation model and selects the
effective subset from the generated data iteratively with a deep reinforcement
learning agent. Experimental results on several datasets demonstrate that the
proposed method generates more diverse text representations for event
extraction and achieves comparable results with the state-of-the-art.",2023-05-16
"Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice
  and Feedback",2023-05-15 19:48:59+00:00,http://arxiv.org/abs/2305.08982v1,"Shang-Ling Hsu, Raj Sanjay Shah, Prathik Senthil, Zahra Ashktorab, Casey Dugan, Werner Geyer, Diyi Yang","cs.HC, cs.CL",dialogue,"Millions of users come to online peer counseling platforms to seek support on
diverse topics ranging from relationship stress to anxiety. However, studies
show that online peer support groups are not always as effective as expected
largely due to users' negative experiences with unhelpful counselors. Peer
counselors are key to the success of online peer counseling platforms, but most
of them often do not have systematic ways to receive guidelines or supervision.
In this work, we introduce CARE: an interactive AI-based tool to empower peer
counselors through automatic suggestion generation. During the practical
training stage, CARE helps diagnose which specific counseling strategies are
most suitable in the given context and provides tailored example responses as
suggestions. Counselors can choose to select, modify, or ignore any suggestion
before replying to the support seeker. Building upon the Motivational
Interviewing framework, CARE utilizes large-scale counseling conversation data
together with advanced natural language generation techniques to achieve these
functionalities. We demonstrate the efficacy of CARE by performing both
quantitative evaluations and qualitative user studies through simulated chats
and semi-structured interviews. We also find that CARE especially helps novice
counselors respond better in challenging situations.",2023-05-15
"NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric
  Preference Checklist",2023-05-15 11:51:55+00:00,http://arxiv.org/abs/2305.08566v3,"Iftitahu Ni'mah, Meng Fang, Vlado Menkovski, Mykola Pechenizkiy",cs.CL,dialogue,"In this study, we analyze NLG automatic metrics based on whether human
evaluation aspect is used as context or objective to compute the metrics: (i)
Task-agnostic and (ii) Human-aligned. Task-agnostic metrics, such as
Perplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverse
NLG tasks, yet they have a weak correlation with human. Human-aligned metrics
(CTC, CtrlEval, UniEval) improves correlation level by incorporating desirable
human-like qualities as training objective. However, their effectiveness at
discerning system-level performance and quality of system outputs remain
unclear.
  We present metric preference checklist as a framework to assess the
discriminative power of automatic metrics in three NLG tasks: Text
Summarization, Dialogue Response Generation, and Controlled Generation. We show
that multi-aspect human-aligned metric (UniEval) is not necessarily dominant
over single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnostic
metrics (BLEU, BERTScore), particularly when a disagreement between human
evaluation aspects is present. We also show particular use cases in which
automatic metrics provide a better guidance than human on discriminating
system-level performance. Our proposed framework provides access: (i) for
verifying whether automatic metrics are faithful to human preference,
regardless their correlation level to human; and (ii) for scrutinizing the
strengths and limitations of NLG systems, which are often obscured by a
standard averaging method of evaluation scores.",2023-05-15
"ProKnow: Process Knowledge for Safety Constrained and Explainable
  Question Generation for Mental Health Diagnostic Assistance",2023-05-13 21:31:02+00:00,http://arxiv.org/abs/2305.08010v1,"Kaushik Roy, Manas Gaur, Misagh Soltani, Vipula Rawte, Ashwin Kalyan, Amit Sheth",cs.CL,dialogue,"Current Virtual Mental Health Assistants (VMHAs) provide counseling and
suggestive care. They refrain from patient diagnostic assistance because they
lack training in safety-constrained and specialized clinical process knowledge.
In this work, we define Proknow as an ordered set of information that maps to
evidence-based guidelines or categories of conceptual understanding to experts
in a domain. We also introduce a new dataset of diagnostic conversations guided
by safety constraints and Proknow that healthcare professionals use. We develop
a method for natural language question generation (NLG) that collects
diagnostic information from the patient interactively. We demonstrate the
limitations of using state-of-the-art large-scale language models (LMs) on this
dataset. Our algorithm models the process knowledge through explicitly modeling
safety, knowledge capture, and explainability. LMs augmented with ProKnow
guided method generated 89% safer questions in the depression and anxiety
domain. The Explainability of the generated question is assessed by computing
similarity with concepts in depression and anxiety knowledge bases. Overall,
irrespective of the type of LMs augmented with our ProKnow, we achieved an
average 82% improvement over simple pre-trained LMs on safety, explainability,
and process-guided question generation. We qualitatively and quantitatively
evaluate the efficacy of the proposed ProKnow-guided methods by introducing
three new evaluation metrics for safety, explainability, and process knowledge
adherence.",2023-05-13
"Dialogue Planning via Brownian Bridge Stochastic Process for
  Goal-directed Proactive Dialogue",2023-05-09 09:28:23+00:00,http://arxiv.org/abs/2305.05290v1,"Jian Wang, Dongding Lin, Wenjie Li","cs.CL, cs.LG",dialogue,"Goal-directed dialogue systems aim to proactively reach a pre-determined
target through multi-turn conversations. The key to achieving this task lies in
planning dialogue paths that smoothly and coherently direct conversations
towards the target. However, this is a challenging and under-explored task. In
this work, we propose a coherent dialogue planning approach that uses a
stochastic process to model the temporal dynamics of dialogue paths. We define
a latent space that captures the coherence of goal-directed behavior using a
Brownian bridge process, which allows us to incorporate user feedback flexibly
in dialogue planning. Based on the derived latent trajectories, we generate
dialogue paths explicitly using pre-trained language models. We finally employ
these paths as natural language prompts to guide dialogue generation. Our
experiments show that our approach generates more coherent utterances and
achieves the goal with a higher success rate.",2023-05-09
Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System,2023-05-04 00:17:49+00:00,http://arxiv.org/abs/2305.02468v1,"Namo Bang, Jeehyun Lee, Myoung-Wan Koo",cs.CL,dialogue,"Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks
by tracking dialogue states and generating appropriate responses to help users
achieve defined goals. Recently, end-to-end dialogue models pre-trained based
on large datasets have shown promising performance in the conversational
system. However, they share the same parameters to train tasks of the dialogue
system (NLU, DST, NLG), so debugging each task is challenging. Also, they
require a lot of effort to fine-tune large parameters to create a task-oriented
chatbot, making it difficult for non-experts to handle. Therefore, we intend to
train relatively lightweight and fast models compared to PLM. In this paper, we
propose an End-to-end TOD system with Task-Optimized Adapters which learn
independently per task, adding only small number of parameters after fixed
layers of pre-trained network. We also enhance the performance of the DST and
NLG modules through reinforcement learning, overcoming the learning curve that
has lacked at the adapter learning and enabling the natural and consistent
response generation that is appropriate for the goal. Our method is a
model-agnostic approach and does not require prompt-tuning as only input data
without a prompt. As results of the experiment, our method shows competitive
performance on the MultiWOZ benchmark compared to the existing end-to-end
models. In particular, we attain state-of-the-art performance on the DST task
of 2.2 dataset.",2023-05-04
Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory,2023-05-03 21:40:54+00:00,http://arxiv.org/abs/2305.02437v1,"Xin Cheng, Di Luo, Xiuying Chen, Lemao Liu, Dongyan Zhao, Rui Yan","cs.CL, cs.AI",dialogue,"With direct access to human-written reference as memory, retrieval-augmented
generation has achieved much progress in a wide range of text generation tasks.
Since better memory would typically prompt better generation~(we define this as
primal problem), previous works mainly focus on how to retrieve better memory.
However, one fundamental limitation exists for current literature: the memory
is retrieved from a fixed corpus and is bounded by the quality of the corpus.
Due to the finite retrieval space, bounded memory would greatly limit the
potential of the memory-augmented generation model. In this paper, by exploring
the duality of the primal problem: better generation also prompts better
memory, we propose a framework called Selfmem, which iteratively adopts a
retrieval-augmented generator itself to generate an unbounded memory pool and
uses a memory selector to pick one generated memory for the next generation
round. By combining the primal and dual problem, a retrieval-augmented
generation model could lift itself up with its own output in the infinite
generation space. To verify our framework, we conduct extensive experiments
across various text generation scenarios including neural machine translation,
abstractive summarization and dialogue generation over seven datasets and
achieve state-of-the-art results in JRC-Acquis(four directions), XSum(50.3
ROUGE-1) and BigPatent(62.9 ROUGE-1).",2023-05-03
"CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to
  Guardrail Models for Virtual Assistants",2023-04-27 17:39:11+00:00,http://arxiv.org/abs/2304.14364v1,"Albert Yu Sun, Varun Nair, Elliot Schumacher, Anitha Kannan","cs.CL, cs.AI, cs.LG",dialogue,"A wave of new task-based virtual assistants has been fueled by increasingly
powerful large language models, such as GPT-4. These conversational agents can
be customized to serve customer-specific use cases, but ensuring that
agent-generated text conforms to designer-specified rules included in prompt
instructions alone is challenging. Therefore, chatbot designers often use
another model, called a guardrail model, to verify that the agent output aligns
with their rules and constraints. We explore using a distillation approach to
guardrail models to monitor the output of the first model using training data
from GPT-4. We find two crucial steps to our CONSCENDI process:
scenario-augmented generation and contrastive training examples. When
generating conversational data, we generate a set of rule-breaking scenarios,
which enumerate a diverse set of high-level ways a rule can be violated. This
scenario-guided approach produces a diverse training set of rule-violating
conversations, and it provides chatbot designers greater control over the
classification process. We also prompt GPT-4 to also generate contrastive
examples by altering conversations with violations into acceptable
conversations. This set of borderline, contrastive examples enables the
distilled model to learn finer-grained distinctions between what is acceptable
and what is not. We find that CONSCENDI results in guardrail models that
improve over baselines.",2023-04-27
"Which Factors Predict the Chat Experience of a Natural Language
  Generation Dialogue Service?",2023-04-21 07:29:07+00:00,http://arxiv.org/abs/2304.10785v1,Eason Chen,"cs.CL, cs.HC",dialogue,"In this paper, we proposed a conceptual model to predict the chat experience
in a natural language generation dialog system. We evaluated the model with 120
participants with Partial Least Squares Structural Equation Modeling (PLS-SEM)
and obtained an R-square (R2) with 0.541. The model considers various factors,
including the prompts used for generation; coherence, sentiment, and similarity
in the conversation; and users' perceived dialog agents' favorability. We then
further explore the effectiveness of the subset of our proposed model. The
results showed that users' favorability and coherence, sentiment, and
similarity in the dialogue are positive predictors of users' chat experience.
Moreover, we found users may prefer dialog agents with characteristics of
Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism.
Through our research, an adaptive dialog system might use collected data to
infer factors in our model, predict the chat experience for users through these
factors, and optimize it by adjusting prompts.",2023-04-21
"An In-depth Investigation of User Response Simulation for Conversational
  Search",2023-04-17 01:55:40+00:00,http://arxiv.org/abs/2304.07944v1,"Zhenduo Wang, Zhichao Xu, Qingyao Ai, Vivek Srikumar",cs.IR,dialogue,"Conversational search has seen increased recent attention in both the IR and
NLP communities. It seeks to clarify and solve a user's search need through
multi-turn natural language interactions. However, most existing systems are
trained and demonstrated with recorded or artificial conversation logs.
Eventually, conversational search systems should be trained, evaluated, and
deployed in an open-ended setting with unseen conversation trajectories. A key
challenge is that training and evaluating such systems both require a
human-in-the-loop, which is expensive and does not scale. One strategy for this
is to simulate users, thereby reducing the scaling costs. However, current user
simulators are either limited to only respond to yes-no questions from the
conversational search system, or unable to produce high quality responses in
general.
  In this paper, we show that current state-of-the-art user simulation system
could be significantly improved by replacing it with a smaller but advanced
natural language generation model. But rather than merely reporting this new
state-of-the-art, we present an in-depth investigation of the task of
simulating user response for conversational search. Our goal is to supplement
existing works with an insightful hand-analysis of what challenges are still
unsolved by the advanced model, as well as to propose our solutions for them.
The challenges we identified include (1) dataset noise, (2) a blind spot that
is difficult for existing models to learn, and (3) a specific type of
misevaluation in the standard empirical setup. Except for the dataset noise
issue, we propose solutions to cover the training blind spot and to avoid the
misevaluation. Our proposed solutions lead to further improvements. Our best
system improves the previous state-of-the-art significantly.",2023-04-17
"Emergent autonomous scientific research capabilities of large language
  models",2023-04-11 16:50:17+00:00,http://arxiv.org/abs/2304.05332v1,"Daniil A. Boiko, Robert MacKnight, Gabe Gomes","physics.chem-ph, cs.CL",dialogue,"Transformer-based large language models are rapidly advancing in the field of
machine learning research, with applications spanning natural language,
biology, chemistry, and computer programming. Extreme scaling and reinforcement
learning from human feedback have significantly improved the quality of
generated text, enabling these models to perform various tasks and reason about
their choices. In this paper, we present an Intelligent Agent system that
combines multiple large language models for autonomous design, planning, and
execution of scientific experiments. We showcase the Agent's scientific
research capabilities with three distinct examples, with the most complex being
the successful performance of catalyzed cross-coupling reactions. Finally, we
discuss the safety implications of such systems and propose measures to prevent
their misuse.",2023-04-11
Pragmatically Appropriate Diversity for Dialogue Evaluation,2023-04-06 01:24:18+00:00,http://arxiv.org/abs/2304.02812v1,"Katherine Stasaski, Marti A. Hearst",cs.CL,dialogue,"Linguistic pragmatics state that a conversation's underlying speech acts can
constrain the type of response which is appropriate at each turn in the
conversation. When generating dialogue responses, neural dialogue agents
struggle to produce diverse responses. Currently, dialogue diversity is
assessed using automatic metrics, but the underlying speech acts do not inform
these metrics.
  To remedy this, we propose the notion of Pragmatically Appropriate Diversity,
defined as the extent to which a conversation creates and constrains the
creation of multiple diverse responses. Using a human-created multi-response
dataset, we find significant support for the hypothesis that speech acts
provide a signal for the diversity of the set of next responses. Building on
this result, we propose a new human evaluation task where creative writers
predict the extent to which conversations inspire the creation of multiple
diverse responses. Our studies find that writers' judgments align with the
Pragmatically Appropriate Diversity of conversations. Our work suggests that
expectations for diversity metric scores should vary depending on the speech
act.",2023-04-06
"Dialog-to-Actions: Building Task-Oriented Dialogue System via
  Action-Level Generation",2023-04-03 11:09:20+00:00,http://arxiv.org/abs/2304.00884v1,"Yuncheng Hua, Xiangyu Xi, Zheng Jiang, Guanwei Zhang, Chaobo Sun, Guanglu Wan, Wei Ye",cs.CL,dialogue,"End-to-end generation-based approaches have been investigated and applied in
task-oriented dialogue systems. However, in industrial scenarios, existing
methods face the bottlenecks of controllability (e.g., domain-inconsistent
responses, repetition problem, etc) and efficiency (e.g., long computation
time, etc). In this paper, we propose a task-oriented dialogue system via
action-level generation. Specifically, we first construct dialogue actions from
large-scale dialogues and represent each natural language (NL) response as a
sequence of dialogue actions. Further, we train a Sequence-to-Sequence model
which takes the dialogue history as input and outputs sequence of dialogue
actions. The generated dialogue actions are transformed into verbal responses.
Experimental results show that our light-weighted method achieves competitive
performance, and has the advantage of controllability and efficiency.",2023-04-03
"PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue
  Model",2023-04-02 18:23:13+00:00,http://arxiv.org/abs/2304.00592v1,"Cheng Deng, Bo Tong, Luoyi Fu, Jiaxin Ding, Dexing Cao, Xinbing Wang, Chenghu Zhou","cs.CL, I.2.7; F.4.1",dialogue,"In the research of end-to-end dialogue systems, using real-world knowledge to
generate natural, fluent, and human-like utterances with correct answers is
crucial. However, domain-specific conversational dialogue systems may be
incoherent and introduce erroneous external information to answer questions due
to the out-of-vocabulary issue or the wrong knowledge from the parameters of
the neural network. In this work, we propose PK-Chat, a Pointer network guided
Knowledge-driven generative dialogue model, incorporating a unified pretrained
language model and a pointer network over knowledge graphs. The words generated
by PK-Chat in the dialogue are derived from the prediction of word lists and
the direct prediction of the external knowledge graph knowledge. Moreover,
based on the PK-Chat, a dialogue system is built for academic scenarios in the
case of geosciences. Finally, an academic dialogue benchmark is constructed to
evaluate the quality of dialogue systems in academic scenarios and the source
code is available online.",2023-04-02
G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment,2023-03-29 12:46:54+00:00,http://arxiv.org/abs/2303.16634v2,"Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, Chenguang Zhu","cs.CL, cs.AI",dialogue,"The quality of texts generated by natural language generation (NLG) systems
is hard to measure automatically. Conventional reference-based metrics, such as
BLEU and ROUGE, have been shown to have relatively low correlation with human
judgments, especially for tasks that require creativity and diversity. Recent
studies suggest using large language models (LLMs) as reference-free metrics
for NLG evaluation, which have the benefit of being applicable to new tasks
that lack human references. However, these LLM-based evaluators still have
lower human correspondence than medium-size neural evaluators. In this work, we
present G-Eval, a framework of using large language models with
chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of
NLG outputs. We experiment with two generation tasks, text summarization and
dialogue generation. We show that G-Eval with GPT-4 as the backbone model
achieves a Spearman correlation of 0.514 with human on summarization task,
outperforming all previous methods by a large margin. We also propose
preliminary analysis on the behavior of LLM-based evaluators, and highlight the
potential issue of LLM-based evaluators having a bias towards the LLM-generated
texts.",2023-03-29
Dialogue-to-Video Retrieval,2023-03-23 02:52:45+00:00,http://arxiv.org/abs/2303.16761v1,"Chenyang Lyu, Manh-Duy Nguyen, Van-Tu Ninh, Liting Zhou, Cathal Gurrin, Jennifer Foster","cs.IR, cs.AI",dialogue,"Recent years have witnessed an increasing amount of dialogue/conversation on
the web especially on social media. That inspires the development of
dialogue-based retrieval, in which retrieving videos based on dialogue is of
increasing interest for recommendation systems. Different from other video
retrieval tasks, dialogue-to-video retrieval uses structured queries in the
form of user-generated dialogue as the search descriptor. We present a novel
dialogue-to-video retrieval system, incorporating structured conversational
information. Experiments conducted on the AVSD dataset show that our proposed
approach using plain-text queries improves over the previous counterpart model
by 15.8% on R@1. Furthermore, our approach using dialogue as a query, improves
retrieval performance by 4.2%, 6.2%, 8.6% on R@1, R@5 and R@10 and outperforms
the state-of-the-art model by 0.7%, 3.6% and 6.0% on R@1, R@5 and R@10
respectively.",2023-03-23
"Generate labeled training data using Prompt Programming and GPT-3. An
  example of Big Five Personality Classification",2023-03-22 03:12:40+00:00,http://arxiv.org/abs/2303.12279v1,Eason Chen,"cs.HC, cs.AI",dialogue,"We generated 25000 conversations labeled with Big Five Personality traits
using prompt programming at GPT-3. Then we train Big Five classification models
with these data and evaluate them with 2500 data from generated dialogues and
real conversational datasets labeled in Big Five by human annotators. The
results indicated that this approach is promising for creating effective
training data. We then compare the performance by different training approaches
and models. Our results suggest that using Adapter-Transformers and transfer
learning from pre-trained RoBERTa sentiment analysis model will perform best
with the generated data. Our best model obtained an accuracy of 0.71 in
generated data and 0.65 in real datasets. Finally, we discuss this approach's
potential limitations and confidence metric.",2023-03-22
cTBL: Augmenting Large Language Models for Conversational Tables,2023-03-21 17:04:44+00:00,http://arxiv.org/abs/2303.12024v2,"Anirudh S Sundar, Larry Heck","cs.CL, cs.AI",dialogue,"An open challenge in multimodal conversational AI requires augmenting large
language models with information from textual and non-textual sources for
multi-turn dialogue. To address this problem, this paper introduces
Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve
tabular information and generate dialogue responses grounded on the retrieved
information. cTBL uses Transformer encoder embeddings for Dense Table Retrieval
and obtains up to 5% relative improvement in Top-1 and Top-3 accuracy over
sparse retrieval on the HyrbiDialogue dataset. Additionally, cTBL performs
tabular knowledge retrieval using both encoder and decoder models, resulting in
up to 46% relative improvement in ROUGE scores and better human evaluation for
response generation on HyrbiDialogue.",2023-03-21
Code-Switching Text Generation and Injection in Mandarin-English ASR,2023-03-20 09:13:27+00:00,http://arxiv.org/abs/2303.10949v1,"Haibin Yu, Yuxuan Hu, Yao Qian, Ma Jin, Linquan Liu, Shujie Liu, Yu Shi, Yanmin Qian, Edward Lin, Michael Zeng","eess.AS, cs.CL, cs.SD",dialogue,"Code-switching speech refers to a means of expression by mixing two or more
languages within a single utterance. Automatic Speech Recognition (ASR) with
End-to-End (E2E) modeling for such speech can be a challenging task due to the
lack of data. In this study, we investigate text generation and injection for
improving the performance of an industry commonly-used streaming model,
Transformer-Transducer (T-T), in Mandarin-English code-switching speech
recognition. We first propose a strategy to generate code-switching text data
and then investigate injecting generated text into T-T model explicitly by
Text-To-Speech (TTS) conversion or implicitly by tying speech and text latent
spaces. Experimental results on the T-T model trained with a dataset containing
1,800 hours of real Mandarin-English code-switched speech show that our
approaches to inject generated code-switching text significantly boost the
performance of T-T models, i.e., 16% relative Token-based Error Rate (TER)
reduction averaged on three evaluation sets, and the approach of tying speech
and text latent spaces is superior to that of TTS conversion on the evaluation
set which contains more homogeneous data with the training set.",2023-03-20
Can AI-Generated Text be Reliably Detected?,2023-03-17 17:53:19+00:00,http://arxiv.org/abs/2303.11156v1,"Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, Soheil Feizi","cs.CL, cs.AI, cs.LG",dialogue,"The rapid progress of Large Language Models (LLMs) has made them capable of
performing astonishingly well on various tasks including document completion
and question answering. The unregulated use of these models, however, can
potentially lead to malicious consequences such as plagiarism, generating fake
news, spamming, etc. Therefore, reliable detection of AI-generated text can be
critical to ensure the responsible use of LLMs. Recent works attempt to tackle
this problem either using certain model signatures present in the generated
text outputs or by applying watermarking techniques that imprint specific
patterns onto them. In this paper, both empirically and theoretically, we show
that these detectors are not reliable in practical scenarios. Empirically, we
show that paraphrasing attacks, where a light paraphraser is applied on top of
the generative text model, can break a whole range of detectors, including the
ones using the watermarking schemes as well as neural network-based detectors
and zero-shot classifiers. We then provide a theoretical impossibility result
indicating that for a sufficiently good language model, even the best-possible
detector can only perform marginally better than a random classifier. Finally,
we show that even LLMs protected by watermarking schemes can be vulnerable
against spoofing attacks where adversarial humans can infer hidden watermarking
signatures and add them to their generated text to be detected as text
generated by the LLMs, potentially causing reputational damages to their
developers. We believe these results can open an honest conversation in the
community regarding the ethical and reliable use of AI-generated text.",2023-03-17
"Reinforcement Learning-based Counter-Misinformation Response Generation:
  A Case Study of COVID-19 Vaccine Misinformation",2023-03-11 15:55:01+00:00,http://arxiv.org/abs/2303.06433v1,"Bing He, Mustaque Ahamad, Srijan Kumar","cs.SI, cs.LG",dialogue,"The spread of online misinformation threatens public health, democracy, and
the broader society. While professional fact-checkers form the first line of
defense by fact-checking popular false claims, they do not engage directly in
conversations with misinformation spreaders. On the other hand, non-expert
ordinary users act as eyes-on-the-ground who proactively counter misinformation
-- recent research has shown that 96% counter-misinformation responses are made
by ordinary users. However, research also found that 2/3 times, these responses
are rude and lack evidence. This work seeks to create a counter-misinformation
response generation model to empower users to effectively correct
misinformation. This objective is challenging due to the absence of datasets
containing ground-truth of ideal counter-misinformation responses, and the lack
of models that can generate responses backed by communication theories. In this
work, we create two novel datasets of misinformation and counter-misinformation
response pairs from in-the-wild social media and crowdsourcing from
college-educated students. We annotate the collected data to distinguish poor
from ideal responses that are factual, polite, and refute misinformation. We
propose MisinfoCorrect, a reinforcement learning-based framework that learns to
generate counter-misinformation responses for an input misinformation post. The
model rewards the generator to increase the politeness, factuality, and
refutation attitude while retaining text fluency and relevancy. Quantitative
and qualitative evaluation shows that our model outperforms several baselines
by generating high-quality counter-responses. This work illustrates the promise
of generative text models for social good -- here, to help create a safe and
reliable information ecosystem. The code and data is accessible on
https://github.com/claws-lab/MisinfoCorrect.",2023-03-11
"POSGen: Personalized Opening Sentence Generation for Online Insurance
  Sales",2023-02-10 01:40:03+00:00,http://arxiv.org/abs/2302.06470v1,"Yu Li, Yi Zhang, Weijia Wu, Zimu Zhou, Qiang Li","cs.CL, Online Insurance Recommendation, Transfer Learning, Data-to-text
  Generation",dialogue,"The insurance industry is shifting their sales mode from offline to online,
in expectation to reach massive potential customers in the digitization era.
Due to the complexity and the nature of insurance products, a cost-effective
online sales solution is to exploit chatbot AI to raise customers' attention
and pass those with interests to human agents for further sales. For high
response and conversion rates of customers, it is crucial for the chatbot to
initiate a conversation with personalized opening sentences, which are
generated with user-specific topic selection and ordering. Such personalized
opening sentence generation is challenging because (i) there are limited
historical samples for conversation topic recommendation in online insurance
sales and (ii) existing text generation schemes often fail to support
customized topic ordering based on user preferences. We design POSGen, a
personalized opening sentence generation scheme dedicated for online insurance
sales. It transfers user embeddings learned from auxiliary online user
behaviours to enhance conversation topic recommendation, and exploits a context
management unit to arrange the recommended topics in user-specific ordering for
opening sentence generation. POSGen is deployed on a real-world online
insurance platform. It achieves 2.33x total insurance premium improvement
through a two-month global test.",2023-02-10
"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based
  Learning",2023-02-08 02:45:21+00:00,http://arxiv.org/abs/2302.03848v1,"Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker",cs.CL,dialogue,"Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.",2023-02-08
Grounding Language Models to Images for Multimodal Generation,2023-01-31 18:33:44+00:00,http://arxiv.org/abs/2301.13823v1,"Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried","cs.CL, cs.AI, cs.CV, cs.LG",dialogue,"We propose an efficient method to ground pretrained text-only language models
to the visual domain, enabling them to process and generate arbitrarily
interleaved image-and-text data. Our method leverages the abilities of language
models learnt from large scale text-only pretraining, such as in-context
learning and free-form text generation. We keep the language model frozen, and
finetune input and output linear layers to enable cross-modality interactions.
This allows our model to process arbitrarily interleaved image-and-text inputs,
and generate free-form text interleaved with retrieved images. We achieve
strong zero-shot performance on grounded tasks such as contextual image
retrieval and multimodal dialogue, and showcase compelling interactive
abilities. Our approach works with any off-the-shelf language model and paves
the way towards an effective, general solution for leveraging pretrained
language models in visually grounded settings.",2023-01-31
"Response-act Guided Reinforced Dialogue Generation for Mental Health
  Counseling",2023-01-30 08:53:35+00:00,http://arxiv.org/abs/2301.12729v1,"Aseem Srivastava, Ishan Pandey, Md. Shad Akhtar, Tanmoy Chakraborty",cs.CL,dialogue,"Virtual Mental Health Assistants (VMHAs) have become a prevalent method for
receiving mental health counseling in the digital healthcare space. An
assistive counseling conversation commences with natural open-ended topics to
familiarize the client with the environment and later converges into more
fine-grained domain-specific topics. Unlike other conversational systems, which
are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid
conversational flow. These counseling bots need to comprehend various aspects
of the conversation, such as dialogue-acts, intents, etc., to engage the client
in an effective conversation. Although the surge in digital health research
highlights applications of many general-purpose response generation systems,
they are barely suitable in the mental health domain -- the prime reason is the
lack of understanding in mental health counseling. Moreover, in general,
dialogue-act guided response generators are either limited to a template-based
paradigm or lack appropriate semantics. To this end, we propose READER -- a
REsponse-Act guided reinforced Dialogue genERation model for the mental health
counseling conversations. READER is built on transformer to jointly predict a
potential dialogue-act d(t+1) for the next utterance (aka response-act) and to
generate an appropriate response u(t+1). Through the
transformer-reinforcement-learning (TRL) with Proximal Policy Optimization
(PPO), we guide the response generator to abide by d(t+1) and ensure the
semantic richness of the responses via BERTScore in our reward computation. We
evaluate READER on HOPE, a benchmark counseling conversation dataset and
observe that it outperforms several baselines across several evaluation metrics
-- METEOR, ROUGE, and BERTScore. We also furnish extensive qualitative and
quantitative analyses on results, including error analysis, human evaluation,
etc.",2023-01-30
"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental
  Health on Social Media",2023-01-26 09:26:01+00:00,http://arxiv.org/abs/2301.11004v1,"Muskan Garg, Chandni Saxena, Usman Naseem, Bonnie J Dorr",cs.CL,dialogue,"Interactions among humans on social media often convey intentions behind
their actions, yielding a psychological language resource for Mental Health
Analysis (MHA) of online users. The success of Computational Intelligence
Techniques (CIT) for inferring mental illness from such social media resources
points to NLP as a lens for causal analysis and perception mining. However, we
argue that more consequential and explainable research is required for optimal
impact on clinical psychology practice and personalized mental healthcare. To
bridge this gap, we posit two significant dimensions: (1) Causal analysis to
illustrate a cause and effect relationship in the user generated text; (2)
Perception mining to infer psychological perspectives of social effects on
online users intentions. Within the scope of Natural Language Processing (NLP),
we further explore critical areas of inquiry associated with these two
dimensions, specifically through recent advancements in discourse analysis.
This position paper guides the community to explore solutions in this space and
advance the state of practice in developing conversational agents for inferring
mental health from social media. We advocate for a more explainable approach
toward modeling computational psychology problems through the lens of language
as we observe an increased number of research contributions in dataset and
problem formulation for causal relation extraction and perception enhancements
while inferring mental states.",2023-01-26
Distilling Text into Circuits,2023-01-25 13:56:34+00:00,http://arxiv.org/abs/2301.10595v1,"Vincent Wang-Mascianica, Jonathon Liu, Bob Coecke","cs.CL, cs.AI, cs.LO, math.CT",dialogue,"This paper concerns the structure of meanings within natural language.
Earlier, a framework named DisCoCirc was sketched that (1) is compositional and
distributional (a.k.a. vectorial); (2) applies to general text; (3) captures
linguistic `connections' between meanings (cf. grammar) (4) updates word
meanings as text progresses; (5) structures sentence types; (6) accommodates
ambiguity. Here, we realise DisCoCirc for a substantial fragment of English.
  When passing to DisCoCirc's text circuits, some `grammatical bureaucracy' is
eliminated, that is, DisCoCirc displays a significant degree of (7) inter- and
intra-language independence. That is, e.g., independence from word-order
conventions that differ across languages, and independence from choices like
many short sentences vs. few long sentences. This inter-language independence
means our text circuits should carry over to other languages, unlike the
language-specific typings of categorial grammars. Hence, text circuits are a
lean structure for the `actual substance of text', that is, the inner-workings
of meanings within text across several layers of expressiveness (cf. words,
sentences, text), and may capture that what is truly universal beneath grammar.
The elimination of grammatical bureaucracy also explains why DisCoCirc: (8)
applies beyond language, e.g. to spatial, visual and other cognitive modes.
While humans could not verbally communicate in terms of text circuits, machines
can.
  We first define a `hybrid grammar' for a fragment of English, i.e. a
purpose-built, minimal grammatical formalism needed to obtain text circuits. We
then detail a translation process such that all text generated by this grammar
yields a text circuit. Conversely, for any text circuit obtained by freely
composing the generators, there exists a text (with hybrid grammar) that gives
rise to it. Hence: (9) text circuits are generative for text.",2023-01-25
"UserSimCRS: A User Simulation Toolkit for Evaluating Conversational
  Recommender Systems",2023-01-13 13:41:20+00:00,http://arxiv.org/abs/2301.05544v2,"Jafar Afzali, Aleksander Mark Drzewiecki, Krisztian Balog, Shuo Zhang",cs.IR,dialogue,"We present an extensible user simulation toolkit to facilitate automatic
evaluation of conversational recommender systems. It builds on an established
agenda-based approach and extends it with several novel elements, including
user satisfaction prediction, persona and context modeling, and conditional
natural language generation. We showcase the toolkit with a pre-existing movie
recommender system and demonstrate its ability to simulate dialogues that mimic
real conversations, while requiring only a handful of manually annotated
dialogues as training data.",2023-01-13
Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models,2023-01-08 23:12:46+00:00,http://arxiv.org/abs/2301.03119v2,"Mariam Bangura, Kristina Barabashova, Anna Karnysheva, Sarah Semczuk, Yifan Wang",cs.CL,dialogue,"This study is devoted to the automatic generation of German drama texts. We
suggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the
outline model) to generate outlines of scenes based on keywords and fine-tuning
a second model (the generation model) to generate scenes from the scene
outline. The input for the neural model comprises two datasets: the German
Drama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).
In order to estimate the effectiveness of the proposed method, our models are
compared with baseline GPT-2 models. Our models perform well according to
automatic quantitative evaluation, but, conversely, manual qualitative analysis
reveals a poor quality of generated texts. This may be due to the quality of
the dataset or training inputs.",2023-01-08
TextBox 2.0: A Text Generation Library with Pre-trained Language Models,2022-12-26 03:50:36+00:00,http://arxiv.org/abs/2212.13005v1,"Tianyi Tang, Junyi Li, Zhipeng Chen, Yiwen Hu, Zhuohao Yu, Wenxun Dai, Zican Dong, Xiaoxue Cheng, Yuhao Wang, Wayne Xin Zhao, Jian-Yun Nie, Ji-Rong Wen",cs.CL,dialogue,"To facilitate research on text generation, this paper presents a
comprehensive and unified library, TextBox 2.0, focusing on the use of
pre-trained language models (PLMs). To be comprehensive, our library covers
$13$ common text generation tasks and their corresponding $83$ datasets and
further incorporates $45$ PLMs covering general, translation, Chinese,
dialogue, controllable, distilled, prompting, and lightweight PLMs. We also
implement $4$ efficient training strategies and provide $4$ generation
objectives for pre-training new PLMs from scratch. To be unified, we design the
interfaces to support the entire research pipeline (from data loading to
training and evaluation), ensuring that each step can be fulfilled in a unified
way. Despite the rich functionality, it is easy to use our library, either
through the friendly Python API or command line. To validate the effectiveness
of our library, we conduct extensive experiments and exemplify four types of
research scenarios. The project is released at the link:
https://github.com/RUCAIBox/TextBox.",2022-12-26
"On Realization of Intelligent Decision-Making in the Real World: A
  Foundation Decision Model Perspective",2022-12-24 06:16:45+00:00,http://arxiv.org/abs/2212.12669v1,"Ying Wen, Ziyu Wan, Ming Zhou, Shufang Hou, Zhe Cao, Chenyang Le, Jingxiao Chen, Zheng Tian, Weinan Zhang, Jun Wang","cs.AI, cs.LG",dialogue,"Our situated environment is full of uncertainty and highly dynamic, thus
hindering the widespread adoption of machine-led Intelligent Decision-Making
(IDM) in real world scenarios. This means IDM should have the capability of
continuously learning new skills and efficiently generalizing across wider
applications. IDM benefits from any new approaches and theoretical
breakthroughs that exhibit Artificial General Intelligence (AGI) breaking the
barriers between tasks and applications. Recent research has well-examined
neural architecture, Transformer, as a backbone foundation model and its
generalization to various tasks, including computer vision, natural language
processing, and reinforcement learning. We therefore argue that a foundation
decision model (FDM) can be established by formulating various decision-making
tasks as a sequence decoding task using the Transformer architecture; this
would be a promising solution to advance the applications of IDM in more
complex real world tasks. In this paper, we elaborate on how a foundation
decision model improves the efficiency and generalization of IDM. We also
discuss potential applications of a FDM in multi-agent game AI, production
scheduling, and robotics tasks. Finally, through a case study, we demonstrate
our realization of the FDM, DigitalBrain (DB1) with 1.2 billion parameters,
which achieves human-level performance over 453 tasks, including text
generation, images caption, video games playing, robotic control, and traveling
salesman problems. As a foundation decision model, DB1 would be a baby step
towards more autonomous and efficient real world IDM applications.",2022-12-24
Ontologically Faithful Generation of Non-Player Character Dialogues,2022-12-20 19:48:10+00:00,http://arxiv.org/abs/2212.10618v1,"Nathaniel Weir, Ryan Thomas, Randolph D'Amore, Kellie Hill, Benjamin Van Durme, Harsh Jhamtani",cs.CL,dialogue,"We introduce a language generation task grounded in a popular video game
environment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)
involves generating dialogue trees conditioned on an ontology captured in
natural language passages providing quest and entity specifications. KNUDGE is
constructed from side quest dialogues drawn directly from game data of Obsidian
Entertainment's The Outer Worlds, leading to real-world complexities in
generation: (1) dialogues are branching trees as opposed to linear chains of
utterances; (2) utterances must remain faithful to the game lore--character
personas, backstories, and entity relationships; and (3) a dialogue must
accurately reveal new quest-related details to the human player. We report
results for supervised and in-context learning techniques, finding there is
significant room for future work on creating realistic game-quality dialogues.",2022-12-20
Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog,2022-12-20 05:51:47+00:00,http://arxiv.org/abs/2212.10008v1,"Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao, Zhu Zhang","cs.CL, cs.AI",dialogue,"Many efforts have been made to construct dialog systems for different types
of conversations, such as task-oriented dialog (TOD) and open-domain dialog
(ODD). To better mimic human-level conversations that usually fuse various
dialog modes, it is essential to build a system that can effectively handle
both TOD and ODD and access different knowledge sources. To address the lack of
available data for the fused task, we propose a framework for automatically
generating dialogues that combine knowledge-grounded ODDs and TODs in various
settings. Additionally, we introduce a unified model PivotBot that is capable
of appropriately adopting TOD and ODD modes and accessing different knowledge
sources in order to effectively tackle the fused task. Evaluation results
demonstrate the superior ability of the proposed model to switch seamlessly
between TOD and ODD tasks.",2022-12-20
"Future Sight: Dynamic Story Generation with Large Pretrained Language
  Models",2022-12-20 01:53:26+00:00,http://arxiv.org/abs/2212.09947v1,"Brian D. Zimmerman, Gaurav Sahu, Olga Vechtomova","cs.CL, cs.AI, cs.LG",dialogue,"Recent advances in deep learning research, such as transformers, have
bolstered the ability for automated agents to generate creative texts similar
to those that a human would write. By default, transformer decoders can only
generate new text with respect to previously generated text. The output
distribution of candidate tokens at any position is conditioned on previously
selected tokens using a self-attention mechanism to emulate the property of
autoregression. This is inherently limiting for tasks such as controllable
story generation where it may be necessary to condition on future plot events
when writing a story. In this work, we propose Future Sight, a method for
finetuning a pretrained generative transformer on the task of future
conditioning. Transformer decoders are typically pretrained on the task of
completing a context, one token at a time, by means of self-attention. Future
Sight additionally enables a decoder to attend to an encoded future plot event.
This motivates the decoder to expand on the context in a way that logically
concludes with the provided future. During inference, the future plot event can
be written by a human author to steer the narrative being generated in a
certain direction. We evaluate the efficacy of our approach on a story
generation task with human evaluators.",2022-12-20
SEScore2: Retrieval Augmented Pretraining for Text Generation Evaluation,2022-12-19 09:02:16+00:00,http://arxiv.org/abs/2212.09305v1,"Wenda Xu, Xian Qian, Mingxuan Wang, Lei Li, William Yang Wang",cs.CL,dialogue,"Is it possible to leverage large scale raw and raw parallel corpora to build
a general learned metric? Existing learned metrics have gaps to human
judgements, are model-dependent or are limited to the domains or tasks where
human ratings are available. In this paper, we propose SEScore2, a model-based
metric pretrained over million-scale synthetic dataset constructed by our novel
retrieval augmented data synthesis pipeline. SEScore2 achieves high correlation
to human judgements without any human rating supervisions. Importantly, our
unsupervised SEScore2 can outperform supervised metrics, which are trained on
the News human ratings, at the TED domain. We evaluate SEScore2 over four text
generation tasks across three languages. SEScore2 outperforms all prior
unsupervised evaluation metrics in machine translation, speech translation,
data-to-text and dialogue generation, with average Kendall improvements 0.158.
SEScore2 even outperforms SOTA supervised BLEURT at data-to-text, dialogue
generation and overall correlation.",2022-12-19
ChatGPT: The End of Online Exam Integrity?,2022-12-19 08:15:16+00:00,http://arxiv.org/abs/2212.09292v1,Teo Susnjak,"cs.AI, cs.CL",dialogue,"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",2022-12-19
"Rainproof: An Umbrella To Shield Text Generators From
  Out-Of-Distribution Data",2022-12-18 21:22:28+00:00,http://arxiv.org/abs/2212.09171v1,"Maxime Darrin, Pablo Piantanida, Pierre Colombo",cs.CL,dialogue,"As more and more conversational and translation systems are deployed in
production, it is essential to implement and to develop effective control
mechanisms guaranteeing their proper functioning and security. An essential
component to ensure safe system behavior is out-of-distribution (OOD)
detection, which aims at detecting whether an input sample is statistically far
from the training distribution. Although OOD detection is a widely covered
topic in classification tasks, it has received much less attention in text
generation. This paper addresses the problem of OOD detection for machine
translation and dialog generation from an operational perspective. Our
contributions include: (i) RAINPROOF a Relative informAItioN Projection ODD
detection framework; and (ii) a more operational evaluation setting for OOD
detection. Surprisingly, we find that OOD detection is not necessarily aligned
with task-specific measures. The OOD detector may filter out samples that are
well processed by the model and keep samples that are not, leading to weaker
performance. Our results show that RAINPROOF breaks this curse and achieve good
results in OOD detection while increasing performance.",2022-12-18
Plansformer: Generating Symbolic Plans using Transformers,2022-12-16 19:06:49+00:00,http://arxiv.org/abs/2212.08681v1,"Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava, Francesco Fabiano, Andrea Loreggia",cs.AI,dialogue,"Large Language Models (LLMs) have been the subject of active research,
significantly advancing the field of Natural Language Processing (NLP). From
BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural
language tasks such as question answering, summarization, and text generation.
Many ongoing efforts focus on understanding LLMs' capabilities, including their
knowledge of the world, syntax, and semantics. However, extending the textual
prowess of LLMs to symbolic reasoning has been slow and predominantly focused
on tackling problems related to the mathematical field. In this paper, we
explore the use of LLMs for automated planning - a branch of AI concerned with
the realization of action sequences (plans) to achieve a goal, typically
executed by intelligent agents, autonomous robots, and unmanned vehicles. We
introduce Plansformer; an LLM fine-tuned on planning problems and capable of
generating plans with favorable behavior in terms of correctness and length
with reduced knowledge-engineering efforts. We also demonstrate the
adaptability of Plansformer in solving different planning domains with varying
complexities, owing to the transfer learning abilities of LLMs. For one
configuration of Plansformer, we achieve ~97% valid plans, out of which ~95%
are optimal for Towers of Hanoi - a puzzle-solving domain.",2022-12-16
"ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data
  Format",2022-11-30 16:37:42+00:00,http://arxiv.org/abs/2211.17148v1,"Qi Zhu, Christian Geishauser, Hsien-chin Lin, Carel van Niekerk, Baolin Peng, Zheng Zhang, Michael Heck, Nurul Lubis, Dazhen Wan, Xiaochen Zhu, Jianfeng Gao, Milica Gašić, Minlie Huang","cs.CL, cs.AI",dialogue,"Diverse data formats and ontologies of task-oriented dialogue (TOD) datasets
hinder us from developing general dialogue models that perform well on many
datasets and studying knowledge transfer between datasets. To address this
issue, we present ConvLab-3, a flexible dialogue system toolkit based on a
unified TOD data format. In ConvLab-3, different datasets are transformed into
one unified format and loaded by models in the same way. As a result, the cost
of adapting a new model or dataset is significantly reduced. Compared to the
previous releases of ConvLab (Lee et al., 2019b; Zhu et al., 2020b), ConvLab-3
allows developing dialogue systems with much more datasets and enhances the
utility of the reinforcement learning (RL) toolkit for dialogue policies. To
showcase the use of ConvLab-3 and inspire future work, we present a
comprehensive study with various settings. We show the benefit of pre-training
on other datasets for few-shot fine-tuning and RL, and encourage evaluating
policy with diverse user simulators.",2022-11-30
"MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous
  Informal Texts",2022-11-25 05:05:29+00:00,http://arxiv.org/abs/2211.13896v1,"Xiangyu Xi, Jianwei Lv, Shuaipeng Liu, Wei Ye, Fan Yang, Guanglu Wan",cs.CL,dialogue,"Event detection (ED) identifies and classifies event triggers from
unstructured texts, serving as a fundamental task for information extraction.
Despite the remarkable progress achieved in the past several years, most
research efforts focus on detecting events from formal texts (e.g., news
articles, Wikipedia documents, financial announcements). Moreover, the texts in
each dataset are either from a single source or multiple yet relatively
homogeneous sources. With massive amounts of user-generated text accumulating
on the Web and inside enterprises, identifying meaningful events in these
informal texts, usually from multiple heterogeneous sources, has become a
problem of significant practical value. As a pioneering exploration that
expands event detection to the scenarios involving informal and heterogeneous
texts, we propose a new large-scale Chinese event detection dataset based on
user reviews, text conversations, and phone conversations in a leading
e-commerce platform for food service. We carefully investigate the proposed
dataset's textual informality and multi-source heterogeneity characteristics by
inspecting data samples quantitatively and qualitatively. Extensive experiments
with state-of-the-art event detection methods verify the unique challenges
posed by these characteristics, indicating that multi-source informal event
detection remains an open problem and requires further efforts. Our benchmark
and code are released at \url{https://github.com/myeclipse/MUSIED}.",2022-11-25
"Human-Machine Collaboration Approaches to Build a Dialogue Dataset for
  Hate Speech Countering",2022-11-07 10:37:13+00:00,http://arxiv.org/abs/2211.03433v1,"Helena Bonaldi, Sara Dellantonio, Serra Sinem Tekiroglu, Marco Guerini","cs.CL, cs.CY",dialogue,"Fighting online hate speech is a challenge that is usually addressed using
Natural Language Processing via automatic detection and removal of hate
content. Besides this approach, counter narratives have emerged as an effective
tool employed by NGOs to respond to online hate on social media platforms. For
this reason, Natural Language Generation is currently being studied as a way to
automatize counter narrative writing. However, the existing resources necessary
to train NLG models are limited to 2-turn interactions (a hate speech and a
counter narrative as response), while in real life, interactions can consist of
multiple turns. In this paper, we present a hybrid approach for dialogical data
collection, which combines the intervention of human expert annotators over
machine generated dialogues obtained using 19 different configurations. The
result of this work is DIALOCONAN, the first dataset comprising over 3000
fictitious multi-turn dialogues between a hater and an NGO operator, covering 6
targets of hate.",2022-11-07
"Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with
  User Simulator",2022-10-26 07:41:32+00:00,http://arxiv.org/abs/2210.14529v1,"Qinyuan Cheng, Linyang Li, Guofeng Quan, Feng Gao, Xiaofeng Mou, Xipeng Qiu",cs.CL,dialogue,"Task-Oriented Dialogue (TOD) systems are drawing more and more attention in
recent studies. Current methods focus on constructing pre-trained models or
fine-tuning strategies while the evaluation of TOD is limited by a policy
mismatch problem. That is, during evaluation, the user utterances are from the
annotated dataset while these utterances should interact with previous
responses which can have many alternatives besides annotated texts. Therefore,
in this work, we propose an interactive evaluation framework for TOD. We first
build a goal-oriented user simulator based on pre-trained models and then use
the user simulator to interact with the dialogue system to generate dialogues.
Besides, we introduce a sentence-level and a session-level score to measure the
sentence fluency and session coherence in the interactive evaluation.
Experimental results show that RL-based TOD systems trained by our proposed
user simulator can achieve nearly 98% inform and success rates in the
interactive evaluation of MultiWOZ dataset and the proposed scores measure the
response quality besides the inform and success rates. We are hoping that our
work will encourage simulator-based interactive evaluations in the TOD task.",2022-10-26
"Are Current Decoding Strategies Capable of Facing the Challenges of
  Visual Dialogue?",2022-10-24 07:34:39+00:00,http://arxiv.org/abs/2210.12997v1,"Amit Kumar Chaudhary, Alex J. Lucassen, Ioanna Tsani, Alberto Testoni","cs.CL, cs.CV",dialogue,"Decoding strategies play a crucial role in natural language generation
systems. They are usually designed and evaluated in open-ended text-only tasks,
and it is not clear how different strategies handle the numerous challenges
that goal-oriented multimodal systems face (such as grounding and
informativeness). To answer this question, we compare a wide variety of
different decoding strategies and hyper-parameter configurations in a Visual
Dialogue referential game. Although none of them successfully balance lexical
richness, accuracy in the task, and visual grounding, our in-depth analysis
allows us to highlight the strengths and weaknesses of each decoding strategy.
We believe our findings and suggestions may serve as a starting point for
designing more effective decoding algorithms that handle the challenges of
Visual Dialogue tasks.",2022-10-24
Language Detoxification with Attribute-Discriminative Latent Space,2022-10-19 06:54:42+00:00,http://arxiv.org/abs/2210.10329v1,"Jin Myung Kwak, Minseon Kim, Sung Ju Hwang","cs.CL, cs.AI",dialogue,"Transformer-based Language Models (LMs) achieve remarkable performances on a
variety of NLU tasks, but are also prone to generating toxic texts such as
insults, threats, and profanities which limit their adaptations to the
real-world applications. To overcome this issue, a few text generation
approaches aim to detoxify toxic texts with additional LMs or perturbations.
However, previous methods require excessive memory, computations, and time
which are serious bottlenecks in their real-world application. To address such
limitations, we propose an effective yet efficient method for language
detoxification using an attribute-discriminative latent space. Specifically, we
project the latent space of an original Transformer LM to a discriminative
latent space on which the texts are well-separated by their attributes, with
the help of a projection block and a discriminator. This allows the LM to
control the text generation to be non-toxic with minimal memory and computation
overhead. We validate our model, Attribute-Discriminative Language Model (ADLM)
on detoxified language and dialogue generation tasks, on which our method
significantly outperforms baselines both in performance and efficiency.",2022-10-19
"Team Flow at DRC2022: Pipeline System for Travel Destination
  Recommendation Task in Spoken Dialogue",2022-10-18 01:11:16+00:00,http://arxiv.org/abs/2210.09518v1,"Ryu Hirai, Atsumoto Ohashi, Ao Guo, Hideki Shiroma, Xulin Zhou, Yukihiko Tone, Shinya Iizuka, Ryuichiro Higashinaka","cs.CL, cs.AI, cs.RO",dialogue,"To improve the interactive capabilities of a dialogue system, e.g., to adapt
to different customers, the Dialogue Robot Competition (DRC2022) was held. As
one of the teams, we built a dialogue system with a pipeline structure
containing four modules. The natural language understanding (NLU) and natural
language generation (NLG) modules were GPT-2 based models, and the dialogue
state tracking (DST) and policy modules were designed on the basis of
hand-crafted rules. After the preliminary round of the competition, we found
that the low variation in training examples for the NLU and failed
recommendation due to the policy used were probably the main reasons for the
limited performance of the system.",2022-10-18
"LEATHER: A Framework for Learning to Generate Human-like Text in
  Dialogue",2022-10-14 13:05:11+00:00,http://arxiv.org/abs/2210.07777v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.LG",dialogue,"Algorithms for text-generation in dialogue can be misguided. For example, in
task-oriented settings, reinforcement learning that optimizes only task-success
can lead to abysmal lexical diversity. We hypothesize this is due to poor
theoretical understanding of the objectives in text-generation and their
relation to the learning process (i.e., model training). To this end, we
propose a new theoretical framework for learning to generate text in dialogue.
Compared to existing theories of learning, our framework allows for analysis of
the multi-faceted goals inherent to text-generation. We use our framework to
develop theoretical guarantees for learners that adapt to unseen data. As an
example, we apply our theory to study data-shift within a cooperative learning
algorithm proposed for the GuessWhat?! visual dialogue game. From this insight,
we propose a new algorithm, and empirically, we demonstrate our proposal
improves both task-success and human-likeness of the generated text. Finally,
we show statistics from our theory are empirically predictive of multiple
qualities of the generated dialogue, suggesting our theory is useful for
model-selection when human evaluations are not available.",2022-10-14
Towards a Unified Multi-Dimensional Evaluator for Text Generation,2022-10-13 17:17:03+00:00,http://arxiv.org/abs/2210.07197v1,"Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, Jiawei Han",cs.CL,dialogue,"Multi-dimensional evaluation is the dominant paradigm for human evaluation in
Natural Language Generation (NLG), i.e., evaluating the generated text from
multiple explainable dimensions, such as coherence and fluency. However,
automatic evaluation in NLG is still dominated by similarity-based metrics, and
we lack a reliable framework for a more comprehensive evaluation of advanced
models. In this paper, we propose a unified multi-dimensional evaluator UniEval
for NLG. We re-frame NLG evaluation as a Boolean Question Answering (QA) task,
and by guiding the model with different questions, we can use one evaluator to
evaluate from multiple dimensions. Furthermore, thanks to the unified Boolean
QA format, we are able to introduce an intermediate learning phase that enables
UniEval to incorporate external knowledge from multiple related tasks and gain
further improvement. Experiments on three typical NLG tasks show that UniEval
correlates substantially better with human judgments than existing metrics.
Specifically, compared to the top-performing unified evaluators, UniEval
achieves a 23% higher correlation on text summarization, and over 43% on
dialogue response generation. Also, UniEval demonstrates a strong zero-shot
learning ability for unseen evaluation dimensions and tasks. Source code, data
and all pre-trained evaluators are available on our GitHub repository
(https://github.com/maszhongming/UniEval).",2022-10-13
Controllable Dialogue Simulation with In-Context Learning,2022-10-09 06:32:58+00:00,http://arxiv.org/abs/2210.04185v1,"Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, Xifeng Yan","cs.CL, cs.AI",dialogue,"Building dialogue systems requires a large corpus of annotated dialogues.
Such datasets are usually created via crowdsourcing, which is expensive and
time-consuming. In this paper, we propose a novel method for dialogue
simulation based on language model in-context learning, dubbed as
\textsc{Dialogic}. Seeded with a few annotated dialogues, \textsc{Dialogic}
automatically selects in-context examples for demonstration and prompts GPT-3
to generate new dialogues and their annotations in a controllable way.
Leveraging the strong in-context learning ability of GPT-3, our method can be
used to rapidly expand a small set of dialogue data without requiring
\textit{human involvement} or \textit{parameter update}, and is thus much more
cost-efficient and time-saving than crowdsourcing. Experimental results on the
MultiWOZ dataset demonstrate that training a model on the simulated dialogues
leads to even better performance than using the same amount of human-generated
dialogues in the low-resource settings, with as few as 85 dialogues as the seed
data. Human evaluation results also show that our simulated dialogues has high
language fluency and annotation accuracy. The code and data are available at
\href{https://github.com/Leezekun/dialogic}{https://github.com/Leezekun/dialogic}.",2022-10-09
"Unsupervised Neural Stylistic Text Generation using Transfer learning
  and Adapters",2022-10-07 00:09:22+00:00,http://arxiv.org/abs/2210.03264v1,"Vinayshekhar Bannihatti Kumar, Rashmi Gangadharaiah, Dan Roth",cs.CL,dialogue,"Research has shown that personality is a key driver to improve engagement and
user experience in conversational systems. Conversational agents should also
maintain a consistent persona to have an engaging conversation with a user.
However, text generation datasets are often crowd sourced and thereby have an
averaging effect where the style of the generation model is an average style of
all the crowd workers that have contributed to the dataset. While one can
collect persona-specific datasets for each task, it would be an expensive and
time consuming annotation effort. In this work, we propose a novel transfer
learning framework which updates only $0.3\%$ of model parameters to learn
style specific attributes for response generation. For the purpose of this
study, we tackle the problem of stylistic story ending generation using the ROC
stories Corpus. We learn style specific attributes from the
PERSONALITY-CAPTIONS dataset. Through extensive experiments and evaluation
metrics we show that our novel training procedure can improve the style
generation by 200 over Encoder-Decoder baselines while maintaining on-par
content relevance metrics with",2022-10-07
"Learning functional sections in medical conversations: iterative
  pseudo-labeling and human-in-the-loop approach",2022-10-06 03:33:00+00:00,http://arxiv.org/abs/2210.02658v2,"Mengqian Wang, Ilya Valmianski, Xavier Amatriain, Anitha Kannan",cs.CL,dialogue,"Medical conversations between patients and medical professionals have
implicit functional sections, such as ""history taking"", ""summarization"",
""education"", and ""care plan."" In this work, we are interested in learning to
automatically extract these sections. A direct approach would require
collecting large amounts of expert annotations for this task, which is
inherently costly due to the contextual inter-and-intra variability between
these sections. This paper presents an approach that tackles the problem of
learning to classify medical dialogue into functional sections without
requiring a large number of annotations. Our approach combines pseudo-labeling
and human-in-the-loop. First, we bootstrap using weak supervision with
pseudo-labeling to generate dialogue turn-level pseudo-labels and train a
transformer-based model, which is then applied to individual sentences to
create noisy sentence-level labels. Second, we iteratively refine
sentence-level labels using a cluster-based human-in-the-loop approach. Each
iteration requires only a few dozen annotator decisions. We evaluate the
results on an expert-annotated dataset of 100 dialogues and find that while our
models start with 69.5% accuracy, we can iteratively improve it to 82.5%. The
code used to perform all experiments described in this paper can be found here:
https://github.com/curai/curai-research/tree/main/functional-sections.",2022-10-06
"Dancing with the Unexpected and Beyond: The Use of AI Assistance in
  Design Fiction Creation",2022-10-03 11:26:39+00:00,http://arxiv.org/abs/2210.00829v1,"Yiying Wu, Yunye Yu, Pengcheng An",cs.HC,dialogue,"The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology.",2022-10-03
"Co-Writing Screenplays and Theatre Scripts with Language Models: An
  Evaluation by Industry Professionals",2022-09-29 17:26:22+00:00,http://arxiv.org/abs/2209.14958v1,"Piotr Mirowski, Kory W. Mathewson, Jaylen Pittman, Richard Evans","cs.HC, cs.CL",dialogue,"Language models are increasingly attracting interest from writers. However,
such models lack long-range semantic coherence, limiting their usefulness for
longform creative writing. We address this limitation by applying language
models hierarchically, in a system we call Dramatron. By building structural
context via prompt chaining, Dramatron can generate coherent scripts and
screenplays complete with title, characters, story beats, location
descriptions, and dialogue. We illustrate Dramatron's usefulness as an
interactive co-creative system with a user study of 15 theatre and film
industry professionals. Participants co-wrote theatre scripts and screenplays
with Dramatron and engaged in open-ended interviews. We report critical
reflections both from our interviewees and from independent reviewers who
watched stagings of the works to illustrate how both Dramatron and hierarchical
text generation could be useful for human-machine co-creativity. Finally, we
discuss the suitability of Dramatron for co-creativity, ethical considerations
-- including plagiarism and bias -- and participatory models for the design and
deployment of such tools.",2022-09-29
"A Benchmark for Understanding and Generating Dialogue between Characters
  in Stories",2022-09-18 10:19:04+00:00,http://arxiv.org/abs/2209.08524v1,"Jianzhu Yao, Ziqi Liu, Jian Guan, Minlie Huang","cs.CL, cs.AI",dialogue,"Many classical fairy tales, fiction, and screenplays leverage dialogue to
advance story plots and establish characters. We present the first study to
explore whether machines can understand and generate dialogue in stories, which
requires capturing traits of different characters and the relationships between
them. To this end, we propose two new tasks including Masked Dialogue
Generation and Dialogue Speaker Recognition, i.e., generating missing dialogue
turns and predicting speakers for specified dialogue turns, respectively. We
build a new dataset DialStory, which consists of 105k Chinese stories with a
large amount of dialogue weaved into the plots to support the evaluation. We
show the difficulty of the proposed tasks by testing existing models with
automatic and manual evaluation on DialStory. Furthermore, we propose to learn
explicit character representations to improve performance on these tasks.
Extensive experiments and case studies show that our approach can generate more
coherent and informative dialogue, and achieve higher speaker recognition
accuracy than strong baselines.",2022-09-18
"Adaptive Natural Language Generation for Task-oriented Dialogue via
  Reinforcement Learning",2022-09-16 12:08:57+00:00,http://arxiv.org/abs/2209.07873v1,"Atsumoto Ohashi, Ryuichiro Higashinaka","cs.CL, cs.AI",dialogue,"When a natural language generation (NLG) component is implemented in a
real-world task-oriented dialogue system, it is necessary to generate not only
natural utterances as learned on training data but also utterances adapted to
the dialogue environment (e.g., noise from environmental sounds) and the user
(e.g., users with low levels of understanding ability). Inspired by recent
advances in reinforcement learning (RL) for language generation tasks, we
propose ANTOR, a method for Adaptive Natural language generation for
Task-Oriented dialogue via Reinforcement learning. In ANTOR, a natural language
understanding (NLU) module, which corresponds to the user's understanding of
system utterances, is incorporated into the objective function of RL. If the
NLG's intentions are correctly conveyed to the NLU, which understands a
system's utterances, the NLG is given a positive reward. We conducted
experiments on the MultiWOZ dataset, and we confirmed that ANTOR could generate
adaptive utterances against speech recognition errors and the different
vocabulary levels of users.",2022-09-16
"OPAL: Ontology-Aware Pretrained Language Model for End-to-End
  Task-Oriented Dialogue",2022-09-10 04:38:27+00:00,http://arxiv.org/abs/2209.04595v1,"Zhi Chen, Yuncong Liu, Lu Chen, Su Zhu, Mengyue Wu, Kai Yu",cs.CL,dialogue,"This paper presents an ontology-aware pretrained language model (OPAL) for
end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models,
task-oriented dialogue models fulfill at least two task-specific modules:
dialogue state tracker (DST) and response generator (RG). The dialogue state
consists of the domain-slot-value triples, which are regarded as the user's
constraints to search the domain-related databases. The large-scale
task-oriented dialogue data with the annotated structured dialogue state
usually are inaccessible. It prevents the development of the pretrained
language model for the task-oriented dialogue. We propose a simple yet
effective pretraining method to alleviate this problem, which consists of two
pretraining phases. The first phase is to pretrain on large-scale contextual
text data, where the structured information of the text is extracted by the
information extracting tool. To bridge the gap between the pretraining method
and downstream tasks, we design two pretraining tasks: ontology-like triple
recovery and next-text generation, which simulates the DST and RG,
respectively. The second phase is to fine-tune the pretrained model on the TOD
data. The experimental results show that our proposed method achieves an
exciting boost and get competitive performance even without any TOD data on
CamRest676 and MultiWOZ benchmarks.",2022-09-10
Unified Knowledge Prompt Pre-training for Customer Service Dialogues,2022-08-31 06:23:53+00:00,http://arxiv.org/abs/2208.14652v1,"Keqing He, Jingang Wang, Chaobo Sun, Wei Wu",cs.CL,dialogue,"Dialogue bots have been widely applied in customer service scenarios to
provide timely and user-friendly experience. These bots must classify the
appropriate domain of a dialogue, understand the intent of users, and generate
proper responses. Existing dialogue pre-training models are designed only for
several dialogue tasks and ignore weakly-supervised expert knowledge in
customer service dialogues. In this paper, we propose a novel unified knowledge
prompt pre-training framework, UFA (\textbf{U}nified Model \textbf{F}or
\textbf{A}ll Tasks), for customer service dialogues. We formulate all the tasks
of customer service dialogues as a unified text-to-text generation task and
introduce a knowledge-driven prompt strategy to jointly learn from a mixture of
distinct dialogue tasks. We pre-train UFA on a large-scale Chinese customer
service corpus collected from practical scenarios and get significant
improvements on both natural language understanding (NLU) and natural language
generation (NLG) benchmarks.",2022-08-31
"GenTUS: Simulating User Behaviour and Language in Task-oriented
  Dialogues with Generative Transformers",2022-08-23 09:01:17+00:00,http://arxiv.org/abs/2208.10817v1,"Hsien-Chin Lin, Christian Geishauser, Shutong Feng, Nurul Lubis, Carel van Niekerk, Michael Heck, Milica Gašić",cs.CL,dialogue,"User simulators (USs) are commonly used to train task-oriented dialogue
systems (DSs) via reinforcement learning. The interactions often take place on
semantic level for efficiency, but there is still a gap from semantic actions
to natural language, which causes a mismatch between training and deployment
environment. Incorporating a natural language generation (NLG) module with USs
during training can partly deal with this problem. However, since the policy
and NLG of USs are optimised separately, these simulated user utterances may
not be natural enough in a given context. In this work, we propose a generative
transformer-based user simulator (GenTUS). GenTUS consists of an
encoder-decoder structure, which means it can optimise both the user policy and
natural language generation jointly. GenTUS generates both semantic actions and
natural language utterances, preserving interpretability and enhancing language
variation. In addition, by representing the inputs and outputs as word
sequences and by using a large pre-trained language model we can achieve
generalisability in feature representation. We evaluate GenTUS with automatic
metrics and human evaluation. Our results show that GenTUS generates more
natural language and is able to transfer to an unseen ontology in a zero-shot
fashion. In addition, its behaviour can be further shaped with reinforcement
learning opening the door to training specialised user simulators.",2022-08-23
"Efficient Task-Oriented Dialogue Systems with Response Selection as an
  Auxiliary Task",2022-08-15 09:59:44+00:00,http://arxiv.org/abs/2208.07097v1,"Radostin Cholakov, Todor Kolev","cs.CL, cs.AI",dialogue,"The adoption of pre-trained language models in task-oriented dialogue systems
has resulted in significant enhancements of their text generation abilities.
However, these architectures are slow to use because of the large number of
trainable parameters and can sometimes fail to generate diverse responses. To
address these limitations, we propose two models with auxiliary tasks for
response selection - (1) distinguishing distractors from ground truth responses
and (2) distinguishing synthetic responses from ground truth labels. They
achieve state-of-the-art results on the MultiWOZ 2.1 dataset with combined
scores of 107.5 and 108.3 and outperform a baseline with three times more
parameters. We publish reproducible code and checkpoints and discuss the
effects of applying auxiliary tasks to T5-based architectures.",2022-08-15
"Dynamically Retrieving Knowledge via Query Generation for informative
  dialogue response",2022-07-30 03:05:43+00:00,http://arxiv.org/abs/2208.00128v1,"Zhongtian Hu, Yangqi Chen, Yushuang Liu, Lifang Wang",cs.CL,dialogue,"Knowledge-driven dialogue generation has recently made remarkable
breakthroughs. Compared with general dialogue systems, superior
knowledge-driven dialogue systems can generate more informative and
knowledgeable responses with pre-provided knowledge. However, in practical
applications, the dialogue system cannot be provided with corresponding
knowledge in advance. In order to solve the problem, we design a
knowledge-driven dialogue system named DRKQG (\emph{Dynamically Retrieving
Knowledge via Query Generation for informative dialogue response}).
Specifically, the system can be divided into two modules: query generation
module and dialogue generation module. First, a time-aware mechanism is
utilized to capture context information and a query can be generated for
retrieving knowledge. Then, we integrate copy Mechanism and Transformers, which
allows the response generation module produces responses derived from the
context and retrieved knowledge. Experimental results at LIC2022, Language and
Intelligence Technology Competition, show that our module outperforms the
baseline model by a large margin on automatic evaluation metrics, while human
evaluation by Baidu Linguistics team shows that our system achieves impressive
results in Factually Correct and Knowledgeable.",2022-07-30
Sequence to sequence pretraining for a less-resourced Slovenian language,2022-07-28 10:08:50+00:00,http://arxiv.org/abs/2207.13988v1,"Matej Ulčar, Marko Robnik-Šikonja",cs.CL,dialogue,"Large pretrained language models have recently conquered the area of natural
language processing. As an alternative to predominant masked language modelling
introduced in BERT, the T5 model has introduced a more general training
objective, namely sequence to sequence transformation, which includes masked
language model but more naturally fits text generation tasks such as machine
translation, summarization, open-domain question answering, text
simplification, dialogue systems, etc. The monolingual variants of T5 models
have been limited to well-resourced languages, while the massively multilingual
T5 model supports 101 languages. In contrast, we trained two different sized
T5-type sequence to sequence models for morphologically rich Slovene language
with much less resources and analyzed their behavior. Concerning classification
tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa
model but are to be considered for the generative tasks.",2022-07-28
A Multi-Party Dialogue Ressource in French,2022-07-25 13:02:54+00:00,http://arxiv.org/abs/2207.12162v1,"Maria Boritchev, Maxime Amblard",cs.AI,dialogue,"We present Dialogues in Games (DinG), a corpus of manual transcriptions of
real-life, oral, spontaneous multi-party dialogues between French-speaking
players of the board game Catan. Our objective is to make available a quality
resource for French, composed of long dialogues, to facilitate their study in
the style of (Asher et al., 2016). In a general dialogue setting, participants
share personal information, which makes it impossible to disseminate the
resource freely and openly. In DinG, the attention of the participants is
focused on the game, which prevents them from talking about themselves. In
addition, we are conducting a study on the nature of the questions in dialogue,
through annotation (Cruz Blandon et al., 2019), in order to develop more
natural automatic dialogue systems.",2022-07-25
Towards a Sentiment-Aware Conversational Agent,2022-07-24 16:59:44+00:00,http://arxiv.org/abs/2207.11774v1,"Isabel Dias, Ricardo Rei, Patrícia Pereira, Luisa Coheur",cs.CL,dialogue,"In this paper, we propose an end-to-end sentiment-aware conversational agent
based on two models: a reply sentiment prediction model, which leverages the
context of the dialogue to predict an appropriate sentiment for the agent to
express in its reply; and a text generation model, which is conditioned on the
predicted sentiment and the context of the dialogue, to produce a reply that is
both context and sentiment appropriate. Additionally, we propose to use a
sentiment classification model to evaluate the sentiment expressed by the agent
during the development of the model. This allows us to evaluate the agent in an
automatic way. Both automatic and human evaluation results show that explicitly
guiding the text generation model with a pre-defined set of sentences leads to
clear improvements, both regarding the expressed sentiment and the quality of
the generated text.",2022-07-24
"TalkToModel: Understanding Machine Learning Models With Open Ended
  Dialogues",2022-07-08 23:42:56+00:00,http://arxiv.org/abs/2207.04154v1,"Dylan Slack, Satyapriya Krishna, Himabindu Lakkaraju, Sameer Singh","cs.LG, cs.AI, cs.CL",dialogue,"Machine Learning (ML) models are increasingly used to make critical decisions
in real-world applications, yet they have also become more complex, making them
harder to understand. To this end, several techniques to explain model
predictions have been proposed. However, practitioners struggle to leverage
explanations because they often do not know which to use, how to interpret the
results, and may have insufficient data science experience to obtain
explanations. In addition, most current works focus on generating one-shot
explanations and do not allow users to follow up and ask fine-grained questions
about the explanations, which can be frustrating. In this work, we address
these challenges by introducing TalkToModel: an open-ended dialogue system for
understanding machine learning models. Specifically, TalkToModel comprises
three key components: 1) a natural language interface for engaging in
dialogues, making understanding ML models highly accessible, 2) a dialogue
engine that adapts to any tabular model and dataset, interprets natural
language, maps it to appropriate operations (e.g., feature importance
explanations, counterfactual explanations, showing model errors), and generates
text responses, and 3) an execution component that run the operations and
ensures explanations are accurate. We carried out quantitative and human
subject evaluations of TalkToModel. We found the system understands user
questions on novel datasets and models with high accuracy, demonstrating the
system's capacity to generalize to new situations. In human evaluations, 73% of
healthcare workers (e.g., doctors and nurses) agreed they would use TalkToModel
over baseline point-and-click systems, and 84.6% of ML graduate students agreed
TalkToModel was easier to use.",2022-07-08
Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk,2022-07-02 04:30:07+00:00,http://arxiv.org/abs/2207.00735v1,"Benyou Wang, Xiangbo Wu, Xiaokang Liu, Jianquan Li, Prayag Tiwari, Qianqian Xie",cs.CL,dialogue,"Language is the principal tool for human communication, in which humor is one
of the most attractive parts. Producing natural language like humans using
computers, a.k.a, Natural Language Generation (NLG), has been widely used for
dialogue systems, chatbots, machine translation, as well as computer-aid
creation e.g., idea generations, scriptwriting. However, the humor aspect of
natural language is relatively under-investigated, especially in the age of
pre-trained language models. In this work, we aim to preliminarily test whether
NLG can generate humor as humans do. We build a new dataset consisting of
numerous digitized Chinese Comical Crosstalk scripts (called C$^3$ in short),
which is for a popular Chinese performing art called `Xiangsheng' since 1800s.
(For convenience for non-Chinese speakers, we called `crosstalk' for
`Xiangsheng' in this paper.) We benchmark various generation approaches
including training-from-scratch Seq2seq, fine-tuned middle-scale PLMs, and
large-scale PLMs (with and without fine-tuning). Moreover, we also conduct a
human assessment, showing that 1) large-scale pretraining largely improves
crosstalk generation quality; and 2) even the scripts generated from the best
PLM is far from what we expect, with only 65% quality of human-created
crosstalk. We conclude, humor generation could be largely improved using
large-scaled PLMs, but it is still in its infancy.
  The data and benchmarking code is publicly available in
\url{https://github.com/anonNo2/crosstalk-generation}.",2022-07-02
"Comparing informativeness of an NLG chatbot vs graphical app in
  diet-information domain",2022-06-23 07:15:58+00:00,http://arxiv.org/abs/2206.13435v1,"Simone Balloccu, Ehud Reiter","cs.CL, cs.AI",dialogue,"Visual representation of data like charts and tables can be challenging to
understand for readers. Previous work showed that combining visualisations with
text can improve the communication of insights in static contexts, but little
is known about interactive ones. In this work we present an NLG chatbot that
processes natural language queries and provides insights through a combination
of charts and text. We apply it to nutrition, a domain communication quality is
critical. Through crowd-sourced evaluation we compare the informativeness of
our chatbot against traditional, static diet-apps. We find that the
conversational context significantly improved users' understanding of dietary
data in various tasks, and that users considered the chatbot as more useful and
quick to use than traditional apps.",2022-06-23
"Automatic Summarization of Russian Texts: Comparison of Extractive and
  Abstractive Methods",2022-06-18 17:28:04+00:00,http://arxiv.org/abs/2206.09253v1,"Valeriya Goloviznina, Evgeny Kotelnikov",cs.CL,dialogue,"The development of large and super-large language models, such as GPT-3, T5,
Switch Transformer, ERNIE, etc., has significantly improved the performance of
text generation. One of the important research directions in this area is the
generation of texts with arguments. The solution of this problem can be used in
business meetings, political debates, dialogue systems, for preparation of
student essays. One of the main domains for these applications is the economic
sphere. The key problem of the argument text generation for the Russian
language is the lack of annotated argumentation corpora. In this paper, we use
translated versions of the Argumentative Microtext, Persuasive Essays and UKP
Sentential corpora to fine-tune RuBERT model. Further, this model is used to
annotate the corpus of economic news by argumentation. Then the annotated
corpus is employed to fine-tune the ruGPT-3 model, which generates argument
texts. The results show that this approach improves the accuracy of the
argument generation by more than 20 percentage points (63.2% vs. 42.5%)
compared to the original ruGPT-3 model.",2022-06-18
Argumentative Text Generation in Economic Domain,2022-06-18 17:22:06+00:00,http://arxiv.org/abs/2206.09251v1,"Irina Fishcheva, Dmitriy Osadchiy, Klavdiya Bochenina, Evgeny Kotelnikov",cs.CL,dialogue,"The development of large and super-large language models, such as GPT-3, T5,
Switch Transformer, ERNIE, etc., has significantly improved the performance of
text generation. One of the important research directions in this area is the
generation of texts with arguments. The solution of this problem can be used in
business meetings, political debates, dialogue systems, for preparation of
student essays. One of the main domains for these applications is the economic
sphere. The key problem of the argument text generation for the Russian
language is the lack of annotated argumentation corpora. In this paper, we use
translated versions of the Argumentative Microtext, Persuasive Essays and UKP
Sentential corpora to fine-tune RuBERT model. Further, this model is used to
annotate the corpus of economic news by argumentation. Then the annotated
corpus is employed to fine-tune the ruGPT-3 model, which generates argument
texts. The results show that this approach improves the accuracy of the
argument generation by more than 20 percentage points (63.2\% vs. 42.5\%)
compared to the original ruGPT-3 model.",2022-06-18
"Offline RL for Natural Language Generation with Implicit Language Q
  Learning",2022-06-05 18:38:42+00:00,http://arxiv.org/abs/2206.11871v1,"Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine","cs.CL, cs.LG",dialogue,"Large language models distill broad knowledge from text corpora. However,
they can be inconsistent when it comes to completing user specified tasks. This
issue can be addressed by finetuning such models via supervised learning on
curated datasets, or via reinforcement learning. In this work, we propose a
novel offline RL motivated method, implicit language Q-learning (ILQL),
designed for use on language models, that combines both the flexible utility
optimization framework of traditional RL algorithms with supervised learning's
ability to leverage existing data and its simplicity and stability. Our method,
based on dynamic programming, employs a blend of value conservatism alongside
an implicit dataset support constraint in learning value functions, which are
then used to guide language model generations towards maximizing utility. In
addition to empirically validating ILQL, we present a detailed empirical
analysis of situations where offline RL can be useful in natural language
generation settings, demonstrating how it can be a more effective utility
optimizer than prior approaches for end-to-end dialogue, and how it can
effectively optimize high variance reward functions based on subjective
judgement, such as whether to label a comment as an example of toxic speech or
not.",2022-06-05
"Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for
  Text-to-Speech",2022-06-05 10:50:34+00:00,http://arxiv.org/abs/2206.02147v1,"Ziyue Jiang, Su Zhe, Zhou Zhao, Qian Yang, Yi Ren, Jinglin Liu, Zhenhui Ye","eess.AS, cs.CL, cs.SD",dialogue,"Polyphone disambiguation aims to capture accurate pronunciation knowledge
from natural text sequences for reliable Text-to-speech (TTS) systems. However,
previous approaches require substantial annotated training data and additional
efforts from language experts, making it difficult to extend high-quality
neural TTS systems to out-of-domain daily conversations and countless languages
worldwide. This paper tackles the polyphone disambiguation problem from a
concise and novel perspective: we propose Dict-TTS, a semantic-aware generative
text-to-speech model with an online website dictionary (the existing prior
information in the natural language). Specifically, we design a
semantics-to-pronunciation attention (S2PA) module to match the semantic
patterns between the input text sequence and the prior semantics in the
dictionary and obtain the corresponding pronunciations; The S2PA module can be
easily trained with the end-to-end TTS model without any annotated phoneme
labels. Experimental results in three languages show that our model outperforms
several strong baseline models in terms of pronunciation accuracy and improves
the prosody modeling of TTS systems. Further extensive analyses with different
linguistic encoders demonstrate that each design in Dict-TTS is effective.
Audio samples are available at \url{https://dicttts.github.io/DictTTS-Demo/}.",2022-06-05
"Findings of the The RuATD Shared Task 2022 on Artificial Text Detection
  in Russian",2022-06-03 14:12:33+00:00,http://arxiv.org/abs/2206.01583v1,"Tatiana Shamardina, Vladislav Mikhailov, Daniil Chernianskii, Alena Fenogenova, Marat Saidov, Anastasiya Valeeva, Tatiana Shavrina, Ivan Smurov, Elena Tutubalina, Ekaterina Artemova",cs.CL,dialogue,"We present the shared task on artificial text detection in Russian, which is
organized as a part of the Dialogue Evaluation initiative, held in 2022. The
shared task dataset includes texts from 14 text generators, i.e., one human
writer and 13 text generative models fine-tuned for one or more of the
following generation tasks: machine translation, paraphrase generation, text
summarization, text simplification. We also consider back-translation and
zero-shot generation approaches. The human-written texts are collected from
publicly available resources across multiple domains. The shared task consists
of two sub-tasks: (i) to determine if a given text is automatically generated
or written by a human; (ii) to identify the author of a given text. The first
task is framed as a binary classification problem. The second task is a
multi-class classification problem. We provide count-based and BERT-based
baselines, along with the human evaluation on the first sub-task. A total of 30
and 8 systems have been submitted to the binary and multi-class sub-tasks,
correspondingly. Most teams outperform the baselines by a wide margin. We
publicly release our codebase, human evaluation results, and other materials in
our GitHub repository (https://github.com/dialogue-evaluation/RuATD).",2022-06-03
Clinical Dialogue Transcription Error Correction using Seq2Seq Models,2022-05-26 18:27:17+00:00,http://arxiv.org/abs/2205.13572v1,"Gayani Nanayakkara, Nirmalie Wiratunga, David Corsar, Kyle Martin, Anjana Wijekoon","cs.CL, cs.AI",dialogue,"Good communication is critical to good healthcare. Clinical dialogue is a
conversation between health practitioners and their patients, with the explicit
goal of obtaining and sharing medical information. This information contributes
to medical decision-making regarding the patient and plays a crucial role in
their healthcare journey. The reliance on note taking and manual scribing
processes are extremely inefficient and leads to manual transcription errors
when digitizing notes. Automatic Speech Recognition (ASR) plays a significant
role in speech-to-text applications, and can be directly used as a text
generator in conversational applications. However, recording clinical dialogue
presents a number of general and domain-specific challenges. In this paper, we
present a seq2seq learning approach for ASR transcription error correction of
clinical dialogues. We introduce a new Gastrointestinal Clinical Dialogue (GCD)
Dataset which was gathered by healthcare professionals from a NHS Inflammatory
Bowel Disease clinic and use this in a comparative study with four commercial
ASR systems. Using self-supervision strategies, we fine-tune a seq2seq model on
a mask-filling task using a domain-specific PubMed dataset which we have shared
publicly for future research. The BART model fine-tuned for mask-filling was
able to correct transcription errors and achieve lower word error rates for
three out of four commercial ASR outputs.",2022-05-26
"The Dialog Must Go On: Improving Visual Dialog via Generative
  Self-Training",2022-05-25 05:40:00+00:00,http://arxiv.org/abs/2205.12502v1,"Gi-Cheon Kang, Sungdong Kim, Jin-Hwa Kim, Donghyun Kwak, Byoung-Tak Zhang","cs.CV, cs.CL, cs.LG",dialogue,"Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).",2022-05-25
"CORAL: Contextual Response Retrievability Loss Function for Training
  Dialog Generation Models",2022-05-21 10:36:22+00:00,http://arxiv.org/abs/2205.10558v1,"Bishal Santra, Ravi Ghadia, Arpit Dwivedi, Manish Gupta, Pawan Goyal",cs.CL,dialogue,"Natural Language Generation (NLG) represents a large collection of tasks in
the field of NLP. While many of these tasks have been tackled well by the
cross-entropy (CE) loss, the task of dialog generation poses a few unique
challenges for this loss function. First, CE loss assumes that for any given
input, the only possible output is the one available as the ground truth in the
training dataset. In general, this is not true for any task, as there can be
multiple semantically equivalent sentences, each with a different surface form.
This problem gets exaggerated further for the dialog generation task, as there
can be multiple valid responses (for a given context) that not only have
different surface forms but are also not semantically equivalent. Second, CE
loss does not take the context into consideration while processing the response
and, hence, it treats all ground truths with equal importance irrespective of
the context. But, we may want our final agent to avoid certain classes of
responses (e.g. bland, non-informative or biased responses) and give relatively
higher weightage for more context-specific responses. To circumvent these
shortcomings of the CE loss, in this paper, we propose a novel loss function,
CORAL, that directly optimizes recently proposed estimates of human preference
for generated responses. Using CORAL, we can train dialog generation models
without assuming non-existence of response other than the ground-truth. Also,
the CORAL loss is computed based on both the context and the response.
Extensive comparisons on two benchmark datasets show that the proposed methods
outperform strong state-of-the-art baseline models of different sizes.",2022-05-21
Self-augmented Data Selection for Few-shot Dialogue Generation,2022-05-19 16:25:50+00:00,http://arxiv.org/abs/2205.09661v1,"Wanyu Du, Hanjie Chen, Yangfeng Ji",cs.CL,dialogue,"The natural language generation (NLG) module in task-oriented dialogue
systems translates structured meaning representations (MRs) into text
responses, which has a great impact on users' experience as the human-machine
interaction interface. However, in practice, developers often only have a few
well-annotated data and confront a high data collection cost to build the NLG
module. In this work, we adopt the self-training framework to deal with the
few-shot MR-to-Text generation problem. We leverage the pre-trained language
model to self-augment many pseudo-labeled data. To prevent the gradual drift
from target data distribution to noisy augmented data distribution, we propose
a novel data selection strategy to select the data that our generation model is
most uncertain about. Compared with existing data selection methods, our method
is: (1) parameter-efficient, which does not require training any additional
neural models, (2) computation-efficient, which only needs to apply several
stochastic forward passes of the model to estimate the uncertainty. We conduct
empirical experiments on two benchmark datasets: FewShotWOZ and FewShotSGD, and
show that our proposed framework consistently outperforms other baselines in
terms of BLEU and ERR.",2022-05-19
Diversifying Neural Dialogue Generation via Negative Distillation,2022-05-05 17:14:56+00:00,http://arxiv.org/abs/2205.02795v1,"Yiwei Li, Shaoxiong Feng, Bin Sun, Kan Li","cs.CL, cs.AI",dialogue,"Generative dialogue models suffer badly from the generic response problem,
limiting their applications to a few toy scenarios. Recently, an interesting
approach, namely negative training, has been proposed to alleviate this problem
by reminding the model not to generate high-frequency responses during
training. However, its performance is hindered by two issues, ignoring
low-frequency but generic responses and bringing low-frequency but meaningless
responses. In this paper, we propose a novel negative training paradigm, called
negative distillation, to keep the model away from the undesirable generic
responses while avoiding the above problems. First, we introduce a negative
teacher model that can produce query-wise generic responses, and then the
student model is required to maximize the distance with multi-level negative
knowledge. Empirical results show that our method outperforms previous negative
training methods significantly.",2022-05-05
AI Personification: Estimating the Personality of Language Models,2022-04-25 23:53:53+00:00,http://arxiv.org/abs/2204.12000v1,"Saketh Reddy Karra, Son Nguyen, Theja Tulabandhula","cs.CL, cs.AI",dialogue,"Technology for open-ended language generation, a key application of
artificial intelligence, has advanced to a great extent in recent years.
Large-scale language models, which are trained on large corpora of text, are
being used in a wide range of applications everywhere, from virtual assistants
to conversational bots. While these language models output fluent text,
existing research shows that these models can and do capture human biases. Many
of these biases, especially those that could potentially cause harm, are being
well investigated. On the other hand, studies that infer and change personality
traits inherited by these models have been scarce or non-existent. In this
work, we explore the personality traits of several large-scale language models
designed for open-ended text generation and the datasets used for training
them. Our work builds on the popular Big Five factors and develops robust
methods that quantify the personality traits of these models and their
underlying datasets. In particular, we trigger the models with a questionnaire
designed for personality assessment and subsequently classify the text
responses into quantifiable traits using a Zero-shot classifier. Our
classification sheds light on an important anthropomorphic element found in
such AI models and can help stakeholders decide how they should be applied and
how society could perceive them. We augment our analysis by studying approaches
that can alter these personalities.",2022-04-25
SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues,2022-04-22 09:31:13+00:00,http://arxiv.org/abs/2204.10591v1,"Ssu Chiu, Maolin Li, Yen-Ting Lin, Yun-Nung Chen","cs.CL, cs.AI",dialogue,"Dialogue systems are usually categorized into two types, open-domain and
task-oriented. The first one focuses on chatting with users and making them
engage in the conversations, where selecting a proper topic to fit the dialogue
context is essential for a successful dialogue. The other one focuses on a
specific task instead of casual talks, e.g., finding a movie on Friday night,
or playing a song. These two directions have been studied separately due to
their different purposes. However, how smoothly transitioning from social
chatting to task-oriented dialogues is important for triggering business
opportunities, and there is no public data focusing on such scenarios. Hence,
this paper focuses on investigating the conversations starting from open-domain
social chatting and then gradually transitioning to task-oriented purposes, and
releases a large-scale dataset with detailed annotations for encouraging this
research direction. To achieve this goal, this paper proposes a framework to
automatically generate many dialogues without human involvement, in which any
powerful open-domain dialogue generation model can be easily leveraged. The
human evaluation shows that our generated dialogue data has a natural flow at a
reasonable quality, showing that our released data has a great potential of
guiding future research directions and commercial activities. Furthermore, the
released models allow researchers to automatically generate unlimited dialogues
in the target scenarios, which can greatly benefit semi-supervised and
unsupervised approaches.",2022-04-22
Event Transition Planning for Open-ended Text Generation,2022-04-20 13:37:51+00:00,http://arxiv.org/abs/2204.09453v1,"Qintong Li, Piji Li, Wei Bi, Zhaochun Ren, Yuxuan Lai, Lingpeng Kong",cs.CL,dialogue,"Open-ended text generation tasks, such as dialogue generation and story
completion, require models to generate a coherent continuation given limited
preceding context. The open-ended nature of these tasks brings new challenges
to the neural auto-regressive text generators nowadays. Despite these neural
models are good at producing human-like text, it is difficult for them to
arrange causalities and relations between given facts and possible ensuing
events. To bridge this gap, we propose a novel two-stage method which
explicitly arranges the ensuing events in open-ended text generation. Our
approach can be understood as a specially-trained coarse-to-fine algorithm,
where an event transition planner provides a ""coarse"" plot skeleton and a text
generator in the second stage refines the skeleton. Experiments on two
open-ended text generation tasks demonstrate that our proposed method
effectively improves the quality of the generated text, especially in coherence
and diversity. The code is available at:
\url{https://github.com/qtli/EventPlanforTextGen}.",2022-04-20
"A Survey on Non-Autoregressive Generation for Neural Machine Translation
  and Beyond",2022-04-20 07:25:22+00:00,http://arxiv.org/abs/2204.09269v1,"Yisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, Tie-yan Liu","cs.CL, cs.LG",dialogue,"Non-autoregressive (NAR) generation, which is first proposed in neural
machine translation (NMT) to speed up inference, has attracted much attention
in both machine learning and natural language processing communities. While NAR
generation can significantly accelerate inference speed for machine
translation, the speedup comes at the cost of sacrificed translation accuracy
compared to its counterpart, auto-regressive (AR) generation. In recent years,
many new models and algorithms have been designed/proposed to bridge the
accuracy gap between NAR generation and AR generation. In this paper, we
conduct a systematic survey with comparisons and discussions of various
non-autoregressive translation (NAT) models from different aspects.
Specifically, we categorize the efforts of NAT into several groups, including
data manipulation, modeling methods, training criterion, decoding algorithms,
and the benefit from pre-trained models. Furthermore, we briefly review other
applications of NAR models beyond machine translation, such as dialogue
generation, text summarization, grammar error correction, semantic parsing,
speech synthesis, and automatic speech recognition. In addition, we also
discuss potential directions for future exploration, including releasing the
dependency of KD, dynamic length prediction, pre-training for NAR, and wider
applications, etc. We hope this survey can help researchers capture the latest
progress in NAR generation, inspire the design of advanced NAR models and
algorithms, and enable industry practitioners to choose appropriate solutions
for their applications. The web page of this survey is at
\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}.",2022-04-20
"Evaluating Mixed-initiative Conversational Search Systems via User
  Simulation",2022-04-17 16:27:33+00:00,http://arxiv.org/abs/2204.08046v1,"Ivan Sekulić, Mohammad Aliannejadi, Fabio Crestani","cs.CL, cs.IR",dialogue,"Clarifying the underlying user information need by asking clarifying
questions is an important feature of modern conversational search system.
However, evaluation of such systems through answering prompted clarifying
questions requires significant human effort, which can be time-consuming and
expensive. In this paper, we propose a conversational User Simulator, called
USi, for automatic evaluation of such conversational search systems. Given a
description of an information need, USi is capable of automatically answering
clarifying questions about the topic throughout the search session. Through a
set of experiments, including automated natural language generation metrics and
crowdsourcing studies, we show that responses generated by USi are both inline
with the underlying information need and comparable to human-generated answers.
Moreover, we make the first steps towards multi-turn interactions, where
conversational search systems asks multiple questions to the (simulated) user
with a goal of clarifying the user need. To this end, we expand on currently
available datasets for studying clarifying questions, i.e., Qulac and ClariQ,
by performing a crowdsourcing-based multi-turn data acquisition. We show that
our generative, GPT2-based model, is capable of providing accurate and natural
answers to unseen clarifying questions in the single-turn setting and discuss
capabilities of our model in the multi-turn setting. We provide the code, data,
and the pre-trained model to be used for further research on the topic.",2022-04-17
UniDU: Towards A Unified Generative Dialogue Understanding Framework,2022-04-10 09:32:34+00:00,http://arxiv.org/abs/2204.04637v1,"Zhi Chen, Lu Chen, Bei Chen, Libo Qin, Yuncong Liu, Su Zhu, Jian-Guang Lou, Kai Yu",cs.CL,dialogue,"With the development of pre-trained language models, remarkable success has
been witnessed in dialogue understanding (DU) direction. However, the current
DU approaches just employ an individual model for each DU task, independently,
without considering the shared knowledge across different DU tasks. In this
paper, we investigate a unified generative dialogue understanding framework,
namely UniDU, to achieve information exchange among DU tasks. Specifically, we
reformulate the DU tasks into unified generative paradigm. In addition, to
consider different training data for each task, we further introduce
model-agnostic training strategy to optimize unified model in a balanced
manner. We conduct the experiments on ten dialogue understanding datasets,
which span five fundamental tasks: dialogue summary, dialogue completion, slot
filling, intent detection and dialogue state tracking. The proposed UniDU
framework outperforms task-specific well-designed methods on all 5 tasks. We
further conduct comprehensive analysis experiments to study the effect factors.
The experimental results also show that the proposed method obtains promising
performance on unseen dialogue domain.",2022-04-10
"BioBART: Pretraining and Evaluation of A Biomedical Generative Language
  Model",2022-04-08 08:07:42+00:00,http://arxiv.org/abs/2204.03905v1,"Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, Sheng Yu",cs.CL,dialogue,"Pretrained language models have served as important backbones for natural
language processing. Recently, in-domain pretraining has been shown to benefit
various domain-specific downstream tasks. In the biomedical domain, natural
language generation (NLG) tasks are of critical importance, while understudied.
Approaching natural language understanding (NLU) tasks as NLG achieves
satisfying performance in the general domain through constrained language
generation or language prompting. We emphasize the lack of in-domain generative
language models and the unsystematic generative downstream benchmarks in the
biomedical domain, hindering the development of the research community. In this
work, we introduce the generative language model BioBART that adapts BART to
the biomedical domain. We collate various biomedical language generation tasks
including dialogue, summarization, entity linking, and named entity
recognition. BioBART pretrained on PubMed abstracts has enhanced performance
compared to BART and set strong baselines on several tasks. Furthermore, we
conduct ablation studies on the pretraining tasks for BioBART and find that
sentence permutation has negative effects on downstream tasks.",2022-04-08
A Roadmap for Big Model,2022-03-26 15:38:00+00:00,http://arxiv.org/abs/2203.14101v1,"Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangxiao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao, Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning Ding, Yongming Rao, Yizhao Gao, Liang Zhang, Ming Ding, Cong Fang, Yisen Wang, Mingsheng Long, Jing Zhang, Yinpeng Dong, Tianyu Pang, Peng Cui, Lingxiao Huang, Zheng Liang, Huawei Shen, Hui Zhang, Quanshi Zhang, Qingxiu Dong, Zhixing Tan, Mingxuan Wang, Shuo Wang, Long Zhou, Haoran Li, Junwei Bao, Yingwei Pan, Weinan Zhang, Zhou Yu, Rui Yan, Chence Shi, Minghao Xu, Zuobai Zhang, Guoqiang Wang, Xiang Pan, Mengjie Li, Xiaoyu Chu, Zijun Yao, Fangwei Zhu, Shulin Cao, Weicheng Xue, Zixuan Ma, Zhengyan Zhang, Shengding Hu, Yujia Qin, Chaojun Xiao, Zheni Zeng, Ganqu Cui, Weize Chen, Weilin Zhao, Yuan Yao, Peng Li, Wenzhao Zheng, Wenliang Zhao, Ziyi Wang, Borui Zhang, Nanyi Fei, Anwen Hu, Zenan Ling, Haoyang Li, Boxi Cao, Xianpei Han, Weidong Zhan, Baobao Chang, Hao Sun, Jiawen Deng, Juanzi Li, Lei Hou, Xigang Cao, Jidong Zhai, Zhiyuan Liu, Maosong Sun, Jiwen Lu, Zhiwu Lu, Qin Jin, Ruihua Song, Ji-Rong Wen, Zhouchen Lin, Liwei Wang, Hang Su, Jun Zhu, Zhifang Sui, Jiajun Zhang, Yang Liu, Xiaodong He, Minlie Huang, Jian Tang, Jie Tang","cs.LG, cs.AI, cs.CL",dialogue,"With the rapid development of deep learning, training Big Models (BMs) for
multiple downstream tasks becomes a popular paradigm. Researchers have achieved
various outcomes in the construction of BMs and the BM application in many
fields. At present, there is a lack of research work that sorts out the overall
progress of BMs and guides the follow-up research. In this paper, we cover not
only the BM technologies themselves but also the prerequisites for BM training
and applications with BMs, dividing the BM review into four parts: Resource,
Models, Key Technologies and Application. We introduce 16 specific BM-related
topics in those four parts, they are Data, Knowledge, Computing System,
Parallel Training System, Language Model, Vision Model, Multi-modal Model,
Theory&Interpretability, Commonsense Reasoning, Reliability&Security,
Governance, Evaluation, Machine Translation, Text Generation, Dialogue and
Protein Research. In each topic, we summarize clearly the current studies and
propose some future research directions. At the end of this paper, we conclude
the further development of BMs in a more general view.",2022-03-26
"GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate
  Degradation of Artificial Neural Language Models",2022-03-25 00:25:42+00:00,http://arxiv.org/abs/2203.13397v1,"Changye Li, David Knopman, Weizhe Xu, Trevor Cohen, Serguei Pakhomov",cs.CL,dialogue,"Deep learning (DL) techniques involving fine-tuning large numbers of model
parameters have delivered impressive performance on the task of discriminating
between language produced by cognitively healthy individuals, and those with
Alzheimer's disease (AD). However, questions remain about their ability to
generalize beyond the small reference sets that are publicly available for
research. As an alternative to fitting model parameters directly, we propose a
novel method by which a Transformer DL model (GPT-2) pre-trained on general
English text is paired with an artificially degraded version of itself (GPT-D),
to compute the ratio between these two models' \textit{perplexities} on
language from cognitively healthy and impaired individuals. This technique
approaches state-of-the-art performance on text data from a widely used ""Cookie
Theft"" picture description task, and unlike established alternatives also
generalizes well to spontaneous conversations. Furthermore, GPT-D generates
text with characteristics known to be associated with AD, demonstrating the
induction of dementia-related linguistic anomalies. Our study is a step toward
better understanding of the relationships between the inner workings of
generative neural language models, the language that they produce, and the
deleterious effects of dementia on human speech and language characteristics.",2022-03-25
Immersive Text Game and Personality Classification,2022-03-20 18:37:03+00:00,http://arxiv.org/abs/2203.10621v1,"Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi","cs.CL, cs.AI, cs.LG",dialogue,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",2022-03-20
"Time Dependency, Data Flow, and Competitive Advantage",2022-03-17 07:09:30+00:00,http://arxiv.org/abs/2203.09128v1,"Ehsan Valavi, Joel Hestness, Marco Iansiti, Newsha Ardalani, Feng Zhu, Karim R. Lakhani","cs.LG, cs.CL, econ.GN, q-fin.EC",dialogue,"Data is fundamental to machine learning-based products and services and is
considered strategic due to its externalities for businesses, governments,
non-profits, and more generally for society. It is renowned that the value of
organizations (businesses, government agencies and programs, and even
industries) scales with the volume of available data. What is often less
appreciated is that the data value in making useful organizational predictions
will range widely and is prominently a function of data characteristics and
underlying algorithms.
  In this research, our goal is to study how the value of data changes over
time and how this change varies across contexts and business areas (e.g. next
word prediction in the context of history, sports, politics). We focus on data
from Reddit.com and compare the value's time-dependency across various Reddit
topics (Subreddits). We make this comparison by measuring the rate at which
user-generated text data loses its relevance to the algorithmic prediction of
conversations. We show that different subreddits have different rates of
relevance decline over time.
  Relating the text topics to various business areas of interest, we argue that
competing in a business area in which data value decays rapidly alters
strategies to acquire competitive advantage. When data value decays rapidly,
access to a continuous flow of data will be more valuable than access to a
fixed stock of data. In this kind of setting, improving user engagement and
increasing user-base help creating and maintaining a competitive advantage.",2022-03-17
"TegTok: Augmenting Text Generation via Task-specific and Open-world
  Knowledge",2022-03-16 10:37:59+00:00,http://arxiv.org/abs/2203.08517v1,"Chao-Hong Tan, Jia-Chen Gu, Chongyang Tao, Zhen-Hua Ling, Can Xu, Huang Hu, Xiubo Geng, Daxin Jiang","cs.CL, cs.AI",dialogue,"Generating natural and informative texts has been a long-standing problem in
NLP. Much effort has been dedicated into incorporating pre-trained language
models (PLMs) with various open-world knowledge, such as knowledge graphs or
wiki pages. However, their ability to access and manipulate the task-specific
knowledge is still limited on downstream tasks, as this type of knowledge is
usually not well covered in PLMs and is hard to acquire. To address the
problem, we propose augmenting TExt Generation via Task-specific and Open-world
Knowledge (TegTok) in a unified framework. Our model selects knowledge entries
from two types of knowledge sources through dense retrieval and then injects
them into the input encoding and output decoding stages respectively on the
basis of PLMs. With the help of these two types of knowledge, our model can
learn what and how to generate. Experiments on two text generation tasks of
dialogue generation and question generation, and on two datasets show that our
method achieves better performance than various baseline models.",2022-03-16
"Faithfulness in Natural Language Generation: A Systematic Survey of
  Analysis, Evaluation and Optimization Methods",2022-03-10 08:28:32+00:00,http://arxiv.org/abs/2203.05227v1,"Wei Li, Wenhao Wu, Moye Chen, Jiachen Liu, Xinyan Xiao, Hua Wu",cs.CL,dialogue,"Natural Language Generation (NLG) has made great progress in recent years due
to the development of deep learning techniques such as pre-trained language
models. This advancement has resulted in more fluent, coherent and even
properties controllable (e.g. stylistic, sentiment, length etc.) generation,
naturally leading to development in downstream tasks such as abstractive
summarization, dialogue generation, machine translation, and data-to-text
generation. However, the faithfulness problem that the generated text usually
contains unfaithful or non-factual information has become the biggest
challenge, which makes the performance of text generation unsatisfactory for
practical applications in many real-world scenarios. Many studies on analysis,
evaluation, and optimization methods for faithfulness problems have been
proposed for various tasks, but have not been organized, compared and discussed
in a combined manner. In this survey, we provide a systematic overview of the
research progress on the faithfulness problem of NLG, including problem
analysis, evaluation metrics and optimization methods. We organize the
evaluation and optimization methods for different tasks into a unified taxonomy
to facilitate comparison and learning across tasks. Several research trends are
discussed further.",2022-03-10
"Towards Generalized Models for Task-oriented Dialogue Modeling on Spoken
  Conversations",2022-03-08 12:26:57+00:00,http://arxiv.org/abs/2203.04045v1,"Ruijie Yan, Shuang Peng, Haitao Mi, Liang Jiang, Shihui Yang, Yuchi Zhang, Jiajun Li, Liangrui Peng, Yongliang Wang, Zujie Wen",cs.CL,dialogue,"Building robust and general dialogue models for spoken conversations is
challenging due to the gap in distributions of spoken and written data. This
paper presents our approach to build generalized models for the
Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations
Challenge of DSTC-10. In order to mitigate the discrepancies between spoken and
written text, we mainly employ extensive data augmentation strategies on
written data, including artificial error injection and round-trip text-speech
transformation. To train robust models for spoken conversations, we improve
pre-trained language models, and apply ensemble algorithms for each sub-task.
Typically, for the detection task, we fine-tune \roberta and ELECTRA, and run
an error-fixing ensemble algorithm. For the selection task, we adopt a
two-stage framework that consists of entity tracking and knowledge ranking, and
propose a multi-task learning method to learn multi-level semantic information
by domain classification and entity selection. For the generation task, we
adopt a cross-validation data process to improve pre-trained generative
language models, followed by a consensus decoding algorithm, which can add
arbitrary features like relative \rouge metric, and tune associated feature
weights toward \bleu directly. Our approach ranks third on the objective
evaluation and second on the final official human evaluation.",2022-03-08
Deep Latent-Variable Models for Text Generation,2022-03-03 23:06:39+00:00,http://arxiv.org/abs/2203.02055v1,Xiaoyu Shen,cs.CL,dialogue,"Text generation aims to produce human-like natural language output for
down-stream tasks. It covers a wide range of applications like machine
translation, document summarization, dialogue generation and so on. Recently
deep neural network-based end-to-end architectures have been widely adopted.
The end-to-end approach conflates all sub-modules, which used to be designed by
complex handcrafted rules, into a holistic encode-decode architecture. Given
enough training data, it is able to achieve state-of-the-art performance yet
avoiding the need of language/domain-dependent knowledge. Nonetheless, deep
learning models are known to be extremely data-hungry, and text generated from
them usually suffer from low diversity, interpretability and controllability.
As a result, it is difficult to trust the output from them in real-life
applications. Deep latent-variable models, by specifying the probabilistic
distribution over an intermediate latent process, provide a potential way of
addressing these problems while maintaining the expressive power of deep neural
networks. This dissertation presents how deep latent-variable models can
improve over the standard encoder-decoder model for text generation.",2022-03-03
Capturing Failures of Large Language Models via Human Cognitive Biases,2022-02-24 18:58:52+00:00,http://arxiv.org/abs/2202.12299v1,"Erik Jones, Jacob Steinhardt","cs.CL, cs.AI, cs.LG",dialogue,"Large language models generate complex, open-ended outputs: instead of
outputting a single class, they can write summaries, generate dialogue, and
produce working code. In order to study the reliability of these open-ended
systems, we must understand not just when they fail, but also how they fail. To
approach this, we draw inspiration from human cognitive biases -- systematic
patterns of deviation from rational judgement. Specifically, we use cognitive
biases to (i) identify inputs that models are likely to err on, and (ii)
develop tests to qualitatively characterize their errors on these inputs. Using
code generation as a case study, we find that OpenAI's Codex errs predictably
based on how the input prompt is framed, adjusts outputs towards anchors, and
is biased towards outputs that mimic frequent training examples. We then use
our framework to uncover high-impact errors such as incorrectly deleting files.
Our experiments suggest that cognitive science can be a useful jumping-off
point to better understand how contemporary machine learning systems behave.",2022-02-24
"Integrating AI Planning with Natural Language Processing: A Combination
  of Explicit and Tacit Knowledge",2022-02-15 02:19:09+00:00,http://arxiv.org/abs/2202.07138v1,"Kebing Jin, Hankz Hankui Zhuo","cs.AI, cs.CL",dialogue,"Automated planning focuses on strategies, building domain models and
synthesizing plans to transit initial states to goals. Natural language
processing concerns with the interactions between agents and human language,
especially processing and analyzing large amounts of natural language data.
These two fields have abilities to generate explicit knowledge, e.g.,
preconditions and effects of action models, and learn from tacit knowledge,
e.g., neural models, respectively. Integrating AI planning and natural language
processing effectively improves the communication between human and intelligent
agents. This paper outlines the commons and relations between AI planning and
natural language processing, argues that each of them can effectively impact on
the other one by four areas: (1) planning-based text understanding, (2)
planning-based text generation, (3) text-based human-robot interaction, and (4)
text-based explainable planning. We also explore some potential future issues
between AI planning and natural language processing.",2022-02-15
Survey of Hallucination in Natural Language Generation,2022-02-08 03:55:01+00:00,http://arxiv.org/abs/2202.03629v1,"Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, Pascale Fung","cs.CL, A.1",dialogue,"Natural Language Generation (NLG) has improved exponentially in recent years
thanks to the development of deep learning technologies such as
Transformer-based language models. This advancement has led to more fluent and
coherent natural language generation, naturally leading to development in
downstream tasks such as abstractive summarization, dialogue generation and
data-to-text generation. However, it is also investigated that such generation
includes hallucinated texts, which makes the performances of text generation
fail to meet users' expectations in many real-world scenarios. In order to
address this issue, studies in evaluation and mitigation methods of
hallucinations have been presented in various tasks, but have not been reviewed
in a combined manner. In this survey, we provide a broad overview of the
research progress and challenges in the hallucination problem of NLG. The
survey is organized into two big divisions: (i) a general overview of metrics,
mitigation methods, and future directions; (ii) task-specific research progress
for hallucinations in a large set of downstream tasks: abstractive
summarization, dialogue generation, generative question answering, data-to-text
generation, and machine translation. This survey could facilitate collaborative
efforts among researchers in these tasks.",2022-02-08
Red Teaming Language Models with Language Models,2022-02-07 15:22:17+00:00,http://arxiv.org/abs/2202.03286v1,"Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, Geoffrey Irving","cs.CL, cs.AI, cs.CR, cs.LG",dialogue,"Language Models (LMs) often cannot be deployed because of their potential to
harm users in hard-to-predict ways. Prior work identifies harmful behaviors
before deployment by using human annotators to hand-write test cases. However,
human annotation is expensive, limiting the number and diversity of test cases.
In this work, we automatically find cases where a target LM behaves in a
harmful way, by generating test cases (""red teaming"") using another LM. We
evaluate the target LM's replies to generated test questions using a classifier
trained to detect offensive content, uncovering tens of thousands of offensive
replies in a 280B parameter LM chatbot. We explore several methods, from
zero-shot generation to reinforcement learning, for generating test cases with
varying levels of diversity and difficulty. Furthermore, we use prompt
engineering to control LM-generated test cases to uncover a variety of other
harms, automatically finding groups of people that the chatbot discusses in
offensive ways, personal and hospital phone numbers generated as the chatbot's
own contact info, leakage of private training data in generated text, and harms
that occur over the course of a conversation. Overall, LM-based red teaming is
one promising tool (among many needed) for finding and fixing diverse,
undesirable LM behaviors before impacting users.",2022-02-07
A Survey on Retrieval-Augmented Text Generation,2022-02-02 16:18:41+00:00,http://arxiv.org/abs/2202.01110v1,"Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu",cs.CL,dialogue,"Recently, retrieval-augmented text generation attracted increasing attention
of the computational linguistics community. Compared with conventional
generation models, retrieval-augmented text generation has remarkable
advantages and particularly has achieved state-of-the-art performance in many
NLP tasks. This paper aims to conduct a survey about retrieval-augmented text
generation. It firstly highlights the generic paradigm of retrieval-augmented
generation, and then it reviews notable approaches according to different tasks
including dialogue response generation, machine translation, and other
generation tasks. Finally, it points out some important directions on top of
recent methods to facilitate future research.",2022-02-02
"Language Generation for Broad-Coverage, Explainable Cognitive Systems",2022-01-25 16:09:19+00:00,http://arxiv.org/abs/2201.10422v1,"Marjorie McShane, Ivan Leon","cs.CL, cs.AI",dialogue,"This paper describes recent progress on natural language generation (NLG) for
language-endowed intelligent agents (LEIAs) developed within the OntoAgent
cognitive architecture. The approach draws heavily from past work on natural
language understanding in this paradigm: it uses the same knowledge bases,
theory of computational linguistics, agent architecture, and methodology of
developing broad-coverage capabilities over time while still supporting
near-term applications.",2022-01-25
Measuring Attribution in Natural Language Generation Models,2021-12-23 22:33:20+00:00,http://arxiv.org/abs/2112.12870v1,"Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, David Reitter",cs.CL,dialogue,"With recent improvements in natural language generation (NLG) models for
various applications, it has become imperative to have the means to identify
and evaluate whether NLG output is only sharing verifiable information about
the external world. In this work, we present a new evaluation framework
entitled Attributable to Identified Sources (AIS) for assessing the output of
natural language generation models, when such output pertains to the external
world. We first define AIS and introduce a two-stage annotation pipeline for
allowing annotators to appropriately evaluate model output according to AIS
guidelines. We empirically validate this approach on three generation datasets
(two in the conversational QA domain and one in summarization) via human
evaluation studies that suggest that AIS could serve as a common framework for
measuring whether model-generated statements are supported by underlying
sources. We release guidelines for the human evaluation studies.",2021-12-23
Taming Repetition in Dialogue Generation,2021-12-16 06:25:46+00:00,http://arxiv.org/abs/2112.08657v1,"Yadong Xi, Jiashu Pu, Xiaoxi Mao",cs.CL,dialogue,"The wave of pre-training language models has been continuously improving the
quality of the machine-generated conversations, however, some of the generated
responses still suffer from excessive repetition, sometimes repeating words
from utterance, sometimes repeating words within self-generated responses, or
both. Inappropriate repetition of words can significantly degrade the quality
of the generated texts. Penalized sampling is one popular solution, reducing
the sampling probability of existing words during inference, however, it is
highly vulnerable to the inappropriate setting of the static weight. Setting it
too high can yield strange and unrealistic sentences while setting it too low
makes the task of suppressing repetition trivial. To remedy the shortcomings of
the above methods, we design a context-aware classifier to explicitly decide
when to allow repetition and when to employ penalized sampling. Such a
classifier can be easily integrated with existing decoding methods, reducing
repetitions where appropriate while preserving the diversity of the text.
Experimental results demonstrate that our method can generate higher quality
and more authentic dialogues.",2021-12-16
DG2: Data Augmentation Through Document Grounded Dialogue Generation,2021-12-15 18:50:14+00:00,http://arxiv.org/abs/2112.08342v1,"Qingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis A. Lastras, Zhou Yu",cs.CL,dialogue,"Collecting data for training dialog systems can be extremely expensive due to
the involvement of human participants and need for extensive annotation.
Especially in document-grounded dialog systems, human experts need to carefully
read the unstructured documents to answer the users' questions. As a result,
existing document-grounded dialog datasets are relatively small-scale and
obstruct the effective training of dialogue systems. In this paper, we propose
an automatic data augmentation technique grounded on documents through a
generative dialogue model. The dialogue model consists of a user bot and agent
bot that can synthesize diverse dialogues given an input document, which are
then used to train a downstream model. When supplementing the original dataset,
our method achieves significant improvement over traditional data augmentation
methods. We also achieve great performance in the low-resource setting.",2021-12-15
Dynamic Human Evaluation for Relative Model Comparisons,2021-12-15 11:32:13+00:00,http://arxiv.org/abs/2112.08048v1,"Thórhildur Thorleiksdóttir, Cedric Renggli, Nora Hollenstein, Ce Zhang",cs.CL,dialogue,"Collecting human judgements is currently the most reliable evaluation method
for natural language generation systems. Automatic metrics have reported flaws
when applied to measure quality aspects of generated text and have been shown
to correlate poorly with human judgements. However, human evaluation is time
and cost-intensive, and we lack consensus on designing and conducting human
evaluation experiments. Thus there is a need for streamlined approaches for
efficient collection of human judgements when evaluating natural language
generation systems. Therefore, we present a dynamic approach to measure the
required number of human annotations when evaluating generated outputs in
relative comparison settings. We propose an agent-based framework of human
evaluation to assess multiple labelling strategies and methods to decide the
better model in a simulation and a crowdsourcing case study. The main results
indicate that a decision about the superior model can be made with high
probability across different labelling strategies, where assigning a single
random worker per task requires the least overall labelling effort and thus the
least cost.",2021-12-15
Controlled Cue Generation for Play Scripts,2021-12-13 19:00:17+00:00,http://arxiv.org/abs/2112.06953v1,"Alara Dirik, Hilal Donmez, Pinar Yanardag","cs.CL, cs.AI, cs.LG",dialogue,"In this paper, we use a large-scale play scripts dataset to propose the novel
task of theatrical cue generation from dialogues. Using over one million lines
of dialogue and cues, we approach the problem of cue generation as a controlled
text generation task, and show how cues can be used to enhance the impact of
dialogue using a language model conditioned on a dialogue/cue discriminator. In
addition, we explore the use of topic keywords and emotions for controlled text
generation. Extensive quantitative and qualitative experiments show that
language models can be successfully used to generate plausible and
attribute-controlled texts in highly specialised domains such as play scripts.
Supporting materials can be found at: https://catlab-team.github.io/cuegen.",2021-12-13
"Representation Learning for Conversational Data using Discourse Mutual
  Information Maximization",2021-12-04 13:17:07+00:00,http://arxiv.org/abs/2112.05787v1,"Bishal Santra, Sumegh Roychowdhury, Aishik Mandal, Vasu Gurram, Atharva Naik, Manish Gupta, Pawan Goyal",cs.CL,dialogue,"Although many pretrained models exist for text or images, there have been
relatively fewer attempts to train representations specifically for dialog
understanding. Prior works usually relied on finetuned representations based on
generic text representation models like BERT or GPT-2. But, existing
pretraining objectives do not take the structural information of text into
consideration. Although generative dialog models can learn structural features
too, we argue that the structure-unaware word-by-word generation is not
suitable for effective conversation modeling. We empirically demonstrate that
such representations do not perform consistently across various dialog
understanding tasks. Hence, we propose a structure-aware Mutual Information
based loss-function DMI (Discourse Mutual Information) for training
dialog-representation models, that additionally captures the inherent
uncertainty in response prediction. Extensive evaluation on nine diverse dialog
modeling tasks shows that our proposed DMI-based models outperform strong
baselines by significant margins, even with small-scale pretraining. Our models
show the most promising performance on the dialog evaluation task
DailyDialog++, in both random and adversarial negative scenarios.",2021-12-04
Realistic simulation of users for IT systems in cyber ranges,2021-11-23 10:53:29+00:00,http://arxiv.org/abs/2111.11785v1,"Alexandre Dey, Benjamin Costé, Éric Totel, Adrien Bécue","cs.AI, cs.CR",dialogue,"Generating user activity is a key capability for both evaluating security
monitoring tools as well as improving the credibility of attacker analysis
platforms (e.g., honeynets). In this paper, to generate this activity, we
instrument each machine by means of an external agent. This agent combines both
deterministic and deep learning based methods to adapt to different environment
(e.g., multiple OS, software versions, etc.), while maintaining high
performances. We also propose conditional text generation models to facilitate
the creation of conversations and documents to accelerate the definition of
coherent, system-wide, life scenarios.",2021-11-23
"MEDCOD: A Medically-Accurate, Emotive, Diverse, and Controllable Dialog
  System",2021-11-17 20:31:16+00:00,http://arxiv.org/abs/2111.09381v1,"Rhys Compton, Ilya Valmianski, Li Deng, Costa Huang, Namit Katariya, Xavier Amatriain, Anitha Kannan","cs.CL, cs.AI, cs.LG",dialogue,"We present MEDCOD, a Medically-Accurate, Emotive, Diverse, and Controllable
Dialog system with a unique approach to the natural language generator module.
MEDCOD has been developed and evaluated specifically for the history taking
task. It integrates the advantage of a traditional modular approach to
incorporate (medical) domain knowledge with modern deep learning techniques to
generate flexible, human-like natural language expressions. Two key aspects of
MEDCOD's natural language output are described in detail. First, the generated
sentences are emotive and empathetic, similar to how a doctor would communicate
to the patient. Second, the generated sentence structures and phrasings are
varied and diverse while maintaining medical consistency with the desired
medical concept (provided by the dialogue manager module of MEDCOD).
Experimental results demonstrate the effectiveness of our approach in creating
a human-like medical dialogue system. Relevant code is available at
https://github.com/curai/curai-research/tree/main/MEDCOD",2021-11-17
A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots,2021-11-02 08:07:55+00:00,http://arxiv.org/abs/2111.01414v1,"Atharv Singh Patlan, Shiven Tripathi, Shubham Korde","cs.CL, cs.AI",dialogue,"In spoken dialogue systems, we aim to deploy artificial intelligence to build
automated dialogue agents that can converse with humans. Dialogue systems are
increasingly being designed to move beyond just imitating conversation and also
improve from such interactions over time. In this survey, we present a broad
overview of methods developed to build dialogue systems over the years.
Different use cases for dialogue systems ranging from task-based systems to
open domain chatbots motivate and necessitate specific systems. Starting from
simple rule-based systems, research has progressed towards increasingly complex
architectures trained on a massive corpus of datasets, like deep learning
systems. Motivated with the intuition of resembling human dialogues, progress
has been made towards incorporating emotions into the natural language
generator, using reinforcement learning. While we see a trend of highly
marginal improvement on some metrics, we find that limited justification exists
for the metrics, and evaluation practices are not uniform. To conclude, we flag
these concerns and highlight possible research directions.",2021-11-02
"Dynamic population-based meta-learning for multi-agent communication
  with natural language",2021-10-27 07:50:02+00:00,http://arxiv.org/abs/2110.14241v1,"Abhinav Gupta, Marc Lanctot, Angeliki Lazaridou","cs.LG, cs.AI, cs.CL, cs.MA",dialogue,"In this work, our goal is to train agents that can coordinate with seen,
unseen as well as human partners in a multi-agent communication environment
involving natural language. Previous work using a single set of agents has
shown great progress in generalizing to known partners, however it struggles
when coordinating with unfamiliar agents. To mitigate that, recent work
explored the use of population-based approaches, where multiple agents interact
with each other with the goal of learning more generic protocols. These
methods, while able to result in good coordination between unseen partners,
still only achieve so in cases of simple languages, thus failing to adapt to
human partners using natural language. We attribute this to the use of static
populations and instead propose a dynamic population-based meta-learning
approach that builds such a population in an iterative manner. We perform a
holistic evaluation of our method on two different referential games, and show
that our agents outperform all prior work when communicating with seen partners
and humans. Furthermore, we analyze the natural language generation skills of
our agents, where we find that our agents also outperform strong baselines.
Finally, we test the robustness of our agents when communicating with
out-of-population agents and carefully test the importance of each component of
our method through ablation studies.",2021-10-27
"FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metricsfor
  Automatic Text Generation",2021-10-16 11:59:48+00:00,http://arxiv.org/abs/2110.08559v1,"Moussa Kamal Eddine, Guokan Shang, Antoine J. -P. Tixier, Michalis Vazirgiannis",cs.CL,dialogue,"Fast and reliable evaluation metrics are key to R&D progress. While
traditional natural language generation metrics are fast, they are not very
reliable. Conversely, new metrics based on large pretrained language models are
much more reliable, but require significant computational resources. In this
paper, we propose FrugalScore, an approach to learn a fixed, low cost version
of any expensive NLG metric, while retaining most of its original performance.
Experiments with BERTScore and MoverScore on summarization and translation show
that FrugalScore is on par with the original metrics (and sometimes better),
while having several orders of magnitude less parameters and running several
times faster. On average over all learned metrics, tasks, and variants,
FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35
times less parameters than the original metrics. We make our trained metrics
publicly available, to benefit the entire NLP community and in particular
researchers and practitioners with limited resources.",2021-10-16
"Hindsight: Posterior-guided training of retrievers for improved
  open-ended generation",2021-10-14 22:24:57+00:00,http://arxiv.org/abs/2110.07752v2,"Ashwin Paranjape, Omar Khattab, Christopher Potts, Matei Zaharia, Christopher D. Manning","cs.CL, cs.IR",dialogue,"Many text generation systems benefit from using a retriever to retrieve
passages from a textual knowledge corpus (e.g., Wikipedia) which are then
provided as additional context to the generator. For open-ended generation
tasks (like generating informative utterances in conversations) many varied
passages may be equally relevant and we find that existing methods that jointly
train the retriever and generator underperform: the retriever may not find
relevant passages even amongst the top-10 and hence the generator may not learn
a preference to ground its generated output in them. We propose using an
additional guide retriever that is allowed to use the target output and ""in
hindsight"" retrieve relevant passages during training. We model the guide
retriever after the posterior distribution Q of passages given the input and
the target output and train it jointly with the standard retriever and the
generator by maximizing the evidence lower bound (ELBo) in expectation over Q.
For informative conversations from the Wizard of Wikipedia dataset, with
posterior-guided training, the retriever finds passages with higher relevance
in the top-10 (23% relative improvement), the generator's responses are more
grounded in the retrieved passage (19% relative improvement) and the end-to-end
system produces better overall output (6.4% relative improvement).",2021-10-14
Federated Natural Language Generation for Personalized Dialogue System,2021-10-13 00:59:52+00:00,http://arxiv.org/abs/2110.06419v1,"Yujie Lu, Chao Huang, Huanli Zhan, Yong Zhuang","cs.CL, cs.AI",dialogue,"Neural conversational models have long suffered from the problem of
inconsistency and lacking coherent personality. To address the issue,
persona-based models capturing individual characteristics have been proposed,
but they still face the dilemma of model adaption and data privacy. To break
this dilemma, we propose a novel Federated Natural Language Generation (FedNLG)
framework, which learns personalized representations from various dataset on
distributed devices, and thus implements the personalized dialogue system
efficiently and safely. FedNLG first pre-trains parameters of standard neural
conversational model over a large dialogue corpus, and then fine-tune the model
parameters and persona embeddings on specific datasets, in a federated manner.
Thus, the model could simultaneously learn the persona embeddings in local
clients and learn shared model parameters by federated aggregation, which
achieves accuracyprivacy balance. By conducting extensive experiments, we
demonstrate the effectiveness of our model by pre-training model over Cornell
Movie-Dialogs Corpus and fine-tuning the model over two TV series dataset.",2021-10-13
"OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset
  with Visual Contexts",2021-09-27 02:10:29+00:00,http://arxiv.org/abs/2109.12761v2,"Shuhe Wang, Yuxian Meng, Xiaoya Li, Xiaofei Sun, Rongbin Ouyang, Jiwei Li",cs.CL,dialogue,"In order to better simulate the real human conversation process, models need
to generate dialogue utterances based on not only preceding textual contexts
but also visual contexts. However, with the development of multi-modal dialogue
learning, the dataset scale gradually becomes a bottleneck. In this report, we
release OpenViDial 2.0, a larger-scale open-domain multi-modal dialogue dataset
compared to the previous version OpenViDial 1.0. OpenViDial 2.0 contains a
total number of 5.6 million dialogue turns extracted from either movies or TV
series from different resources, and each dialogue turn is paired with its
corresponding visual context. We hope this large-scale dataset can help
facilitate future researches on open-domain multi-modal dialog generation,
e.g., multi-modal pretraining for dialogue generation.",2021-09-27
"An animated picture says at least a thousand words: Selecting Gif-based
  Replies in Multimodal Dialog",2021-09-24 21:48:27+00:00,http://arxiv.org/abs/2109.12212v1,"Xingyao Wang, David Jurgens","cs.CL, cs.CV, cs.CY",dialogue,"Online conversations include more than just text. Increasingly, image-based
responses such as memes and animated gifs serve as culturally recognized and
often humorous responses in conversation. However, while NLP has broadened to
multimodal models, conversational dialog systems have largely focused only on
generating text replies. Here, we introduce a new dataset of 1.56M text-gif
conversation turns and introduce a new multimodal conversational model Pepe the
King Prawn for selecting gif-based replies. We demonstrate that our model
produces relevant and high-quality gif responses and, in a large randomized
control trial of multiple models replying to real users, we show that our model
replies with gifs that are significantly better received by the community.",2021-09-24
Style Control for Schema-Guided Natural Language Generation,2021-09-24 21:47:58+00:00,http://arxiv.org/abs/2109.12211v1,"Alicia Y. Tsai, Shereen Oraby, Vittorio Perera, Jiun-Yu Kao, Yuheng Du, Anjali Narayan-Chen, Tagyoung Chung, Dilek Hakkani-Tur",cs.CL,dialogue,"Natural Language Generation (NLG) for task-oriented dialogue systems focuses
on communicating specific content accurately, fluently, and coherently. While
these attributes are crucial for a successful dialogue, it is also desirable to
simultaneously accomplish specific stylistic goals, such as response length,
point-of-view, descriptiveness, sentiment, formality, and empathy. In this
work, we focus on stylistic control and evaluation for schema-guided NLG, with
joint goals of achieving both semantic and stylistic control. We experiment in
detail with various controlled generation methods for large pretrained language
models: specifically, conditional training, guided fine-tuning, and guided
decoding. We discuss their advantages and limitations, and evaluate them with a
broad range of automatic and human evaluation metrics. Our results show that
while high style accuracy and semantic correctness are easier to achieve for
more lexically-defined styles with conditional training, stylistic control is
also achievable for more semantically complex styles using discriminator-based
guided decoding methods. The results also suggest that methods that are more
scalable (with less hyper-parameters tuning) and that disentangle content
generation and stylistic variations are more effective at achieving semantic
correctness and style accuracy.",2021-09-24
"Controllable Dialogue Generation with Disentangled Multi-grained Style
  Specification and Attribute Consistency Reward",2021-09-14 14:29:38+00:00,http://arxiv.org/abs/2109.06717v1,"Zhe Hu, Zhiwei Cao, Hou Pong Chan, Jiachen Liu, Xinyan Xiao, Jinsong Su, Hua Wu","cs.CL, cs.AI",dialogue,"Controllable text generation is an appealing but challenging task, which
allows users to specify particular attributes of the generated outputs. In this
paper, we propose a controllable dialogue generation model to steer response
generation under multi-attribute constraints. Specifically, we define and
categorize the commonly used control attributes into global and local ones,
which possess different granularities of effects on response generation. Then,
we significantly extend the conventional seq2seq framework by introducing a
novel two-stage decoder, which first uses a multi-grained style specification
layer to impose the stylistic constraints and determine word-level control
states of responses based on the attributes, and then employs a response
generation layer to generate final responses maintaining both semantic
relevancy to the contexts and fidelity to the attributes. Furthermore, we train
our model with an attribute consistency reward to promote response control with
explicit supervision signals. Extensive experiments and in-depth analyses on
two datasets indicate that our model can significantly outperform competitive
baselines in terms of response quality, content diversity and controllability.",2021-09-14
"End-to-End Conversational Search for Online Shopping with Utterance
  Transfer",2021-09-12 08:33:44+00:00,http://arxiv.org/abs/2109.05460v1,"Liqiang Xiao, Jun Ma2, Xin Luna Dong, Pascual Martinez-Gomez, Nasser Zalmout, Wei Chen, Tong Zhao, Hao He, Yaohui Jin","cs.CL, cs.AI",dialogue,"Successful conversational search systems can present natural, adaptive and
interactive shopping experience for online shopping customers. However,
building such systems from scratch faces real word challenges from both
imperfect product schema/knowledge and lack of training dialog data.In this
work we first propose ConvSearch, an end-to-end conversational search system
that deeply combines the dialog system with search. It leverages the text
profile to retrieve products, which is more robust against imperfect product
schema/knowledge compared with using product attributes alone. We then address
the lack of data challenges by proposing an utterance transfer approach that
generates dialogue utterances by using existing dialog from other domains, and
leveraging the search behavior data from e-commerce retailer. With utterance
transfer, we introduce a new conversational search dataset for online shopping.
Experiments show that our utterance transfer method can significantly improve
the availability of training dialogue data without crowd-sourcing, and the
conversational search system significantly outperformed the best tested
baseline.",2021-09-12
Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration,2021-09-12 04:17:53+00:00,http://arxiv.org/abs/2109.05426v1,"Chuanxin Tang, Chong Luo, Zhiyuan Zhao, Dacheng Yin, Yucheng Zhao, Wenjun Zeng","cs.SD, cs.AI, eess.AS",dialogue,"Given a piece of speech and its transcript text, text-based speech editing
aims to generate speech that can be seamlessly inserted into the given speech
by editing the transcript. Existing methods adopt a two-stage approach:
synthesize the input text using a generic text-to-speech (TTS) engine and then
transform the voice to the desired voice using voice conversion (VC). A major
problem of this framework is that VC is a challenging problem which usually
needs a moderate amount of parallel training data to work satisfactorily. In
this paper, we propose a one-stage context-aware framework to generate natural
and coherent target speech without any training data of the target speaker. In
particular, we manage to perform accurate zero-shot duration prediction for the
inserted text. The predicted duration is used to regulate both text embedding
and speech embedding. Then, based on the aligned cross-modality input, we
directly generate the mel-spectrogram of the edited speech with a
transformer-based decoder. Subjective listening tests show that despite the
lack of training data for the speaker, our method has achieved satisfactory
results. It outperforms a recent zero-shot TTS engine by a large margin.",2021-09-12
Refocusing on Relevance: Personalization in NLG,2021-09-10 23:50:02+00:00,http://arxiv.org/abs/2109.05140v1,"Shiran Dudy, Steven Bedrick, Bonnie Webber","cs.CL, cs.CY, cs.HC",dialogue,"Many NLG tasks such as summarization, dialogue response, or open domain
question answering focus primarily on a source text in order to generate a
target response. This standard approach falls short, however, when a user's
intent or context of work is not easily recoverable based solely on that source
text -- a scenario that we argue is more of the rule than the exception. In
this work, we argue that NLG systems in general should place a much higher
level of emphasis on making use of additional context, and suggest that
relevance (as used in Information Retrieval) be thought of as a crucial tool
for designing user-oriented text-generating tasks. We further discuss possible
harms and hazards around such personalization, and argue that value-sensitive
design represents a crucial path forward through these challenges.",2021-09-10
"Generating Self-Contained and Summary-Centric Question Answer Pairs via
  Differentiable Reward Imitation Learning",2021-09-10 06:34:55+00:00,http://arxiv.org/abs/2109.04689v1,"Li Zhou, Kevin Small, Yong Zhang, Sandeep Atluri","cs.CL, cs.AI, cs.LG",dialogue,"Motivated by suggested question generation in conversational news
recommendation systems, we propose a model for generating question-answer pairs
(QA pairs) with self-contained, summary-centric questions and
length-constrained, article-summarizing answers. We begin by collecting a new
dataset of news articles with questions as titles and pairing them with
summaries of varying length. This dataset is used to learn a QA pair generation
model producing summaries as answers that balance brevity with sufficiency
jointly with their corresponding questions. We then reinforce the QA pair
generation process with a differentiable reward function to mitigate exposure
bias, a common problem in natural language generation. Both automatic metrics
and human evaluation demonstrate these QA pairs successfully capture the
central gists of the articles and achieve high answer accuracy.",2021-09-10
"Hi, my name is Martha: Using names to measure and mitigate bias in
  generative dialogue models",2021-09-07 19:20:24+00:00,http://arxiv.org/abs/2109.03300v1,"Eric Michael Smith, Adina Williams",cs.CL,dialogue,"All AI models are susceptible to learning biases in data that they are
trained on. For generative dialogue models, being trained on real human
conversations containing unbalanced gender and race/ethnicity references can
lead to models that display learned biases, which we define here broadly as any
measurable differences in the distributions of words or semantic content of
conversations based on demographic groups. We measure the strength of such
biases by producing artificial conversations between two copies of a dialogue
model, conditioning one conversational partner to state a name commonly
associated with a certain gender and/or race/ethnicity. We find that larger
capacity models tend to exhibit more gender bias and greater stereotyping of
occupations by gender. We show that several methods of tuning these dialogue
models, specifically name scrambling, controlled generation, and unlikelihood
training, are effective in reducing bias in conversation, including on a
downstream conversational task. Name scrambling is also effective in lowering
differences in token usage across conversations where partners have names
associated with different genders or races/ethnicities.",2021-09-07
"Naturalness Evaluation of Natural Language Generation in Task-oriented
  Dialogues using BERT",2021-09-07 08:40:14+00:00,http://arxiv.org/abs/2109.02938v1,"Ye Liu, Wolfgang Maier, Wolfgang Minker, Stefan Ultes","cs.CL, cs.AI",dialogue,"This paper presents an automatic method to evaluate the naturalness of
natural language generation in dialogue systems. While this task was previously
rendered through expensive and time-consuming human labor, we present this
novel task of automatic naturalness evaluation of generated language. By
fine-tuning the BERT model, our proposed naturalness evaluation method shows
robust results and outperforms the baselines: support vector machines,
bi-directional LSTMs, and BLEURT. In addition, the training speed and
evaluation performance of naturalness model are improved by transfer learning
from quality and informativeness linguistic knowledge.",2021-09-07
"SideControl: Controlled Open-domain Dialogue Generation via Additive
  Side Networks",2021-09-05 01:15:26+00:00,http://arxiv.org/abs/2109.01958v1,"Wanyu Du, Yangfeng Ji",cs.CL,dialogue,"Transformer-based pre-trained language models boost the performance of
open-domain dialogue systems. Prior works leverage Transformer-based
pre-trained language models to generate texts with desired attributes in two
general approaches: (1) gradient-based methods: updating all latent
representations of pre-trained models with gradients from attribute models; (2)
weighted-decoding methods: re-ranking beam candidates from pre-trained models
with attribute functions. However, gradient-based methods lead to high
computation cost and can easily get overfitted on small training sets, while
weighted-decoding methods are inherently constrained by the low-variance
high-bias pre-trained model. In this work, we propose a novel approach to
control the generation of Transformer-based pre-trained language models: the
SideControl framework, which leverages a novel control attributes loss to
incorporate useful control signals, and is shown to perform well with very
limited training samples. We evaluate our proposed method on two benchmark
open-domain dialogue datasets, and results show that the SideControl framework
has better controllability, higher generation quality and better
sample-efficiency than existing gradient-based and weighted-decoding baselines.",2021-09-05
Task-Oriented Dialogue System as Natural Language Generation,2021-08-31 08:36:42+00:00,http://arxiv.org/abs/2108.13679v2,"Weizhi Wang, Zhirui Zhang, Junliang Guo, Yinpei Dai, Boxing Chen, Weihua Luo","cs.CL, cs.AI",dialogue,"In this paper, we propose to formulate the task-oriented dialogue system as
the purely natural language generation task, so as to fully leverage the
large-scale pre-trained models like GPT-2 and simplify complicated
delexicalization prepossessing. However, directly applying this method heavily
suffers from the dialogue entity inconsistency caused by the removal of
delexicalized tokens, as well as the catastrophic forgetting problem of the
pre-trained model during fine-tuning, leading to unsatisfactory performance. To
alleviate these problems, we design a novel GPT-Adapter-CopyNet network, which
incorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve
better performance on transfer learning and dialogue entity generation.
Experimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ
dataset demonstrate that our proposed approach significantly outperforms
baseline models with a remarkable performance on automatic and human
evaluations.",2021-08-31
Semantic-based Self-Critical Training For Question Generation,2021-08-26 20:33:35+00:00,http://arxiv.org/abs/2108.12026v1,"Loïc, Kwate Dassi","cs.CL, cs.AI",dialogue,"We present in this work a fully Transformer-based reinforcement learning
generator-evaluator architecture for neural question generation. Question
generation is a task that consists in generating questions given a context and
answer. To improve the quality of the generated question, we came up with a
semantic-based self-critical training layout in generator-evaluator
architecture, which goes beyond typical maximum likelihood training. Evaluation
metrics for language modeling only based on n-gram overlapping do not consider
semantic relations between reference and candidate strings. To improve the
evaluation step, we assess our model for both n-gram overlap using BLEU and
semantically using BERTScore and NUBIA, a novel state-of-the-art evaluation
metric for text generation. Question generation could be used in many
downstream applications, including in extending question answering datasets,
conversational systems, and educational assessment systems.",2021-08-26
"Just Say No: Analyzing the Stance of Neural Dialogue Generation in
  Offensive Contexts",2021-08-26 14:58:05+00:00,http://arxiv.org/abs/2108.11830v1,"Ashutosh Baheti, Maarten Sap, Alan Ritter, Mark Riedl",cs.CL,dialogue,"Dialogue models trained on human conversations inadvertently learn to
generate offensive responses. Moreover, models can insult anyone by agreeing
with an offensive context. To understand the dynamics of contextually offensive
language, we study the stance of dialogue model responses in offensive Reddit
conversations. Specifically, we crowd-annotate ToxiChat, a new dataset of 2,000
Reddit threads and model responses labeled with offensive language and stance.
Our analysis reveals that 42% of user responses agree with toxic comments; 3x
their agreement with safe comments (13%). Pre-trained transformer-based
classifiers fine-tuned on our dataset achieve 0.71 F1 for offensive labels and
0.53 Macro-F1 for stance labels. Finally, we analyze some existing controllable
text generation (CTG) methods to mitigate the contextual offensive behavior of
dialogue models. Compared to the baseline, our best CTG model obtains a 19%
reduction in agreement with offensive context and 29% fewer offensive
responses. This highlights the need for future work to characterize and analyze
more forms of inappropriate behavior in dialogue models to help make them
safer. Our code and corpus are available at
https://github.com/abaheti95/ToxiChat .",2021-08-26
Viola: A Topic Agnostic Generate-and-Rank Dialogue System,2021-08-25 06:20:34+00:00,http://arxiv.org/abs/2108.11063v1,"Hyundong Cho, Basel Shbita, Kartik Shenoy, Shuai Liu, Nikhil Patel, Hitesh Pindikanti, Jennifer Lee, Jonathan May",cs.CL,dialogue,"We present Viola, an open-domain dialogue system for spoken conversation that
uses a topic-agnostic dialogue manager based on a simple generate-and-rank
approach. Leveraging recent advances of generative dialogue systems powered by
large language models, Viola fetches a batch of response candidates from
various neural dialogue models trained with different datasets and
knowledge-grounding inputs. Additional responses originating from
template-based generators are also considered, depending on the user's input
and detected entities. The hand-crafted generators build on a dynamic knowledge
graph injected with rich content that is crawled from the web and automatically
processed on a daily basis. Viola's response ranker is a fine-tuned polyencoder
that chooses the best response given the dialogue history. While dedicated
annotations for the polyencoder alone can indirectly steer it away from
choosing problematic responses, we add rule-based safety nets to detect neural
degeneration and a dedicated classifier to filter out offensive content. We
analyze conversations that Viola took part in for the Alexa Prize Socialbot
Grand Challenge 4 and discuss the strengths and weaknesses of our approach.
Lastly, we suggest future work with a focus on curating conversation data
specifcially for socialbots that will contribute towards a more robust
data-driven socialbot.",2021-08-25
"Using BERT Encoding and Sentence-Level Language Model for Sentence
  Ordering",2021-08-24 23:03:36+00:00,http://arxiv.org/abs/2108.10986v1,"Melika Golestani, Seyedeh Zahra Razavi, Zeinab Borhanifard, Farnaz Tahmasebian, Hesham Faili",cs.CL,dialogue,"Discovering the logical sequence of events is one of the cornerstones in
Natural Language Understanding. One approach to learn the sequence of events is
to study the order of sentences in a coherent text. Sentence ordering can be
applied in various tasks such as retrieval-based Question Answering, document
summarization, storytelling, text generation, and dialogue systems.
Furthermore, we can learn to model text coherence by learning how to order a
set of shuffled sentences. Previous research has relied on RNN, LSTM, and
BiLSTM architecture for learning text language models. However, these networks
have performed poorly due to the lack of attention mechanisms. We propose an
algorithm for sentence ordering in a corpus of short stories. Our proposed
method uses a language model based on Universal Transformers (UT) that captures
sentences' dependencies by employing an attention mechanism. Our method
improves the previous state-of-the-art in terms of Perfect Match Ratio (PMR)
score in the ROCStories dataset, a corpus of nearly 100K short human-made
stories. The proposed model includes three components: Sentence Encoder,
Language Model, and Sentence Arrangement with Brute Force Search. The first
component generates sentence embeddings using SBERT-WK pre-trained model
fine-tuned on the ROCStories data. Then a Universal Transformer network
generates a sentence-level language model. For decoding, the network generates
a candidate sentence as the following sentence of the current sentence. We use
cosine similarity as a scoring function to assign scores to the candidate
embedding and the embeddings of other sentences in the shuffled set. Then a
Brute Force Search is employed to maximize the sum of similarities between
pairs of consecutive sentences.",2021-08-24
Taming the Beast: Learning to Control Neural Conversational Models,2021-08-24 07:58:16+00:00,http://arxiv.org/abs/2108.10561v1,Andrea Madotto,"cs.CL, cs.AI, cs.LG",dialogue,"This thesis investigates the controllability of deep learning-based,
end-to-end, generative dialogue systems in both task-oriented and chit-chat
scenarios. In particular, we study the different aspects of controlling
generative dialogue systems, including controlling styles and topics and
continuously adding and combining dialogue skills. In the three decades since
the first dialogue system was commercialized, the basic architecture of such
systems has remained substantially unchanged, consisting of four pipelined
basic components, namely, natural language understanding (NLU), dialogue state
tracking (DST), a dialogue manager (DM) and natural language generation (NLG).
The dialogue manager, which is the critical component of the modularized
system, controls the response content and style. This module is usually
programmed by rules and is designed to be highly controllable and easily
extendable. With the emergence of powerful ""deep learning"" architectures,
end-to-end generative dialogue systems have been proposed to optimize overall
system performance and simplify training. However, these systems cannot be
easily controlled and extended as the modularized dialogue manager can. This is
because a single neural system is used, which is usually a large pre-trained
language model (e.g., GPT-2), and thus it is hard to surgically change
desirable attributes (e.g., style, topics, etc.). More importantly,
uncontrollable dialogue systems can generate offensive and even toxic
responses. Therefore, in this thesis, we study controllable methods for
end-to-end generative dialogue systems in task-oriented and chit-chat
scenarios. Throughout the chapters, we describe 1) how to control the style and
topics of chit-chat models, 2) how to continuously control and extend
task-oriented dialogue systems, and 3) how to compose and control multi-skill
dialogue models.",2021-08-24
CGEMs: A Metric Model for Automatic Code Generation using GPT-3,2021-08-23 13:28:57+00:00,http://arxiv.org/abs/2108.10168v1,"Aishwarya Narasimhan, Krishna Prasad Agara Venkatesha Rao, Veena M B",cs.AI,dialogue,"Today, AI technology is showing its strengths in almost every industry and
walks of life. From text generation, text summarization, chatbots, NLP is being
used widely. One such paradigm is automatic code generation. An AI could be
generating anything; hence the output space is unconstrained. A self-driving
car is driven for 100 million miles to validate its safety, but tests cannot be
written to monitor and cover an unconstrained space. One of the solutions to
validate AI-generated content is to constrain the problem and convert it from
abstract to realistic, and this can be accomplished by either validating the
unconstrained algorithm using theoretical proofs or by using Monte-Carlo
simulation methods. In this case, we use the latter approach to test/validate a
statistically significant number of samples. This hypothesis of validating the
AI-generated code is the main motive of this work and to know if AI-generated
code is reliable, a metric model CGEMs is proposed. This is an extremely
challenging task as programs can have different logic with different naming
conventions, but the metrics must capture the structure and logic of the
program. This is similar to the importance grammar carries in AI-based text
generation, Q&A, translations, etc. The various metrics that are garnered in
this work to support the evaluation of generated code are as follows:
Compilation, NL description to logic conversion, number of edits needed, some
of the commonly used static-code metrics and NLP metrics. These metrics are
applied to 80 codes generated using OpenAI's GPT-3. Post which a Neural network
is designed for binary classification (acceptable/not acceptable quality of the
generated code). The inputs to this network are the values of the features
obtained from the metrics. The model achieves a classification accuracy of
76.92% and an F1 score of 55.56%. XAI is augmented for model interpretability.",2021-08-23
"A Neural Conversation Generation Model via Equivalent Shared Memory
  Investigation",2021-08-20 13:20:14+00:00,http://arxiv.org/abs/2108.09164v1,"Changzhen Ji, Yating Zhang, Xiaozhong Liu, Adam Jatowt, Changlong Sun, Conghui Zhu, Tiejun Zhao",cs.CL,dialogue,"Conversation generation as a challenging task in Natural Language Generation
(NLG) has been increasingly attracting attention over the last years. A number
of recent works adopted sequence-to-sequence structures along with external
knowledge, which successfully enhanced the quality of generated conversations.
Nevertheless, few works utilized the knowledge extracted from similar
conversations for utterance generation. Taking conversations in customer
service and court debate domains as examples, it is evident that essential
entities/phrases, as well as their associated logic and inter-relationships can
be extracted and borrowed from similar conversation instances. Such information
could provide useful signals for improving conversation generation. In this
paper, we propose a novel reading and memory framework called Deep Reading
Memory Network (DRMN) which is capable of remembering useful information of
similar conversations for improving utterance generation. We apply our model to
two large-scale conversation datasets of justice and e-commerce fields.
Experiments prove that the proposed model outperforms the state-of-the-art
approaches.",2021-08-20
Sentence Semantic Regression for Text Generation,2021-08-06 07:35:59+00:00,http://arxiv.org/abs/2108.02984v1,"Wei Wang, Piji Li, Hai-Tao Zheng",cs.CL,dialogue,"Recall the classical text generation works, the generation framework can be
briefly divided into two phases: \textbf{idea reasoning} and \textbf{surface
realization}. The target of idea reasoning is to figure out the main idea which
will be presented in the following talking/writing periods. Surface realization
aims to arrange the most appropriate sentence to depict and convey the
information distilled from the main idea. However, the current popular
token-by-token text generation methods ignore this crucial process and suffer
from many serious issues, such as idea/topic drift. To tackle the problems and
realize this two-phase paradigm, we propose a new framework named Sentence
Semantic Regression (\textbf{SSR}) based on sentence-level language modeling.
For idea reasoning, two architectures \textbf{SSR-AR} and \textbf{SSR-NonAR}
are designed to conduct sentence semantic regression autoregressively (like
GPT2/3) and bidirectionally (like BERT). In the phase of surface realization, a
mixed-granularity sentence decoder is designed to generate text with better
consistency by jointly incorporating the predicted sentence-level main idea as
well as the preceding contextual token-level information. We conduct
experiments on four tasks of story ending prediction, story ending generation,
dialogue generation, and sentence infilling. The results show that SSR can
obtain better performance in terms of automatic metrics and human evaluation.",2021-08-06
Internet-Augmented Dialogue Generation,2021-07-15 19:00:35+00:00,http://arxiv.org/abs/2107.07566v1,"Mojtaba Komeili, Kurt Shuster, Jason Weston","cs.AI, cs.CL",dialogue,"The largest store of continually updating knowledge on our planet can be
accessed via internet search. In this work we study giving access to this
information to conversational agents. Large language models, even though they
store an impressive amount of knowledge within their weights, are known to
hallucinate facts when generating dialogue (Shuster et al., 2021); moreover,
those facts are frozen in time at the point of model training. In contrast, we
propose an approach that learns to generate an internet search query based on
the context, and then conditions on the search results to finally generate a
response, a method that can employ up-to-the-minute relevant information. We
train and evaluate such models on a newly collected dataset of human-human
conversations whereby one of the speakers is given access to internet search
during knowledgedriven discussions in order to ground their responses. We find
that search-query based access of the internet in conversation provides
superior performance compared to existing approaches that either use no
augmentation or FAISS-based retrieval (Lewis et al., 2020).",2021-07-15
A Survey on Dialogue Summarization: Recent Advances and New Frontiers,2021-07-07 12:11:14+00:00,http://arxiv.org/abs/2107.03175v1,"Xiachong Feng, Xiaocheng Feng, Bing Qin",cs.CL,dialogue,"With the development of dialogue systems and natural language generation
techniques, the resurgence of dialogue summarization has attracted significant
research attentions, which aims to condense the original dialogue into a
shorter version covering salient information. However, there remains a lack of
comprehensive survey for this task. To this end, we take the first step and
present a thorough review of this research field. In detail, we provide an
overview of publicly available research datasets, summarize existing works
according to the domain of input dialogue as well as organize leaderboards
under unified metrics. Furthermore, we discuss some future directions and give
our thoughts. We hope that this first survey of dialogue summarization can
provide the community with a quick access and a general picture to this task
and motivate future researches.",2021-07-07
"Do Encoder Representations of Generative Dialogue Models Encode
  Sufficient Information about the Task ?",2021-06-20 04:52:37+00:00,http://arxiv.org/abs/2106.10622v1,"Prasanna Parthasarathi, Joelle Pineau, Sarath Chandar",cs.CL,dialogue,"Predicting the next utterance in dialogue is contingent on encoding of users'
input text to generate appropriate and relevant response in data-driven
approaches. Although the semantic and syntactic quality of the language
generated is evaluated, more often than not, the encoded representation of
input is not evaluated. As the representation of the encoder is essential for
predicting the appropriate response, evaluation of encoder representation is a
challenging yet important problem. In this work, we showcase evaluating the
text generated through human or automatic metrics is not sufficient to
appropriately evaluate soundness of the language understanding of dialogue
models and, to that end, propose a set of probe tasks to evaluate encoder
representation of different language encoders commonly used in dialogue models.
From experiments, we observe that some of the probe tasks are easier and some
are harder for even sophisticated model architectures to learn. And, through
experiments we observe that RNN based architectures have lower performance on
automatic metrics on text generation than transformer model but perform better
than the transformer model on the probe tasks indicating that RNNs might
preserve task information better than the Transformers.",2021-06-20
Local Explanation of Dialogue Response Generation,2021-06-11 17:58:36+00:00,http://arxiv.org/abs/2106.06528v1,"Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, William Yang Wang","cs.CL, stat.ML",dialogue,"In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose anew method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.",2021-06-11
"AUGNLG: Few-shot Natural Language Generation using Self-trained Data
  Augmentation",2021-06-10 08:45:28+00:00,http://arxiv.org/abs/2106.05589v1,"Xinnuo Xu, Guoyin Wang, Young-Bum Kim, Sungjin Lee",cs.CL,dialogue,"Natural Language Generation (NLG) is a key component in a task-oriented
dialogue system, which converts the structured meaning representation (MR) to
the natural language. For large-scale conversational systems, where it is
common to have over hundreds of intents and thousands of slots, neither
template-based approaches nor model-based approaches are scalable. Recently,
neural NLGs started leveraging transfer learning and showed promising results
in few-shot settings. This paper proposes AUGNLG, a novel data augmentation
approach that combines a self-trained neural retrieval model with a few-shot
learned NLU model, to automatically create MR-to-Text data from open-domain
texts. The proposed system mostly outperforms the state-of-the-art methods on
the FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm
improved results on the FewShotSGD data and provide comprehensive analysis
results on key components of our system. Our code and data are available at
https://github.com/XinnuoXu/AugNLG.",2021-06-10
Defending against Backdoor Attacks in Natural Language Generation,2021-06-03 13:00:28+00:00,http://arxiv.org/abs/2106.01810v1,"Chun Fan, Xiaoya Li, Yuxian Meng, Xiaofei Sun, Xiang Ao, Fei Wu, Jiwei Li, Tianwei Zhang",cs.CL,dialogue,"The frustratingly fragile nature of neural network models make current
natural language generation (NLG) systems prone to backdoor attacks and
generate malicious sequences that could be sexist or offensive. Unfortunately,
little effort has been invested to how backdoor attacks can affect current NLG
models and how to defend against these attacks. In this work, we investigate
this problem on two important NLG tasks, machine translation and dialogue
generation. By giving a formal definition for backdoor attack and defense, and
developing corresponding benchmarks, we design methods to attack NLG models,
which achieve high attack success to ask NLG models to generate malicious
sequences. To defend against these attacks, we propose to detect the attack
trigger by examining the effect of deleting or replacing certain words on the
generation outputs, which we find successful for certain types of attacks. We
will discuss the limitation of this work, and hope this work can raise the
awareness of backdoor risks concealed in deep NLG systems. (Code and data are
available at https://github.com/ShannonAI/backdoor_nlg.)",2021-06-03
"Generate, Prune, Select: A Pipeline for Counterspeech Generation against
  Online Hate Speech",2021-06-03 06:54:03+00:00,http://arxiv.org/abs/2106.01625v1,"Wanzheng Zhu, Suma Bhat",cs.CL,dialogue,"Countermeasures to effectively fight the ever increasing hate speech online
without blocking freedom of speech is of great social interest. Natural
Language Generation (NLG), is uniquely capable of developing scalable
solutions. However, off-the-shelf NLG methods are primarily
sequence-to-sequence neural models and they are limited in that they generate
commonplace, repetitive and safe responses regardless of the hate speech (e.g.,
""Please refrain from using such language."") or irrelevant responses, making
them ineffective for de-escalating hateful conversations. In this paper, we
design a three-module pipeline approach to effectively improve the diversity
and relevance. Our proposed pipeline first generates various counterspeech
candidates by a generative model to promote diversity, then filters the
ungrammatical ones using a BERT model, and finally selects the most relevant
counterspeech response using a novel retrieval-based method. Extensive
Experiments on three representative datasets demonstrate the efficacy of our
approach in generating diverse and relevant counterspeech.",2021-06-03
"Detecting Bot-Generated Text by Characterizing Linguistic Accommodation
  in Human-Bot Interactions",2021-06-02 14:10:28+00:00,http://arxiv.org/abs/2106.01170v1,"Paras Bhatt, Anthony Rios",cs.CL,dialogue,"Language generation models' democratization benefits many domains, from
answering health-related questions to enhancing education by providing
AI-driven tutoring services. However, language generation models'
democratization also makes it easier to generate human-like text at-scale for
nefarious activities, from spreading misinformation to targeting specific
groups with hate speech. Thus, it is essential to understand how people
interact with bots and develop methods to detect bot-generated text. This paper
shows that bot-generated text detection methods are more robust across datasets
and models if we use information about how people respond to it rather than
using the bot's text directly. We also analyze linguistic alignment, providing
insight into differences between human-human and human-bot conversations.",2021-06-02
"NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based
  Simulation",2021-05-30 07:54:54+00:00,http://arxiv.org/abs/2105.14454v1,"Sungdong Kim, Minsuk Chang, Sang-Woo Lee",cs.CL,dialogue,"We propose NeuralWOZ, a novel dialogue collection framework that uses
model-based dialogue simulation. NeuralWOZ has two pipelined models, Collector
and Labeler. Collector generates dialogues from (1) user's goal instructions,
which are the user context and task constraints in natural language, and (2)
system's API call results, which is a list of possible query responses for user
requests from the given knowledge base. Labeler annotates the generated
dialogue by formulating the annotation as a multiple-choice problem, in which
the candidate labels are extracted from goal instructions and API call results.
We demonstrate the effectiveness of the proposed method in the zero-shot domain
transfer learning for dialogue state tracking. In the evaluation, the synthetic
dialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with
improvements of 4.4% point joint goal accuracy on average across domains, and
improvements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1
dataset.",2021-05-30
