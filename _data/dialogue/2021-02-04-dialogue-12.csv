title,pubdate,id,authors,categories,search,abstract,displaydate
Persistent Rule-based Interactive Reinforcement Learning,2021-02-04 06:48:57+00:00,http://arxiv.org/abs/2102.02441v1,"Adam Bignold, Francisco Cruz, Richard Dazeley, Peter Vamplew, Cameron Foale","cs.AI, cs.MA",dialogue,"Interactive reinforcement learning has allowed speeding up the learning
process in autonomous agents by including a human trainer providing extra
information to the agent in real-time. Current interactive reinforcement
learning research has been limited to interactions that offer relevant advice
to the current state only. Additionally, the information provided by each
interaction is not retained and instead discarded by the agent after a
single-use. In this work, we propose a persistent rule-based interactive
reinforcement learning approach, i.e., a method for retaining and reusing
provided knowledge, allowing trainers to give general advice relevant to more
than just the current state. Our experimental results show persistent advice
substantially improves the performance of the agent while reducing the number
of interactions required for the trainer. Moreover, rule-based advice shows
similar performance impact as state-based advice, but with a substantially
reduced interaction count.",2021-02-04
"Converse, Focus and Guess -- Towards Multi-Document Driven Dialogue",2021-02-04 06:36:11+00:00,http://arxiv.org/abs/2102.02435v1,"Han Liu, Caixia Yuan, Xiaojie Wang, Yushu Yang, Huixing Jiang, Zhongyuan Wang",cs.CL,dialogue,"We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an
agent can guess the target document that the user is interested in by leading a
dialogue. To benchmark progress, we introduce a new dataset of GuessMovie,
which contains 16,881 documents, each describing a movie, and associated 13,434
dialogues. Further, we propose the MD3 model. Keeping guessing the target
document in mind, it converses with the user conditioned on both document
engagement and user feedback. In order to incorporate large-scale external
documents into the dialogue, it pretrains a document representation which is
sensitive to attributes it talks about an object. Then it tracks dialogue state
by detecting evolvement of document belief and attribute belief, and finally
optimizes dialogue policy in principle of entropy decreasing and reward
increasing, which is expected to successfully guess the user's target in a
minimum number of turns. Experiments show that our method significantly
outperforms several strong baseline methods and is very close to human's
performance.",2021-02-04
Neural Recursive Belief States in Multi-Agent Reinforcement Learning,2021-02-03 20:10:23+00:00,http://arxiv.org/abs/2102.02274v1,"Pol Moreno, Edward Hughes, Kevin R. McKee, Bernardo Avila Pires, Th√©ophane Weber","cs.LG, cs.AI, cs.MA",dialogue,"In multi-agent reinforcement learning, the problem of learning to act is
particularly difficult because the policies of co-players may be heavily
conditioned on information only observed by them. On the other hand, humans
readily form beliefs about the knowledge possessed by their peers and leverage
beliefs to inform decision-making. Such abilities underlie individual success
in a wide range of Markov games, from bluffing in Poker to conditional
cooperation in the Prisoner's Dilemma, to convention-building in Bridge.
Classical methods are usually not applicable to complex domains due to the
intractable nature of hierarchical beliefs (i.e. beliefs of other agents'
beliefs). We propose a scalable method to approximate these belief structures
using recursive deep generative models, and to use the belief models to obtain
representations useful to acting in complex tasks. Our agents trained with
belief models outperform model-free baselines with equivalent representational
capacity using common training paradigms. We also show that higher-order belief
models outperform agents with lower-order models.",2021-02-03
"DiSCoL: Toward Engaging Dialogue Systems through Conversational Line
  Guided Response Generation",2021-02-03 18:36:58+00:00,http://arxiv.org/abs/2102.02191v1,"Sarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, Nanyun Peng",cs.CL,dialogue,"Having engaging and informative conversations with users is the utmost goal
for open-domain conversational systems. Recent advances in transformer-based
language models and their applications to dialogue systems have succeeded to
generate fluent and human-like responses. However, they still lack control over
the generation process towards producing contentful responses and achieving
engaging conversations. To achieve this goal, we present \textbf{DiSCoL}
(\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational
\textbf{L}ine guided response generation). DiSCoL is an open-domain dialogue
system that leverages conversational lines (briefly \textbf{convlines}) as
controllable and informative content-planning elements to guide the generation
model produce engaging and informative responses. Two primary modules in
DiSCoL's pipeline are conditional generators trained for 1) predicting relevant
and informative convlines for dialogue contexts and 2) generating high-quality
responses conditioned on the predicted convlines. Users can also change the
returned convlines to \textit{control} the direction of the conversations
towards topics that are more interesting for them. Through automatic and human
evaluations, we demonstrate the efficiency of the convlines in producing
engaging conversations.",2021-02-03
"Learning a Compact State Representation for Navigation Tasks by
  Autoencoding 2D-Lidar Scans",2021-02-03 16:10:26+00:00,http://arxiv.org/abs/2102.02127v1,"Christopher Gebauer, Maren Bennewitz","cs.RO, cs.LG",dialogue,"In this paper, we address the problem of generating a compact representation
of 2D-lidar scans for reinforcement learning in navigation tasks. By now only
little work focuses on the compactness of the provided state, which is a
necessary condition to successfully and efficiently train a navigation agent.
Our approach works in three stages. First, we propose a novel preprocessing of
the distance measurements and compute a local, egocentric, binary grid map
based on the current range measurements. We then autoencode the local map using
a variational autoencoder, where the latent space serves as state
representation. An important key for a compact and, at the same time,
meaningful representation is the degree of disentanglement, which describes the
correlation between each latent dimension. Therefore, we finally apply
state-of-the-art disentangling methods to improve the representation power.
Furthermore, we investige the possibilities of incorporating time-dependent
information into the latent space. In particular, we incorporate the relation
of consecutive scans, especially ego-motion, by applying a memory model. We
implemented our approach in python using tensorflow. Our datasets are simulated
with pybullet as well as recorded using a slamtec rplidar A3. The experiments
show the capability of our approach to highly compress lidar data, maintain a
meaningful distribution of the latent space, and even incorporate time-depended
information.",2021-02-03
Learning to Select External Knowledge with Multi-Scale Negative Sampling,2021-02-03 14:59:35+00:00,http://arxiv.org/abs/2102.02096v1,"Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zhengyu Niu, Haifeng Wang",cs.CL,dialogue,"The Track-1 of DSTC9 aims to effectively answer user requests or questions
during task-oriented dialogues, which are out of the scope of APIs/DB. By
leveraging external knowledge resources, relevant information can be retrieved
and encoded into the response generation for these out-of-API-coverage queries.
In this work, we have explored several advanced techniques to enhance the
utilization of external knowledge and boost the quality of response generation,
including schema guided knowledge decision, negatives enhanced knowledge
selection, and knowledge grounded response generation. To evaluate the
performance of our proposed method, comprehensive experiments have been carried
out on the publicly available dataset. Our approach was ranked as the best in
human evaluation of DSTC9 Track-1.",2021-02-03
Advances and Challenges in Conversational Recommender Systems: A Survey,2021-01-23 08:53:15+00:00,http://arxiv.org/abs/2101.09459v4,"Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, Tat-Seng Chua","cs.IR, cs.CL",dialogue,"Recommender systems exploit interaction history to estimate user preference,
having been heavily used in a wide range of industry applications. However,
static recommendation models are difficult to answer two important questions
well due to inherent shortcomings: (a) What exactly does a user like? (b) Why
does a user like an item? The shortcomings are due to the way that static
models learn user preference, i.e., without explicit instructions and active
feedback from users. The recent rise of conversational recommender systems
(CRSs) changes this situation fundamentally. In a CRS, users and the system can
dynamically communicate through natural language interactions, which provide
unprecedented opportunities to explicitly obtain the exact preference of users.
Considerable efforts, spread across disparate settings and applications, have
been put into developing CRSs. Existing models, technologies, and evaluation
methods for CRSs are far from mature. In this paper, we provide a systematic
review of the techniques used in current CRSs. We summarize the key challenges
of developing CRSs into five directions: (1) Question-based user preference
elicitation. (2) Multi-turn conversational recommendation strategies. (3)
Dialogue understanding and generation. (4) Exploitation-exploration trade-offs.
(5) Evaluation and user simulation. These research directions involve multiple
research fields like information retrieval (IR), natural language processing
(NLP), and human-computer interaction (HCI). Based on these research
directions, we discuss some future challenges and opportunities. We provide a
road map for researchers from multiple communities to get started in this area.
We hope this survey helps to identify and address challenges in CRSs and
inspire future research.",2021-01-23
"Beyond Domain APIs: Task-oriented Conversational Modeling with
  Unstructured Knowledge Access Track in DSTC9",2021-01-22 18:57:56+00:00,http://arxiv.org/abs/2101.09276v3,"Seokhwan Kim, Mihail Eric, Behnam Hedayatnia, Karthik Gopalakrishnan, Yang Liu, Chao-Wei Huang, Dilek Hakkani-Tur",cs.CL,dialogue,"Most prior work on task-oriented dialogue systems are restricted to a limited
coverage of domain APIs, while users oftentimes have domain related requests
that are not covered by the APIs. This challenge track aims to expand the
coverage of task-oriented dialogue systems by incorporating external
unstructured knowledge sources. We define three tasks: knowledge-seeking turn
detection, knowledge selection, and knowledge-grounded response generation. We
introduce the data sets and the neural baseline models for three tasks. The
challenge track received a total of 105 entries from 24 participating teams. In
the evaluation results, the ensemble methods with different large-scale
pretrained language models achieved high performances with improved knowledge
selection capability and better generalization into unseen data.",2021-01-22
"Rank the Episodes: A Simple Approach for Exploration in
  Procedurally-Generated Environments",2021-01-20 14:22:01+00:00,http://arxiv.org/abs/2101.08152v2,"Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu",cs.LG,dialogue,"Exploration under sparse reward is a long-standing challenge of model-free
reinforcement learning. The state-of-the-art methods address this challenge by
introducing intrinsic rewards to encourage exploration in novel states or
uncertain environment dynamics. Unfortunately, methods based on intrinsic
rewards often fall short in procedurally-generated environments, where a
different environment is generated in each episode so that the agent is not
likely to visit the same state more than once. Motivated by how humans
distinguish good exploration behaviors by looking into the entire episode, we
introduce RAPID, a simple yet effective episode-level exploration method for
procedurally-generated environments. RAPID regards each episode as a whole and
gives an episodic exploration score from both per-episode and long-term views.
Those highly scored episodes are treated as good exploration behaviors and are
stored in a small ranking buffer. The agent then imitates the episodes in the
buffer to reproduce the past good exploration behaviors. We demonstrate our
method on several procedurally-generated MiniGrid environments, a
first-person-view 3D Maze navigation task from MiniWorld, and several sparse
MuJoCo tasks. The results show that RAPID significantly outperforms the
state-of-the-art intrinsic reward strategies in terms of sample efficiency and
final performance. The code is available at https://github.com/daochenzha/rapid",2021-01-20
Transforming Multi-Conditioned Generation from Meaning Representation,2021-01-12 01:45:06+00:00,http://arxiv.org/abs/2101.04257v1,Joosung Lee,"cs.CL, cs.AI",dialogue,"In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.",2021-01-12
Continual Learning in Task-Oriented Dialogue Systems,2020-12-31 08:44:25+00:00,http://arxiv.org/abs/2012.15504v1,"Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang","cs.CL, cs.AI",dialogue,"Continual learning in task-oriented dialogue systems can allow us to add new
domains and functionalities through time without incurring the high cost of a
whole system retraining. In this paper, we propose a continual learning
benchmark for task-oriented dialogue systems with 37 domains to be learned
continuously in four settings, such as intent recognition, state tracking,
natural language generation, and end-to-end. Moreover, we implement and compare
multiple existing continual learning baselines, and we propose a simple yet
effective architectural method based on residual adapters. Our experiments
demonstrate that the proposed architectural method and a simple replay-based
strategy perform comparably well but they both achieve inferior performance to
the multi-task learning baseline, in where all the data are shown at once,
showing that continual learning in task-oriented dialogue systems is a
challenging task. Furthermore, we reveal several trade-offs between different
continual learning methods in term of parameter usage and memory size, which
are important in the design of a task-oriented dialogue system. The proposed
benchmark is released together with several baselines to promote more research
in this direction.",2020-12-31
"Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous
  Rendering Machines",2020-12-29 07:41:48+00:00,http://arxiv.org/abs/2012.14645v1,"Yangming Li, Kaisheng Yao",cs.CL,dialogue,"End-to-end neural networks have achieved promising performances in natural
language generation (NLG). However, they are treated as black boxes and lack
interpretability. To address this problem, we propose a novel framework,
heterogeneous rendering machines (HRM), that interprets how neural generators
render an input dialogue act (DA) into an utterance. HRM consists of a renderer
set and a mode switcher. The renderer set contains multiple decoders that vary
in both structure and functionality. For every generation step, the mode
switcher selects an appropriate decoder from the renderer set to generate an
item (a word or a phrase). To verify the effectiveness of our method, we have
conducted extensive experiments on 5 benchmark datasets. In terms of automatic
metrics (e.g., BLEU), our model is competitive with the current
state-of-the-art method. The qualitative analysis shows that our model can
interpret the rendering process of neural generators well. Human evaluation
also confirms the interpretability of our proposed approach.",2020-12-29
