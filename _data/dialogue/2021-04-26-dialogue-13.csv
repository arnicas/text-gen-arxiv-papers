title,pubdate,id,authors,categories,search,abstract,displaydate
Focused Attention Improves Document-Grounded Generation,2021-04-26 16:56:29+00:00,http://arxiv.org/abs/2104.12714v1,"Shrimai Prabhumoye, Kazuma Hashimoto, Yingbo Zhou, Alan W Black, Ruslan Salakhutdinov",cs.CL,dialogue,"Document grounded generation is the task of using the information provided in
a document to improve text generation. This work focuses on two different
document grounded generation tasks: Wikipedia Update Generation task and
Dialogue response generation. Our work introduces two novel adaptations of
large scale pre-trained encoder-decoder models focusing on building context
driven representation of the document and enabling specific attention to the
information in the document. Additionally, we provide a stronger BART baseline
for these tasks. Our proposed techniques outperform existing methods on both
automated (at least 48% increase in BLEU-4 points) and human evaluation for
closeness to reference and relevance to the document. Furthermore, we perform
comprehensive manual inspection of the generated output and categorize errors
to provide insights into future directions in modeling these tasks.",2021-04-26
"Estimating Subjective Crowd-Evaluations as an Additional Objective to
  Improve Natural Language Generation",2021-04-12 06:33:16+00:00,http://arxiv.org/abs/2104.05224v1,"Jakob Nyberg, Ramesh Manuvinakurike, Maike Paetzel-Pr√ºsmann",cs.CL,dialogue,"Human ratings are one of the most prevalent methods to evaluate the
performance of natural language processing algorithms. Similarly, it is common
to measure the quality of sentences generated by a natural language generation
model using human raters. In this paper, we argue for exploring the use of
subjective evaluations within the process of training language generation
models in a multi-task learning setting. As a case study, we use a
crowd-authored dialogue corpus to fine-tune six different language generation
models. Two of these models incorporate multi-task learning and use subjective
ratings of lines as part of an explicit learning goal. A human evaluation of
the generated dialogue lines reveals that utterances generated by the
multi-tasking models were subjectively rated as the most typical, most moving
the conversation forward, and least offensive. Based on these promising first
results, we discuss future research directions for incorporating subjective
human evaluations into language model training and to hence keep the human user
in the loop during the development process.",2021-04-12
"Overprotective Training Environments Fall Short at Testing Time: Let
  Models Contribute to Their Own Training",2021-03-20 09:55:50+00:00,http://arxiv.org/abs/2103.11145v1,"Alberto Testoni, Raffaella Bernardi",cs.CL,dialogue,"Despite important progress, conversational systems often generate dialogues
that sound unnatural to humans. We conjecture that the reason lies in their
different training and testing conditions: agents are trained in a controlled
""lab"" setting but tested in the ""wild"". During training, they learn to generate
an utterance given the human dialogue history. On the other hand, during
testing, they must interact with each other, and hence deal with noisy data. We
propose to fill this gap by training the model with mixed batches containing
both samples of human and machine-generated dialogues. We assess the validity
of the proposed method on",2021-03-20
Causal-aware Safe Policy Improvement for Task-oriented dialogue,2021-03-10 22:34:28+00:00,http://arxiv.org/abs/2103.06370v1,"Govardana Sachithanandam Ramachandran, Kazuma Hashimoto, Caiming Xiong","cs.CL, cs.AI, cs.LG",dialogue,"The recent success of reinforcement learning's (RL) in solving complex tasks
is most often attributed to its capacity to explore and exploit an environment
where it has been trained. Sample efficiency is usually not an issue since
cheap simulators are available to sample data on-policy. On the other hand,
task oriented dialogues are usually learnt from offline data collected using
human demonstrations. Collecting diverse demonstrations and annotating them is
expensive. Unfortunately, use of RL methods trained on off-policy data are
prone to issues of bias and generalization, which are further exacerbated by
stochasticity in human response and non-markovian belief state of a dialogue
management system. To this end, we propose a batch RL framework for task
oriented dialogue policy learning: causal aware safe policy improvement
(CASPI). This method gives guarantees on dialogue policy's performance and also
learns to shape rewards according to intentions behind human responses, rather
than just mimicking demonstration data; this couple with batch-RL helps overall
with sample efficiency of the framework. We demonstrate the effectiveness of
this framework on a dialogue-context-to-text Generation and end-to-end dialogue
task of the Multiwoz2.0 dataset. The proposed method outperforms the current
state of the art on these metrics, in both case. In the end-to-end case, our
method trained only on 10\% of the data was able to out perform current state
in three out of four evaluation metrics.",2021-03-10
"Empathetic BERT2BERT Conversational Model: Learning Arabic Language
  Generation with Little Data",2021-03-07 13:23:51+00:00,http://arxiv.org/abs/2103.04353v1,"Tarek Naous, Wissam Antoun, Reem A. Mahmoud, Hazem Hajj",cs.CL,dialogue,"Enabling empathetic behavior in Arabic dialogue agents is an important aspect
of building human-like conversational models. While Arabic Natural Language
Processing has seen significant advances in Natural Language Understanding
(NLU) with language models such as AraBERT, Natural Language Generation (NLG)
remains a challenge. The shortcomings of NLG encoder-decoder models are
primarily due to the lack of Arabic datasets suitable to train NLG models such
as conversational agents. To overcome this issue, we propose a
transformer-based encoder-decoder initialized with AraBERT parameters. By
initializing the weights of the encoder and decoder with AraBERT pre-trained
weights, our model was able to leverage knowledge transfer and boost
performance in response generation. To enable empathy in our conversational
model, we train it using the ArabicEmpatheticDialogues dataset and achieve high
performance in empathetic response generation. Specifically, our model achieved
a low perplexity value of 17.0 and an increase in 5 BLEU points compared to the
previous state-of-the-art model. Also, our proposed model was rated highly by
85 human evaluators, validating its high capability in exhibiting empathy while
generating relevant and fluent responses in open-domain settings.",2021-03-07
Towards Conversational Humor Analysis and Design,2021-02-28 15:22:57+00:00,http://arxiv.org/abs/2103.00536v1,"Tanishq Chaudhary, Mayank Goel, Radhika Mamidi","cs.CL, cs.HC, cs.LG",dialogue,"Well-defined jokes can be divided neatly into a setup and a punchline. While
most works on humor today talk about a joke as a whole, the idea of generating
punchlines to a setup has applications in conversational humor, where funny
remarks usually occur with a non-funny context. Thus, this paper is based
around two core concepts: Classification and the Generation of a punchline from
a particular setup based on the Incongruity Theory. We first implement a
feature-based machine learning model to classify humor. For humor generation,
we use a neural model, and then merge the classical rule-based approaches with
the neural approach to create a hybrid model. The idea behind being: combining
insights gained from other tasks with the setup-punchline model and thus
applying it to existing text generation approaches. We then use and compare our
model with human written jokes with the help of human evaluators in a
double-blind study.",2021-02-28
"BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language
  Generation",2021-01-27 22:07:03+00:00,http://arxiv.org/abs/2101.11718v1,"Jwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, Rahul Gupta","cs.CL, cs.AI, cs.LG",dialogue,"Recent advances in deep learning techniques have enabled machines to generate
cohesive open-ended text when prompted with a sequence of words as context.
While these models now empower many downstream applications from conversation
bots to automatic storytelling, they have been shown to generate texts that
exhibit social biases. To systematically study and benchmark social biases in
open-ended language generation, we introduce the Bias in Open-Ended Language
Generation Dataset (BOLD), a large-scale dataset that consists of 23,679
English text generation prompts for bias benchmarking across five domains:
profession, gender, race, religion, and political ideology. We also propose new
automated metrics for toxicity, psycholinguistic norms, and text gender
polarity to measure social biases in open-ended text generation from multiple
angles. An examination of text generated from three popular language models
reveals that the majority of these models exhibit a larger social bias than
human-written Wikipedia text across all domains. With these results we
highlight the need to benchmark biases in open-ended language generation and
caution users of language generation models on downstream tasks to be cognizant
of these embedded prejudices.",2021-01-27
"An Empirical Study of Cross-Lingual Transferability in Generative
  Dialogue State Tracker",2021-01-27 12:45:55+00:00,http://arxiv.org/abs/2101.11360v1,"Yen-Ting Lin, Yun-Nung Chen",cs.CL,dialogue,"There has been a rapid development in data-driven task-oriented dialogue
systems with the benefit of large-scale datasets. However, the progress of
dialogue systems in low-resource languages lags far behind due to the lack of
high-quality data. To advance the cross-lingual technology in building dialog
systems, DSTC9 introduces the task of cross-lingual dialog state tracking,
where we test the DST module in a low-resource language given the rich-resource
training dataset.
  This paper studies the transferability of a cross-lingual generative dialogue
state tracking system using a multilingual pre-trained seq2seq model. We
experiment under different settings, including joint-training or pre-training
on cross-lingual and cross-ontology datasets. We also find out the low
cross-lingual transferability of our approaches and provides investigation and
discussion.",2021-01-27
BERT Transformer model for Detecting Arabic GPT2 Auto-Generated Tweets,2021-01-22 21:50:38+00:00,http://arxiv.org/abs/2101.09345v1,"Fouzi Harrag, Maria Debbah, Kareem Darwish, Ahmed Abdelali",cs.CL,dialogue,"During the last two decades, we have progressively turned to the Internet and
social media to find news, entertain conversations and share opinion. Recently,
OpenAI has developed a ma-chine learning system called GPT-2 for Generative
Pre-trained Transformer-2, which can pro-duce deepfake texts. It can generate
blocks of text based on brief writing prompts that look like they were written
by humans, facilitating the spread false or auto-generated text. In line with
this progress, and in order to counteract potential dangers, several methods
have been pro-posed for detecting text written by these language models. In
this paper, we propose a transfer learning based model that will be able to
detect if an Arabic sentence is written by humans or automatically generated by
bots. Our dataset is based on tweets from a previous work, which we have
crawled and extended using the Twitter API. We used GPT2-Small-Arabic to
generate fake Arabic Sentences. For evaluation, we compared different recurrent
neural network (RNN) word embeddings based baseline models, namely: LSTM,
BI-LSTM, GRU and BI-GRU, with a transformer-based model. Our new
transfer-learning model has obtained an accuracy up to 98%. To the best of our
knowledge, this work is the first study where ARABERT and GPT2 were combined to
detect and classify the Arabic auto-generated texts.",2021-01-22
Transforming Multi-Conditioned Generation from Meaning Representation,2021-01-12 01:45:06+00:00,http://arxiv.org/abs/2101.04257v1,Joosung Lee,"cs.CL, cs.AI",dialogue,"In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.",2021-01-12
Continual Learning in Task-Oriented Dialogue Systems,2020-12-31 08:44:25+00:00,http://arxiv.org/abs/2012.15504v1,"Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang","cs.CL, cs.AI",dialogue,"Continual learning in task-oriented dialogue systems can allow us to add new
domains and functionalities through time without incurring the high cost of a
whole system retraining. In this paper, we propose a continual learning
benchmark for task-oriented dialogue systems with 37 domains to be learned
continuously in four settings, such as intent recognition, state tracking,
natural language generation, and end-to-end. Moreover, we implement and compare
multiple existing continual learning baselines, and we propose a simple yet
effective architectural method based on residual adapters. Our experiments
demonstrate that the proposed architectural method and a simple replay-based
strategy perform comparably well but they both achieve inferior performance to
the multi-task learning baseline, in where all the data are shown at once,
showing that continual learning in task-oriented dialogue systems is a
challenging task. Furthermore, we reveal several trade-offs between different
continual learning methods in term of parameter usage and memory size, which
are important in the design of a task-oriented dialogue system. The proposed
benchmark is released together with several baselines to promote more research
in this direction.",2020-12-31
"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual
  Contexts",2020-12-30 03:02:50+00:00,http://arxiv.org/abs/2012.15015v1,"Yuxian Meng, Shuhe Wang, Qinghong Han, Xiaofei Sun, Fei Wu, Rui Yan, Jiwei Li",cs.CL,dialogue,"When humans converse, what a speaker will say next significantly depends on
what he sees. Unfortunately, existing dialogue models generate dialogue
utterances only based on preceding textual contexts, and visual contexts are
rarely considered. This is due to a lack of a large-scale multi-module dialogue
dataset with utterances paired with visual contexts. In this paper, we release
{\bf OpenViDial}, a large-scale multi-module dialogue dataset. The dialogue
turns and visual contexts are extracted from movies and TV series, where each
dialogue turn is paired with the corresponding visual context in which it takes
place. OpenViDial contains a total number of 1.1 million dialogue turns, and
thus 1.1 million visual contexts stored in images. Based on this dataset, we
propose a family of encoder-decoder models leveraging both textual and visual
contexts, from coarse-grained image features extracted from CNNs to
fine-grained object features extracted from Faster R-CNNs. We observe that
visual information significantly improves dialogue generation qualities,
verifying the necessity of integrating multi-modal features for dialogue
learning. Our work marks an important step towards large-scale multi-modal
dialogue learning.",2020-12-30
"Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous
  Rendering Machines",2020-12-29 07:41:48+00:00,http://arxiv.org/abs/2012.14645v2,"Yangming Li, Kaisheng Yao",cs.CL,dialogue,"End-to-end neural networks have achieved promising performances in natural
language generation (NLG). However, they are treated as black boxes and lack
interpretability. To address this problem, we propose a novel framework,
heterogeneous rendering machines (HRM), that interprets how neural generators
render an input dialogue act (DA) into an utterance. HRM consists of a renderer
set and a mode switcher. The renderer set contains multiple decoders that vary
in both structure and functionality. For every generation step, the mode
switcher selects an appropriate decoder from the renderer set to generate an
item (a word or a phrase). To verify the effectiveness of our method, we have
conducted extensive experiments on 5 benchmark datasets. In terms of automatic
metrics (e.g., BLEU), our model is competitive with the current
state-of-the-art method. The qualitative analysis shows that our model can
interpret the rendering process of neural generators well. Human evaluation
also confirms the interpretability of our proposed approach.",2020-12-29
