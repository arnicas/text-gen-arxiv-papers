title,pubdate,id,authors,categories,search,abstract,displaydate
A Survey on Dialogue Summarization: Recent Advances and New Frontiers,2021-07-07 12:11:14+00:00,http://arxiv.org/abs/2107.03175v1,"Xiachong Feng, Xiaocheng Feng, Bing Qin",cs.CL,dialogue,"With the development of dialogue systems and natural language generation
techniques, the resurgence of dialogue summarization has attracted significant
research attentions, which aims to condense the original dialogue into a
shorter version covering salient information. However, there remains a lack of
comprehensive survey for this task. To this end, we take the first step and
present a thorough review of this research field. In detail, we provide an
overview of publicly available research datasets, summarize existing works
according to the domain of input dialogue as well as organize leaderboards
under unified metrics. Furthermore, we discuss some future directions and give
our thoughts. We hope that this first survey of dialogue summarization can
provide the community with a quick access and a general picture to this task
and motivate future researches.",2021-07-07
"Do Encoder Representations of Generative Dialogue Models Encode
  Sufficient Information about the Task ?",2021-06-20 04:52:37+00:00,http://arxiv.org/abs/2106.10622v1,"Prasanna Parthasarathi, Joelle Pineau, Sarath Chandar",cs.CL,dialogue,"Predicting the next utterance in dialogue is contingent on encoding of users'
input text to generate appropriate and relevant response in data-driven
approaches. Although the semantic and syntactic quality of the language
generated is evaluated, more often than not, the encoded representation of
input is not evaluated. As the representation of the encoder is essential for
predicting the appropriate response, evaluation of encoder representation is a
challenging yet important problem. In this work, we showcase evaluating the
text generated through human or automatic metrics is not sufficient to
appropriately evaluate soundness of the language understanding of dialogue
models and, to that end, propose a set of probe tasks to evaluate encoder
representation of different language encoders commonly used in dialogue models.
From experiments, we observe that some of the probe tasks are easier and some
are harder for even sophisticated model architectures to learn. And, through
experiments we observe that RNN based architectures have lower performance on
automatic metrics on text generation than transformer model but perform better
than the transformer model on the probe tasks indicating that RNNs might
preserve task information better than the Transformers.",2021-06-20
Local Explanation of Dialogue Response Generation,2021-06-11 17:58:36+00:00,http://arxiv.org/abs/2106.06528v1,"Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, William Yang Wang","cs.CL, stat.ML",dialogue,"In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose anew method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.",2021-06-11
"AUGNLG: Few-shot Natural Language Generation using Self-trained Data
  Augmentation",2021-06-10 08:45:28+00:00,http://arxiv.org/abs/2106.05589v1,"Xinnuo Xu, Guoyin Wang, Young-Bum Kim, Sungjin Lee",cs.CL,dialogue,"Natural Language Generation (NLG) is a key component in a task-oriented
dialogue system, which converts the structured meaning representation (MR) to
the natural language. For large-scale conversational systems, where it is
common to have over hundreds of intents and thousands of slots, neither
template-based approaches nor model-based approaches are scalable. Recently,
neural NLGs started leveraging transfer learning and showed promising results
in few-shot settings. This paper proposes AUGNLG, a novel data augmentation
approach that combines a self-trained neural retrieval model with a few-shot
learned NLU model, to automatically create MR-to-Text data from open-domain
texts. The proposed system mostly outperforms the state-of-the-art methods on
the FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm
improved results on the FewShotSGD data and provide comprehensive analysis
results on key components of our system. Our code and data are available at
https://github.com/XinnuoXu/AugNLG.",2021-06-10
Defending against Backdoor Attacks in Natural Language Generation,2021-06-03 13:00:28+00:00,http://arxiv.org/abs/2106.01810v1,"Chun Fan, Xiaoya Li, Yuxian Meng, Xiaofei Sun, Xiang Ao, Fei Wu, Jiwei Li, Tianwei Zhang",cs.CL,dialogue,"The frustratingly fragile nature of neural network models make current
natural language generation (NLG) systems prone to backdoor attacks and
generate malicious sequences that could be sexist or offensive. Unfortunately,
little effort has been invested to how backdoor attacks can affect current NLG
models and how to defend against these attacks. In this work, we investigate
this problem on two important NLG tasks, machine translation and dialogue
generation. By giving a formal definition for backdoor attack and defense, and
developing corresponding benchmarks, we design methods to attack NLG models,
which achieve high attack success to ask NLG models to generate malicious
sequences. To defend against these attacks, we propose to detect the attack
trigger by examining the effect of deleting or replacing certain words on the
generation outputs, which we find successful for certain types of attacks. We
will discuss the limitation of this work, and hope this work can raise the
awareness of backdoor risks concealed in deep NLG systems. (Code and data are
available at https://github.com/ShannonAI/backdoor_nlg.)",2021-06-03
"Generate, Prune, Select: A Pipeline for Counterspeech Generation against
  Online Hate Speech",2021-06-03 06:54:03+00:00,http://arxiv.org/abs/2106.01625v1,"Wanzheng Zhu, Suma Bhat",cs.CL,dialogue,"Countermeasures to effectively fight the ever increasing hate speech online
without blocking freedom of speech is of great social interest. Natural
Language Generation (NLG), is uniquely capable of developing scalable
solutions. However, off-the-shelf NLG methods are primarily
sequence-to-sequence neural models and they are limited in that they generate
commonplace, repetitive and safe responses regardless of the hate speech (e.g.,
""Please refrain from using such language."") or irrelevant responses, making
them ineffective for de-escalating hateful conversations. In this paper, we
design a three-module pipeline approach to effectively improve the diversity
and relevance. Our proposed pipeline first generates various counterspeech
candidates by a generative model to promote diversity, then filters the
ungrammatical ones using a BERT model, and finally selects the most relevant
counterspeech response using a novel retrieval-based method. Extensive
Experiments on three representative datasets demonstrate the efficacy of our
approach in generating diverse and relevant counterspeech.",2021-06-03
"Detecting Bot-Generated Text by Characterizing Linguistic Accommodation
  in Human-Bot Interactions",2021-06-02 14:10:28+00:00,http://arxiv.org/abs/2106.01170v1,"Paras Bhatt, Anthony Rios",cs.CL,dialogue,"Language generation models' democratization benefits many domains, from
answering health-related questions to enhancing education by providing
AI-driven tutoring services. However, language generation models'
democratization also makes it easier to generate human-like text at-scale for
nefarious activities, from spreading misinformation to targeting specific
groups with hate speech. Thus, it is essential to understand how people
interact with bots and develop methods to detect bot-generated text. This paper
shows that bot-generated text detection methods are more robust across datasets
and models if we use information about how people respond to it rather than
using the bot's text directly. We also analyze linguistic alignment, providing
insight into differences between human-human and human-bot conversations.",2021-06-02
"NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based
  Simulation",2021-05-30 07:54:54+00:00,http://arxiv.org/abs/2105.14454v1,"Sungdong Kim, Minsuk Chang, Sang-Woo Lee",cs.CL,dialogue,"We propose NeuralWOZ, a novel dialogue collection framework that uses
model-based dialogue simulation. NeuralWOZ has two pipelined models, Collector
and Labeler. Collector generates dialogues from (1) user's goal instructions,
which are the user context and task constraints in natural language, and (2)
system's API call results, which is a list of possible query responses for user
requests from the given knowledge base. Labeler annotates the generated
dialogue by formulating the annotation as a multiple-choice problem, in which
the candidate labels are extracted from goal instructions and API call results.
We demonstrate the effectiveness of the proposed method in the zero-shot domain
transfer learning for dialogue state tracking. In the evaluation, the synthetic
dialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with
improvements of 4.4% point joint goal accuracy on average across domains, and
improvements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1
dataset.",2021-05-30
OTTers: One-turn Topic Transitions for Open-Domain Dialogue,2021-05-28 10:16:59+00:00,http://arxiv.org/abs/2105.13710v1,"Karin Sevegnani, David M. Howcroft, Ioannis Konstas, Verena Rieser",cs.CL,dialogue,"Mixed initiative in open-domain dialogue requires a system to pro-actively
introduce new topics. The one-turn topic transition task explores how a system
connects two topics in a cooperative and coherent manner. The goal of the task
is to generate a ""bridging"" utterance connecting the new topic to the topic of
the previous conversation turn. We are especially interested in commonsense
explanations of how a new topic relates to what has been mentioned before. We
first collect a new dataset of human one-turn topic transitions, which we call
OTTers. We then explore different strategies used by humans when asked to
complete such a task, and notice that the use of a bridging utterance to
connect the two topics is the approach used the most. We finally show how
existing state-of-the-art text generation models can be adapted to this task
and examine the performance of these baselines on different splits of the
OTTers data.",2021-05-28
Generative Adversarial Imitation Learning for Empathy-based AI,2021-05-27 17:37:37+00:00,http://arxiv.org/abs/2105.13328v1,"Pratyush Muthukumar, Karishma Muthukumar, Deepan Muthirayan, Pramod Khargonekar",cs.CL,dialogue,"Generative adversarial imitation learning (GAIL) is a model-free algorithm
that has been shown to provide strong results in imitating complex behaviors in
high-dimensional environments. In this paper, we utilize the GAIL model for
text generation to develop empathy-based context-aware conversational AI. Our
model uses an expert trajectory of empathetic prompt-response dialogues which
can accurately exhibit the correct empathetic emotion when generating a
response. The Generator of the GAIL model uses the GPT-2 sequential pre-trained
language model trained on 117 million parameters from 40 GB of internet data.
We propose a novel application of an approach used in transfer learning to fine
tune the GPT-2 model in order to generate concise, user-specific empathetic
responses validated against the Discriminator. Our novel GAIL model utilizes a
sentiment analysis history-based reinforcement learning approach to
empathetically respond to human interactions in a personalized manner. We find
that our model's response scores on various human-generated prompts collected
from the Facebook Empathetic Dialogues dataset outperform baseline
counterparts. Moreover, our model improves upon various history-based
conversational AI models developed recently, as our model's performance over a
sustained conversation of 3 or more interactions outperform similar
conversational AI models.",2021-05-27
"Empirical Error Modeling Improves Robustness of Noisy Neural Sequence
  Labeling",2021-05-25 12:15:45+00:00,http://arxiv.org/abs/2105.11872v1,"Marcin Namysl, Sven Behnke, Joachim Köhler",cs.CL,dialogue,"Despite recent advances, standard sequence labeling systems often fail when
processing noisy user-generated text or consuming the output of an Optical
Character Recognition (OCR) process. In this paper, we improve the noise-aware
training method by proposing an empirical error generation approach that
employs a sequence-to-sequence model trained to perform translation from
error-free to erroneous text. Using an OCR engine, we generated a large
parallel text corpus for training and produced several real-world noisy
sequence labeling benchmarks for evaluation. Moreover, to overcome the data
sparsity problem that exacerbates in the case of imperfect textual input, we
learned noisy language model-based embeddings. Our approach outperformed the
baseline noise generation and error correction techniques on the erroneous
sequence labeling data sets. To facilitate future research on robustness, we
make our code, embeddings, and data conversion scripts publicly available.",2021-05-25
"Towards a Universal NLG for Dialogue Systems and Simulators with Future
  Bridging",2021-05-21 10:37:10+00:00,http://arxiv.org/abs/2105.10267v2,"Philipp Ennen, Yen-Ting Lin, Ali Girayhan Ozbay, Ferdinando Insalata, Maolin Li, Ye Tian, Sepehr Jalali, Da-shan Shiu","cs.CL, cs.AI, cs.LG",dialogue,"In a dialogue system pipeline, a natural language generation (NLG) unit
converts the dialogue direction and content to a corresponding natural language
realization. A recent trend for dialogue systems is to first pre-train on large
datasets and then fine-tune in a supervised manner using datasets annotated
with application-specific features. Though novel behaviours can be learned from
custom annotation, the required effort severely bounds the quantity of the
training set, and the application-specific nature limits the reuse. In light of
the recent success of data-driven approaches, we propose the novel future
bridging NLG (FBNLG) concept for dialogue systems and simulators. The critical
step is for an FBNLG to accept a future user or system utterance to bridge the
present context towards. Future bridging enables self supervised training over
annotation-free datasets, decoupled the training of NLG from the rest of the
system. An FBNLG, pre-trained with massive datasets, is expected to apply in
classical or new dialogue scenarios with minimal adaptation effort. We evaluate
a prototype FBNLG to show that future bridging can be a viable approach to a
universal few-shot NLG for task-oriented and chit-chat dialogues.",2021-05-21
Retrieval-Augmented Transformer-XL for Close-Domain Dialog Generation,2021-05-19 16:34:33+00:00,http://arxiv.org/abs/2105.09235v1,"Giovanni Bonetta, Rossella Cancelliere, Ding Liu, Paul Vozila","cs.CL, cs.AI",dialogue,"Transformer-based models have demonstrated excellent capabilities of
capturing patterns and structures in natural language generation and achieved
state-of-the-art results in many tasks. In this paper we present a
transformer-based model for multi-turn dialog response generation. Our solution
is based on a hybrid approach which augments a transformer-based generative
model with a novel retrieval mechanism, which leverages the memorized
information in the training data via k-Nearest Neighbor search. Our system is
evaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1,
released by Google and holding high quality, goal-oriented conversational data
and a proprietary dataset collected from a real customer service call center.
Both achieve better BLEU scores over strong baselines.",2021-05-19
"Retrieval-Free Knowledge-Grounded Dialogue Response Generation with
  Adapters",2021-05-13 12:33:23+00:00,http://arxiv.org/abs/2105.06232v1,"Yan Xu, Etsuko Ishii, Zihan Liu, Genta Indra Winata, Dan Su, Andrea Madotto, Pascale Fung","cs.CL, cs.AI",dialogue,"To diversify and enrich generated dialogue responses, knowledge-grounded
dialogue has been investigated in recent years. Despite the success of the
existing methods, they mainly follow the paradigm of retrieving the relevant
sentences over a large corpus and augment the dialogues with explicit extra
information, which is time- and resource-consuming. In this paper, we propose
KnowExpert, an end-to-end framework to bypass the retrieval process by
injecting prior knowledge into the pre-trained language models with lightweight
adapters. To the best of our knowledge, this is the first attempt to tackle
this task relying solely on a generation-based approach. Experimental results
show that KnowExpert performs comparably with the retrieval-based baselines,
demonstrating the potential of our proposed direction.",2021-05-13
Focused Attention Improves Document-Grounded Generation,2021-04-26 16:56:29+00:00,http://arxiv.org/abs/2104.12714v1,"Shrimai Prabhumoye, Kazuma Hashimoto, Yingbo Zhou, Alan W Black, Ruslan Salakhutdinov",cs.CL,dialogue,"Document grounded generation is the task of using the information provided in
a document to improve text generation. This work focuses on two different
document grounded generation tasks: Wikipedia Update Generation task and
Dialogue response generation. Our work introduces two novel adaptations of
large scale pre-trained encoder-decoder models focusing on building context
driven representation of the document and enabling specific attention to the
information in the document. Additionally, we provide a stronger BART baseline
for these tasks. Our proposed techniques outperform existing methods on both
automated (at least 48% increase in BLEU-4 points) and human evaluation for
closeness to reference and relevance to the document. Furthermore, we perform
comprehensive manual inspection of the generated output and categorize errors
to provide insights into future directions in modeling these tasks.",2021-04-26
"Estimating Subjective Crowd-Evaluations as an Additional Objective to
  Improve Natural Language Generation",2021-04-12 06:33:16+00:00,http://arxiv.org/abs/2104.05224v1,"Jakob Nyberg, Ramesh Manuvinakurike, Maike Paetzel-Prüsmann",cs.CL,dialogue,"Human ratings are one of the most prevalent methods to evaluate the
performance of natural language processing algorithms. Similarly, it is common
to measure the quality of sentences generated by a natural language generation
model using human raters. In this paper, we argue for exploring the use of
subjective evaluations within the process of training language generation
models in a multi-task learning setting. As a case study, we use a
crowd-authored dialogue corpus to fine-tune six different language generation
models. Two of these models incorporate multi-task learning and use subjective
ratings of lines as part of an explicit learning goal. A human evaluation of
the generated dialogue lines reveals that utterances generated by the
multi-tasking models were subjectively rated as the most typical, most moving
the conversation forward, and least offensive. Based on these promising first
results, we discuss future research directions for incorporating subjective
human evaluations into language model training and to hence keep the human user
in the loop during the development process.",2021-04-12
"Overprotective Training Environments Fall Short at Testing Time: Let
  Models Contribute to Their Own Training",2021-03-20 09:55:50+00:00,http://arxiv.org/abs/2103.11145v1,"Alberto Testoni, Raffaella Bernardi",cs.CL,dialogue,"Despite important progress, conversational systems often generate dialogues
that sound unnatural to humans. We conjecture that the reason lies in their
different training and testing conditions: agents are trained in a controlled
""lab"" setting but tested in the ""wild"". During training, they learn to generate
an utterance given the human dialogue history. On the other hand, during
testing, they must interact with each other, and hence deal with noisy data. We
propose to fill this gap by training the model with mixed batches containing
both samples of human and machine-generated dialogues. We assess the validity
of the proposed method on",2021-03-20
Causal-aware Safe Policy Improvement for Task-oriented dialogue,2021-03-10 22:34:28+00:00,http://arxiv.org/abs/2103.06370v1,"Govardana Sachithanandam Ramachandran, Kazuma Hashimoto, Caiming Xiong","cs.CL, cs.AI, cs.LG",dialogue,"The recent success of reinforcement learning's (RL) in solving complex tasks
is most often attributed to its capacity to explore and exploit an environment
where it has been trained. Sample efficiency is usually not an issue since
cheap simulators are available to sample data on-policy. On the other hand,
task oriented dialogues are usually learnt from offline data collected using
human demonstrations. Collecting diverse demonstrations and annotating them is
expensive. Unfortunately, use of RL methods trained on off-policy data are
prone to issues of bias and generalization, which are further exacerbated by
stochasticity in human response and non-markovian belief state of a dialogue
management system. To this end, we propose a batch RL framework for task
oriented dialogue policy learning: causal aware safe policy improvement
(CASPI). This method gives guarantees on dialogue policy's performance and also
learns to shape rewards according to intentions behind human responses, rather
than just mimicking demonstration data; this couple with batch-RL helps overall
with sample efficiency of the framework. We demonstrate the effectiveness of
this framework on a dialogue-context-to-text Generation and end-to-end dialogue
task of the Multiwoz2.0 dataset. The proposed method outperforms the current
state of the art on these metrics, in both case. In the end-to-end case, our
method trained only on 10\% of the data was able to out perform current state
in three out of four evaluation metrics.",2021-03-10
"Empathetic BERT2BERT Conversational Model: Learning Arabic Language
  Generation with Little Data",2021-03-07 13:23:51+00:00,http://arxiv.org/abs/2103.04353v1,"Tarek Naous, Wissam Antoun, Reem A. Mahmoud, Hazem Hajj",cs.CL,dialogue,"Enabling empathetic behavior in Arabic dialogue agents is an important aspect
of building human-like conversational models. While Arabic Natural Language
Processing has seen significant advances in Natural Language Understanding
(NLU) with language models such as AraBERT, Natural Language Generation (NLG)
remains a challenge. The shortcomings of NLG encoder-decoder models are
primarily due to the lack of Arabic datasets suitable to train NLG models such
as conversational agents. To overcome this issue, we propose a
transformer-based encoder-decoder initialized with AraBERT parameters. By
initializing the weights of the encoder and decoder with AraBERT pre-trained
weights, our model was able to leverage knowledge transfer and boost
performance in response generation. To enable empathy in our conversational
model, we train it using the ArabicEmpatheticDialogues dataset and achieve high
performance in empathetic response generation. Specifically, our model achieved
a low perplexity value of 17.0 and an increase in 5 BLEU points compared to the
previous state-of-the-art model. Also, our proposed model was rated highly by
85 human evaluators, validating its high capability in exhibiting empathy while
generating relevant and fluent responses in open-domain settings.",2021-03-07
Towards Conversational Humor Analysis and Design,2021-02-28 15:22:57+00:00,http://arxiv.org/abs/2103.00536v1,"Tanishq Chaudhary, Mayank Goel, Radhika Mamidi","cs.CL, cs.HC, cs.LG",dialogue,"Well-defined jokes can be divided neatly into a setup and a punchline. While
most works on humor today talk about a joke as a whole, the idea of generating
punchlines to a setup has applications in conversational humor, where funny
remarks usually occur with a non-funny context. Thus, this paper is based
around two core concepts: Classification and the Generation of a punchline from
a particular setup based on the Incongruity Theory. We first implement a
feature-based machine learning model to classify humor. For humor generation,
we use a neural model, and then merge the classical rule-based approaches with
the neural approach to create a hybrid model. The idea behind being: combining
insights gained from other tasks with the setup-punchline model and thus
applying it to existing text generation approaches. We then use and compare our
model with human written jokes with the help of human evaluators in a
double-blind study.",2021-02-28
"BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language
  Generation",2021-01-27 22:07:03+00:00,http://arxiv.org/abs/2101.11718v1,"Jwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, Rahul Gupta","cs.CL, cs.AI, cs.LG",dialogue,"Recent advances in deep learning techniques have enabled machines to generate
cohesive open-ended text when prompted with a sequence of words as context.
While these models now empower many downstream applications from conversation
bots to automatic storytelling, they have been shown to generate texts that
exhibit social biases. To systematically study and benchmark social biases in
open-ended language generation, we introduce the Bias in Open-Ended Language
Generation Dataset (BOLD), a large-scale dataset that consists of 23,679
English text generation prompts for bias benchmarking across five domains:
profession, gender, race, religion, and political ideology. We also propose new
automated metrics for toxicity, psycholinguistic norms, and text gender
polarity to measure social biases in open-ended text generation from multiple
angles. An examination of text generated from three popular language models
reveals that the majority of these models exhibit a larger social bias than
human-written Wikipedia text across all domains. With these results we
highlight the need to benchmark biases in open-ended language generation and
caution users of language generation models on downstream tasks to be cognizant
of these embedded prejudices.",2021-01-27
"An Empirical Study of Cross-Lingual Transferability in Generative
  Dialogue State Tracker",2021-01-27 12:45:55+00:00,http://arxiv.org/abs/2101.11360v1,"Yen-Ting Lin, Yun-Nung Chen",cs.CL,dialogue,"There has been a rapid development in data-driven task-oriented dialogue
systems with the benefit of large-scale datasets. However, the progress of
dialogue systems in low-resource languages lags far behind due to the lack of
high-quality data. To advance the cross-lingual technology in building dialog
systems, DSTC9 introduces the task of cross-lingual dialog state tracking,
where we test the DST module in a low-resource language given the rich-resource
training dataset.
  This paper studies the transferability of a cross-lingual generative dialogue
state tracking system using a multilingual pre-trained seq2seq model. We
experiment under different settings, including joint-training or pre-training
on cross-lingual and cross-ontology datasets. We also find out the low
cross-lingual transferability of our approaches and provides investigation and
discussion.",2021-01-27
BERT Transformer model for Detecting Arabic GPT2 Auto-Generated Tweets,2021-01-22 21:50:38+00:00,http://arxiv.org/abs/2101.09345v1,"Fouzi Harrag, Maria Debbah, Kareem Darwish, Ahmed Abdelali",cs.CL,dialogue,"During the last two decades, we have progressively turned to the Internet and
social media to find news, entertain conversations and share opinion. Recently,
OpenAI has developed a ma-chine learning system called GPT-2 for Generative
Pre-trained Transformer-2, which can pro-duce deepfake texts. It can generate
blocks of text based on brief writing prompts that look like they were written
by humans, facilitating the spread false or auto-generated text. In line with
this progress, and in order to counteract potential dangers, several methods
have been pro-posed for detecting text written by these language models. In
this paper, we propose a transfer learning based model that will be able to
detect if an Arabic sentence is written by humans or automatically generated by
bots. Our dataset is based on tweets from a previous work, which we have
crawled and extended using the Twitter API. We used GPT2-Small-Arabic to
generate fake Arabic Sentences. For evaluation, we compared different recurrent
neural network (RNN) word embeddings based baseline models, namely: LSTM,
BI-LSTM, GRU and BI-GRU, with a transformer-based model. Our new
transfer-learning model has obtained an accuracy up to 98%. To the best of our
knowledge, this work is the first study where ARABERT and GPT2 were combined to
detect and classify the Arabic auto-generated texts.",2021-01-22
Transforming Multi-Conditioned Generation from Meaning Representation,2021-01-12 01:45:06+00:00,http://arxiv.org/abs/2101.04257v1,Joosung Lee,"cs.CL, cs.AI",dialogue,"In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.",2021-01-12
Continual Learning in Task-Oriented Dialogue Systems,2020-12-31 08:44:25+00:00,http://arxiv.org/abs/2012.15504v1,"Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang","cs.CL, cs.AI",dialogue,"Continual learning in task-oriented dialogue systems can allow us to add new
domains and functionalities through time without incurring the high cost of a
whole system retraining. In this paper, we propose a continual learning
benchmark for task-oriented dialogue systems with 37 domains to be learned
continuously in four settings, such as intent recognition, state tracking,
natural language generation, and end-to-end. Moreover, we implement and compare
multiple existing continual learning baselines, and we propose a simple yet
effective architectural method based on residual adapters. Our experiments
demonstrate that the proposed architectural method and a simple replay-based
strategy perform comparably well but they both achieve inferior performance to
the multi-task learning baseline, in where all the data are shown at once,
showing that continual learning in task-oriented dialogue systems is a
challenging task. Furthermore, we reveal several trade-offs between different
continual learning methods in term of parameter usage and memory size, which
are important in the design of a task-oriented dialogue system. The proposed
benchmark is released together with several baselines to promote more research
in this direction.",2020-12-31
"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual
  Contexts",2020-12-30 03:02:50+00:00,http://arxiv.org/abs/2012.15015v1,"Yuxian Meng, Shuhe Wang, Qinghong Han, Xiaofei Sun, Fei Wu, Rui Yan, Jiwei Li",cs.CL,dialogue,"When humans converse, what a speaker will say next significantly depends on
what he sees. Unfortunately, existing dialogue models generate dialogue
utterances only based on preceding textual contexts, and visual contexts are
rarely considered. This is due to a lack of a large-scale multi-module dialogue
dataset with utterances paired with visual contexts. In this paper, we release
{\bf OpenViDial}, a large-scale multi-module dialogue dataset. The dialogue
turns and visual contexts are extracted from movies and TV series, where each
dialogue turn is paired with the corresponding visual context in which it takes
place. OpenViDial contains a total number of 1.1 million dialogue turns, and
thus 1.1 million visual contexts stored in images. Based on this dataset, we
propose a family of encoder-decoder models leveraging both textual and visual
contexts, from coarse-grained image features extracted from CNNs to
fine-grained object features extracted from Faster R-CNNs. We observe that
visual information significantly improves dialogue generation qualities,
verifying the necessity of integrating multi-modal features for dialogue
learning. Our work marks an important step towards large-scale multi-modal
dialogue learning.",2020-12-30
"Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous
  Rendering Machines",2020-12-29 07:41:48+00:00,http://arxiv.org/abs/2012.14645v2,"Yangming Li, Kaisheng Yao",cs.CL,dialogue,"End-to-end neural networks have achieved promising performances in natural
language generation (NLG). However, they are treated as black boxes and lack
interpretability. To address this problem, we propose a novel framework,
heterogeneous rendering machines (HRM), that interprets how neural generators
render an input dialogue act (DA) into an utterance. HRM consists of a renderer
set and a mode switcher. The renderer set contains multiple decoders that vary
in both structure and functionality. For every generation step, the mode
switcher selects an appropriate decoder from the renderer set to generate an
item (a word or a phrase). To verify the effectiveness of our method, we have
conducted extensive experiments on 5 benchmark datasets. In terms of automatic
metrics (e.g., BLEU), our model is competitive with the current
state-of-the-art method. The qualitative analysis shows that our model can
interpret the rendering process of neural generators well. Human evaluation
also confirms the interpretability of our proposed approach.",2020-12-29
