title,pubdate,id,authors,categories,search,abstract,displaydate
"Quantifying environment and population diversity in multi-agent
  reinforcement learning",2021-02-16 18:54:39+00:00,http://arxiv.org/abs/2102.08370v1,"Kevin R. McKee, Joel Z. Leibo, Charlie Beattie, Richard Everett","cs.MA, cs.AI",dialogue,"Generalization is a major challenge for multi-agent reinforcement learning.
How well does an agent perform when placed in novel environments and in
interactions with new co-players? In this paper, we investigate and quantify
the relationship between generalization and diversity in the multi-agent
domain. Across the range of multi-agent environments considered here,
procedurally generating training levels significantly improves agent
performance on held-out levels. However, agent performance on the specific
levels used in training sometimes declines as a result. To better understand
the effects of co-player variation, our experiments introduce a new
environment-agnostic measure of behavioral diversity. Results demonstrate that
population size and intrinsic motivation are both effective methods of
generating greater population diversity. In turn, training with a diverse set
of co-players strengthens agent performance in some (but not all) cases.",2021-02-16
"A Cooperative Memory Network for Personalized Task-oriented Dialogue
  Systems with Incomplete User Profiles",2021-02-16 18:05:54+00:00,http://arxiv.org/abs/2102.08322v1,"Jiahuan Pei, Pengjie Ren, Maarten de Rijke","cs.AI, cs.CL, cs.IR",dialogue,"There is increasing interest in developing personalized Task-oriented
Dialogue Systems (TDSs). Previous work on personalized TDSs often assumes that
complete user profiles are available for most or even all users. This is
unrealistic because (1) not everyone is willing to expose their profiles due to
privacy concerns; and (2) rich user profiles may involve a large number of
attributes (e.g., gender, age, tastes, . . .). In this paper, we study
personalized TDSs without assuming that user profiles are complete. We propose
a Cooperative Memory Network (CoMemNN) that has a novel mechanism to gradually
enrich user profiles as dialogues progress and to simultaneously improve
response selection based on the enriched profiles. CoMemNN consists of two core
modules: User Profile Enrichment (UPE) and Dialogue Response Selection (DRS).
The former enriches incomplete user profiles by utilizing collaborative
information from neighbor users as well as current dialogues. The latter uses
the enriched profiles to update the current user query so as to encode more
useful information, based on which a personalized response to a user request is
selected.
  We conduct extensive experiments on the personalized bAbI dialogue benchmark
datasets. We find that CoMemNN is able to enrich user profiles effectively,
which results in an improvement of 3.06% in terms of response selection
accuracy compared to state-of-the-art methods. We also test the robustness of
CoMemNN against incompleteness of user profiles by randomly discarding
attribute values from user profiles. Even when discarding 50% of the attribute
values, CoMemNN is able to match the performance of the best performing
baseline without discarding user profiles, showing the robustness of CoMemNN.",2021-02-16
"An Effort to Measure Customer Relationship Performance in Indonesia's
  Fintech Industry",2021-02-16 16:33:46+00:00,http://arxiv.org/abs/2102.08262v1,"Alisya Putri Rabbani, Andry Alamsyah, Sri Widiyanesti","econ.GN, cs.CY, cs.LG, cs.SI, q-fin.EC, 00-XX, K.4.m",dialogue,"The availability of social media simplifies the companies-customers
relationship. An effort to engage customers in conversation networks using
social media is called Social Customer Relationship Management (SCRM). Social
Network Analysis helps to understand network characteristics and how active the
conversation network on social media. Calculating its network properties is
beneficial for measuring customer relationship performance. Financial
Technology, a new emerging industry that provides digital-based financial
services utilize social media to interact with its customers. Measuring SCRM
performance is needed in order to stay competitive among others. Therefore, we
aim to explore the SCRM performance of the Indonesia Fintech company. In terms
of discovering the market majority thought in conversation networks, we perform
sentiment analysis by classifying into positive and negative opinion. As case
studies, we investigate Twitter conversations about GoPay, OVO, Dana, and
LinkAja during the observation period from 1st October until 1st November 2019.
The result of this research is beneficial for business intelligence purposes
especially in managing relationships with customers.",2021-02-16
Composing Pick-and-Place Tasks By Grounding Language,2021-02-16 11:29:09+00:00,http://arxiv.org/abs/2102.08094v1,"Oier Mees, Wolfram Burgard","cs.RO, cs.AI, cs.CV, cs.LG",dialogue,"Controlling robots to perform tasks via natural language is one of the most
challenging topics in human-robot interaction. In this work, we present a robot
system that follows unconstrained language instructions to pick and place
arbitrary objects and effectively resolves ambiguities through dialogues. Our
approach infers objects and their relationships from input images and language
expressions and can place objects in accordance with the spatial relations
expressed by the user. Unlike previous approaches, we consider grounding not
only for the picking but also for the placement of everyday objects from
language. Specifically, by grounding objects and their spatial relations, we
allow specification of complex placement instructions, e.g. ""place it behind
the middle red bowl"". Our results obtained using a real-world PR2 robot
demonstrate the effectiveness of our method in understanding pick-and-place
language instructions and sequentially composing them to solve tabletop
manipulation tasks. Videos are available at
http://speechrobot.cs.uni-freiburg.de",2021-02-16
Steadily Learn to Drive with Virtual Memory,2021-02-16 10:46:52+00:00,http://arxiv.org/abs/2102.08072v1,"Yuhang Zhang, Yao Mu, Yujie Yang, Yang Guan, Shengbo Eben Li, Qi Sun, Jianyu Chen","cs.LG, cs.AI, cs.RO, cs.SY, eess.SY",dialogue,"Reinforcement learning has shown great potential in developing high-level
autonomous driving. However, for high-dimensional tasks, current RL methods
suffer from low data efficiency and oscillation in the training process. This
paper proposes an algorithm called Learn to drive with Virtual Memory (LVM) to
overcome these problems. LVM compresses the high-dimensional information into
compact latent states and learns a latent dynamic model to summarize the
agent's experience. Various imagined latent trajectories are generated as
virtual memory by the latent dynamic model. The policy is learned by
propagating gradient through the learned latent model with the imagined latent
trajectories and thus leads to high data efficiency. Furthermore, a double
critic structure is designed to reduce the oscillation during the training
process. The effectiveness of LVM is demonstrated by an image-input autonomous
driving task, in which LVM outperforms the existing method in terms of data
efficiency, learning stability, and control performance.",2021-02-16
"DFAC Framework: Factorizing the Value Function via Quantile Mixture for
  Multi-Agent Distributional Q-Learning",2021-02-16 03:16:49+00:00,http://arxiv.org/abs/2102.07936v1,"Wei-Fang Sun, Cheng-Kuang Lee, Chun-Yi Lee","cs.MA, cs.LG",dialogue,"In fully cooperative multi-agent reinforcement learning (MARL) settings, the
environments are highly stochastic due to the partial observability of each
agent and the continuously changing policies of the other agents. To address
the above issues, we integrate distributional RL and value function
factorization methods by proposing a Distributional Value Function
Factorization (DFAC) framework to generalize expected value function
factorization methods to their DFAC variants. DFAC extends the individual
utility functions from deterministic variables to random variables, and models
the quantile function of the total return as a quantile mixture. To validate
DFAC, we demonstrate DFAC's ability to factorize a simple two-step matrix game
with stochastic rewards and perform experiments on all Super Hard tasks of
StarCraft Multi-Agent Challenge, showing that DFAC is able to outperform
expected value function factorization baselines.",2021-02-16
"""From What I see, this makes sense"": Seeing meaning in algorithmic
  results",2021-02-15 20:50:11+00:00,http://arxiv.org/abs/2102.07844v1,Samir Passi,"cs.HC, cs.CL",dialogue,"In this workshop paper, we use an empirical example from our ongoing
fieldwork, to showcase the complexity and situatedness of the process of making
sense of algorithmic results; i.e. how to evaluate, validate, and contextualize
algorithmic outputs. So far, in our research work, we have focused on such
sense-making processes in data analytic learning environments such as
classrooms and training workshops. Multiple moments in our fieldwork suggest
that meaning, in data analytics, is constructed through an iterative and
reflexive dialogue between data, code, assumptions, prior knowledge, and
algorithmic results. A data analytic result is nothing short of a
sociotechnical accomplishment - one in which it is extremely difficult, if not
at times impossible, to clearly distinguish between 'human' and 'technical'
forms of data analytic work. We conclude this paper with a set of questions
that we would like to explore further in this workshop.",2021-02-15
Interim envy-freeness: A new fairness concept for random allocations,2021-02-15 20:35:55+00:00,http://arxiv.org/abs/2102.07839v1,"Ioannis Caragiannis, Panagiotis Kanellopoulos, Maria Kyropoulou",cs.GT,dialogue,"With very few exceptions, research in fair division has mostly focused on
deterministic allocations. Deviating from this trend, we define and study the
novel notion of interim envy-freeness (iEF) for lotteries over allocations,
which aims to serve as a sweet spot between the too stringent notion of ex-post
envy-freeness and the very weak notion of ex-ante envy-freeness. Our new
fairness notion is a natural generalization of envy-freeness to random
allocations in the sense that a deterministic envy-free allocation is iEF (when
viewed as a degenerate lottery). It is also certainly meaningful as it allows
for a richer solution space, which includes solutions that are provably better
than envy-freeness according to several criteria. Our analysis relates iEF to
other fairness notions as well, and reveals tradeoffs between iEF and
efficiency. Even though several of our results apply to general fair division
problems, we are particularly interested in instances with equal numbers of
agents and items where allocations are perfect matchings of the items to the
agents. Envy-freeness can be trivially decided and (when it can be achieved,
it) implies full efficiency in this setting. Although computing iEF allocations
in matching allocation instances is considerably more challenging, we show how
to compute them in polynomial time, while also maximizing several efficiency
objectives. Our algorithms use the ellipsoid method for linear programming and
efficient solutions to a novel variant of the bipartite matching problem as a
separation oracle. We also extend the interim envy-freeness notion by
introducing payments to or from the agents. We present a series of results on
two optimization problems, including a generalization of the classical rent
division problem to random allocations using interim envy-freeness as the
solution concept.",2021-02-15
End-to-End Egospheric Spatial Memory,2021-02-15 18:59:07+00:00,http://arxiv.org/abs/2102.07764v1,"Daniel Lenton, Stephen James, Ronald Clark, Andrew J. Davison","cs.RO, cs.AI, cs.CV, cs.LG, cs.NE",dialogue,"Spatial memory, or the ability to remember and recall specific locations and
objects, is central to autonomous agents' ability to carry out tasks in real
environments. However, most existing artificial memory modules have difficulty
recalling information over long time periods and are not very adept at storing
spatial information. We propose a parameter-free module, Egospheric Spatial
Memory (ESM), which encodes the memory in an ego-sphere around the agent,
enabling expressive 3D representations. ESM can be trained end-to-end via
either imitation or reinforcement learning, and improves both training
efficiency and final performance against other memory baselines on both drone
and manipulator visuomotor control tasks. The explicit egocentric geometry also
enables us to seamlessly combine the learned controller with other non-learned
modalities, such as local obstacle avoidance. We further show applications to
semantic segmentation on the ScanNet dataset, where ESM naturally combines
image-level and map-level inference modalities. Through our broad set of
experiments, we show that ESM provides a general computation graph for embodied
spatial reasoning, and the module forms a bridge between real-time mapping
systems and differentiable memory architectures.",2021-02-15
Data-driven Analysis for Understanding Team Sports Behaviors,2021-02-15 13:31:45+00:00,http://arxiv.org/abs/2102.07545v1,Keisuke Fujii,cs.AI,dialogue,"Understanding the principles of real-world biological multi-agent behaviors
is a current challenge in various scientific and engineering fields. The rules
regarding the real-world biological multi-agent behaviors such as team sports
are often largely unknown due to their inherently higher-order interactions,
cognition, and body dynamics. Estimation of the rules from data, i.e.,
data-driven approaches such as machine learning, provides an effective way for
the analysis of such behaviors. Although most data-driven models have
non-linear structures and high prediction performances, it is sometimes hard to
interpret them. This survey focuses on data-driven analysis for quantitative
understanding of invasion team sports behaviors such as basketball and
football, and introduces two main approaches for understanding such multi-agent
behaviors: (1) extracting easily interpretable features or rules from data and
(2) generating and controlling behaviors in visually-understandable ways. The
first approach involves the visualization of learned representations and the
extraction of mathematical structures behind the behaviors. The second approach
can be used to test hypotheses by simulating and controlling future and
counterfactual behaviors. Lastly, the potential practical applications of
extracted rules, features, and generated behaviors are discussed. These
approaches can contribute to a better understanding of multi-agent behaviors in
the real world.",2021-02-15
Cooperation and Reputation Dynamics with Reinforcement Learning,2021-02-15 12:48:56+00:00,http://arxiv.org/abs/2102.07523v1,"Nicolas Anastassacos, Julian García, Stephen Hailes, Mirco Musolesi","cs.MA, cs.AI",dialogue,"Creating incentives for cooperation is a challenge in natural and artificial
systems. One potential answer is reputation, whereby agents trade the immediate
cost of cooperation for the future benefits of having a good reputation. Game
theoretical models have shown that specific social norms can make cooperation
stable, but how agents can independently learn to establish effective
reputation mechanisms on their own is less understood. We use a simple model of
reinforcement learning to show that reputation mechanisms generate two
coordination problems: agents need to learn how to coordinate on the meaning of
existing reputations and collectively agree on a social norm to assign
reputations to others based on their behavior. These coordination problems
exhibit multiple equilibria, some of which effectively establish cooperation.
When we train agents with a standard Q-learning algorithm in an environment
with the presence of reputation mechanisms, convergence to undesirable
equilibria is widespread. We propose two mechanisms to alleviate this: (i)
seeding a proportion of the system with fixed agents that steer others towards
good equilibria; and (ii), intrinsic rewards based on the idea of
introspection, i.e., augmenting agents' rewards by an amount proportionate to
the performance of their own strategy against themselves. A combination of
these simple mechanisms is successful in stabilizing cooperation, even in a
fully decentralized version of the problem where agents learn to use and assign
reputations simultaneously. We show how our results relate to the literature in
Evolutionary Game Theory, and discuss implications for artificial, human and
hybrid systems, where reputations can be used as a way to establish trust and
cooperation.",2021-02-15
"Improving Model-Based Reinforcement Learning with Internal State
  Representations through Self-Supervision",2021-02-10 17:55:04+00:00,http://arxiv.org/abs/2102.05599v1,"Julien Scholz, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter",cs.LG,dialogue,"Using a model of the environment, reinforcement learning agents can plan
their future moves and achieve superhuman performance in board games like
Chess, Shogi, and Go, while remaining relatively sample-efficient. As
demonstrated by the MuZero Algorithm, the environment model can even be learned
dynamically, generalizing the agent to many more tasks while at the same time
achieving state-of-the-art performance. Notably, MuZero uses internal state
representations derived from real environment states for its predictions. In
this paper, we bind the model's predicted internal state representation to the
environment state via two additional terms: a reconstruction model loss and a
simpler consistency loss, both of which work independently and unsupervised,
acting as constraints to stabilize the learning process. Our experiments show
that this new integration of reconstruction model loss and simpler consistency
loss provide a significant performance increase in OpenAI Gym environments. Our
modifications also enable self-supervised pretraining for MuZero, so the
algorithm can learn about environment dynamics before a goal is made available.",2021-02-10
Multi-turn Dialogue Reading Comprehension with Pivot Turns and Knowledge,2021-02-10 15:00:12+00:00,http://arxiv.org/abs/2102.05474v1,"Zhuosheng Zhang, Junlong Li, Hai Zhao","cs.CL, cs.AI",dialogue,"Multi-turn dialogue reading comprehension aims to teach machines to read
dialogue contexts and solve tasks such as response selection and answering
questions. The major challenges involve noisy history contexts and especial
prerequisites of commonsense knowledge that is unseen in the given material.
Existing works mainly focus on context and response matching approaches. This
work thus makes the first attempt to tackle the above two challenges by
extracting substantially important turns as pivot utterances and utilizing
external knowledge to enhance the representation of context. We propose a
pivot-oriented deep selection model (PoDS) on top of the Transformer-based
language models for dialogue comprehension. In detail, our model first picks
out the pivot utterances from the conversation history according to the
semantic matching with the candidate response or question, if any. Besides,
knowledge items related to the dialogue context are extracted from a knowledge
graph as external knowledge. Then, the pivot utterances and the external
knowledge are combined with a well-designed mechanism for refining predictions.
Experimental results on four dialogue comprehension benchmark tasks show that
our proposed model achieves great improvements on baselines. A series of
empirical comparisons are conducted to show how our selection strategies and
the extra knowledge injection influence the results.",2021-02-10
"Automated and Distributed Statistical Analysis of Economic Agent-Based
  Models",2021-02-10 12:39:34+00:00,http://arxiv.org/abs/2102.05405v1,"Andrea Vandin, Daniele Giachini, Francesco Lamperti, Francesca Chiaromonte","econ.GN, cs.MA, cs.PF, q-fin.EC",dialogue,"We propose a novel approach to the statistical analysis of simulation models
and, especially, agent-based models (ABMs). Our main goal is to provide a fully
automated and model-independent tool-kit to inspect simulations and perform
counterfactual analysis. Our approach: (i) is easy-to-use by the modeller, (ii)
improves reproducibility of results, (iii) optimizes running time given the
modeller's machine, (iv) automatically chooses the number of required
simulations and simulation steps to reach user-specified statistical
confidence, and (v) automatically performs a variety of statistical tests. In
particular, our framework is designed to distinguish the transient dynamics of
the model from its steady-state behaviour (if any), estimate properties of the
model in both ""phases"", and provide indications on the ergodic (or non-ergodic)
nature of the simulated processes -- which, in turns allows one to gauge the
reliability of a steady-state analysis. Estimates are equipped with statistical
guarantees, allowing for robust comparisons across computational experiments.
To demonstrate the effectiveness of our approach, we apply it to two models
from the literature: a large scale macro-financial ABM and a small scale
prediction market model. Compared to prior analyses of these models, we obtain
new insights and we are able to identify and fix some erroneous conclusions.",2021-02-10
"Policy Augmentation: An Exploration Strategy for Faster Convergence of
  Deep Reinforcement Learning Algorithms",2021-02-10 03:51:45+00:00,http://arxiv.org/abs/2102.05249v1,Arash Mahyari,"cs.LG, cs.AI, cs.CV, cs.RO, cs.SY, eess.SY",dialogue,"Despite advancements in deep reinforcement learning algorithms, developing an
effective exploration strategy is still an open problem. Most existing
exploration strategies either are based on simple heuristics, or require the
model of the environment, or train additional deep neural networks to generate
imagination-augmented paths. In this paper, a revolutionary algorithm, called
Policy Augmentation, is introduced. Policy Augmentation is based on a newly
developed inductive matrix completion method. The proposed algorithm augments
the values of unexplored state-action pairs, helping the agent take actions
that will result in high-value returns while the agent is in the early
episodes. Training deep reinforcement learning algorithms with high-value
rollouts leads to the faster convergence of deep reinforcement learning
algorithms. Our experiments show the superior performance of Policy
Augmentation. The code can be found at:
https://github.com/arashmahyari/PolicyAugmentation.",2021-02-10
Decontextualization: Making Sentences Stand-Alone,2021-02-09 22:52:37+00:00,http://arxiv.org/abs/2102.05169v1,"Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das, Michael Collins","cs.CL, cs.AI",dialogue,"Models for question answering, dialogue agents, and summarization often
interpret the meaning of a sentence in a rich context and use that meaning in a
new context. Taking excerpts of text can be problematic, as key pieces may not
be explicit in a local window. We isolate and define the problem of sentence
decontextualization: taking a sentence together with its context and rewriting
it to be interpretable out of context, while preserving its meaning. We
describe an annotation procedure, collect data on the Wikipedia corpus, and use
the data to train models to automatically decontextualize sentences. We present
preliminary studies that show the value of sentence decontextualization in a
user facing task, and as preprocessing for systems that perform document
understanding. We argue that decontextualization is an important subtask in
many downstream applications, and that the definitions and resources provided
can benefit tasks that operate on sentences that occur in a richer context.",2021-02-09
Scheduling the NASA Deep Space Network with Deep Reinforcement Learning,2021-02-09 22:48:05+00:00,http://arxiv.org/abs/2102.05167v1,"Edwin Goh, Hamsa Shwetha Venkataram, Mark Hoffmann, Mark Johnston, Brian Wilson",cs.LG,dialogue,"With three complexes spread evenly across the Earth, NASA's Deep Space
Network (DSN) is the primary means of communications as well as a significant
scientific instrument for dozens of active missions around the world. A rapidly
rising number of spacecraft and increasingly complex scientific instruments
with higher bandwidth requirements have resulted in demand that exceeds the
network's capacity across its 12 antennae. The existing DSN scheduling process
operates on a rolling weekly basis and is time-consuming; for a given week,
generation of the final baseline schedule of spacecraft tracking passes takes
roughly 5 months from the initial requirements submission deadline, with
several weeks of peer-to-peer negotiations in between. This paper proposes a
deep reinforcement learning (RL) approach to generate candidate DSN schedules
from mission requests and spacecraft ephemeris data with demonstrated
capability to address real-world operational constraints. A deep RL agent is
developed that takes mission requests for a given week as input, and interacts
with a DSN scheduling environment to allocate tracks such that its reward
signal is maximized. A comparison is made between an agent trained using
Proximal Policy Optimization and its random, untrained counterpart. The results
represent a proof-of-concept that, given a well-shaped reward signal, a deep RL
agent can learn the complex heuristics used by experts to schedule the DSN. A
trained agent can potentially be used to generate candidate schedules to
bootstrap the scheduling process and thus reduce the turnaround cycle for DSN
scheduling.",2021-02-09
AuGPT: Dialogue with Pre-trained Language Models and Data Augmentation,2021-02-09 20:53:34+00:00,http://arxiv.org/abs/2102.05126v1,"Jonáš Kulhánek, Vojtěch Hudeček, Tomáš Nekvinda, Ondřej Dušek","cs.CL, cs.AI, cs.LG",dialogue,"Attention-based pre-trained language models such as GPT-2 brought
considerable progress to end-to-end dialogue modelling. However, they also
present considerable risks for task-oriented dialogue, such as lack of
knowledge grounding or diversity. To address these issues, we introduce
modified training objectives for language model finetuning, and we employ
massive data augmentation via back-translation to increase the diversity of the
training data. We further examine the possibilities of combining data from
multiples sources to improve performance on the target dataset. We carefully
evaluate our contributions with both human and automatic methods. Our model
achieves state-of-the-art performance on the MultiWOZ data and shows
competitive performance in human evaluation.",2021-02-09
RL for Latent MDPs: Regret Guarantees and a Lower Bound,2021-02-09 16:49:58+00:00,http://arxiv.org/abs/2102.04939v1,"Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor",cs.LG,dialogue,"In this work, we consider the regret minimization problem for reinforcement
learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is
randomly drawn from a set of $M$ possible MDPs at the beginning of the
interaction, but the identity of the chosen MDP is not revealed to the agent.
We first show that a general instance of LMDPs requires at least
$\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we
consider sufficient assumptions under which learning good policies requires
polynomial number of episodes. We show that the key link is a notion of
separation between the MDP system dynamics. With sufficient separation, we
provide an efficient algorithm with local guarantee, {\it i.e.,} providing a
sublinear regret guarantee when we are given a good initialization. Finally, if
we are given standard statistical sufficiency assumptions common in the
Predictive State Representation (PSR) literature (e.g., Boots et al.) and a
reachability assumption, we show that the need for initialization can be
removed.",2021-02-09
"Learning State Representations from Random Deep Action-conditional
  Predictions",2021-02-09 15:53:22+00:00,http://arxiv.org/abs/2102.04897v1,"Zeyu Zheng, Vivek Veeriah, Risto Vuorio, Richard Lewis, Satinder Singh","cs.LG, cs.AI",dialogue,"In this work, we study auxiliary prediction tasks defined by
temporal-difference networks (TD networks); these networks are a language for
expressing a rich space of general value function (GVF) prediction targets that
may be learned efficiently with TD. Through analysis in an illustrative domain
we show the benefits to learning state representations of exploiting the full
richness of TD networks, including both action-conditional predictions and
temporally deep predictions. Our main (and perhaps surprising) result is that
deep action-conditional TD networks with random structures that create random
prediction-questions about random features yield state representations that are
competitive with state-of-the-art hand-crafted value prediction and pixel
control auxiliary tasks in both Atari games and DeepMind Lab tasks. We also
show through stop-gradient experiments that learning the state representations
solely via these unsupervised random TD network prediction tasks yield agents
that outperform the end-to-end-trained actor-critic baseline.",2021-02-09
Persistent Rule-based Interactive Reinforcement Learning,2021-02-04 06:48:57+00:00,http://arxiv.org/abs/2102.02441v1,"Adam Bignold, Francisco Cruz, Richard Dazeley, Peter Vamplew, Cameron Foale","cs.AI, cs.MA",dialogue,"Interactive reinforcement learning has allowed speeding up the learning
process in autonomous agents by including a human trainer providing extra
information to the agent in real-time. Current interactive reinforcement
learning research has been limited to interactions that offer relevant advice
to the current state only. Additionally, the information provided by each
interaction is not retained and instead discarded by the agent after a
single-use. In this work, we propose a persistent rule-based interactive
reinforcement learning approach, i.e., a method for retaining and reusing
provided knowledge, allowing trainers to give general advice relevant to more
than just the current state. Our experimental results show persistent advice
substantially improves the performance of the agent while reducing the number
of interactions required for the trainer. Moreover, rule-based advice shows
similar performance impact as state-based advice, but with a substantially
reduced interaction count.",2021-02-04
"Converse, Focus and Guess -- Towards Multi-Document Driven Dialogue",2021-02-04 06:36:11+00:00,http://arxiv.org/abs/2102.02435v1,"Han Liu, Caixia Yuan, Xiaojie Wang, Yushu Yang, Huixing Jiang, Zhongyuan Wang",cs.CL,dialogue,"We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an
agent can guess the target document that the user is interested in by leading a
dialogue. To benchmark progress, we introduce a new dataset of GuessMovie,
which contains 16,881 documents, each describing a movie, and associated 13,434
dialogues. Further, we propose the MD3 model. Keeping guessing the target
document in mind, it converses with the user conditioned on both document
engagement and user feedback. In order to incorporate large-scale external
documents into the dialogue, it pretrains a document representation which is
sensitive to attributes it talks about an object. Then it tracks dialogue state
by detecting evolvement of document belief and attribute belief, and finally
optimizes dialogue policy in principle of entropy decreasing and reward
increasing, which is expected to successfully guess the user's target in a
minimum number of turns. Experiments show that our method significantly
outperforms several strong baseline methods and is very close to human's
performance.",2021-02-04
Neural Recursive Belief States in Multi-Agent Reinforcement Learning,2021-02-03 20:10:23+00:00,http://arxiv.org/abs/2102.02274v1,"Pol Moreno, Edward Hughes, Kevin R. McKee, Bernardo Avila Pires, Théophane Weber","cs.LG, cs.AI, cs.MA",dialogue,"In multi-agent reinforcement learning, the problem of learning to act is
particularly difficult because the policies of co-players may be heavily
conditioned on information only observed by them. On the other hand, humans
readily form beliefs about the knowledge possessed by their peers and leverage
beliefs to inform decision-making. Such abilities underlie individual success
in a wide range of Markov games, from bluffing in Poker to conditional
cooperation in the Prisoner's Dilemma, to convention-building in Bridge.
Classical methods are usually not applicable to complex domains due to the
intractable nature of hierarchical beliefs (i.e. beliefs of other agents'
beliefs). We propose a scalable method to approximate these belief structures
using recursive deep generative models, and to use the belief models to obtain
representations useful to acting in complex tasks. Our agents trained with
belief models outperform model-free baselines with equivalent representational
capacity using common training paradigms. We also show that higher-order belief
models outperform agents with lower-order models.",2021-02-03
"DiSCoL: Toward Engaging Dialogue Systems through Conversational Line
  Guided Response Generation",2021-02-03 18:36:58+00:00,http://arxiv.org/abs/2102.02191v1,"Sarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, Nanyun Peng",cs.CL,dialogue,"Having engaging and informative conversations with users is the utmost goal
for open-domain conversational systems. Recent advances in transformer-based
language models and their applications to dialogue systems have succeeded to
generate fluent and human-like responses. However, they still lack control over
the generation process towards producing contentful responses and achieving
engaging conversations. To achieve this goal, we present \textbf{DiSCoL}
(\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational
\textbf{L}ine guided response generation). DiSCoL is an open-domain dialogue
system that leverages conversational lines (briefly \textbf{convlines}) as
controllable and informative content-planning elements to guide the generation
model produce engaging and informative responses. Two primary modules in
DiSCoL's pipeline are conditional generators trained for 1) predicting relevant
and informative convlines for dialogue contexts and 2) generating high-quality
responses conditioned on the predicted convlines. Users can also change the
returned convlines to \textit{control} the direction of the conversations
towards topics that are more interesting for them. Through automatic and human
evaluations, we demonstrate the efficiency of the convlines in producing
engaging conversations.",2021-02-03
"Learning a Compact State Representation for Navigation Tasks by
  Autoencoding 2D-Lidar Scans",2021-02-03 16:10:26+00:00,http://arxiv.org/abs/2102.02127v1,"Christopher Gebauer, Maren Bennewitz","cs.RO, cs.LG",dialogue,"In this paper, we address the problem of generating a compact representation
of 2D-lidar scans for reinforcement learning in navigation tasks. By now only
little work focuses on the compactness of the provided state, which is a
necessary condition to successfully and efficiently train a navigation agent.
Our approach works in three stages. First, we propose a novel preprocessing of
the distance measurements and compute a local, egocentric, binary grid map
based on the current range measurements. We then autoencode the local map using
a variational autoencoder, where the latent space serves as state
representation. An important key for a compact and, at the same time,
meaningful representation is the degree of disentanglement, which describes the
correlation between each latent dimension. Therefore, we finally apply
state-of-the-art disentangling methods to improve the representation power.
Furthermore, we investige the possibilities of incorporating time-dependent
information into the latent space. In particular, we incorporate the relation
of consecutive scans, especially ego-motion, by applying a memory model. We
implemented our approach in python using tensorflow. Our datasets are simulated
with pybullet as well as recorded using a slamtec rplidar A3. The experiments
show the capability of our approach to highly compress lidar data, maintain a
meaningful distribution of the latent space, and even incorporate time-depended
information.",2021-02-03
Learning to Select External Knowledge with Multi-Scale Negative Sampling,2021-02-03 14:59:35+00:00,http://arxiv.org/abs/2102.02096v1,"Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zhengyu Niu, Haifeng Wang",cs.CL,dialogue,"The Track-1 of DSTC9 aims to effectively answer user requests or questions
during task-oriented dialogues, which are out of the scope of APIs/DB. By
leveraging external knowledge resources, relevant information can be retrieved
and encoded into the response generation for these out-of-API-coverage queries.
In this work, we have explored several advanced techniques to enhance the
utilization of external knowledge and boost the quality of response generation,
including schema guided knowledge decision, negatives enhanced knowledge
selection, and knowledge grounded response generation. To evaluate the
performance of our proposed method, comprehensive experiments have been carried
out on the publicly available dataset. Our approach was ranked as the best in
human evaluation of DSTC9 Track-1.",2021-02-03
Advances and Challenges in Conversational Recommender Systems: A Survey,2021-01-23 08:53:15+00:00,http://arxiv.org/abs/2101.09459v4,"Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, Tat-Seng Chua","cs.IR, cs.CL",dialogue,"Recommender systems exploit interaction history to estimate user preference,
having been heavily used in a wide range of industry applications. However,
static recommendation models are difficult to answer two important questions
well due to inherent shortcomings: (a) What exactly does a user like? (b) Why
does a user like an item? The shortcomings are due to the way that static
models learn user preference, i.e., without explicit instructions and active
feedback from users. The recent rise of conversational recommender systems
(CRSs) changes this situation fundamentally. In a CRS, users and the system can
dynamically communicate through natural language interactions, which provide
unprecedented opportunities to explicitly obtain the exact preference of users.
Considerable efforts, spread across disparate settings and applications, have
been put into developing CRSs. Existing models, technologies, and evaluation
methods for CRSs are far from mature. In this paper, we provide a systematic
review of the techniques used in current CRSs. We summarize the key challenges
of developing CRSs into five directions: (1) Question-based user preference
elicitation. (2) Multi-turn conversational recommendation strategies. (3)
Dialogue understanding and generation. (4) Exploitation-exploration trade-offs.
(5) Evaluation and user simulation. These research directions involve multiple
research fields like information retrieval (IR), natural language processing
(NLP), and human-computer interaction (HCI). Based on these research
directions, we discuss some future challenges and opportunities. We provide a
road map for researchers from multiple communities to get started in this area.
We hope this survey helps to identify and address challenges in CRSs and
inspire future research.",2021-01-23
"Beyond Domain APIs: Task-oriented Conversational Modeling with
  Unstructured Knowledge Access Track in DSTC9",2021-01-22 18:57:56+00:00,http://arxiv.org/abs/2101.09276v3,"Seokhwan Kim, Mihail Eric, Behnam Hedayatnia, Karthik Gopalakrishnan, Yang Liu, Chao-Wei Huang, Dilek Hakkani-Tur",cs.CL,dialogue,"Most prior work on task-oriented dialogue systems are restricted to a limited
coverage of domain APIs, while users oftentimes have domain related requests
that are not covered by the APIs. This challenge track aims to expand the
coverage of task-oriented dialogue systems by incorporating external
unstructured knowledge sources. We define three tasks: knowledge-seeking turn
detection, knowledge selection, and knowledge-grounded response generation. We
introduce the data sets and the neural baseline models for three tasks. The
challenge track received a total of 105 entries from 24 participating teams. In
the evaluation results, the ensemble methods with different large-scale
pretrained language models achieved high performances with improved knowledge
selection capability and better generalization into unseen data.",2021-01-22
"Rank the Episodes: A Simple Approach for Exploration in
  Procedurally-Generated Environments",2021-01-20 14:22:01+00:00,http://arxiv.org/abs/2101.08152v2,"Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu",cs.LG,dialogue,"Exploration under sparse reward is a long-standing challenge of model-free
reinforcement learning. The state-of-the-art methods address this challenge by
introducing intrinsic rewards to encourage exploration in novel states or
uncertain environment dynamics. Unfortunately, methods based on intrinsic
rewards often fall short in procedurally-generated environments, where a
different environment is generated in each episode so that the agent is not
likely to visit the same state more than once. Motivated by how humans
distinguish good exploration behaviors by looking into the entire episode, we
introduce RAPID, a simple yet effective episode-level exploration method for
procedurally-generated environments. RAPID regards each episode as a whole and
gives an episodic exploration score from both per-episode and long-term views.
Those highly scored episodes are treated as good exploration behaviors and are
stored in a small ranking buffer. The agent then imitates the episodes in the
buffer to reproduce the past good exploration behaviors. We demonstrate our
method on several procedurally-generated MiniGrid environments, a
first-person-view 3D Maze navigation task from MiniWorld, and several sparse
MuJoCo tasks. The results show that RAPID significantly outperforms the
state-of-the-art intrinsic reward strategies in terms of sample efficiency and
final performance. The code is available at https://github.com/daochenzha/rapid",2021-01-20
Transforming Multi-Conditioned Generation from Meaning Representation,2021-01-12 01:45:06+00:00,http://arxiv.org/abs/2101.04257v1,Joosung Lee,"cs.CL, cs.AI",dialogue,"In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.",2021-01-12
Continual Learning in Task-Oriented Dialogue Systems,2020-12-31 08:44:25+00:00,http://arxiv.org/abs/2012.15504v1,"Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang","cs.CL, cs.AI",dialogue,"Continual learning in task-oriented dialogue systems can allow us to add new
domains and functionalities through time without incurring the high cost of a
whole system retraining. In this paper, we propose a continual learning
benchmark for task-oriented dialogue systems with 37 domains to be learned
continuously in four settings, such as intent recognition, state tracking,
natural language generation, and end-to-end. Moreover, we implement and compare
multiple existing continual learning baselines, and we propose a simple yet
effective architectural method based on residual adapters. Our experiments
demonstrate that the proposed architectural method and a simple replay-based
strategy perform comparably well but they both achieve inferior performance to
the multi-task learning baseline, in where all the data are shown at once,
showing that continual learning in task-oriented dialogue systems is a
challenging task. Furthermore, we reveal several trade-offs between different
continual learning methods in term of parameter usage and memory size, which
are important in the design of a task-oriented dialogue system. The proposed
benchmark is released together with several baselines to promote more research
in this direction.",2020-12-31
"Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous
  Rendering Machines",2020-12-29 07:41:48+00:00,http://arxiv.org/abs/2012.14645v1,"Yangming Li, Kaisheng Yao",cs.CL,dialogue,"End-to-end neural networks have achieved promising performances in natural
language generation (NLG). However, they are treated as black boxes and lack
interpretability. To address this problem, we propose a novel framework,
heterogeneous rendering machines (HRM), that interprets how neural generators
render an input dialogue act (DA) into an utterance. HRM consists of a renderer
set and a mode switcher. The renderer set contains multiple decoders that vary
in both structure and functionality. For every generation step, the mode
switcher selects an appropriate decoder from the renderer set to generate an
item (a word or a phrase). To verify the effectiveness of our method, we have
conducted extensive experiments on 5 benchmark datasets. In terms of automatic
metrics (e.g., BLEU), our model is competitive with the current
state-of-the-art method. The qualitative analysis shows that our model can
interpret the rendering process of neural generators well. Human evaluation
also confirms the interpretability of our proposed approach.",2020-12-29
