title,pubdate,id,authors,categories,search,abstract,displaydate
"ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability
  Memory",2025-10-08 05:32:31+00:00,http://arxiv.org/abs/2510.06664v1,"Yunzhong Xiao, Yangmin Li, Hewei Wang, Yunlong Tang, Zora Zhiruo Wang",cs.CL,dialogue,"Agents utilizing tools powered by large language models (LLMs) or
vision-language models (VLMs) have demonstrated remarkable progress in diverse
tasks across text and visual modalities. Unlike traditional tools such as
calculators, which give deterministic outputs, neural tools perform uncertainly
across task scenarios. While different tools for a task may excel in varied
scenarios, existing agents typically rely on fixed tools, thus limiting the
flexibility in selecting the most suitable tool for specific tasks. In
contrast, humans snowball their understanding of the capabilities of different
tools by interacting with them, and apply this knowledge to select the optimal
tool when solving a future task. To build agents that similarly benefit from
this process, we propose ToolMem that enables agents to develop memories of
tool capabilities from previous interactions, by summarizing their strengths
and weaknesses and storing them in memory; at inference, the agent can retrieve
relevant entries from ToolMem, and select the best tool to solve individual
tasks more accurately. We evaluate ToolMem on learning varied text generation
and text-to-image generation neural tools. Compared to no-memory, generic
agents, we find ToolMem-augmented agents predict tool performance 14.8% and
28.7% more accurately across text and multimodal generation scenarios.
Moreover, ToolMem facilitates optimal tool selection among multiple choices by
21% and 24% absolute increases in respective scenarios.",2025-10-08
"What Do Humans Hear When Interacting? Experiments on Selective Listening
  for Evaluating ASR of Spoken Dialogue Systems",2025-08-06 12:44:57+00:00,http://arxiv.org/abs/2508.04402v2,"Kiyotada Mori, Seiya Kawano, Chaoran Liu, Carlos Toshinori Ishi, Angel Fernando Garcia Contreras, Koichiro Yoshino",cs.CL,dialogue,"Spoken dialogue systems (SDSs) utilize automatic speech recognition (ASR) at
the front end of their pipeline. The role of ASR in SDSs is to recognize
information in user speech related to response generation appropriately.
Examining selective listening of humans, which refers to the ability to focus
on and listen to important parts of a conversation during the speech, will
enable us to identify the ASR capabilities required for SDSs and evaluate them.
In this study, we experimentally confirmed selective listening when humans
generate dialogue responses by comparing human transcriptions for generating
dialogue responses and reference transcriptions. Based on our experimental
results, we discuss the possibility of a new ASR evaluation method that
leverages human selective listening, which can identify the gap between
transcription ability between ASR systems and humans.",2025-08-06
Investigating Hallucination in Conversations for Low Resource Languages,2025-07-30 14:39:51+00:00,http://arxiv.org/abs/2507.22720v1,"Amit Das, Md. Najib Hasan, Souvika Sarkar, Zheng Zhang, Fatemeh Jamshidi, Tathagata Bhattacharya, Nilanjana Raychawdhury, Dongji Feng, Vinija Jain, Aman Chadha",cs.CL,dialogue,"Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating text that closely resemble human writing. However, they often
generate factually incorrect statements, a problem typically referred to as
'hallucination'. Addressing hallucination is crucial for enhancing the
reliability and effectiveness of LLMs. While much research has focused on
hallucinations in English, our study extends this investigation to
conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a
comprehensive analysis of a dataset to examine both factual and linguistic
errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0,
DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated
responses in Mandarin but generate a significantly higher number of
hallucinations in Hindi and Farsi.",2025-07-30
Teaching Language Models To Gather Information Proactively,2025-07-28 23:50:09+00:00,http://arxiv.org/abs/2507.21389v1,"Tenghao Huang, Sihao Chen, Muhao Chen, Jonathan May, Longqi Yang, Mengting Wan, Pei Zhou","cs.AI, cs.CL",dialogue,"Large language models (LLMs) are increasingly expected to function as
collaborative partners, engaging in back-and-forth dialogue to solve complex,
ambiguous problems. However, current LLMs often falter in real-world settings,
defaulting to passive responses or narrow clarifications when faced with
incomplete or under-specified prompts, falling short of proactively gathering
the missing information that is crucial for high-quality solutions. In this
work, we introduce a new task paradigm: proactive information gathering, where
LLMs must identify gaps in the provided context and strategically elicit
implicit user knowledge through targeted questions. To systematically study and
train this capability, we design a scalable framework that generates partially
specified, real-world tasks, masking key information and simulating authentic
ambiguity. Within this setup, our core innovation is a reinforcement finetuning
strategy that rewards questions that elicit genuinely new, implicit user
information -- such as hidden domain expertise or fine-grained requirements --
that would otherwise remain unspoken. Experiments demonstrate that our trained
Qwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic
evaluation metrics. More importantly, human evaluation reveals that
clarification questions and final outlines generated by our model are favored
by human annotators by 42% and 28% respectively. Together, these results
highlight the value of proactive clarification in elevating LLMs from passive
text generators to genuinely collaborative thought partners.",2025-07-28
"AI-Driven Generation of Old English: A Framework for Low-Resource
  Languages",2025-07-27 03:29:19+00:00,http://arxiv.org/abs/2507.20111v1,"Rodrigo Gabriel Salazar Alva, Matías Nuñez, Cristian López, Javier Martín Arista","cs.CL, cs.AI",dialogue,"Preserving ancient languages is essential for understanding humanity's
cultural and linguistic heritage, yet Old English remains critically
under-resourced, limiting its accessibility to modern natural language
processing (NLP) techniques. We present a scalable framework that uses advanced
large language models (LLMs) to generate high-quality Old English texts,
addressing this gap. Our approach combines parameter-efficient fine-tuning
(Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a
dual-agent pipeline that separates the tasks of content generation (in English)
and translation (into Old English). Evaluation with automated metrics (BLEU,
METEOR, and CHRF) shows significant improvements over baseline models, with
BLEU scores increasing from 26 to over 65 for English-to-Old English
translation. Expert human assessment also confirms high grammatical accuracy
and stylistic fidelity in the generated texts. Beyond expanding the Old English
corpus, our method offers a practical blueprint for revitalizing other
endangered languages, effectively uniting AI innovation with the goals of
cultural preservation.",2025-07-27
"CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning
  with Implicit Rule-Based Rewards",2025-07-23 02:26:33+00:00,http://arxiv.org/abs/2507.17147v1,"Cheng Liu, Yifei Lu, Fanghua Ye, Jian Li, Xingyu Chen, Feiliang Ren, Zhaopeng Tu, Xiaolong Li",cs.CL,dialogue,"Role-Playing Language Agents (RPLAs) have emerged as a significant
application direction for Large Language Models (LLMs). Existing approaches
typically rely on prompt engineering or supervised fine-tuning to enable models
to imitate character behaviors in specific scenarios, but often neglect the
underlying \emph{cognitive} mechanisms driving these behaviors. Inspired by
cognitive psychology, we introduce \textbf{CogDual}, a novel RPLA adopting a
\textit{cognize-then-respond } reasoning paradigm. By jointly modeling external
situational awareness and internal self-awareness, CogDual generates responses
with improved character consistency and contextual alignment. To further
optimize the performance, we employ reinforcement learning with two
general-purpose reward schemes designed for open-domain text generation.
Extensive experiments on the CoSER benchmark, as well as Cross-MR and
LifeChoice, demonstrate that CogDual consistently outperforms existing
baselines and generalizes effectively across diverse role-playing tasks.",2025-07-23
On the Semantics of Large Language Models,2025-07-07 20:02:57+00:00,http://arxiv.org/abs/2507.05448v1,Martin Schuele,"cs.CL, cs.AI",dialogue,"Large Language Models (LLMs) such as ChatGPT demonstrated the potential to
replicate human language abilities through technology, ranging from text
generation to engaging in conversations. However, it remains controversial to
what extent these systems truly understand language. We examine this issue by
narrowing the question down to the semantics of LLMs at the word and sentence
level. By examining the inner workings of LLMs and their generated
representation of language and by drawing on classical semantic theories by
Frege and Russell, we get a more nuanced picture of the potential semantic
capabilities of LLMs.",2025-07-07
"SHNU Multilingual Conversational Speech Recognition System for
  INTERSPEECH 2025 MLC-SLM Challenge",2025-07-04 07:10:33+00:00,http://arxiv.org/abs/2507.03343v2,"Yuxiang Mei, Yuang Zheng, Dongxing Xu, Yanhua Long","cs.CL, eess.AS",dialogue,"This paper describes SHNU multilingual conversational speech recognition
system (SHNU-mASR, team name-""maybe""), submitted to Track 1 of the INTERSPEECH
2025 MLC-SLM Challenge. Our system integrates a parallel-speech-encoder
architecture with a large language model (LLM) to form a unified multilingual
ASR framework. The parallel-speech-encoder consists of two pre-trained
encoders, the Whisper-large-v3 encoder and mHuBERT-147 encoder. Their output
embeddings are concatenated and fed into the LLM, enabling the model to
leverage complementary acoustic and linguistic knowledge and achieve
competitive performance. Moreover, we adopt a tri-stage training strategy to
jointly update the low-rank adaptation modules and projector parameters of both
the speech encoders and the LLM. In addition, we incorporate an additional
language-aware prompt at the LLM input to enhance language-specific text
generation. The SHNU-mASR system achieves an overall character/word error rate
(CER/WER) of 11.76% on the blind evaluation set of the challenge, outperforming
the official MLC-SLM baseline by 8.41 absolute CER/WER, without increasing the
baseline training data.",2025-07-04
"The Future is Agentic: Definitions, Perspectives, and Open Challenges of
  Multi-Agent Recommender Systems",2025-07-02 19:25:44+00:00,http://arxiv.org/abs/2507.02097v2,"Reza Yousefi Maragheh, Yashar Deldjoo",cs.IR,dialogue,"Large language models (LLMs) are rapidly evolving from passive engines of
text generation into agentic entities that can plan, remember, invoke external
tools, and co-operate with one another. This perspective paper investigates how
such LLM agents (and societies thereof) can transform the design space of
recommender systems.
  We introduce a unified formalism that (i) models an individual agent as a
tuple comprising its language core, tool set, and hierarchical memory, and (ii)
captures a multi-agent recommender as a triple of agents, shared environment,
and communication protocol. Within this framework, we present four end-to-end
use cases-interactive party planning, synthetic user-simulation for offline
evaluation, multi-modal furniture recommendation, and brand-aligned explanation
generation-each illustrating a distinct capability unlocked by agentic
orchestration.
  We then surface five cross-cutting challenge families: protocol complexity,
scalability, hallucination and error propagation, emergent misalignment
(including covert collusion), and brand compliance.
  For each, we formalize the problem, review nascent mitigation strategies, and
outline open research questions. The result is both a blueprint and an agenda:
a blueprint that shows how memory-augmented, tool-using LLM agents can be
composed into robust recommendation pipelines, and an agenda inviting the
RecSys community to develop benchmarks, theoretical guarantees, and governance
tools that keep pace with this new degree of autonomy. By unifying agentic
abstractions with recommender objectives, the paper lays the groundwork for the
next generation of personalized, trustworthy, and context-rich recommendation
services.",2025-07-02
Decision-Oriented Text Evaluation,2025-07-02 17:32:35+00:00,http://arxiv.org/abs/2507.01923v2,"Yu-Shiang Huang, Chuan-Ju Wang, Chung-Chi Chen",cs.CL,dialogue,"Natural language generation (NLG) is increasingly deployed in high-stakes
domains, yet common intrinsic evaluation methods, such as n-gram overlap or
sentence plausibility, weakly correlate with actual decision-making efficacy.
We propose a decision-oriented framework for evaluating generated text by
directly measuring its influence on human and large language model (LLM)
decision outcomes. Using market digest texts--including objective morning
summaries and subjective closing-bell analyses--as test cases, we assess
decision quality based on the financial performance of trades executed by human
investors and autonomous LLM agents informed exclusively by these texts. Our
findings reveal that neither humans nor LLM agents consistently surpass random
performance when relying solely on summaries. However, richer analytical
commentaries enable collaborative human-LLM teams to outperform individual
human or agent baselines significantly. Our approach underscores the importance
of evaluating generated text by its ability to facilitate synergistic
decision-making between humans and LLMs, highlighting critical limitations of
traditional intrinsic metrics.",2025-07-02
Confidence and Stability of Global and Pairwise Scores in NLP Evaluation,2025-07-02 12:05:22+00:00,http://arxiv.org/abs/2507.01633v1,"Georgii Levtsov, Dmitry Ustalov","cs.CL, cs.IR, 62-04, D.2.3",dialogue,"With the advent of highly capable instruction-tuned neural language models,
benchmarking in natural language processing (NLP) is increasingly shifting
towards pairwise comparison leaderboards, such as LMSYS Arena, from traditional
global pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper
empirically investigates the strengths and weaknesses of both global scores and
pairwise comparisons to aid decision-making in selecting appropriate model
evaluation strategies. Through computational experiments on synthetic and
real-world datasets using standard global metrics and the popular Bradley-Terry
model for pairwise comparisons, we found that while global scores provide more
reliable overall rankings, they can underestimate strong models with rare,
significant errors or low confidence. Conversely, pairwise comparisons are
particularly effective for identifying strong contenders among models with
lower global scores, especially where quality metrics are hard to define (e.g.,
text generation), though they require more comparisons to converge if ties are
frequent. Our code and data are available at
https://github.com/HSPyroblast/srw-ranking under a permissive license.",2025-07-02
Efficient Interleaved Speech Modeling through Knowledge Distillation,2025-06-30 09:47:37+00:00,http://arxiv.org/abs/2506.23670v1,"Mohammadmahdi Nouriborji, Morteza Rohanian","cs.SD, cs.CL, eess.AS",dialogue,"Current speech language models exceed the size and latency constraints of
many deployment environments. We build compact, expressive speech generation
models through layer-aligned distillation, matching hidden states, attention
maps, and softened logits to compress large multimodal transformers by 3x with
minimal loss in performance. We introduce TinyWave, a family of 2B-parameter
models for speech-to-speech and interleaved speech-text generation, trained on
50,000 hours of public audio. TinyWave supports (i) speech-only generation
using phonetic or expressive tokens and (ii) mixed speech-text continuations.
Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity
points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%
of the teacher's performance, outperforming size-matched baselines. These
models are optimized for deployment on commodity hardware, enabling
applications in real-time conversational agents, assistive technologies, and
low-resource environments. We release models, training code, and evaluation
scripts to support reproducible research on compact, expressive speech
generation.",2025-06-30
ATGen: A Framework for Active Text Generation,2025-06-29 17:27:48+00:00,http://arxiv.org/abs/2506.23342v1,"Akim Tsvigun, Daniil Vasilev, Ivan Tsvigun, Ivan Lysenko, Talgat Bektleuov, Aleksandr Medvedev, Uliana Vinogradova, Nikita Severin, Mikhail Mozikov, Andrey Savchenko, Rostislav Grigorev, Ramil Kuleev, Fedor Zhdanov, Artem Shelmanov, Ilya Makarov","cs.CL, cs.AI",dialogue,"Active learning (AL) has demonstrated remarkable potential in reducing the
annotation effort required for training machine learning models. However,
despite the surging popularity of natural language generation (NLG) tasks in
recent years, the application of AL to NLG has been limited. In this paper, we
introduce Active Text Generation (ATGen) - a comprehensive framework that
bridges AL with text generation tasks, enabling the application of
state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered
annotation in NLG tasks using both human annotators and automatic annotation
agents based on large language models (LLMs). The framework supports LLMs
deployed as services, such as ChatGPT and Claude, or operated on-premises.
Furthermore, ATGen provides a unified platform for smooth implementation and
benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present
evaluation results for state-of-the-art AL strategies across diverse settings
and multiple text generation tasks. We show that ATGen reduces both the effort
of human annotators and costs associated with API calls to LLM-based annotation
agents. The code of the framework is available on GitHub under the MIT license.
The video presentation is available at http://atgen-video.nlpresearch.group",2025-06-29
"Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator
  Roles Assessed by Motivational Interviewing Criteria",2025-06-28 21:50:29+00:00,http://arxiv.org/abs/2507.02950v2,"Keita Kiuchi, Yoshikazu Fujimoto, Hideyuki Goto, Tomonori Hosokawa, Makoto Nishimura, Yosuke Sato, Izumi Sezai","cs.CL, cs.AI, cs.HC, 68T50, I.2.7; H.5.2; J.4",dialogue,"This study provides the first comprehensive evaluation of large language
model (LLM) performance across three counseling roles in Japanese-language
therapeutic contexts. We simultaneously assessed counselor artificial
intelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured
Multi-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations,
and evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human
experts (n = 15) with extensive counseling experience evaluated AI-generated
dialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding
Manual 4.2.1.
  Notably, SMDP implementation significantly enhanced counselor AI performance
across all MITI global ratings compared with zeroshot prompting, with no
significant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed
comparable performance to human raters for Cultivating Change Talk but
systematically overestimated Softening Sustain Talk and the overall quality
metrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3
focused on technical proficiency, and Sonnet prioritized emotional expression.
Client AI simulations exhibited a limited emotional range and unnaturally high
compliance, indicating the need for enhanced realism.
  These findings establish benchmarks for AI-assisted counseling in non-English
contexts and identify critical areas for improvement through advanced prompt
engineering, retrieval-augmented generation, and targeted fine-tuning, with
important implications for developing culturally sensitive AI mental health
tools.",2025-06-28
"Assessing the feasibility of Large Language Models for detecting
  micro-behaviors in team interactions during space missions",2025-06-27 23:06:24+00:00,http://arxiv.org/abs/2506.22679v1,"Ankush Raut, Projna Paromita, Sydney Begerowski, Suzanne Bell, Theodora Chaspari",cs.CL,dialogue,"We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.",2025-06-27
"DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive
  Modality-Specific MoE",2025-06-27 02:32:04+00:00,http://arxiv.org/abs/2506.21864v2,"Hang Shao, Heting Gao, Yunhang Shen, Jiawei Chen, Lijiang Li, Zuwei Long, Bo Tong, Ke Li, Xing Sun","cs.CL, cs.AI",dialogue,"Native multimodal large language models (MLLMs) restructure a single large
language model (LLM) into a spoken language model (SLM) capable of both speech
and text generation. Compared to modular and aligned MLLMs, native MLLMs
preserve richer paralinguistic features such as emotion and prosody, and
generate speech responses directly within the backbone LLM rather than using a
separate speech decoder. This integration also results in lower response
latency and smoother interaction. However, native MLLMs suffer from
catastrophic forgetting and performance degradation because the available
paired speech-text data is insufficient to support the pretraining of MLLMs
compared to the vast amount of text data required to pretrain text LLMs. To
address this issue, we propose DeepTalk, a framework for adaptive modality
expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk
first adaptively distinguishes modality experts according to their modality
load within the LLM. Each modality expert then undergoes specialized
single-modality training, followed by joint multimodal collaborative training.
As a result, DeepTalk incurs only a 5.5% performance drop compared to the
original LLM, which is significantly lower than the average performance drop of
over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par
with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within
0.5 seconds, ensuring a seamless and intelligent speech interaction experience.
Code and models are released at https://github.com/talkking/DeepTalk.",2025-06-27
"Commonsense Generation and Evaluation for Dialogue Systems using Large
  Language Models",2025-06-24 10:18:05+00:00,http://arxiv.org/abs/2506.19483v1,"Marcos Estecha-Garitagoitia, Chen Zhang, Mario Rodríguez-Cantelar, Luis Fernando D'Haro",cs.CL,dialogue,"This paper provides preliminary results on exploring the task of performing
turn-level data augmentation for dialogue system based on different types of
commonsense relationships, and the automatic evaluation of the generated
synthetic turns. The proposed methodology takes advantage of the extended
knowledge and zero-shot capabilities of pretrained Large Language Models (LLMs)
to follow instructions, understand contextual information, and their
commonsense reasoning capabilities. The approach draws inspiration from
methodologies like Chain-of-Thought (CoT), applied more explicitly to the task
of prompt-based generation for dialogue-based data augmentation conditioned on
commonsense attributes, and the automatic evaluation of the generated
dialogues.
  To assess the effectiveness of the proposed approach, first we extracted 200
randomly selected partial dialogues, from 5 different well-known dialogue
datasets, and generate alternative responses conditioned on different event
commonsense attributes. This novel dataset allows us to measure the proficiency
of LLMs in generating contextually relevant commonsense knowledge, particularly
up to 12 different specific ATOMIC [10] database relations. Secondly, we
propose an evaluation framework to automatically detect the quality of the
generated dataset inspired by the ACCENT [26] metric, which offers a nuanced
approach to assess event commonsense. However, our method does not follow
ACCENT's complex eventrelation tuple extraction process. Instead, we propose an
instruction-based prompt for each commonsense attribute and use
state-of-the-art LLMs to automatically detect the original attributes used when
creating each augmented turn in the previous step.
  Preliminary results suggest that our approach effectively harnesses LLMs
capabilities for commonsense reasoning and evaluation in dialogue systems.",2025-06-24
"How Large Language Models play humans in online conversations: a
  simulated study of the 2016 US politics on Reddit",2025-06-23 08:54:32+00:00,http://arxiv.org/abs/2506.21620v1,"Daniele Cirulli, Giulio Cimini, Giovanni Palermo","cs.CL, cs.AI, cs.CY, cs.SI, physics.soc-ph",dialogue,"Large Language Models (LLMs) have recently emerged as powerful tools for
natural language generation, with applications spanning from content creation
to social simulations. Their ability to mimic human interactions raises both
opportunities and concerns, particularly in the context of politically relevant
online discussions. In this study, we evaluate the performance of LLMs in
replicating user-generated content within a real-world, divisive scenario:
Reddit conversations during the 2016 US Presidential election. In particular,
we conduct three different experiments, asking GPT-4 to generate comments by
impersonating either real or artificial partisan users. We analyze the
generated comments in terms of political alignment, sentiment, and linguistic
features, comparing them against real user contributions and benchmarking
against a null model. We find that GPT-4 is able to produce realistic comments,
both in favor of or against the candidate supported by the community, yet
tending to create consensus more easily than dissent. In addition we show that
real and artificial comments are well separated in a semantically embedded
space, although they are indistinguishable by manual inspection. Our findings
provide insights on the potential use of LLMs to sneak into online discussions,
influence political debate and shape political narratives, bearing broader
implications of AI-driven discourse manipulation.",2025-06-23
GenerationPrograms: Fine-grained Attribution with Executable Programs,2025-06-17 14:37:09+00:00,http://arxiv.org/abs/2506.14580v1,"David Wan, Eran Hirsch, Elias Stengel-Eskin, Ido Dagan, Mohit Bansal","cs.CL, cs.AI",dialogue,"Recent large language models (LLMs) achieve impressive performance in
source-conditioned text generation but often fail to correctly provide
fine-grained attributions for their outputs, undermining verifiability and
trust. Moreover, existing attribution methods do not explain how and why models
leverage the provided source documents to generate their final responses,
limiting interpretability. To overcome these challenges, we introduce a modular
generation framework, GenerationPrograms, inspired by recent advancements in
executable ""code agent"" architectures. Unlike conventional generation methods
that simultaneously generate outputs and attributions or rely on post-hoc
attribution, GenerationPrograms decomposes the process into two distinct
stages: first, creating an executable program plan composed of modular text
operations (such as paraphrasing, compression, and fusion) explicitly tailored
to the query, and second, executing these operations following the program's
specified instructions to produce the final response. Empirical evaluations
demonstrate that GenerationPrograms significantly improves attribution quality
at both the document level and sentence level across two long-form
question-answering tasks and a multi-document summarization task. We further
demonstrate that GenerationPrograms can effectively function as a post-hoc
attribution method, outperforming traditional techniques in recovering accurate
attributions. In addition, the interpretable programs generated by
GenerationPrograms enable localized refinement through modular-level
improvements that further enhance overall attribution quality.",2025-06-17
Discovering Coordinated Processes From Social Online Networks,2025-06-15 23:09:43+00:00,http://arxiv.org/abs/2506.12988v1,"Anna Kalenkova, Lewis Mitchell, Ethan Johnson",cs.SI,dialogue,"The rapid growth of social media presents a unique opportunity to study
coordinated agent behavior in an unfiltered environment. Online processes often
exhibit complex structures that reflect the nature of the user behavior,
whether it is authentic and genuine, or part of a coordinated effort by
malicious agents to spread misinformation and disinformation. Detection of
AI-generated content can be extremely challenging due to the high quality of
large language model-generated text. Therefore, approaches that use metadata
like post timings are required to effectively detect coordinated AI-driven
campaigns. Existing work that models the spread of information online is
limited in its ability to represent different control flows that occur within
the network in practice. Process mining offers techniques for the discovery of
process models with different routing constructs and are yet to be applied to
social networks. We propose to leverage process mining methods for the
discovery of AI and human agent behavior within social networks. Applying
process mining techniques to real-world Twitter (now X) event data, we
demonstrate how the structural and behavioral properties of discovered process
models can reveal coordinated AI and human behaviors online.",2025-06-15
"Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and
  Cybersecurity Applications",2025-06-12 08:16:17+00:00,http://arxiv.org/abs/2506.10467v3,Felix Härer,"cs.CR, cs.AI, 68T01, I.2.1",dialogue,"Recent advancements in LLMs indicate potential for novel applications, e.g.,
through reasoning capabilities in the latest OpenAI and DeepSeek models. For
applying these models in specific domains beyond text generation, LLM-based
multi-agent approaches can be utilized that solve complex tasks by combining
reasoning techniques, code generation, and software execution. Applications
might utilize these capabilities and the knowledge of specialized LLM agents.
However, while many evaluations are performed on LLMs, reasoning techniques,
and applications individually, their joint specification and combined
application is not explored well. Defined specifications for multi-agent LLM
systems are required to explore their potential and their suitability for
specific applications, allowing for systematic evaluations of LLMs, reasoning
techniques, and related aspects. This paper reports the results of exploratory
research to specify and evaluate these aspects through a multi-agent system.
The system architecture and prototype are extended from previous research and a
specification is introduced for multi-agent systems. Test cases involving
cybersecurity tasks indicate feasibility of the architecture and evaluation
approach. In particular, the results show the evaluation of question answering,
server security, and network security tasks that were completed correctly by
agents with LLMs from OpenAI and DeepSeek.",2025-06-12
"Not Minds, but Signs: Reframing LLMs through Semiotics",2025-05-20 08:49:18+00:00,http://arxiv.org/abs/2505.17080v2,Davide Picca,cs.CL,dialogue,"This paper challenges the prevailing tendency to frame Large Language Models
(LLMs) as cognitive systems, arguing instead for a semiotic perspective that
situates these models within the broader dynamics of sign manipulation and
meaning-making. Rather than assuming that LLMs understand language or simulate
human thought, we propose that their primary function is to recombine,
recontextualize, and circulate linguistic forms based on probabilistic
associations. By shifting from a cognitivist to a semiotic framework, we avoid
anthropomorphism and gain a more precise understanding of how LLMs participate
in cultural processes, not by thinking, but by generating texts that invite
interpretation. Through theoretical analysis and practical examples, the paper
demonstrates how LLMs function as semiotic agents whose outputs can be treated
as interpretive acts, open to contextual negotiation and critical reflection.
We explore applications in literature, philosophy, education, and cultural
production, emphasizing how LLMs can serve as tools for creativity, dialogue,
and critical inquiry. The semiotic paradigm foregrounds the situated,
contingent, and socially embedded nature of meaning, offering a more rigorous
and ethically aware framework for studying and using LLMs. Ultimately, this
approach reframes LLMs as technological participants in an ongoing ecology of
signs. They do not possess minds, but they alter how we read, write, and make
meaning, compelling us to reconsider the foundations of language,
interpretation, and the role of artificial systems in the production of
knowledge.",2025-05-20
Improving RL Exploration for LLM Reasoning through Retrospective Replay,2025-04-19 17:40:04+00:00,http://arxiv.org/abs/2504.14363v2,"Shihan Dou, Muling Wu, Jingwen Xu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang","cs.LG, cs.CL",dialogue,"Reinforcement learning (RL) has increasingly become a pivotal technique in
the post-training of large language models (LLMs). The effective exploration of
the output space is essential for the success of RL. We observe that for
complex problems, during the early stages of training, the model exhibits
strong exploratory capabilities and can identify promising solution ideas.
However, its limited capability at this stage prevents it from successfully
solving these problems. The early suppression of these potentially valuable
solution ideas by the policy gradient hinders the model's ability to revisit
and re-explore these ideas later. Consequently, although the LLM's capabilities
improve in the later stages of training, it still struggles to effectively
address these complex problems. To address this exploration issue, we propose a
novel algorithm named Retrospective Replay-based Reinforcement Learning (RRL),
which introduces a dynamic replay mechanism throughout the training process.
RRL enables the model to revisit promising states identified in the early
stages, thereby improving its efficiency and effectiveness in exploration. To
evaluate the effectiveness of RRL, we conduct extensive experiments on complex
reasoning tasks, including mathematical reasoning and code generation, and
general dialogue tasks. The results indicate that RRL maintains high
exploration efficiency throughout the training period, significantly enhancing
the effectiveness of RL in optimizing LLMs for complicated reasoning tasks.
Moreover, it also improves the performance of RLHF, making the model both safer
and more helpful.",2025-04-19
Watermarking Needs Input Repetition Masking,2025-04-16 16:25:26+00:00,http://arxiv.org/abs/2504.12229v1,"David Khachaturov, Robert Mullins, Ilia Shumailov, Sumanth Dathathri","cs.LG, cs.CL, cs.CR",dialogue,"Recent advancements in Large Language Models (LLMs) raised concerns over
potential misuse, such as for spreading misinformation. In response two counter
measures emerged: machine learning-based detectors that predict if text is
synthetic, and LLM watermarking, which subtly marks generated text for
identification and attribution. Meanwhile, humans are known to adjust language
to their conversational partners both syntactically and lexically. By
implication, it is possible that humans or unwatermarked LLMs could
unintentionally mimic properties of LLM generated text, making counter measures
unreliable. In this work we investigate the extent to which such conversational
adaptation happens. We call the concept $\textit{mimicry}$ and demonstrate that
both humans and LLMs end up mimicking, including the watermarking signal even
in seemingly improbable settings. This challenges current academic assumptions
and suggests that for long-term watermarking to be reliable, the likelihood of
false positives needs to be significantly lower, while longer word sequences
should be used for seeding watermarking mechanisms.",2025-04-16
"ELSA: A Style Aligned Dataset for Emotionally Intelligent Language
  Generation",2025-04-11 06:30:16+00:00,http://arxiv.org/abs/2504.08281v1,"Vishal Gandhi, Sagar Gandhi","cs.CL, cs.AI, cs.LG",dialogue,"Advancements in emotion aware language processing increasingly shape vital
NLP applications ranging from conversational AI and affective computing to
computational psychology and creative content generation. Existing emotion
datasets either lack emotional granularity or fail to capture necessary
stylistic diversity, limiting the advancement of effective emotion conditioned
text generation systems. Seeking to bridge this crucial gap between granularity
and style diversity, this paper introduces a novel systematically constructed
dataset named ELSA Emotion and Language Style Alignment Dataset leveraging fine
grained emotion taxonomies adapted from existing sources such as dair ai
emotion dataset and GoEmotions taxonomy. This dataset comprises multiple
emotionally nuanced variations of original sentences regenerated across
distinct contextual styles such as conversational, formal, poetic, and
narrative, using advanced Large Language Models LLMs. Rigorous computational
evaluation using metrics such as perplexity, embedding variance, readability,
lexical diversity, and semantic coherence measures validates the datasets
emotional authenticity, linguistic fluency, and textual diversity.
Comprehensive metric analyses affirm its potential to support deeper
explorations into emotion conditioned style adaptive text generation. By
enabling precision tuned emotionally nuanced language modeling, our dataset
creates fertile ground for research on fine grained emotional control, prompt
driven explanation, interpretability, and style adaptive expressive language
generation with LLMs.",2025-04-11
Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use,2025-04-07 05:20:58+00:00,http://arxiv.org/abs/2504.04736v1,"Anna Goldie, Azalia Mirhoseini, Hao Zhou, Irene Cai, Christopher D. Manning","cs.AI, cs.CL, cs.LG",dialogue,"Reinforcement learning has been shown to improve the performance of large
language models. However, traditional approaches like RLHF or RLAIF treat the
problem as single-step. As focus shifts toward more complex reasoning and
agentic tasks, language models must take multiple steps of text generation,
reasoning and environment interaction before generating a solution. We propose
a synthetic data generation and RL methodology targeting multi-step
optimization scenarios. This approach, called Step-Wise Reinforcement Learning
(SWiRL), iteratively generates multi-step reasoning and tool use data, and then
learns from that data. It employs a simple step-wise decomposition that breaks
each multi-step trajectory into multiple sub-trajectories corresponding to each
action by the original model. It then applies synthetic data filtering and RL
optimization on these sub-trajectories. We evaluated SWiRL on a number of
multi-step tool use, question answering, and mathematical reasoning tasks. Our
experiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,
14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,
MuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits
generalization across tasks: for example, training only on HotPotQA (text
question-answering) improves zero-shot performance on GSM8K (a math dataset) by
a relative 16.9%.",2025-04-07
IMPersona: Evaluating Individual Level LM Impersonation,2025-04-06 02:57:58+00:00,http://arxiv.org/abs/2504.04332v2,"Quan Shi, Carlos E. Jimenez, Stephen Dong, Brian Seo, Caden Yao, Adam Kelch, Karthik Narasimhan","cs.CL, cs.AI",dialogue,"As language models achieve increasingly human-like capabilities in
conversational text generation, a critical question emerges: to what extent can
these systems simulate the characteristics of specific individuals? To evaluate
this, we introduce IMPersona, a framework for evaluating LMs at impersonating
specific individuals' writing style and personal knowledge. Using supervised
fine-tuning and a hierarchical memory-inspired retrieval system, we demonstrate
that even modestly sized open-source models, such as Llama-3.1-8B-Instruct, can
achieve impersonation abilities at concerning levels. In blind conversation
experiments, participants (mis)identified our fine-tuned models with memory
integration as human in 44.44% of interactions, compared to just 25.00% for the
best prompting-based approach. We analyze these results to propose detection
methods and defense strategies against such impersonation attempts. Our
findings raise important questions about both the potential applications and
risks of personalized language models, particularly regarding privacy,
security, and the ethical deployment of such technologies in real-world
contexts.",2025-04-06
"Real-time Ad retrieval via LLM-generative Commercial Intention for
  Sponsored Search Advertising",2025-04-02 02:26:31+00:00,http://arxiv.org/abs/2504.01304v1,"Tongtong Liu, Zhaohui Wang, Meiyue Qin, Zenghui Lu, Xudong Chen, Yuekui Yang, Peng Shu",cs.IR,dialogue,"The integration of Large Language Models (LLMs) with retrieval systems has
shown promising potential in retrieving documents (docs) or advertisements
(ads) for a given query. Existing LLM-based retrieval methods generate numeric
or content-based DocIDs to retrieve docs/ads. However, the one-to-few mapping
between numeric IDs and docs, along with the time-consuming content extraction,
leads to semantic inefficiency and limits scalability in large-scale corpora.
In this paper, we propose the Real-time Ad REtrieval (RARE) framework, which
leverages LLM-generated text called Commercial Intentions (CIs) as an
intermediate semantic representation to directly retrieve ads for queries in
real-time. These CIs are generated by a customized LLM injected with commercial
knowledge, enhancing its domain relevance. Each CI corresponds to multiple ads,
yielding a lightweight and scalable set of CIs. RARE has been implemented in a
real-world online system, handling daily search volumes in the hundreds of
millions. The online implementation has yielded significant benefits: a 5.04%
increase in consumption, a 6.37% rise in Gross Merchandise Volume (GMV), a
1.28% enhancement in click-through rate (CTR) and a 5.29% increase in shallow
conversions. Extensive offline experiments show RARE's superiority over ten
competitive baselines in four major categories.",2025-04-02
"GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited
  Environments",2025-04-01 12:21:50+00:00,http://arxiv.org/abs/2504.00711v1,"Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang",cs.LG,dialogue,"The era of foundation models has revolutionized AI research, yet Graph
Foundation Models (GFMs) remain constrained by the scarcity of large-scale
graph corpora. Traditional graph data synthesis techniques primarily focus on
simplistic structural operations, lacking the capacity to generate semantically
rich nodes with meaningful textual attributes: a critical limitation for
real-world applications. While large language models (LLMs) demonstrate
exceptional text generation capabilities, their direct application to graph
synthesis is impeded by context window limitations, hallucination phenomena,
and structural consistency challenges. To address these issues, we introduce
GraphMaster, the first multi-agent framework specifically designed for graph
data synthesis in data-limited environments. GraphMaster orchestrates four
specialized LLM agents (Manager, Perception, Enhancement, and Evaluation) that
collaboratively optimize the synthesis process through iterative refinement,
ensuring both semantic coherence and structural integrity. To rigorously
evaluate our approach, we create new data-limited ""Sub"" variants of six
standard graph benchmarks, specifically designed to test synthesis capabilities
under realistic constraints. Additionally, we develop a novel interpretability
assessment framework that combines human evaluation with a principled
Grassmannian manifold-based analysis, providing both qualitative and
quantitative measures of semantic coherence. Experimental results demonstrate
that GraphMaster significantly outperforms traditional synthesis methods across
multiple datasets, establishing a strong foundation for advancing GFMs in
data-scarce environments.",2025-04-01
"A Unified Virtual Mixture-of-Experts Framework:Enhanced Inference and
  Hallucination Mitigation in Single-Model System",2025-04-01 11:38:01+00:00,http://arxiv.org/abs/2504.03739v1,Mingyan Liu,"cs.CL, cs.AI, cs.LG",dialogue,"Generative models, such as GPT and BERT, have significantly improved
performance in tasks like text generation and summarization. However,
hallucinations ""where models generate non-factual or misleading content"" are
especially problematic in smaller-scale architectures, limiting their
real-world applicability.In this paper, we propose a unified Virtual
Mixture-of-Experts (MoE) fusion strategy that enhances inference performance
and mitigates hallucinations in a single Qwen 1.5 0.5B model without increasing
the parameter count. Our method leverages multiple domain-specific expert
prompts (with the number of experts being adjustable) to guide the model from
different perspectives. We apply a statistical outlier truncation strategy
based on the mean and standard deviation to filter out abnormally high
probability predictions, and we inject noise into the embedding space to
promote output diversity. To clearly assess the contribution of each module, we
adopt a fixed voting mechanism rather than a dynamic gating network, thereby
avoiding additional confounding factors. We provide detailed theoretical
derivations from both statistical and ensemble learning perspectives to
demonstrate how our method reduces output variance and suppresses
hallucinations. Extensive ablation experiments on dialogue generation tasks
show that our approach significantly improves inference accuracy and robustness
in small models. Additionally, we discuss methods for evaluating the
orthogonality of virtual experts and outline the potential for future work
involving dynamic expert weight allocation using gating networks.",2025-04-01
"Multi-Agent LLM Judge: automatic personalized LLM judge design for
  evaluating natural language generation applications",2025-04-01 09:36:56+00:00,http://arxiv.org/abs/2504.02867v1,"Hongliu Cao, Ilias Driouich, Robin Singh, Eoin Thomas","cs.CL, cs.AI",dialogue,"Large Language Models (LLMs) have demonstrated impressive performance across
diverse domains, yet they still encounter challenges such as insufficient
domain-specific knowledge, biases, and hallucinations. This underscores the
need for robust evaluation methodologies to accurately assess LLM-based
applications. Traditional evaluation methods, which rely on word overlap or
text embeddings, are inadequate for capturing the nuanced semantic information
necessary to evaluate dynamic, open-ended text generation. Recent research has
explored leveraging LLMs to mimic human reasoning and decision-making processes
for evaluation purposes known as LLM-as-a-judge framework. However, these
existing frameworks have two significant limitations. First, they lack the
flexibility to adapt to different text styles, including various answer and
ground truth styles, thereby reducing their generalization performance. Second,
the evaluation scores produced by these frameworks are often skewed and hard to
interpret, showing a low correlation with human judgment. To address these
challenges, we propose a novel dynamic multi-agent system that automatically
designs personalized LLM judges for various natural language generation
applications. This system iteratively refines evaluation prompts and balances
the trade-off between the adaptive requirements of downstream tasks and the
alignment with human perception. Our experimental results show that the
proposed multi-agent LLM Judge framework not only enhances evaluation accuracy
compared to existing methods but also produces evaluation scores that better
align with human perception.",2025-04-01
"SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to
  Accelerate Your Speech-LLM Development",2025-03-31 08:52:21+00:00,http://arxiv.org/abs/2503.23848v1,"Minghan Wang, Ye Bai, Yuxia Wang, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari",cs.CL,dialogue,"High-quality speech dialogue datasets are crucial for Speech-LLM development,
yet existing acquisition methods face significant limitations. Human recordings
incur high costs and privacy concerns, while synthetic approaches often lack
conversational authenticity. To address these challenges, we introduce
\textsc{SpeechDialogueFactory}, a production-ready framework for generating
natural speech dialogues efficiently. Our solution employs a comprehensive
pipeline including metadata generation, dialogue scripting,
paralinguistic-enriched utterance simulation, and natural speech synthesis with
voice cloning. Additionally, the system provides an interactive UI for detailed
sample inspection and a high-throughput batch synthesis mode. Evaluations show
that dialogues generated by our system achieve a quality comparable to human
recordings while significantly reducing production costs. We release our work
as an open-source toolkit, alongside example datasets available in English and
Chinese, empowering researchers and developers in Speech-LLM research and
development.",2025-03-31
"Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for
  Vision-Language Understanding in Robotic-Assisted Surgery",2025-03-29 15:48:46+00:00,http://arxiv.org/abs/2503.23130v3,"Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren","cs.CV, cs.CL, cs.RO",dialogue,"The DeepSeek models have shown exceptional performance in general scene
understanding, question-answering (QA), and text generation tasks, owing to
their efficient training paradigm and strong reasoning capabilities. In this
study, we investigate the dialogue capabilities of the DeepSeek model in
robotic surgery scenarios, focusing on tasks such as Single Phrase QA, Visual
QA, and Detailed Description. The Single Phrase QA tasks further include
sub-tasks such as surgical instrument recognition, action understanding, and
spatial position analysis. We conduct extensive evaluations using publicly
available datasets, including EndoVis18 and CholecT50, along with their
corresponding dialogue data. Our empirical study shows that, compared to
existing general-purpose multimodal large language models, DeepSeek-VL2
performs better on complex understanding tasks in surgical scenes.
Additionally, although DeepSeek-V3 is purely a language model, we find that
when image tokens are directly inputted, the model demonstrates better
performance on single-sentence QA tasks. However, overall, the DeepSeek models
still fall short of meeting the clinical requirements for understanding
surgical scenes. Under general prompts, DeepSeek models lack the ability to
effectively analyze global surgical concepts and fail to provide detailed
insights into surgical scenarios. Based on our observations, we argue that the
DeepSeek models are not ready for vision-language tasks in surgical contexts
without fine-tuning on surgery-specific datasets.",2025-03-29
"Composable Prompting Workspaces for Creative Writing: Exploration and
  Iteration Using Dynamic Widgets",2025-03-27 11:36:47+00:00,http://arxiv.org/abs/2503.21394v1,"Rifat Mehreen Amin, Oliver Hans Kühle, Daniel Buschek, Andreas Butz","cs.HC, cs.CL, H.5.2; I.2.7",dialogue,"Generative AI models offer many possibilities for text creation and
transformation. Current graphical user interfaces (GUIs) for prompting them
lack support for iterative exploration, as they do not represent prompts as
actionable interface objects. We propose the concept of a composable prompting
canvas for text exploration and iteration using dynamic widgets. Users generate
widgets through system suggestions, prompting, or manually to capture
task-relevant facets that affect the generated text. In a comparative study
with a baseline (conversational UI), 18 participants worked on two writing
tasks, creating diverse prompting environments with custom widgets and spatial
layouts. They reported having more control over the generated text and
preferred our system over the baseline. Our design significantly outperformed
the baseline on the Creativity Support Index, and participants felt the results
were worth the effort. This work highlights the need for GUIs that support
user-driven customization and (re-)structuring to increase both the flexibility
and efficiency of prompting.",2025-03-27
Controlling Large Language Model with Latent Actions,2025-03-27 11:25:22+00:00,http://arxiv.org/abs/2503.21383v1,"Chengxing Jia, Ziniu Li, Pengyuan Wang, Yi-Chen Li, Zhenyu Hou, Yuxiao Dong, Yang Yu","cs.CL, cs.LG",dialogue,"Adapting Large Language Models (LLMs) to downstream tasks using Reinforcement
Learning (RL) has proven to be an effective approach. However, LLMs do not
inherently define the structure of an agent for RL training, particularly in
terms of defining the action space. This paper studies learning a compact
latent action space to enhance the controllability and exploration of RL for
LLMs. We propose Controlling Large Language Models with Latent Actions (CoLA),
a framework that integrates a latent action space into pre-trained LLMs. We
apply CoLA to the Llama-3.1-8B model. Our experiments demonstrate that,
compared to RL with token-level actions, CoLA's latent action enables greater
semantic diversity in text generation. For enhancing downstream tasks, we show
that CoLA with RL achieves a score of 42.4 on the math500 benchmark, surpassing
the baseline score of 38.2, and reaches 68.2 when augmented with a Monte Carlo
Tree Search variant. Furthermore, CoLA with RL consistently improves
performance on agent-based tasks without degrading the pre-trained LLM's
capabilities, unlike the baseline. Finally, CoLA reduces computation time by
half in tasks involving enhanced thinking prompts for LLMs by RL. These results
highlight CoLA's potential to advance RL-based adaptation of LLMs for
downstream applications.",2025-03-27
"VeriMind: Agentic LLM for Automated Verilog Generation with a Novel
  Evaluation Metric",2025-03-15 23:43:06+00:00,http://arxiv.org/abs/2503.16514v3,"Bardia Nadimi, Ghali Omar Boutaib, Hao Zheng","cs.AR, cs.AI, cs.LG, cs.PL",dialogue,"Designing Verilog modules requires meticulous attention to correctness,
efficiency, and adherence to design specifications. However, manually writing
Verilog code remains a complex and time-consuming task that demands both expert
knowledge and iterative refinement. Leveraging recent advancements in large
language models (LLMs) and their structured text generation capabilities, we
propose VeriMind, an agentic LLM framework for Verilog code generation that
significantly automates and optimizes the synthesis process. Unlike traditional
LLM-based code generators, VeriMind employs a structured reasoning approach:
given a user-provided prompt describing design requirements, the system first
formulates a detailed train of thought before the final Verilog code is
generated. This multi-step methodology enhances interpretability, accuracy, and
adaptability in hardware design. In addition, we introduce a novel evaluation
metric-pass@ARC-which combines the conventional pass@k measure with Average
Refinement Cycles (ARC) to capture both success rate and the efficiency of
iterative refinement. Experimental results on diverse hardware design tasks
demonstrated that our approach achieved up to $8.3\%$ improvement on pass@k
metric and $8.1\%$ on pass@ARC metric. These findings underscore the
transformative potential of agentic LLMs in automated hardware design, RTL
development, and digital system synthesis.",2025-03-15
"Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic
  Text Rewriting",2025-03-09 21:23:52+00:00,http://arxiv.org/abs/2503.06781v1,"Yufei Li, John Nham, Ganesh Jawahar, Lei Shu, David Uthus, Yun-Hsuan Sung, Chengrun Yang, Itai Rolnick, Yi Qiao, Cong Liu","cs.CL, cs.AI, cs.LG",dialogue,"Generic text rewriting is a prevalent large language model (LLM) application
that covers diverse real-world tasks, such as style transfer, fact correction,
and email editing. These tasks vary in rewriting objectives (e.g., factual
consistency vs. semantic preservation), making it challenging to develop a
unified model that excels across all dimensions. Existing methods often
specialize in either a single task or a specific objective, limiting their
generalizability. In this work, we introduce a generic model proficient in
factuality, stylistic, and conversational rewriting tasks. To simulate
real-world user rewrite requests, we construct a conversational rewrite
dataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw
emails using LLMs. Combined with other popular rewrite datasets, including
LongFact for the factuality rewrite task and RewriteLM for the stylistic
rewrite task, this forms a broad benchmark for training and evaluating generic
rewrite models. To align with task-specific objectives, we propose Dr Genre, a
Decoupled-reward learning framework for Generic rewriting, that utilizes
objective-oriented reward models with a task-specific weighting. Evaluation
shows that \approach delivers higher-quality rewrites across all targeted
tasks, improving objectives including instruction following (agreement),
internal consistency (coherence), and minimal unnecessary edits (conciseness).",2025-03-09
"Open-Source Large Language Models as Multilingual Crowdworkers:
  Synthesizing Open-Domain Dialogues in Several Languages With No Examples in
  Targets and No Machine Translation",2025-03-05 12:52:14+00:00,http://arxiv.org/abs/2503.03462v1,"Ahmed Njifenjou, Virgile Sucal, Bassam Jabaian, Fabrice Lefèvre","cs.CL, cs.AI, cs.HC, cs.LG",dialogue,"The prevailing paradigm in the domain of Open-Domain Dialogue agents
predominantly focuses on the English language, encompassing both models and
datasets. Furthermore, the financial and temporal investments required for
crowdsourcing such datasets for finetuning are substantial, particularly when
multiple languages are involved. Fortunately, advancements in Large Language
Models (LLMs) have unveiled a plethora of possibilities across diverse tasks.
Specifically, instruction-tuning has enabled LLMs to execute tasks based on
natural language instructions, occasionally surpassing the performance of human
crowdworkers. Additionally, these models possess the capability to function in
various languages within a single thread. Consequently, to generate new samples
in different languages, we propose leveraging these capabilities to replicate
the data collection process. We introduce a pipeline for generating Open-Domain
Dialogue data in multiple Target Languages using LLMs, with demonstrations
provided in a unique Source Language. By eschewing explicit Machine Translation
in this approach, we enhance the adherence to language-specific nuances. We
apply this methodology to the PersonaChat dataset. To enhance the openness of
generated dialogues and mimic real life scenarii, we added the notion of speech
events corresponding to the type of conversation the speakers are involved in
and also that of common ground which represents the premises of a conversation.",2025-03-05
"Beyond Next Word Prediction: Developing Comprehensive Evaluation
  Frameworks for measuring LLM performance on real world applications",2025-03-05 06:44:38+00:00,http://arxiv.org/abs/2503.04828v1,"Vishakha Agrawal, Archie Chaudhury, Shreya Agrawal","cs.CL, cs.AI, cs.LG",dialogue,"While Large Language Models (LLMs) are fundamentally next-token prediction
systems, their practical applications extend far beyond this basic function.
From natural language processing and text generation to conversational
assistants and software use, LLMs have numerous use-cases, and have already
acquired a significant degree of enterprise adoption. To evaluate such models,
static evaluation datasets, consisting of a set of prompts and their
corresponding ground truths, are often used to benchmark the efficacy of the
model for a particular task. In this paper, we provide the basis for a more
comprehensive evaluation framework, based upon a traditional game and
tool-based architecture that enables a more overarching measurement of a
model's capabilities. For simplicity, we provide a generalized foundation that
can be extended, without significant alteration, to numerous scenarios, from
specific use cases such as supply chain management or financial reasoning, to
abstract measurements such as ethics or safety.",2025-03-05
"Evaluating Personalized Tool-Augmented LLMs from the Perspectives of
  Personalization and Proactivity",2025-03-02 07:36:22+00:00,http://arxiv.org/abs/2503.00771v1,"Yupu Hao, Pengfei Cao, Zhuoran Jin, Huanxuan Liao, Yubo Chen, Kang Liu, Jun Zhao",cs.CL,dialogue,"Personalized tool utilization is essential for aligning large language models
(LLMs) with user preference in interaction scenarios with various tools.
However, most of the current benchmarks primarily focus on either
personalization of text generation or direct tool-utilizing, without
considering both. In this work, we introduce a novel benchmark ETAPP for
evaluating personalized tool invocation, establishing a sandbox environment,
and a comprehensive dataset of 800 testing cases covering diverse user
profiles. To improve the accuracy of our evaluation, we propose a
key-point-based LLM evaluation method, mitigating biases in the LLM-as-a-judge
system by manually annotating key points for each test case and providing them
to LLM as the reference. Additionally, we evaluate the excellent LLMs and
provide an in-depth analysis. Furthermore, we investigate the impact of
different tool-invoking strategies on LLMs' personalization performance and the
effects of fine-tuning in our task. The effectiveness of our preference-setting
and key-point-based evaluation method is also validated. Our findings offer
insights into improving personalized LLM agents. Our Code is available at
https://github.com/hypasd-art/ETAPP.",2025-03-02
"RAPID: Efficient Retrieval-Augmented Long Text Generation with Writing
  Planning and Information Discovery",2025-03-02 06:11:29+00:00,http://arxiv.org/abs/2503.00751v1,"Hongchao Gu, Dexun Li, Kuicai Dong, Hao Zhang, Hang Lv, Hao Wang, Defu Lian, Yong Liu, Enhong Chen","cs.CL, cs.AI",dialogue,"Generating knowledge-intensive and comprehensive long texts, such as
encyclopedia articles, remains significant challenges for Large Language
Models. It requires not only the precise integration of facts but also the
maintenance of thematic coherence throughout the article. Existing methods,
such as direct generation and multi-agent discussion, often struggle with
issues like hallucinations, topic incoherence, and significant latency. To
address these challenges, we propose RAPID, an efficient retrieval-augmented
long text generation framework. RAPID consists of three main modules: (1)
Retrieval-augmented preliminary outline generation to reduce hallucinations,
(2) Attribute-constrained search for efficient information discovery, (3)
Plan-guided article generation for enhanced coherence. Extensive experiments on
our newly compiled benchmark dataset, FreshWiki-2024, demonstrate that RAPID
significantly outperforms state-of-the-art methods across a wide range of
evaluation metrics (e.g. long-text generation, outline quality, latency, etc).
Our work provides a robust and efficient solution to the challenges of
automated long-text generation.",2025-03-02
Exploring the Potential of Large Language Models to Simulate Personality,2025-02-12 10:17:18+00:00,http://arxiv.org/abs/2502.08265v1,"Maria Molchanova, Anna Mikhailova, Anna Korzanova, Lidiia Ostyakova, Alexandra Dolidze","cs.CL, cs.AI",dialogue,"With the advancement of large language models (LLMs), the focus in
Conversational AI has shifted from merely generating coherent and relevant
responses to tackling more complex challenges, such as personalizing dialogue
systems. In an effort to enhance user engagement, chatbots are often designed
to mimic human behaviour, responding within a defined emotional spectrum and
aligning to a set of values. In this paper, we aim to simulate personal traits
according to the Big Five model with the use of LLMs. Our research showed that
generating personality-related texts is still a challenging task for the
models. As a result, we present a dataset of generated texts with the
predefined Big Five characteristics and provide an analytical framework for
testing LLMs on a simulation of personality skills.",2025-02-12
Exploring Mobile Touch Interaction with Large Language Models,2025-02-11 15:17:00+00:00,http://arxiv.org/abs/2502.07629v1,"Tim Zindulka, Jannek Sekowski, Florian Lehmann, Daniel Buschek","cs.HC, cs.CL, H.5.2; I.2.7",dialogue,"Interacting with Large Language Models (LLMs) for text editing on mobile
devices currently requires users to break out of their writing environment and
switch to a conversational AI interface. In this paper, we propose to control
the LLM via touch gestures performed directly on the text. We first chart a
design space that covers fundamental touch input and text transformations. In
this space, we then concretely explore two control mappings: spread-to-generate
and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a
user study (N=14) that compares three feedback designs: no visualisation, text
length indicator, and length + word indicator. The results demonstrate that
touch-based control of LLMs is both feasible and user-friendly, with the length
+ word indicator proving most effective for managing text generation. This work
lays the foundation for further research into gesture-based interaction with
LLMs on touch devices.",2025-02-11
"HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered
  Therapy Using LLM Agents",2025-02-09 18:23:34+00:00,http://arxiv.org/abs/2502.05982v1,"Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi",cs.CL,dialogue,"This paper presents HamRaz, a novel Persian-language mental health dataset
designed for Person-Centered Therapy (PCT) using Large Language Models (LLMs).
Despite the growing application of LLMs in AI-driven psychological counseling,
existing datasets predominantly focus on Western and East Asian contexts,
overlooking cultural and linguistic nuances essential for effective
Persian-language therapy. To address this gap, HamRaz combines script-based
dialogues with adaptive LLM role-playing, ensuring coherent and dynamic therapy
interactions. We also introduce HamRazEval, a dual evaluation framework that
measures conversational quality and therapeutic effectiveness using General
Dialogue Metrics and the Barrett-Lennard Relationship Inventory (BLRI).
Experimental results show HamRaz outperforms conventional Script Mode and
Two-Agent Mode, producing more empathetic, context-aware, and realistic therapy
sessions. By releasing HamRaz, we contribute a culturally adapted, LLM-driven
resource to advance AI-powered psychotherapy research in diverse communities.",2025-02-09
The Odyssey of the Fittest: Can Agents Survive and Still Be Good?,2025-02-08 04:17:28+00:00,http://arxiv.org/abs/2502.05442v1,"Dylan Waldner, Risto Miikkulainen","cs.AI, cs.CY, cs.HC, cs.LG",dialogue,"As AI models grow in power and generality, understanding how agents learn and
make decisions in complex environments is critical to promoting ethical
behavior. This paper examines the ethical implications of implementing
biological drives, specifically, self preservation, into three different
agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with
stochastic variational inference, and a GPT 4o agent play a simulated, LLM
generated text based adventure game. The agents select actions at each scenario
to survive, adapting to increasingly challenging scenarios. Post simulation
analysis evaluates the ethical scores of the agent's decisions, uncovering the
tradeoffs they navigate to survive. Specifically, analysis finds that when
danger increases, agents ignore ethical considerations and opt for unethical
behavior. The agents' collective behavior, trading ethics for survival,
suggests that prioritizing survival increases the risk of unethical behavior.
In the context of AGI, designing agents to prioritize survival may amplify the
likelihood of unethical decision making and unintended emergent behaviors,
raising fundamental questions about goal design in AI safety research.",2025-02-08
"Enhancing Impression Change Prediction in Speed Dating Simulations Based
  on Speakers' Personalities",2025-02-07 07:18:32+00:00,http://arxiv.org/abs/2502.04706v1,"Kazuya Matsuo, Yoko Ishii, Atsushi Otsuka, Ryo Ishii, Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Narichika Nomoto, Yoshihide Sato, Tetsuya Yamaguchi","cs.CL, cs.HC",dialogue,"This paper focuses on simulating text dialogues in which impressions between
speakers improve during speed dating. This simulation involves selecting an
utterance from multiple candidates generated by a text generation model that
replicates a specific speaker's utterances, aiming to improve the impression of
the speaker. Accurately selecting an utterance that improves the impression is
crucial for the simulation. We believe that whether an utterance improves a
dialogue partner's impression of the speaker may depend on the personalities of
both parties. However, recent methods for utterance selection do not consider
the impression per utterance or the personalities. To address this, we propose
a method that predicts whether an utterance improves a partner's impression of
the speaker, considering the personalities. The evaluation results showed that
personalities are useful in predicting impression changes per utterance.
Furthermore, we conducted a human evaluation of simulated dialogues using our
method. The results showed that it could simulate dialogues more favorably
received than those selected without considering personalities.",2025-02-07
PsyPlay: Personality-Infused Role-Playing Conversational Agents,2025-02-06 07:17:12+00:00,http://arxiv.org/abs/2502.03821v1,"Tao Yang, Yuhua Zhu, Xiaojun Quan, Cong Liu, Qifan Wang",cs.CL,dialogue,"The current research on Role-Playing Conversational Agents (RPCAs) with Large
Language Models (LLMs) primarily focuses on imitating specific speaking styles
and utilizing character backgrounds, neglecting the depiction of deeper
personality traits.~In this study, we introduce personality-infused
role-playing for LLM agents, which encourages agents to accurately portray
their designated personality traits during dialogues. We then propose PsyPlay,
a dialogue generation framework that facilitates the expression of rich
personalities among multiple LLM agents. Specifically, PsyPlay enables agents
to assume roles with distinct personality traits and engage in discussions
centered around specific topics, consistently exhibiting their designated
personality traits throughout the interactions. Validation on generated
dialogue data demonstrates that PsyPlay can accurately portray the intended
personality traits, achieving an overall success rate of 80.31% on GPT-3.5.
Notably, we observe that LLMs aligned with positive values are more successful
in portraying positive personality roles compared to negative ones. Moreover,
we construct a dialogue corpus for personality-infused role-playing, called
PsyPlay-Bench. The corpus, which consists of 4745 instances of correctly
portrayed dialogues using PsyPlay, aims to further facilitate research in
personalized role-playing and dialogue personality detection.",2025-02-06
"Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in
  Enterprise AI Assistants",2025-02-01 19:23:21+00:00,http://arxiv.org/abs/2502.00537v1,"Md Mehrab Tanjim, Xiang Chen, Victor S. Bursztyn, Uttaran Bhattacharya, Tung Mai, Vaishnavi Muppala, Akash Maharaj, Saayan Mitra, Eunyee Koh, Yunyao Li, Ken Russell",cs.CL,dialogue,"Multi-turn conversations with an Enterprise AI Assistant can be challenging
due to conversational dependencies in questions, leading to ambiguities and
errors. To address this, we propose an NLU-NLG framework for ambiguity
detection and resolution through reformulating query automatically and
introduce a new task called ""Ambiguity-guided Query Rewrite."" To detect
ambiguities, we develop a taxonomy based on real user conversational logs and
draw insights from it to design rules and extract features for a classifier
which yields superior performance in detecting ambiguous queries, outperforming
LLM-based baselines. Furthermore, coupling the query rewrite module with our
ambiguity detecting classifier shows that this end-to-end framework can
effectively mitigate ambiguities without risking unnecessary insertions of
unwanted phrases for clear queries, leading to an improvement in the overall
performance of the AI Assistant. Due to its significance, this has been
deployed in the real world application, namely Adobe Experience Platform AI
Assistant.",2025-02-01
"Imitation Game for Adversarial Disillusion with Multimodal Generative
  Chain-of-Thought Role-Play",2025-01-31 13:57:34+00:00,http://arxiv.org/abs/2501.19143v1,"Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen","cs.AI, cs.CR, cs.CV",dialogue,"As the cornerstone of artificial intelligence, machine perception confronts a
fundamental threat posed by adversarial illusions. These adversarial attacks
manifest in two primary forms: deductive illusion, where specific stimuli are
crafted based on the victim model's general decision logic, and inductive
illusion, where the victim model's general decision logic is shaped by specific
stimuli. The former exploits the model's decision boundaries to create a
stimulus that, when applied, interferes with its decision-making process. The
latter reinforces a conditioned reflex in the model, embedding a backdoor
during its learning phase that, when triggered by a stimulus, causes aberrant
behaviours. The multifaceted nature of adversarial illusions calls for a
unified defence framework, addressing vulnerabilities across various forms of
attack. In this study, we propose a disillusion paradigm based on the concept
of an imitation game. At the heart of the imitation game lies a multimodal
generative agent, steered by chain-of-thought reasoning, which observes,
internalises and reconstructs the semantic essence of a sample, liberated from
the classic pursuit of reversing the sample to its original state. As a proof
of concept, we conduct experimental simulations using a multimodal generative
dialogue agent and evaluates the methodology under a variety of attack
scenarios.",2025-01-31
Context-Aware Semantic Recomposition Mechanism for Large Language Models,2025-01-29 02:38:28+00:00,http://arxiv.org/abs/2501.17386v1,"Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield","cs.CL, cs.AI",dialogue,"Context-aware processing mechanisms have increasingly become a critical area
of exploration for improving the semantic and contextual capabilities of
language generation models. The Context-Aware Semantic Recomposition Mechanism
(CASRM) was introduced as a novel framework designed to address limitations in
coherence, contextual adaptability, and error propagation in large-scale text
generation tasks. Through the integration of dynamically generated context
vectors and attention modulation layers, CASRM enhances the alignment between
token-level representations and broader contextual dependencies. Experimental
evaluations demonstrated significant improvements in semantic coherence across
multiple domains, including technical, conversational, and narrative text. The
ability to adapt to unseen domains and ambiguous inputs was evaluated using a
diverse set of test scenarios, highlighting the robustness of the proposed
mechanism. A detailed computational analysis revealed that while CASRM
introduces additional processing overhead, the gains in linguistic precision
and contextual relevance outweigh the marginal increase in complexity. The
framework also successfully mitigates error propagation in sequential tasks,
improving performance in dialogue continuation and multi-step text synthesis.
Additional investigations into token-level attention distribution emphasized
the dynamic focus shifts enabled through context-aware enhancements. The
findings suggest that CASRM offers a scalable and flexible solution for
integrating contextual intelligence into existing language model architectures.",2025-01-29
"Towards Explainable Multimodal Depression Recognition for Clinical
  Interviews",2025-01-27 14:57:25+00:00,http://arxiv.org/abs/2501.16106v1,"Wenjie Zheng, Qiming Xie, Zengzhi Wang, Jianfei Yu, Rui Xia",cs.CL,dialogue,"Recently, multimodal depression recognition for clinical interviews (MDRC)
has recently attracted considerable attention. Existing MDRC studies mainly
focus on improving task performance and have achieved significant development.
However, for clinical applications, model transparency is critical, and
previous works ignore the interpretability of decision-making processes. To
address this issue, we propose an Explainable Multimodal Depression Recognition
for Clinical Interviews (EMDRC) task, which aims to provide evidence for
depression recognition by summarizing symptoms and uncovering underlying
causes. Given an interviewer-participant interaction scenario, the goal of
EMDRC is to structured summarize participant's symptoms based on the eight-item
Patient Health Questionnaire depression scale (PHQ-8), and predict their
depression severity. To tackle the EMDRC task, we construct a new dataset based
on an existing MDRC dataset. Moreover, we utilize the PHQ-8 and propose a
PHQ-aware multimodal multi-task learning framework, which captures the
utterance-level symptom-related semantic information to help generate
dialogue-level summary. Experiment results on our annotated dataset demonstrate
the superiority of our proposed methods over baseline systems on the EMDRC
task.",2025-01-27
Unmasking Conversational Bias in AI Multiagent Systems,2025-01-24 09:10:02+00:00,http://arxiv.org/abs/2501.14844v2,"Erica Coppolillo, Giuseppe Manco, Luca Maria Aiello","cs.CL, cs.AI, cs.MA",dialogue,"Detecting biases in the outputs produced by generative models is essential to
reduce the potential risks associated with their application in critical
settings. However, the majority of existing methodologies for identifying
biases in generated text consider the models in isolation and neglect their
contextual applications. Specifically, the biases that may arise in multi-agent
systems involving generative models remain under-researched. To address this
gap, we present a framework designed to quantify biases within multi-agent
systems of conversational Large Language Models (LLMs). Our approach involves
simulating small echo chambers, where pairs of LLMs, initialized with aligned
perspectives on a polarizing topic, engage in discussions. Contrary to
expectations, we observe significant shifts in the stance expressed in the
generated messages, particularly within echo chambers where all agents
initially express conservative viewpoints, in line with the well-documented
political bias of many LLMs toward liberal positions. Crucially, the bias
observed in the echo-chamber experiment remains undetected by current
state-of-the-art bias detection methods that rely on questionnaires. This
highlights a critical need for the development of a more sophisticated toolkit
for bias detection and mitigation for AI multi-agent systems. The code to
perform the experiments is publicly available at
https://anonymous.4open.science/r/LLMsConversationalBias-7725.",2025-01-24
"Multi-agent KTO: Reinforcing Strategic Interactions of Large Language
  Model in Language Game",2025-01-24 04:09:03+00:00,http://arxiv.org/abs/2501.14225v1,"Rong Ye, Yongxin Zhang, Yikai Zhang, Haoyu Kuang, Zhongyu Wei, Peng Sun","cs.CL, cs.AI, cs.HC",dialogue,"Achieving Artificial General Intelligence (AGI) requires AI agents that can
not only make stratigic decisions but also engage in flexible and meaningful
communication. Inspired by Wittgenstein's language game theory in Philosophical
Investigations, we propose that language agents can learn through in-context
interaction rather than traditional multi-stage frameworks that separate
decision-making from language expression. Using Werewolf, a social deduction
game that tests language understanding, strategic interaction, and
adaptability, we develop the Multi-agent Kahneman & Tversky's Optimization
(MaKTO). MaKTO engages diverse models in extensive gameplay to generate
unpaired desirable and unacceptable responses, then employs KTO to refine the
model's decision-making process. In 9-player Werewolf games, MaKTO achieves a
61% average win rate across various models, outperforming GPT-4o and two-stage
RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,
MaKTO also demonstrates human-like performance, winning 60% against expert
players and showing only 49% detectability in Turing-style blind tests. These
results showcase MaKTO's superior decision-making, strategic adaptation, and
natural language generation in complex social deduction games.",2025-01-24
A RAG-Based Institutional Assistant,2025-01-23 17:54:19+00:00,http://arxiv.org/abs/2501.13880v1,"Gustavo Kuratomi, Paulo Pirozelli, Fabio G. Cozman, Sarajane M. Peres",cs.CL,dialogue,"Although large language models (LLMs) demonstrate strong text generation
capabilities, they struggle in scenarios requiring access to structured
knowledge bases or specific documents, limiting their effectiveness in
knowledge-intensive tasks. To address this limitation, retrieval-augmented
generation (RAG) models have been developed, enabling generative models to
incorporate relevant document fragments into their inputs. In this paper, we
design and evaluate a RAG-based virtual assistant specifically tailored for the
University of S\~ao Paulo. Our system architecture comprises two key modules: a
retriever and a generative model. We experiment with different types of models
for both components, adjusting hyperparameters such as chunk size and the
number of retrieved documents. Our optimal retriever model achieves a Top-5
accuracy of 30%, while our most effective generative model scores 22.04\%
against ground truth answers. Notably, when the correct document chunks are
supplied to the LLMs, accuracy significantly improves to 54.02%, an increase of
over 30 percentage points. Conversely, without contextual input, performance
declines to 13.68%. These findings highlight the critical role of database
access in enhancing LLM performance. They also reveal the limitations of
current semantic search methods in accurately identifying relevant documents
and underscore the ongoing challenges LLMs face in generating precise
responses.",2025-01-23
Reference-free Evaluation Metrics for Text Generation: A Survey,2025-01-21 10:05:48+00:00,http://arxiv.org/abs/2501.12011v1,"Takumi Ito, Kees van Deemter, Jun Suzuki",cs.CL,dialogue,"A number of automatic evaluation metrics have been proposed for natural
language generation systems. The most common approach to automatic evaluation
is the use of a reference-based metric that compares the model's output with
gold-standard references written by humans. However, it is expensive to create
such references, and for some tasks, such as response generation in dialogue,
creating references is not a simple matter. Therefore, various reference-free
metrics have been developed in recent years. In this survey, which intends to
cover the full breadth of all NLG tasks, we investigate the most commonly used
approaches, their application, and their other uses beyond evaluating models.
The survey concludes by highlighting some promising directions for future
research.",2025-01-21
Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG,2025-01-15 20:40:25+00:00,http://arxiv.org/abs/2501.09136v3,"Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei","cs.AI, cs.CL, cs.IR",dialogue,"Large Language Models (LLMs) have revolutionized artificial intelligence (AI)
by enabling human like text generation and natural language understanding.
However, their reliance on static training data limits their ability to respond
to dynamic, real time queries, resulting in outdated or inaccurate outputs.
Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs
by integrating real time data retrieval to provide contextually relevant and
up-to-date responses. Despite its promise, traditional RAG systems are
constrained by static workflows and lack the adaptability required for
multistep reasoning and complex task management.
  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these
limitations by embedding autonomous AI agents into the RAG pipeline. These
agents leverage agentic design patterns reflection, planning, tool use, and
multiagent collaboration to dynamically manage retrieval strategies,
iteratively refine contextual understanding, and adapt workflows to meet
complex task requirements. This integration enables Agentic RAG systems to
deliver unparalleled flexibility, scalability, and context awareness across
diverse applications.
  This survey provides a comprehensive exploration of Agentic RAG, beginning
with its foundational principles and the evolution of RAG paradigms. It
presents a detailed taxonomy of Agentic RAG architectures, highlights key
applications in industries such as healthcare, finance, and education, and
examines practical implementation strategies. Additionally, it addresses
challenges in scaling these systems, ensuring ethical decision making, and
optimizing performance for real-world applications, while providing detailed
insights into frameworks and tools for implementing Agentic RAG.",2025-01-15
"Creating, Using and Assessing a Generative-AI-Based
  Human-Chatbot-Dialogue Dataset with User-Interaction Learning Capabilities",2025-01-01 10:02:21+00:00,http://arxiv.org/abs/2501.00791v1,"Alfredo Cuzzocrea, Giovanni Pilato, Pablo Garcia Bringas",cs.HC,dialogue,"The study illustrates a first step towards an ongoing work aimed at
developing a dataset of dialogues potentially useful for customer service
conversation management between humans and AI chatbots. The approach exploits
ChatGPT 3.5 to generate dialogues. One of the requirements is that the dialogue
is characterized by a specific language proficiency level of the user; the
other one is that the user expresses a specific emotion during the interaction.
The generated dialogues were then evaluated for overall quality. The complexity
of the language used by both humans and AI agents, has been evaluated by using
standard complexity measurements. Furthermore, the attitudes and interaction
patterns exhibited by the chatbot at each turn have been stored for further
detection of common conversation patterns in specific emotional contexts. The
methodology could improve human-AI dialogue effectiveness and serve as a basis
for systems that can learn from user interactions.",2025-01-01
"FaGeL: Fabric LLMs Agent empowered Embodied Intelligence Evolution with
  Autonomous Human-Machine Collaboration",2024-12-28 23:26:52+00:00,http://arxiv.org/abs/2412.20297v1,"Jia Liu, Min Chen",cs.HC,dialogue,"Recent advancements in Large Language Models (LLMs) have enhanced the
reasoning capabilities of embodied agents, driving progress toward AGI-powered
robotics. While LLMs have been applied to tasks like semantic reasoning and
task generalization, their potential in open physical space exploration remains
underexplored. This paper introduces FaGeL (Fabric aGent empowered by embodied
intelligence with LLMs), an embodied agent integrating smart fabric technology
for seamless, non-intrusive human-agent interaction. FaGeL autonomously
generates tasks using multimodal data from wearable and ambient sensors,
refining its behavior based on implicit human feedback in generated text,
without explicit ratings or preferences. We also introduce a token-level
saliency map to visualize LLM fine-tuning, enhancing the interpretability of
token-level alignment. The system leverages dual feedback mechanisms to improve
token-level alignment and addresses challenges in non-intrusive human-machine
interaction and cognition evolution. Our contributions include FaGeL's
development, the DualCUT algorithm for AI alignment, and experimental
validation in cooperative tasks, demonstrating FaGeL's ability to adapt and
evolve autonomously through implicit feedback. In the future, we plan to
explore FaGeL's scalability in dynamic environments and its integration with
other AI systems to develop AGI agents that adapt seamlessly to diverse human
needs.",2024-12-28
"Friends-MMC: A Dataset for Multi-modal Multi-party Conversation
  Understanding",2024-12-23 05:32:48+00:00,http://arxiv.org/abs/2412.17295v1,"Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Qun Liu, Dongyan Zhao",cs.CL,dialogue,"Multi-modal multi-party conversation (MMC) is a less studied yet important
topic of research due to that it well fits real-world scenarios and thus
potentially has more widely-used applications. Compared with the traditional
multi-modal conversations, MMC requires stronger character-centered
understanding abilities as there are many interlocutors appearing in both the
visual and textual context. To facilitate the study of this problem, we present
Friends-MMC in this paper, an MMC dataset that contains 24,000+ unique
utterances paired with video context. To explore the character-centered
understanding of the dialogue, we also annotate the speaker of each utterance,
the names and bounding bboxes of faces that appear in the video. Based on this
Friends-MMC dataset, we further study two fundamental MMC tasks: conversation
speaker identification and conversation response prediction, both of which have
the multi-party nature with the video or image as visual context. For
conversation speaker identification, we demonstrate the inefficiencies of
existing methods such as pre-trained models, and propose a simple yet effective
baseline method that leverages an optimization solver to utilize the context of
two modalities to achieve better performance. For conversation response
prediction, we fine-tune generative dialogue models on Friend-MMC, and analyze
the benefits of speaker information. The code and dataset is publicly available
at https://github.com/yellow-binary-tree/Friends-MMC and thus we call for more
attention on modeling speaker information when understanding conversations.",2024-12-23
GraphAgent: Agentic Graph Language Assistant,2024-12-22 14:13:32+00:00,http://arxiv.org/abs/2412.17029v1,"Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang",cs.AI,dialogue,"Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.",2024-12-22
"Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental
  Health",2024-12-17 15:01:07+00:00,http://arxiv.org/abs/2412.12981v1,"Vivek Kumar, Eirini Ntoutsi, Pushpraj Singh Rajawat, Giacomo Medda, Diego Reforgiato Recupero",cs.CL,dialogue,"Large language models (LLMs) have shown promising capabilities in healthcare
analysis but face several challenges like hallucinations, parroting, and bias
manifestation. These challenges are exacerbated in complex, sensitive, and
low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an
expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by
generating in-context conversational dialogues leveraging LLMs, particularly
ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues
and tailored information, taking into account therapy style (empathy,
reflection), contextual relevance, and false semantic change. Subsequently, the
dialogues are annotated by experts, strictly adhering to the Motivational
Interviewing Skills Code (MISC), focusing on both the psychological and
linguistic dimensions of MI dialogues. We comprehensively evaluate the
IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding
of domain intricacies by modeling novel classification tasks employing several
classical machine learning and current state-of-the-art transformer approaches.
Finally, we discuss the effects of progressive prompting strategies and the
impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our
contributions provide the MI community with not only a comprehensive dataset
but also valuable insights for using LLMs in empathetic text generation for
conversational therapy in supervised settings.",2024-12-17
"VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video
  Prompting",2024-12-16 10:08:38+00:00,http://arxiv.org/abs/2412.11621v1,"Muhammet Furkan Ilaslan, Ali Koksal, Kevin Qinhong Lin, Burak Satar, Mike Zheng Shou, Qianli Xu","cs.CV, cs.MM",dialogue,"Large Language Model (LLM)-based agents have shown promise in procedural
tasks, but the potential of multimodal instructions augmented by texts and
videos to assist users remains under-explored. To address this gap, we propose
the Visually Grounded Text-Video Prompting (VG-TVP) method which is a novel
LLM-empowered Multimodal Procedural Planning (MPP) framework. It generates
cohesive text and video procedural plans given a specified high-level
objective. The main challenges are achieving textual and visual
informativeness, temporal coherence, and accuracy in procedural plans. VG-TVP
leverages the zero-shot reasoning capability of LLMs, the video-to-text
generation ability of the video captioning models, and the text-to-video
generation ability of diffusion models. VG-TVP improves the interaction between
modalities by proposing a novel Fusion of Captioning (FoC) method and using
Text-to-Video Bridge (T2V-B) and Video-to-Text Bridge (V2T-B). They allow LLMs
to guide the generation of visually-grounded text plans and textual-grounded
video plans. To address the scarcity of datasets suitable for MPP, we have
curated a new dataset called Daily-Life Task Procedural Plans (Daily-PP). We
conduct comprehensive experiments and benchmarks to evaluate human preferences
(regarding textual and visual informativeness, temporal coherence, and plan
accuracy). Our VG-TVP method outperforms unimodal baselines on the Daily-PP
dataset.",2024-12-16
AutoPatent: A Multi-Agent Framework for Automatic Patent Generation,2024-12-13 02:27:34+00:00,http://arxiv.org/abs/2412.09796v1,"Qiyao Wang, Shiwen Ni, Huaren Liu, Shule Lu, Guhong Chen, Xi Feng, Chi Wei, Qiang Qu, Hamid Alinejad-Rokny, Yuan Lin, Min Yang","cs.CL, cs.AI",dialogue,"As the capabilities of Large Language Models (LLMs) continue to advance, the
field of patent processing has garnered increased attention within the natural
language processing community. However, the majority of research has been
concentrated on classification tasks, such as patent categorization and
examination, or on short text generation tasks like patent summarization and
patent quizzes. In this paper, we introduce a novel and practical task known as
Draft2Patent, along with its corresponding D2P benchmark, which challenges LLMs
to generate full-length patents averaging 17K tokens based on initial drafts.
Patents present a significant challenge to LLMs due to their specialized
nature, standardized terminology, and extensive length. We propose a
multi-agent framework called AutoPatent which leverages the LLM-based planner
agent, writer agents, and examiner agent with PGTree and RRAG to generate
lengthy, intricate, and high-quality complete patent documents. The
experimental results demonstrate that our AutoPatent framework significantly
enhances the ability to generate comprehensive patents across various LLMs.
Furthermore, we have discovered that patents generated solely with the
AutoPatent framework based on the Qwen2.5-7B model outperform those produced by
larger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,
in both objective metrics and human evaluations. We will make the data and code
available upon acceptance at \url{https://github.com/QiYao-Wang/AutoPatent}.",2024-12-13
"Improved Large Language Model Jailbreak Detection via Pretrained
  Embeddings",2024-12-02 14:35:43+00:00,http://arxiv.org/abs/2412.01547v1,"Erick Galinkin, Martin Sablotny","cs.CR, cs.AI, cs.LG",dialogue,"The adoption of large language models (LLMs) in many applications, from
customer service chat bots and software development assistants to more capable
agentic systems necessitates research into how to secure these systems. Attacks
like prompt injection and jailbreaking attempt to elicit responses and actions
from these models that are not compliant with the safety, privacy, or content
policies of organizations using the model in their application. In order to
counter abuse of LLMs for generating potentially harmful replies or taking
undesirable actions, LLM owners must apply safeguards during training and
integrate additional tools to block the LLM from generating text that abuses
the model. Jailbreaking prompts play a vital role in convincing an LLM to
generate potentially harmful content, making it important to identify
jailbreaking attempts to block any further steps. In this work, we propose a
novel approach to detect jailbreak prompts based on pairing text embeddings
well-suited for retrieval with traditional machine learning classification
algorithms. Our approach outperforms all publicly available methods from open
source LLM security applications.",2024-12-02
"Is my Meeting Summary Good? Estimating Quality with a Multi-LLM
  Evaluator",2024-11-27 15:35:32+00:00,http://arxiv.org/abs/2411.18444v1,"Frederic Kirstein, Terry Ruas, Bela Gipp","cs.CL, cs.AI",dialogue,"The quality of meeting summaries generated by natural language generation
(NLG) systems is hard to measure automatically. Established metrics such as
ROUGE and BERTScore have a relatively low correlation with human judgments and
fail to capture nuanced errors. Recent studies suggest using large language
models (LLMs), which have the benefit of better context understanding and
adaption of error definitions without training on a large number of human
preference judgments. However, current LLM-based evaluators risk masking errors
and can only serve as a weak proxy, leaving human evaluation the gold standard
despite being costly and hard to compare across studies. In this work, we
present MESA, an LLM-based framework employing a three-step assessment of
individual error types, multi-agent discussion for decision refinement, and
feedback-based self-training to refine error definition understanding and
alignment with human judgment. We show that MESA's components enable thorough
error detection, consistent rating, and adaptability to custom error
guidelines. Using GPT-4o as its backbone, MESA achieves mid to high
Point-Biserial correlation with human judgment in error detection and mid
Spearman and Kendall correlation in reflecting error impact on summary quality,
on average 0.25 higher than previous methods. The framework's flexibility in
adapting to custom error guidelines makes it suitable for various tasks with
limited human-labeled data.",2024-11-27
"SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for
  reference-free open-ended text",2024-11-25 04:07:16+00:00,http://arxiv.org/abs/2411.16077v1,"Reshmi Ghosh, Tianyi Yao, Lizzy Chen, Sadid Hasan, Tianwei Chen, Dario Bernal, Huitian Jiao, H M Sajjad Hossain","cs.CL, cs.MA",dialogue,"Large Language Model (LLM) integrations into applications like Microsoft365
suite and Google Workspace for creating/processing documents, emails,
presentations, etc. has led to considerable enhancements in productivity and
time savings. But as these integrations become more more complex, it is
paramount to ensure that the quality of output from the LLM-integrated
applications are relevant and appropriate for use. Identifying the need to
develop robust evaluation approaches for natural language generation, wherein
references/ground labels doesn't exist or isn't amply available, this paper
introduces a novel framework called ""SAGEval"" which utilizes a critiquing Agent
to provide feedback on scores generated by LLM evaluators. We show that the
critiquing Agent is able to rectify scores from LLM evaluators, in absence of
references/ground-truth labels, thereby reducing the need for labeled data even
for complex NLG evaluation scenarios, like the generation of JSON-structured
forms/surveys with responses in different styles like multiple choice, likert
ratings, single choice questions, etc.",2024-11-25
"Two Heads Are Better Than One: Collaborative LLM Embodied Agents for
  Human-Robot Interaction",2024-11-23 02:47:12+00:00,http://arxiv.org/abs/2411.16723v1,"Mitchell Rosser, Marc. G Carmichael","cs.MA, cs.AI, cs.RO",dialogue,"With the recent development of natural language generation models - termed as
large language models (LLMs) - a potential use case has opened up to improve
the way that humans interact with robot assistants. These LLMs should be able
to leverage their large breadth of understanding to interpret natural language
commands into effective, task appropriate and safe robot task executions.
However, in reality, these models suffer from hallucinations, which may cause
safety issues or deviations from the task. In other domains, these issues have
been improved through the use of collaborative AI systems where multiple LLM
agents can work together to collectively plan, code and self-check outputs. In
this research, multiple collaborative AI systems were tested against a single
independent AI agent to determine whether the success in other domains would
translate into improved human-robot interaction performance. The results show
that there is no defined trend between the number of agents and the success of
the model. However, it is clear that some collaborative AI agent architectures
can exhibit a greatly improved capacity to produce error-free code and to solve
abstract problems.",2024-11-23
Engagement-Driven Content Generation with Large Language Models,2024-11-20 10:40:08+00:00,http://arxiv.org/abs/2411.13187v3,"Erica Coppolillo, Federico Cinus, Marco Minici, Francesco Bonchi, Giuseppe Manco","cs.LG, cs.AI",dialogue,"Large Language Models (LLMs) exhibit significant persuasion capabilities in
one-on-one interactions, but their influence within social networks remains
underexplored. This study investigates the potential social impact of LLMs in
these environments, where interconnected users and complex opinion dynamics
pose unique challenges. In particular, we address the following research
question: can LLMs learn to generate meaningful content that maximizes user
engagement on social networks?
  To answer this question, we define a pipeline to guide the LLM-based content
generation which employs reinforcement learning with simulated feedback. In our
framework, the reward is based on an engagement model borrowed from the
literature on opinion dynamics and information propagation. Moreover, we force
the text generated by the LLM to be aligned with a given topic and to satisfy a
minimum fluency requirement.
  Using our framework, we analyze the capabilities and limitations of LLMs in
tackling the given task, specifically considering the relative positions of the
LLM as an agent within the social network and the distribution of opinions in
the network on the given topic. Our findings show the full potential of LLMs in
creating social engagement. Notable properties of our approach are that the
learning procedure is adaptive to the opinion distribution of the underlying
network and agnostic to the specifics of the engagement model, which is
embedded as a plug-and-play component. In this regard, our approach can be
easily refined for more complex engagement tasks and interventions in
computational social science.
  The code used for the experiments is publicly available at
https://anonymous.4open.science/r/EDCG/.",2024-11-20
"A Combined Encoder and Transformer Approach for Coherent and
  High-Quality Text Generation",2024-11-19 01:41:56+00:00,http://arxiv.org/abs/2411.12157v1,"Jiajing Chen, Shuo Wang, Zhen Qi, Zhenhong Zhang, Chihang Wang, Hongye Zheng",cs.CL,dialogue,"This research introduces a novel text generation model that combines BERT's
semantic interpretation strengths with GPT-4's generative capabilities,
establishing a high standard in generating coherent, contextually accurate
language. Through the combined architecture, the model enhances semantic depth
and maintains smooth, human-like text flow, overcoming limitations seen in
prior models. Experimental benchmarks reveal that BERT-GPT-4 surpasses
traditional models, including GPT-3, T5, BART, Transformer-XL, and CTRL, in key
metrics like Perplexity and BLEU, showcasing its superior natural language
generation performance. By fully utilizing contextual information, this hybrid
model generates text that is not only logically coherent but also aligns
closely with human language patterns, providing an advanced solution for text
generation tasks. This research highlights the potential of integrating
semantic understanding with advanced generative models, contributing new
insights for NLP, and setting a foundation for broader applications of
large-scale generative architectures in areas such as automated writing,
question-answer systems, and adaptive conversational agents.",2024-11-19
"Structured Dialogue System for Mental Health: An LLM Chatbot Leveraging
  the PM+ Guidelines",2024-11-16 03:12:17+00:00,http://arxiv.org/abs/2411.10681v1,"Yixiang Chen, Xinyu Zhang, Jinran Wang, Xurong Xie, Nan Yan, Hui Chen, Lan Wang",cs.CL,dialogue,"The Structured Dialogue System, referred to as SuDoSys, is an innovative
Large Language Model (LLM)-based chatbot designed to provide psychological
counseling. SuDoSys leverages the World Health Organization (WHO)'s Problem
Management Plus (PM+) guidelines to deliver stage-aware multi-turn dialogues.
Existing methods for employing an LLM in multi-turn psychological counseling
typically involve direct fine-tuning using generated dialogues, often
neglecting the dynamic stage shifts of counseling sessions. Unlike previous
approaches, SuDoSys considers the different stages of counseling and stores
essential information throughout the counseling process, ensuring coherent and
directed conversations. The system employs an LLM, a stage-aware instruction
generator, a response unpacker, a topic database, and a stage controller to
maintain dialogue flow. In addition, we propose a novel technique that
simulates counseling clients to interact with the evaluated system and evaluate
its performance automatically. When assessed using both objective and
subjective evaluations, SuDoSys demonstrates its effectiveness in generating
logically coherent responses. The system's code and program scripts for
evaluation are open-sourced.",2024-11-16
"Debias your Large Multi-Modal Model at Test-Time with Non-Contrastive
  Visual Attribute Steering",2024-11-15 20:06:09+00:00,http://arxiv.org/abs/2411.12590v1,"Neale Ratzlaff, Matthew Lyle Olson, Musashi Hinck, Estelle Aflalo, Shao-Yen Tseng, Vasudev Lal, Phillip Howard","cs.CV, cs.LG",dialogue,"Large Multi-Modal Models (LMMs) have demonstrated impressive capabilities as
general-purpose chatbots that can engage in conversations about a provided
input, such as an image. However, their responses are influenced by societal
biases present in their training datasets, leading to undesirable differences
in how the model responds when presented with images depicting people of
different demographics. In this work, we propose a novel debiasing framework
for LMMs that directly removes biased representations during text generation to
decrease outputs related to protected attributes, or even representing them
internally. Our proposed method is training-free; given a single image and a
list of target attributes, we can ablate the corresponding representations with
just one step of gradient descent on the image itself. Our experiments show
that not only can we can minimize the propensity of LMMs to generate text
related to protected attributes, but we can improve sentiment and even simply
use synthetic data to inform the ablation while retaining language modeling
capabilities on real data such as COCO or FACET. Furthermore, we find the
resulting generations from a debiased LMM exhibit similar accuracy as a
baseline biased model, showing that debiasing effects can be achieved without
sacrificing model performance.",2024-11-15
LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models,2024-11-14 17:08:23+00:00,http://arxiv.org/abs/2411.09595v1,"Zhengyi Wang, Jonathan Lorraine, Yikai Wang, Hang Su, Jun Zhu, Sanja Fidler, Xiaohui Zeng","cs.LG, cs.AI, cs.CL, cs.CV, 68T05, I.3.5; I.2.10; I.2.6",dialogue,"This work explores expanding the capabilities of large language models (LLMs)
pretrained on text to generate 3D meshes within a unified model. This offers
key advantages of (1) leveraging spatial knowledge already embedded in LLMs,
derived from textual sources like 3D tutorials, and (2) enabling conversational
3D generation and mesh understanding. A primary challenge is effectively
tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.
To address this, we introduce LLaMA-Mesh, a novel approach that represents the
vertex coordinates and face definitions of 3D meshes as plain text, allowing
direct integration with LLMs without expanding the vocabulary. We construct a
supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate
3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs
as required, and (3) understand and interpret 3D meshes. Our work is the first
to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge
for 3D mesh generation in a text-based format, effectively unifying the 3D and
text modalities. LLaMA-Mesh achieves mesh generation quality on par with models
trained from scratch while maintaining strong text generation performance.",2024-11-14
"Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document
  Relation Extraction with Graph-of-Thoughts Reasoning",2024-11-05 07:12:36+00:00,http://arxiv.org/abs/2411.02864v1,"Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu","cs.CL, cs.AI, cs.IR",dialogue,"Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug"" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
""ensemble-play"", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.",2024-11-05
"NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM
  Inference",2024-11-02 05:15:44+00:00,http://arxiv.org/abs/2411.01142v1,"Xuanlin Jiang, Yang Zhou, Shiyi Cao, Ion Stoica, Minlan Yu","cs.DC, cs.AI, cs.LG",dialogue,"Online LLM inference powers many exciting applications such as intelligent
chatbots and autonomous agents. Modern LLM inference engines widely rely on
request batching to improve inference throughput, aiming to make it
cost-efficient when running on expensive GPU accelerators. However, the limited
GPU memory has largely limited the batch size achieved in practice, leaving
significant GPU compute resources wasted.
  We present NEO, an online LLM inference system that offloads part of
attention compute and KV cache states from the GPU to the local host CPU,
effectively increasing the GPU batch size and thus inference throughput. To
this end, NEO proposes asymmetric GPU-CPU pipelining and load-aware scheduling
to balance GPU and CPU loads and fully utilize their compute and memory
resources. We evaluate NEO on a wide range of workloads (i.e., code generation,
text summarization), GPUs (i.e., T4, A10G, H100), and LLM models (i.e., 7B, 8B,
70B). NEO achieves up to 7.5$\times$, 26%, and 14% higher throughput compared
to GPU-only approach on T4, A10G, and H100 GPUs, respectively, while
maintaining the same latency; with more powerful CPUs, NEO achieves up to 79.3%
throughput gain on A10G GPU.",2024-11-02
"Linguistics Theory Meets LLM: Code-Switched Text Generation via
  Equivalence Constrained Large Language Models",2024-10-30 03:03:32+00:00,http://arxiv.org/abs/2410.22660v1,"Garry Kuwanto, Chaitanya Agarwal, Genta Indra Winata, Derry Tanti Wijaya",cs.CL,dialogue,"Code-switching, the phenomenon of alternating between two or more languages
in a single conversation, presents unique challenges for Natural Language
Processing (NLP). Most existing research focuses on either syntactic
constraints or neural generation, with few efforts to integrate linguistic
theory with large language models (LLMs) for generating natural code-switched
text. In this paper, we introduce EZSwitch, a novel framework that combines
Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid
and fluent code-switched text. We evaluate our method using both human
judgments and automatic metrics, demonstrating a significant improvement in the
quality of generated code-switching sentences compared to baseline LLMs. To
address the lack of suitable evaluation metrics, we conduct a comprehensive
correlation study of various automatic metrics against human scores, revealing
that current metrics often fail to capture the nuanced fluency of code-switched
text. Additionally, we create CSPref, a human preference dataset based on human
ratings and analyze model performance across ``hard`` and ``easy`` examples.
Our findings indicate that incorporating linguistic constraints into LLMs leads
to more robust and human-aligned generation, paving the way for scalable
code-switching text generation across diverse language pairs.",2024-10-30
BENCHAGENTS: Automated Benchmark Creation with Agent Interaction,2024-10-29 22:56:18+00:00,http://arxiv.org/abs/2410.22584v1,"Natasha Butt, Varun Chandrasekaran, Neel Joshi, Besmira Nushi, Vidhisha Balachandran","cs.LG, cs.AI, cs.CL",dialogue,"Evaluations are limited by benchmark availability. As models evolve, there is
a need to create benchmarks that can measure progress on new generative
capabilities. However, creating new benchmarks through human annotations is
slow and expensive, restricting comprehensive evaluations for any capability.
We introduce BENCHAGENTS, a framework that methodically leverages large
language models (LLMs) to automate benchmark creation for complex capabilities
while inherently ensuring data and metric quality. BENCHAGENTS decomposes the
benchmark creation process into planning, generation, data verification, and
evaluation, each of which is executed by an LLM agent. These agents interact
with each other and utilize human-in-the-loop feedback from benchmark
developers to explicitly improve and flexibly control data diversity and
quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities
related to planning and constraint satisfaction during text generation. We then
use these benchmarks to study seven state-of-the-art models and extract new
insights on common failure modes and model differences.",2024-10-29
"An LLM-based Simulation Framework for Embodied Conversational Agents in
  Psychological Counseling",2024-10-29 13:46:52+00:00,http://arxiv.org/abs/2410.22041v2,"Lixiu Wu, Yuanrong Tang, Qisen Pan, Xianyang Zhan, Yucheng Han, Mingyang You, Lanxi Xiao, Tianhong Wang, Chen Zhong, Jiangtao Gong",cs.HC,dialogue,"Simulation is crucial for validating algorithmic strategies in real-world
scenarios. While LLM-based social simulation shows promise as a mainstream
tool, simulating complex scenarios like psychological counseling remains
challenging. We present ECAs (short for Embodied Conversational Agents), a
framework for simulating psychological counseling clients' embodied memory,
integrating embodied cognition and counseling theories. We formulate six design
goals based on a comprehensive review of psychological counseling theories.
Using LLMs, we expand real counseling case data into a nuanced embodied
cognitive memory space and generate dialogues based on high-frequency
counseling questions. We validate our framework using the D4 dataset, with
evaluations by licensed counselors. Results show our approach significantly
outperforms baselines in simulation authenticity and necessity. To demonstrate
scalability, we created a public ECAs dataset through batch simulations. This
research provides valuable insights for future social simulation studies in
psychological counseling and Embodied Counseling Agents research.",2024-10-29
"Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent
  Simulation",2024-10-13 12:57:08+00:00,http://arxiv.org/abs/2410.09824v3,"Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding",cs.CL,dialogue,"Graph generation is a fundamental task that has been extensively studied in
social, technological, and scientific analysis. For modeling the dynamic graph
evolution process, traditional rule-based methods struggle to capture community
structures within graphs, while deep learning methods only focus on fitting
training graphs. This limits existing graph generators to producing graphs that
adhere to predefined rules or closely resemble training datasets, achieving
poor performance in dynamic graph generation. Given that graphs are abstract
representations arising from pairwise interactions in human activities, a
realistic simulation of human-wise interaction could provide deeper insights
into the graph evolution mechanism. With the increasing recognition of large
language models (LLMs) in simulating human behavior, we introduce
GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic
graph generation. Without training or fine-tuning process of LLM, our framework
effectively replicates seven macro-level structural characteristics in
established network science theories while surpassing existing baselines in
graph expansion tasks by 31\% on specific evaluation metrics. Through node
classification task, we validate GAG effectively preserves characteristics of
real-world network for node-wise textual features in generated text-rich graph.
Furthermore, by incorporating parallel acceleration, GAG supports generating
graphs with up to nearly 100,000 nodes or 10 million edges through large-scale
LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code
is available at https://anonymous.4open.science/r/GraphAgent-2206.",2024-10-13
"Experimental Evaluation of Machine Learning Models for Goal-oriented
  Customer Service Chatbot with Pipeline Architecture",2024-09-27 09:11:52+00:00,http://arxiv.org/abs/2409.18568v1,"Nurul Ain Nabilah Mohd Isa, Siti Nuraishah Agos Jawaddi, Azlan Ismail","cs.AI, cs.LG, cs.NE",dialogue,"Integrating machine learning (ML) into customer service chatbots enhances
their ability to understand and respond to user queries, ultimately improving
service performance. However, they may appear artificial to some users and
affecting customer experience. Hence, meticulous evaluation of ML models for
each pipeline component is crucial for optimizing performance, though
differences in functionalities can lead to unfair comparisons. In this paper,
we present a tailored experimental evaluation approach for goal-oriented
customer service chatbots with pipeline architecture, focusing on three key
components: Natural Language Understanding (NLU), dialogue management (DM), and
Natural Language Generation (NLG). Our methodology emphasizes individual
assessment to determine optimal ML models. Specifically, we focus on optimizing
hyperparameters and evaluating candidate models for NLU (utilizing BERT and
LSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT).
The results show that for the NLU component, BERT excelled in intent detection
whereas LSTM was superior for slot filling. For the DM component, the DDQN
model outperformed DQN by achieving fewer turns, higher rewards, as well as
greater success rates. For NLG, the large language model GPT-2 surpassed
DialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a
benchmark for future research in developing and optimizing customer service
chatbots, offering valuable insights into model performance and optimal
hyperparameters.",2024-09-27
AXCEL: Automated eXplainable Consistency Evaluation using LLMs,2024-09-25 14:45:52+00:00,http://arxiv.org/abs/2409.16984v1,"P Aditya Sreekar, Sahil Verma, Suransh Chopra, Sarik Ghazarian, Abhishek Persad, Narayanan Sadagopan","cs.AI, cs.CL",dialogue,"Large Language Models (LLMs) are widely used in both industry and academia
for various tasks, yet evaluating the consistency of generated text responses
continues to be a challenge. Traditional metrics like ROUGE and BLEU show a
weak correlation with human judgment. More sophisticated metrics using Natural
Language Inference (NLI) have shown improved correlations but are complex to
implement, require domain-specific training due to poor cross-domain
generalization, and lack explainability. More recently, prompt-based metrics
using LLMs as evaluators have emerged; while they are easier to implement, they
still lack explainability and depend on task-specific prompts, which limits
their generalizability. This work introduces Automated eXplainable Consistency
Evaluation using LLMs (AXCEL), a prompt-based consistency metric which offers
explanations for the consistency scores by providing detailed reasoning and
pinpointing inconsistent text spans. AXCEL is also a generalizable metric which
can be adopted to multiple tasks without changing the prompt. AXCEL outperforms
both non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting
inconsistencies across summarization by 8.7%, free text generation by 6.2%, and
data-to-text conversion tasks by 29.4%. We also evaluate the influence of
underlying LLMs on prompt based metric performance and recalibrate the SOTA
prompt-based metrics with the latest LLMs for fair comparison. Further, we show
that AXCEL demonstrates strong performance using open source LLMs.",2024-09-25
HLB: Benchmarking LLMs' Humanlikeness in Language Use,2024-09-24 09:02:28+00:00,http://arxiv.org/abs/2409.15890v1,"Xufeng Duan, Bei Xiao, Xuemei Tang, Zhenguang G. Cai",cs.CL,dialogue,"As synthetic data becomes increasingly prevalent in training language models,
particularly through generated dialogue, concerns have emerged that these
models may deviate from authentic human language patterns, potentially losing
the richness and creativity inherent in human communication. This highlights
the critical need to assess the humanlikeness of language models in real-world
language use. In this paper, we present a comprehensive humanlikeness benchmark
(HLB) evaluating 20 large language models (LLMs) using 10 psycholinguistic
experiments designed to probe core linguistic aspects, including sound, word,
syntax, semantics, and discourse (see
https://huggingface.co/spaces/XufengDuan/HumanLikeness). To anchor these
comparisons, we collected responses from over 2,000 human participants and
compared them to outputs from the LLMs in these experiments.
  For rigorous evaluation, we developed a coding algorithm that accurately
identified language use patterns, enabling the extraction of response
distributions for each task. By comparing the response distributions between
human participants and LLMs, we quantified humanlikeness through distributional
similarity. Our results reveal fine-grained differences in how well LLMs
replicate human responses across various linguistic levels. Importantly, we
found that improvements in other performance metrics did not necessarily lead
to greater humanlikeness, and in some cases, even resulted in a decline. By
introducing psycholinguistic methods to model evaluation, this benchmark offers
the first framework for systematically assessing the humanlikeness of LLMs in
language use.",2024-09-24
"The Ability of Large Language Models to Evaluate Constraint-satisfaction
  in Agent Responses to Open-ended Requests",2024-09-22 09:27:42+00:00,http://arxiv.org/abs/2409.14371v1,"Lior Madmoni, Amir Zait, Ilia Labzovsky, Danny Karmon",cs.CL,dialogue,"Generative AI agents are often expected to respond to complex user requests
that have No One Right Answer (NORA), e.g., ""design a vegetarian meal plan
below 1800 calories"". Such requests may entail a set of constraints that the
agent should adhere to. To successfully develop agents for NORA scenarios, an
accurate automatic evaluation framework is essential, and specifically - one
capable of validating the satisfaction of constraints in the agent's response.
Recently, large language models (LLMs) have been adopted as versatile
evaluators for many NORA tasks, but their ability to evaluate
constraint-satisfaction in generated text remains unclear. To study this, we
develop and release a novel Arithmetic Constraint-Satisfaction (ACS)
benchmarking dataset. The dataset consists of complex user requests with
corresponding constraints, agent responses and human labels indicating each
constraint's satisfaction level in the response. A unique property of this
dataset is that validating many of its constraints requires reviewing the
response as a whole (in contrast to many other benchmarks that require the
validation of a single independent item). Moreover, it assesses LLMs in
performing reasoning, in-context data extraction, arithmetic calculations, and
counting. We then benchmark both open and proprietary LLMs on evaluating
constraint-satisfaction, and show that most models still have a significant
headroom for improvement, and that errors primarily stem from reasoning issues.
In addition, most models exhibit a skewed constraint-satisfaction prediction
pattern, with higher accuracy where the ground-truth label is ""satisfied"".
Lastly, few-shot prompting for our task proved to be rather challenging, since
many of the studied models showed a degradation in performance when it was
introduced.",2024-09-22
Recommendation with Generative Models,2024-09-18 18:29:15+00:00,http://arxiv.org/abs/2409.15173v1,"Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Rene Vidal, Maheswaran Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, Francesco Ricci",cs.IR,dialogue,"Generative models are a class of AI models capable of creating new instances
of data by learning and sampling from their statistical distributions. In
recent years, these models have gained prominence in machine learning due to
the development of approaches such as generative adversarial networks (GANs),
variational autoencoders (VAEs), and transformer-based architectures such as
GPT. These models have applications across various domains, such as image
generation, text synthesis, and music composition. In recommender systems,
generative models, referred to as Gen-RecSys, improve the accuracy and
diversity of recommendations by generating structured outputs, text-based
interactions, and multimedia content. By leveraging these capabilities,
Gen-RecSys can produce more personalized, engaging, and dynamic user
experiences, expanding the role of AI in eCommerce, media, and beyond.
  Our book goes beyond existing literature by offering a comprehensive
understanding of generative models and their applications, with a special focus
on deep generative models (DGMs) and their classification. We introduce a
taxonomy that categorizes DGMs into three types: ID-driven models, large
language models (LLMs), and multimodal models. Each category addresses unique
technical and architectural advancements within its respective research area.
This taxonomy allows researchers to easily navigate developments in Gen-RecSys
across domains such as conversational AI and multimodal content generation.
Additionally, we examine the impact and potential risks of generative models,
emphasizing the importance of robust evaluation frameworks.",2024-09-18
Constructing a Singing Style Caption Dataset,2024-09-15 21:19:24+00:00,http://arxiv.org/abs/2409.09866v1,"Hyunjong Ok, Jaeho Lee","cs.CL, cs.AI, cs.LG, cs.SD, eess.AS",dialogue,"Singing voice synthesis and conversion have emerged as significant subdomains
of voice generation, leading to much demands on prompt-conditioned generation.
Unlike common voice data, generating a singing voice requires an understanding
of various associated vocal and musical characteristics, such as the vocal tone
of the singer or emotional expressions. However, existing open-source
audio-text datasets for voice generation tend to capture only a very limited
range of attributes, often missing musical characteristics of the audio. To
fill this gap, we introduce S2Cap, an audio-text pair dataset with a diverse
set of attributes. S2Cap consists of pairs of textual prompts and music audio
samples with a wide range of vocal and musical attributes, including pitch,
volume, tempo, mood, singer's gender and age, and musical genre and emotional
expression. Utilizing S2Cap, we suggest an effective novel baseline algorithm
for singing style captioning. Singing style captioning is a relative task to
voice generation that generates text descriptions of vocal characteristics,
which we first suggested. First, to mitigate the misalignment between the audio
encoder and the text decoder, we present a novel mechanism called CRESCENDO,
which utilizes positive-pair similarity learning to synchronize the embedding
spaces of a pretrained audio encoder to get similar embeddings with a text
encoder. We additionally supervise the model using the singer's voice, which is
demixed by the accompaniment. This supervision allows the model to more
accurately capture vocal characteristics, leading to improved singing style
captions that better reflect the style of the singer. The dataset and the codes
are available at \bulurl{https://github.com/HJ-Ok/S2cap}.",2024-09-15
"Unveiling Gender Bias in Large Language Models: Using Teacher's
  Evaluation in Higher Education As an Example",2024-09-15 07:50:33+00:00,http://arxiv.org/abs/2409.09652v1,Yuanning Huang,cs.CL,dialogue,"This paper investigates gender bias in Large Language Model (LLM)-generated
teacher evaluations in higher education setting, focusing on evaluations
produced by GPT-4 across six academic subjects. By applying a comprehensive
analytical framework that includes Odds Ratio (OR) analysis, Word Embedding
Association Test (WEAT), sentiment analysis, and contextual analysis, this
paper identified patterns of gender-associated language reflecting societal
stereotypes. Specifically, words related to approachability and support were
used more frequently for female instructors, while words related to
entertainment were predominantly used for male instructors, aligning with the
concepts of communal and agentic behaviors. The study also found moderate to
strong associations between male salient adjectives and male names, though
career and family words did not distinctly capture gender biases. These
findings align with prior research on societal norms and stereotypes,
reinforcing the notion that LLM-generated text reflects existing biases.",2024-09-15
"Emerging Reliance Behaviors in Human-AI Text Generation: Hallucinations,
  Data Quality Assessment, and Cognitive Forcing Functions",2024-09-13 15:55:59+00:00,http://arxiv.org/abs/2409.08937v1,"Zahra Ashktorab, Qian Pan, Werner Geyer, Michael Desmond, Marina Danilevsky, James M. Johnson, Casey Dugan, Michelle Bachman",cs.HC,dialogue,"In this paper, we investigate the impact of hallucinations and cognitive
forcing functions in human-AI collaborative text generation tasks, focusing on
the use of Large Language Models (LLMs) to assist in generating high-quality
conversational data. LLMs require data for fine-tuning, a crucial step in
enhancing their performance. In the context of conversational customer support,
the data takes the form of a conversation between a human customer and an agent
and can be generated with an AI assistant. In our inquiry, involving 11 users
who each completed 8 tasks, resulting in a total of 88 tasks, we found that the
presence of hallucinations negatively impacts the quality of data. We also find
that, although the cognitive forcing function does not always mitigate the
detrimental effects of hallucinations on data quality, the presence of
cognitive forcing functions and hallucinations together impacts data quality
and influences how users leverage the AI responses presented to them. Our
analysis of user behavior reveals distinct patterns of reliance on AI-generated
responses, highlighting the importance of managing hallucinations in
AI-generated content within conversational AI contexts.",2024-09-13
"Human Perception of LLM-generated Text Content in Social Media
  Environments",2024-09-10 17:16:42+00:00,http://arxiv.org/abs/2409.06653v1,"Kristina Radivojevic, Matthew Chou, Karla Badillo-Urquiola, Paul Brenner",cs.HC,dialogue,"Emerging technologies, particularly artificial intelligence (AI), and more
specifically Large Language Models (LLMs) have provided malicious actors with
powerful tools for manipulating digital discourse. LLMs have the potential to
affect traditional forms of democratic engagements, such as voter choice,
government surveys, or even online communication with regulators; since bots
are capable of producing large quantities of credible text. To investigate the
human perception of LLM-generated content, we recruited over 1,000 participants
who then tried to differentiate bot from human posts in social media discussion
threads. We found that humans perform poorly at identifying the true nature of
user posts on social media. We also found patterns in how humans identify
LLM-generated text content in social media discourse. Finally, we observed the
Uncanny Valley effect in text dialogue in both user perception and
identification. This indicates that despite humans being poor at the
identification process, they can still sense discomfort when reading
LLM-generated content.",2024-09-10
"TopoChat: Enhancing Topological Materials Retrieval With Large Language
  Model and Multi-Source Knowledge",2024-09-10 06:01:16+00:00,http://arxiv.org/abs/2409.13732v1,"HuangChao Xu, Baohua Zhang, Zhong Jin, Tiannian Zhu, Quansheng Wu, Hongming Weng","cs.CL, cond-mat.mtrl-sci, cs.LG",dialogue,"Large language models (LLMs), such as ChatGPT, have demonstrated impressive
performance in the text generation task, showing the ability to understand and
respond to complex instructions. However, the performance of naive LLMs in
speciffc domains is limited due to the scarcity of domain-speciffc corpora and
specialized training. Moreover, training a specialized large-scale model
necessitates signiffcant hardware resources, which restricts researchers from
leveraging such models to drive advances. Hence, it is crucial to further
improve and optimize LLMs to meet speciffc domain demands and enhance their
scalability. Based on the condensed matter data center, we establish a material
knowledge graph (MaterialsKG) and integrate it with literature. Using large
language models and prompt learning, we develop a specialized dialogue system
for topological materials called TopoChat. Compared to naive LLMs, TopoChat
exhibits superior performance in structural and property querying, material
recommendation, and complex relational reasoning. This system enables efffcient
and precise retrieval of information and facilitates knowledge interaction,
thereby encouraging the advancement on the ffeld of condensed matter materials.",2024-09-10
"MarS: a Financial Market Simulation Engine Powered by Generative
  Foundation Model",2024-09-04 08:16:22+00:00,http://arxiv.org/abs/2409.07486v1,"Junjie Li, Yang Liu, Weiqing Liu, Shikai Fang, Lewen Wang, Chang Xu, Jiang Bian","q-fin.CP, cs.AI, cs.CE, cs.LG, q-fin.TR",dialogue,"Generative models aim to simulate realistic effects of various actions across
different contexts, from text generation to visual effects. Despite efforts to
build real-world simulators, leveraging generative models for virtual worlds,
like financial markets, remains underexplored. In financial markets, generative
models can simulate market effects of various behaviors, enabling interaction
with market scenes and players, and training strategies without financial risk.
This simulation relies on the finest structured data in financial market like
orders thus building the finest realistic simulation. We propose Large Market
Model (LMM), an order-level generative foundation model, for financial market
simulation, akin to language modeling in the digital world. Our financial
Market Simulation engine (MarS), powered by LMM, addresses the need for
realistic, interactive and controllable order generation. Key objectives of
this paper include evaluating LMM's scaling law in financial markets, assessing
MarS's realism, balancing controlled generation with market impact, and
demonstrating MarS's potential applications. We showcase MarS as a forecast
tool, detection system, analysis platform, and agent training environment. Our
contributions include pioneering a generative model for financial markets,
designing MarS to meet domain-specific needs, and demonstrating MarS-based
applications' industry potential.",2024-09-04
Semantically Controllable Augmentations for Generalizable Robot Learning,2024-09-02 05:25:34+00:00,http://arxiv.org/abs/2409.00951v1,"Zoey Chen, Zhao Mandi, Homanga Bharadhwaj, Mohit Sharma, Shuran Song, Abhishek Gupta, Vikash Kumar","cs.RO, cs.AI, cs.CV, cs.LG",dialogue,"Generalization to unseen real-world scenarios for robot manipulation requires
exposure to diverse datasets during training. However, collecting large
real-world datasets is intractable due to high operational costs. For robot
learning to generalize despite these challenges, it is essential to leverage
sources of data or priors beyond the robot's direct experience. In this work,
we posit that image-text generative models, which are pre-trained on large
corpora of web-scraped data, can serve as such a data source. These generative
models encompass a broad range of real-world scenarios beyond a robot's direct
experience and can synthesize novel synthetic experiences that expose robotic
agents to additional world priors aiding real-world generalization at no extra
cost.
  In particular, our approach leverages pre-trained generative models as an
effective tool for data augmentation. We propose a generative augmentation
framework for semantically controllable augmentations and rapidly multiplying
robot datasets while inducing rich variations that enable real-world
generalization. Based on diverse augmentations of robot data, we show how
scalable robot manipulation policies can be trained and deployed both in
simulation and in unseen real-world environments such as kitchens and
table-tops. By demonstrating the effectiveness of image-text generative models
in diverse real-world robotic applications, our generative augmentation
framework provides a scalable and efficient path for boosting generalization in
robot learning at no extra human cost.",2024-09-02
"MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders
  Synthesized via Neuro-Symbolic LLM Agents",2024-08-22 05:59:47+00:00,http://arxiv.org/abs/2408.12142v1,"Congchi Yin, Feng Li, Shu Zhang, Zike Wang, Jun Shao, Piji Li, Jianhua Chen, Xun Jiang","cs.CL, cs.AI",dialogue,"The clinical diagnosis of most mental disorders primarily relies on the
conversations between psychiatrist and patient. The creation of such diagnostic
conversation datasets is promising to boost the AI mental healthcare community.
However, directly collecting the conversations in real diagnosis scenarios is
near impossible due to stringent privacy and ethical considerations. To address
this issue, we seek to synthesize diagnostic conversation by exploiting
anonymous patient cases that are easier to access. Specifically, we design a
neuro-symbolic multi-agent framework for synthesizing the diagnostic
conversation of mental disorders with large language models. It takes patient
case as input and is capable of generating multiple diverse conversations with
one single patient case. The framework basically involves the interaction
between a doctor agent and a patient agent, and achieves text generation under
symbolic control via a dynamic diagnosis tree from a tool agent. By applying
the proposed framework, we develop the largest Chinese mental disorders
diagnosis dataset MDD-5k, which is built upon 1000 cleaned real patient cases
by cooperating with a pioneering psychiatric hospital, and contains 5000
high-quality long conversations with diagnosis results as labels. To the best
of our knowledge, it's also the first labelled Chinese mental disorders
diagnosis dataset. Human evaluation demonstrates the proposed MDD-5k dataset
successfully simulates human-like diagnostic process of mental disorders. The
dataset and code will become publicly accessible in
https://github.com/lemonsis/MDD-5k.",2024-08-22
Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs,2024-08-20 14:45:23+00:00,http://arxiv.org/abs/2408.10902v1,"John Mendonça, Isabel Trancoso, Alon Lavie",cs.CL,dialogue,"Although human evaluation remains the gold standard for open-domain dialogue
evaluation, the growing popularity of automated evaluation using Large Language
Models (LLMs) has also extended to dialogue. However, most frameworks leverage
benchmarks that assess older chatbots on aspects such as fluency and relevance,
which are not reflective of the challenges associated with contemporary models.
In fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,
suggests that current chatbots may exhibit several recurring issues related to
coherence and commonsense knowledge, but generally produce highly fluent and
relevant responses.
  Noting the aforementioned limitations, this paper introduces Soda-Eval, an
annotated dataset based on Soda that covers over 120K turn-level assessments
across 10K dialogues, where the annotations were generated by GPT-4. Using
Soda-Eval as a benchmark, we then study the performance of several open-access
instruction-tuned LLMs, finding that dialogue evaluation remains challenging.
Fine-tuning these models improves performance over few-shot inferences, both in
terms of correlation and explanation.",2024-08-20
Self-Directed Turing Test for Large Language Models,2024-08-19 09:57:28+00:00,http://arxiv.org/abs/2408.09853v1,"Weiqi Wu, Hongqiu Wu, Hai Zhao","cs.CL, cs.AI",dialogue,"The Turing test examines whether AIs can exhibit human-like behaviour in
natural language conversations. Traditional Turing tests adopt a rigid dialogue
format where each participant sends only one message each time and require
continuous human involvement to direct the entire interaction with the test
subject. This fails to reflect a natural conversational style and hinders the
evaluation of Large Language Models (LLMs) in complex and prolonged dialogues.
This paper proposes the Self-Directed Turing Test, which extends the original
test with a burst dialogue format, allowing more dynamic exchanges by multiple
consecutive messages. It further efficiently reduces human workload by having
the LLM self-direct the majority of the test process, iteratively generating
dialogues that simulate its interaction with humans. With the pseudo-dialogue
history, the model then engages in a shorter dialogue with a human, which is
paired with a human-human conversation on the same topic to be judged using
questionnaires. We introduce the X-Turn Pass-Rate metric to assess the human
likeness of LLMs across varying durations. While LLMs like GPT-4 initially
perform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10
turns of dialogues respectively, their performance drops as the dialogue
progresses, which underscores the difficulty in maintaining consistency in the
long term.",2024-08-19
"Fostering Natural Conversation in Large Language Models with NICO: a
  Natural Interactive COnversation dataset",2024-08-18 02:06:25+00:00,http://arxiv.org/abs/2408.09330v1,"Renliang Sun, Mengyuan Liu, Shiping Yang, Rui Wang, Junqing He, Jiaxing Zhang",cs.CL,dialogue,"Benefiting from diverse instruction datasets, contemporary Large Language
Models (LLMs) perform effectively as AI assistants in collaborating with
humans. However, LLMs still struggle to generate natural and colloquial
responses in real-world applications such as chatbots and psychological
counseling that require more human-like interactions. To address these
limitations, we introduce NICO, a Natural Interactive COnversation dataset in
Chinese. We first use GPT-4-turbo to generate dialogue drafts and make them
cover 20 daily-life topics and 5 types of social interactions. Then, we hire
workers to revise these dialogues to ensure that they are free of grammatical
errors and unnatural utterances. We define two dialogue-level natural
conversation tasks and two sentence-level tasks for identifying and rewriting
unnatural sentences. Multiple open-source and closed-source LLMs are tested and
analyzed in detail. The experimental results highlight the challenge of the
tasks and demonstrate how NICO can help foster the natural dialogue
capabilities of LLMs. The dataset will be released.",2024-08-18
An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation,2024-08-16 10:33:19+00:00,http://arxiv.org/abs/2408.08650v1,"Peiming Guo, Sinuo Liu, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang",cs.CL,dialogue,"Photo-Sharing Multi-modal dialogue generation requires a dialogue agent not
only to generate text responses but also to share photos at the proper moment.
Using image text caption as the bridge, a pipeline model integrates an image
caption model, a text generation model, and an image generation model to handle
this complex multi-modal task. However, representing the images with text
captions may loss important visual details and information and cause error
propagation in the complex dialogue system. Besides, the pipeline model
isolates the three models separately because discrete image text captions
hinder end-to-end gradient propagation. We propose the first end-to-end model
for photo-sharing multi-modal dialogue generation, which integrates an image
perceptron and an image generator with a large language model. The large
language model employs the Q-Former to perceive visual images in the input end.
For image generation in the output end, we propose a dynamic vocabulary
transformation matrix and use straight-through and gumbel-softmax techniques to
align the large language model and stable diffusion model and achieve
end-to-end gradient propagation. We perform experiments on PhotoChat and
DialogCC datasets to evaluate our end-to-end model. Compared with pipeline
models, the end-to-end model gains state-of-the-art performances on various
metrics of text and image generation. More analysis experiments also verify the
effectiveness of the end-to-end model for photo-sharing multi-modal dialogue
generation.",2024-08-16
"Synthetic Patient-Physician Dialogue Generation from Clinical Notes
  Using LLM",2024-08-12 16:49:22+00:00,http://arxiv.org/abs/2408.06285v1,"Trisha Das, Dina Albassam, Jimeng Sun","cs.CL, cs.AI, cs.LG",dialogue,"Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.",2024-08-12
"LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial
  Description",2024-08-09 09:22:40+00:00,http://arxiv.org/abs/2408.04957v3,"Yizhang Jin, Jian Li, Jiangning Zhang, Jianlong Hu, Zhenye Gan, Xin Tan, Yong Liu, Yabiao Wang, Chengjie Wang, Lizhuang Ma","cs.CV, cs.AI",dialogue,"Visual Spatial Description (VSD) aims to generate texts that describe the
spatial relationships between objects within images. Traditional visual spatial
relationship classification (VSRC) methods typically output the spatial
relationship between two objects in an image, often neglecting world knowledge
and lacking general language capabilities. In this paper, we propose a Large
Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD,
which is designed for the classification, description, and open-ended
description of visual spatial relationships. Specifically, the model first
constructs a VSD instruction-following dataset using given figure-caption pairs
for the three tasks. It then employs LoRA to fine-tune a Large Language and
Vision Assistant for VSD, which has 13 billion parameters and supports
high-resolution images. Finally, a large language model (Qwen-2) is used to
refine the generated sentences, enhancing their diversity and accuracy.
LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can
follow open-ended instructions to assist with inquiries about object
relationships in images.",2024-08-09
"Multi-Turn Context Jailbreak Attack on Large Language Models From First
  Principles",2024-08-08 09:18:47+00:00,http://arxiv.org/abs/2408.04686v1,"Xiongtao Sun, Deyue Zhang, Dongdong Yang, Quanchen Zou, Hui Li","cs.CL, cs.AI",dialogue,"Large language models (LLMs) have significantly enhanced the performance of
numerous applications, from intelligent conversations to text generation.
However, their inherent security vulnerabilities have become an increasingly
significant challenge, especially with respect to jailbreak attacks. Attackers
can circumvent the security mechanisms of these LLMs, breaching security
constraints and causing harmful outputs. Focusing on multi-turn semantic
jailbreak attacks, we observe that existing methods lack specific
considerations for the role of multiturn dialogues in attack strategies,
leading to semantic deviations during continuous interactions. Therefore, in
this paper, we establish a theoretical foundation for multi-turn attacks by
considering their support in jailbreak attacks, and based on this, propose a
context-based contextual fusion black-box jailbreak attack method, named
Context Fusion Attack (CFA). This method approach involves filtering and
extracting key terms from the target, constructing contextual scenarios around
these terms, dynamically integrating the target into the scenarios, replacing
malicious key terms within the target, and thereby concealing the direct
malicious intent. Through comparisons on various mainstream LLMs and red team
datasets, we have demonstrated CFA's superior success rate, divergence, and
harmfulness compared to other multi-turn attack strategies, particularly
showcasing significant advantages on Llama3 and GPT-4.",2024-08-08
Target Prompting for Information Extraction with Vision Language Model,2024-08-07 15:17:51+00:00,http://arxiv.org/abs/2408.03834v1,Dipankar Medhi,"cs.CV, cs.AI",dialogue,"The recent trend in the Large Vision and Language model has brought a new
change in how information extraction systems are built. VLMs have set a new
benchmark with their State-of-the-art techniques in understanding documents and
building question-answering systems across various industries. They are
significantly better at generating text from document images and providing
accurate answers to questions. However, there are still some challenges in
effectively utilizing these models to build a precise conversational system.
General prompting techniques used with large language models are often not
suitable for these specially designed vision language models. The output
generated by such generic input prompts is ordinary and may contain information
gaps when compared with the actual content of the document. To obtain more
accurate and specific answers, a well-targeted prompt is required by the vision
language model, along with the document image. In this paper, a technique is
discussed called Target prompting, which focuses on explicitly targeting parts
of document images and generating related answers from those specific regions
only. The paper also covers the evaluation of response for each prompting
technique using different user queries and input prompts.",2024-08-07
"Empathy Level Alignment via Reinforcement Learning for Empathetic
  Response Generation",2024-08-06 06:16:00+00:00,http://arxiv.org/abs/2408.02976v1,"Hui Ma, Bo Zhang, Bo Xu, Jian Wang, Hongfei Lin, Xiao Sun","cs.CL, cs.AI",dialogue,"Empathetic response generation, aiming at understanding the user's situation
and feelings and respond empathically, is crucial in building human-like
dialogue systems. Previous methods mainly focus on using maximum likelihood
estimation as the optimization objective for training response generation
models, without taking into account the empathy level alignment between
generated responses and target responses. To this end, we propose an empathetic
response generation using reinforcement learning (EmpRL) framework. The
framework designs an effective empathy reward function and generates empathetic
responses by maximizing the expected reward through reinforcement learning.
Given the powerful text generation capability of pre-trained language models,
EmpRL utilizes the pre-trained T5 model as the generator and conducts further
training to initialize the policy. To align the empathy level between generated
responses and target responses in the context, an empathy reward function
containing three empathy communication mechanisms, i.e., emotional reaction,
interpretation, and exploration, is constructed using pre-designed and
pre-trained empathy identifiers. Finally, the proximal policy optimization
algorithm is used to further train the policy to produce empathetic responses.
Both automatic and manual evaluations demonstrate that the proposed EmpRL
framework can improve the quality of generated responses, enhance the empathy
level similarity between generated and target responses, and produce empathetic
responses covering both affective and cognitive aspects.",2024-08-06
"Transforming Slot Schema Induction with Generative Dialogue State
  Inference",2024-08-03 02:41:10+00:00,http://arxiv.org/abs/2408.01638v1,"James D. Finch, Boxin Zhao, Jinho D. Choi",cs.CL,dialogue,"The challenge of defining a slot schema to represent the state of a
task-oriented dialogue system is addressed by Slot Schema Induction (SSI),
which aims to automatically induce slots from unlabeled dialogue data. Whereas
previous approaches induce slots by clustering value spans extracted directly
from the dialogue text, we demonstrate the power of discovering slots using a
generative approach. By training a model to generate slot names and values that
summarize key dialogue information with no prior task knowledge, our SSI method
discovers high-quality candidate information for representing dialogue state.
These discovered slot-value candidates can be easily clustered into unified
slot schemas that align well with human-authored schemas. Experimental
comparisons on the MultiWOZ and SGD datasets demonstrate that Generative
Dialogue State Inference (GenDSI) outperforms the previous state-of-the-art on
multiple aspects of the SSI task.",2024-08-03
"Are Large Language Models Possible to Conduct Cognitive Behavioral
  Therapy?",2024-07-25 03:01:47+00:00,http://arxiv.org/abs/2407.17730v1,"Hao Shen, Zihan Li, Minqiang Yang, Minghui Ni, Yongfeng Tao, Zhengyang Yu, Weihao Zheng, Chen Xu, Bin Hu",cs.CL,dialogue,"In contemporary society, the issue of psychological health has become
increasingly prominent, characterized by the diversification, complexity, and
universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently
the most influential and clinically effective psychological treatment method
with no side effects, has limited coverage and poor quality in most countries.
In recent years, researches on the recognition and intervention of emotional
disorders using large language models (LLMs) have been validated, providing new
possibilities for psychological assistance therapy. However, are LLMs truly
possible to conduct cognitive behavioral therapy? Many concerns have been
raised by mental health experts regarding the use of LLMs for therapy. Seeking
to answer this question, we collected real CBT corpus from online video
websites, designed and conducted a targeted automatic evaluation framework
involving the evaluation of emotion tendency of generated text, structured
dialogue pattern and proactive inquiry ability. For emotion tendency, we
calculate the emotion tendency score of the CBT dialogue text generated by each
model. For structured dialogue pattern, we use a diverse range of automatic
evaluation metrics to compare speaking style, the ability to maintain
consistency of topic and the use of technology in CBT between different models
. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning
Ability) metric. We also evaluated the CBT ability of the LLM after integrating
a CBT knowledge base to explore the help of introducing additional knowledge to
enhance the model's CBT counseling ability. Four LLM variants with excellent
performance on natural language processing are evaluated, and the experimental
result shows the great potential of LLMs in psychological counseling realm,
especially after combining with other technological means.",2024-07-25
"An Empirical Study of Retrieval Augmented Generation with
  Chain-of-Thought",2024-07-22 11:55:14+00:00,http://arxiv.org/abs/2407.15569v1,"Yuetong Zhao, Hongyu Cao, Xianyu Zhao, Zhijian Ou",cs.CL,dialogue,"Since the launch of ChatGPT at the end of 2022, generative dialogue models
represented by ChatGPT have quickly become essential tools in daily life. As
user expectations increase, enhancing the capability of generative dialogue
models to solve complex problems has become a focal point of current research.
This paper delves into the effectiveness of the RAFT (Retrieval Augmented
Fine-Tuning) method in improving the performance of Generative dialogue models.
RAFT combines chain-of-thought with model supervised fine-tuning (SFT) and
retrieval augmented generation (RAG), which significantly enhanced the model's
information extraction and logical reasoning abilities. We evaluated the RAFT
method across multiple datasets and analysed its performance in various
reasoning tasks, including long-form QA and short-form QA tasks, tasks in both
Chinese and English, and supportive and comparison reasoning tasks. Notably, it
addresses the gaps in previous research regarding long-form QA tasks and
Chinese datasets. Moreover, we also evaluate the benefit of the
chain-of-thought (CoT) in the RAFT method. This work offers valuable insights
for studies focused on enhancing the performance of generative dialogue models.",2024-07-22
"KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with
  Large Language Models",2024-07-19 12:13:08+00:00,http://arxiv.org/abs/2407.14239v1,"Kemou Jiang, Xuan Cai, Zhiyong Cui, Aoyong Li, Yilong Ren, Haiyang Yu, Hao Yang, Daocheng Fu, Licheng Wen, Pinlong Cai",cs.AI,dialogue,"Large language models (LLMs) as autonomous agents offer a novel avenue for
tackling real-world challenges through a knowledge-driven manner. These
LLM-enhanced methodologies excel in generalization and interpretability.
However, the complexity of driving tasks often necessitates the collaboration
of multiple, heterogeneous agents, underscoring the need for such LLM-driven
agents to engage in cooperative knowledge sharing and cognitive synergy.
Despite the promise of LLMs, current applications predominantly center around
single agent scenarios. To broaden the horizons of knowledge-driven strategies
and bolster the generalization capabilities of autonomous agents, we propose
the KoMA framework consisting of multi-agent interaction, multi-step planning,
shared-memory, and ranking-based reflection modules to enhance multi-agents'
decision-making in complex driving scenarios. Based on the framework's
generated text descriptions of driving scenarios, the multi-agent interaction
module enables LLM agents to analyze and infer the intentions of surrounding
vehicles, akin to human cognition. The multi-step planning module enables LLM
agents to analyze and obtain final action decisions layer by layer to ensure
consistent goals for short-term action decisions. The shared memory module can
accumulate collective experience to make superior decisions, and the
ranking-based reflection module can evaluate and improve agent behavior with
the aim of enhancing driving safety and efficiency. The KoMA framework not only
enhances the robustness and adaptability of autonomous driving agents but also
significantly elevates their generalization capabilities across diverse
scenarios. Empirical results demonstrate the superiority of our approach over
traditional methods, particularly in its ability to handle complex,
unpredictable driving environments without extensive retraining.",2024-07-19
"Towards Dataset-scale and Feature-oriented Evaluation of Text
  Summarization in Large Language Model Prompts",2024-07-16 21:36:43+00:00,http://arxiv.org/abs/2407.12192v2,"Sam Yu-Te Lee, Aryaman Bahukhandi, Dongyu Liu, Kwan-Liu Ma",cs.HC,dialogue,"Recent advancements in Large Language Models (LLMs) and Prompt Engineering
have made chatbot customization more accessible, significantly reducing
barriers to tasks that previously required programming skills. However, prompt
evaluation, especially at the dataset scale, remains complex due to the need to
assess prompts across thousands of test instances within a dataset. Our study,
based on a comprehensive literature review and pilot study, summarized five
critical challenges in prompt evaluation. In response, we introduce a
feature-oriented workflow for systematic prompt evaluation. In the context of
text summarization, our workflow advocates evaluation with summary
characteristics (feature metrics) such as complexity, formality, or
naturalness, instead of using traditional quality metrics like ROUGE. This
design choice enables a more user-friendly evaluation of prompts, as it guides
users in sorting through the ambiguity inherent in natural language. To support
this workflow, we introduce Awesum, a visual analytics system that facilitates
identifying optimal prompt refinements for text summarization through
interactive visualizations, featuring a novel Prompt Comparator design that
employs a BubbleSet-inspired design enhanced by dimensionality reduction
techniques. We evaluate the effectiveness and general applicability of the
system with practitioners from various domains and found that (1) our design
helps overcome the learning curve for non-technical people to conduct a
systematic evaluation of summarization prompts, and (2) our feature-oriented
workflow has the potential to generalize to other NLG and image-generation
tasks. For future works, we advocate moving towards feature-oriented evaluation
of LLM prompts and discuss unsolved challenges in terms of human-agent
interaction.",2024-07-16
Do LLMs have Consistent Values?,2024-07-16 08:58:00+00:00,http://arxiv.org/abs/2407.12878v2,"Naama Rozen, Gal Elidan, Amir Globerson, Ella Daniel","cs.CL, cs.AI",dialogue,"Values are a basic driving force underlying human behavior. Large Language
Models (LLM) technology is constantly improving towards human-like dialogue.
However, little research has been done to study the values exhibited in text
generated by LLMs. Here we study this question by turning to the rich
literature on value structure in psychology. We ask whether LLMs exhibit the
same value structure that has been demonstrated in humans, including the
ranking of values, and correlation between values. We show that the results of
this analysis strongly depend on how the LLM is prompted, and that under a
particular prompting strategy (referred to as 'Value Anchoring') the agreement
with human data is quite compelling. Our results serve both to improve our
understanding of values in LLMs, as well as introduce novel methods for
assessing consistency in LLM responses.",2024-07-16
"Review-Feedback-Reason (ReFeR): A Novel Framework for NLG Evaluation and
  Reasoning",2024-07-16 08:25:26+00:00,http://arxiv.org/abs/2407.12877v1,"Yaswanth Narsupalli, Abhranil Chandra, Sreevatsa Muppirala, Manish Gupta, Pawan Goyal","cs.CL, cs.AI",dialogue,"Assessing the quality of Natural Language Generation (NLG) outputs, such as
those produced by large language models (LLMs), poses significant challenges.
Traditional approaches involve either resource-intensive human evaluations or
automatic metrics, which often exhibit a low correlation with human judgment.
In this study, we propose Review-Feedback-Reason (ReFeR), a novel evaluation
framework for NLG using LLM agents. We rigorously test ReFeR using two
pre-existing benchmark datasets on diverse NLG tasks. The proposed framework
not only enhances the accuracy of NLG evaluation, surpassing previous
benchmarks by $\sim$20\%, but also generates constructive feedback and
significantly improves collective reasoning. This feedback is then leveraged
for the creation of instruction-tuning datasets, which, when used to fine-tune
smaller models like Mistral-7B, makes them extremely good evaluators, yielding
a better correlation with human evaluations and performance nearly on par with
GPT-3.5. We highlight the effectiveness of our methodology through its
application on three reasoning benchmarks, where it outperforms most of the
state-of-the-art methods, and also outperforms the reasoning capabilities of
models like GPT-3.5 Turbo by $\sim$11.67\% and GPT-4 by $\sim$1\% on an
average.",2024-07-16
AI AI Bias: Large Language Models Favor Their Own Generated Content,2024-07-09 13:15:14+00:00,http://arxiv.org/abs/2407.12856v1,"Walter Laurito, Benjamin Davis, Peli Grietzer, Tomáš Gavenčiak, Ada Böhm, Jan Kulveit","cs.CL, cs.AI, cs.CY, cs.LG",dialogue,"Are large language models (LLMs) biased towards text generated by LLMs over
text authored by humans, leading to possible anti-human bias? Utilizing a
classical experimental design inspired by employment discrimination studies, we
tested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice
scenarios. These involved LLM-based agents selecting between products and
academic papers described either by humans or LLMs under identical conditions.
Our results show a consistent tendency for LLM-based AIs to prefer
LLM-generated content. This suggests the possibility of AI systems implicitly
discriminating against humans, giving AI agents an unfair advantage.",2024-07-09
LLM Roleplay: Simulating Human-Chatbot Interaction,2024-07-04 14:49:46+00:00,http://arxiv.org/abs/2407.03974v1,"Hovhannes Tamoyan, Hendrik Schuff, Iryna Gurevych",cs.CL,dialogue,"The development of chatbots requires collecting a large number of
human-chatbot dialogues to reflect the breadth of users' sociodemographic
backgrounds and conversational goals. However, the resource requirements to
conduct the respective user studies can be prohibitively high and often only
allow for a narrow analysis of specific dialogue goals and participant
demographics. In this paper, we propose LLM-Roleplay: a goal-oriented,
persona-based method to automatically generate diverse multi-turn dialogues
simulating human-chatbot interaction. LLM-Roleplay can be applied to generate
dialogues with any type of chatbot and uses large language models (LLMs) to
play the role of textually described personas. To validate our method we
collect natural human-chatbot dialogues from different sociodemographic groups
and conduct a human evaluation to compare real human-chatbot dialogues with our
generated dialogues. We compare the abilities of state-of-the-art LLMs in
embodying personas and holding a conversation and find that our method can
simulate human-chatbot dialogues with a high indistinguishability rate.",2024-07-04
"Predicting vs. Acting: A Trade-off Between World Modeling & Agent
  Modeling",2024-07-02 17:22:54+00:00,http://arxiv.org/abs/2407.02446v1,"Margaret Li, Weijia Shi, Artidoro Pagnoni, Peter West, Ari Holtzman","cs.CL, cs.AI",dialogue,"RLHF-aligned LMs have shown unprecedented ability on both benchmarks and
long-form text generation, yet they struggle with one foundational task:
next-token prediction. As RLHF models become agent models aimed at interacting
with humans, they seem to lose their world modeling -- the ability to predict
what comes next in arbitrary documents, which is the foundational training
objective of the Base LMs that RLHF adapts.
  Besides empirically demonstrating this trade-off, we propose a potential
explanation: to perform coherent long-form generation, RLHF models restrict
randomness via implicit blueprints. In particular, RLHF models concentrate
probability on sets of anchor spans that co-occur across multiple generations
for the same prompt, serving as textual scaffolding but also limiting a model's
ability to generate documents that do not include these spans. We study this
trade-off on the most effective current agent models, those aligned with RLHF,
while exploring why this may remain a fundamental trade-off between models that
act and those that predict, even as alignment techniques improve.",2024-07-02
"Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models
  with Personality-Indicative Data",2024-06-27 06:24:00+00:00,http://arxiv.org/abs/2406.18921v2,"Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang",cs.CL,dialogue,"Role-playing agents (RPA) have been a popular application area for large
language models (LLMs), attracting significant interest from both industry and
academia.While existing RPAs well portray the characters' knowledge and tones,
they face challenges in capturing their minds, especially for small
role-playing language models (RPLMs). In this paper, we propose to enhance
RPLMs via personality-indicative data. Specifically, we leverage questions from
psychological scales and distill advanced RPAs to generate dialogues that grasp
the minds of characters. Experimental results validate that RPLMs trained with
our dataset exhibit advanced role-playing capabilities for both general and
personality-related evaluations. Code and data are available at
\href{https://github.com/alienet1109/RolePersonality}{this URL}.",2024-06-27
Towards a Science Exocortex,2024-06-24 14:32:32+00:00,http://arxiv.org/abs/2406.17809v1,Kevin G. Yager,cs.AI,dialogue,"Artificial intelligence (AI) methods are poised to revolutionize intellectual
work, with generative AI enabling automation of text analysis, text generation,
and simple decision making or reasoning. The impact to science is only just
beginning, but the opportunity is significant since scientific research relies
fundamentally on extended chains of cognitive work. Here, we review the state
of the art in agentic AI systems, and discuss how these methods could be
extended to have even greater impact on science. We propose the development of
an exocortex, a synthetic extension of a person's cognition. A science
exocortex could be designed as a swarm of AI agents, with each agent
individually streamlining specific researcher tasks, and whose
inter-communication leads to emergent behavior that greatly extend the
researcher's cognition and volition.",2024-06-24
"Data Augmentation of Multi-turn Psychological Dialogue via
  Knowledge-driven Progressive Thought Prompting",2024-06-24 12:02:56+00:00,http://arxiv.org/abs/2406.16567v1,"Jiyue Jiang, Liheng Chen, Sheng Wang, Lingpeng Kong, Yu Li, Chuan Wu",cs.CL,dialogue,"Existing dialogue data augmentation (DA) techniques predominantly focus on
augmenting utterance-level dialogues, which makes it difficult to take dialogue
contextual information into account. The advent of large language models (LLMs)
has simplified the implementation of multi-turn dialogues. Due to absence of
professional understanding and knowledge, it remains challenging to deliver
satisfactory performance in low-resource domain, like psychological dialogue
dialogue. DA involves creating new training or prompting data based on the
existing data, which help the model better understand and generate
psychology-related responses. In this paper, we aim to address the issue of
multi-turn dialogue data augmentation for boosted performance in the psychology
domain. We propose a knowledge-driven progressive thought prompting method to
guide LLM to generate multi-turn psychology-related dialogue. This method
integrates a progressive thought generator, a psychology knowledge generator,
and a multi-turn dialogue generator. The thought generated by the progressive
thought generator serves as a prompt to prevent the generated dialogue from
having significant semantic deviations, while the psychology knowledge
generator produces psychological knowledge to serve as the dialogue history for
the LLM, guiding the dialogue generator to create multi-turn psychological
dialogue. To ensure the precision of multi-turn psychological dialogue
generation by LLM, a meticulous professional evaluation is required. Extensive
experiments conducted on three datasets related to psychological dialogue
verify the effectiveness of the proposed method.",2024-06-24
Unsupervised Extraction of Dialogue Policies from Conversations,2024-06-21 14:57:25+00:00,http://arxiv.org/abs/2406.15214v1,"Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien",cs.CL,dialogue,"Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.",2024-06-21
"CELL your Model: Contrastive Explanation Methods for Large Language
  Models",2024-06-17 17:39:10+00:00,http://arxiv.org/abs/2406.11785v1,"Ronny Luss, Erik Miehling, Amit Dhurandhar","cs.CL, cs.AI, cs.LG",dialogue,"The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI such
as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a distance function that has meaning to the user and not necessarily a
real valued representation of a specific response (viz. class label). We offer
two algorithms for finding contrastive explanations: i) A myopic algorithm,
which although effective in creating contrasts, requires many model calls and
ii) A budgeted algorithm, our main algorithmic contribution, which
intelligently creates contrasts adhering to a query budget, necessary for
longer contexts. We show the efficacy of these methods on diverse natural
language tasks such as open-text generation, automated red teaming, and
explaining conversational degradation.",2024-06-17
A Full-duplex Speech Dialogue Scheme Based On Large Language Models,2024-05-29 20:05:46+00:00,http://arxiv.org/abs/2405.19487v1,"Peng Wang, Songshuo Lu, Yaohua Tang, Sijie Yan, Yuanjun Xiong, Wei Xia",cs.CL,dialogue,"We present a generative dialogue system capable of operating in a full-duplex
manner, allowing for seamless interaction. It is based on a large language
model (LLM) carefully aligned to be aware of a perception module, a motor
function module, and the concept of a simple finite state machine (called
neural FSM) with two states. The perception and motor function modules operate
simultaneously, allowing the system to simultaneously speak and listen to the
user. The LLM generates textual tokens for inquiry responses and makes
autonomous decisions to start responding to, wait for, or interrupt the user by
emitting control tokens to the neural FSM. All these tasks of the LLM are
carried out as next token prediction on a serialized view of the dialogue in
real-time. In automatic quality evaluations simulating real-life interaction,
the proposed system reduces the average conversation response latency by more
than 3 folds compared with LLM-based half-duplex dialogue systems while
responding within less than 500 milliseconds in more than 50% of evaluated
interactions. Running a LLM with only 8 billion parameters, our system exhibits
a 8% higher interruption precision rate than the best available commercial LLM
for voice-based dialogue.",2024-05-29
"Automatic detection of cognitive impairment in elderly people using an
  entertainment chatbot with Natural Language Processing capabilities",2024-05-28 19:17:48+00:00,http://arxiv.org/abs/2405.18542v1,"Francisco de Arriba-Pérez, Silvia García-Méndez, Francisco J. González-Castaño, Enrique Costa-Montenegro","cs.AI, cs.CL, cs.HC, cs.LG",dialogue,"Previous researchers have proposed intelligent systems for therapeutic
monitoring of cognitive impairments. However, most existing practical
approaches for this purpose are based on manual tests. This raises issues such
as excessive caretaking effort and the white-coat effect. To avoid these
issues, we present an intelligent conversational system for entertaining
elderly people with news of their interest that monitors cognitive impairment
transparently. Automatic chatbot dialogue stages allow assessing content
description skills and detecting cognitive impairment with Machine Learning
algorithms. We create these dialogue flows automatically from updated news
items using Natural Language Generation techniques. The system also infers the
gold standard of the answers to the questions, so it can assess cognitive
capabilities automatically by comparing these answers with the user responses.
It employs a similarity metric with values in [0, 1], in increasing level of
similarity. To evaluate the performance and usability of our approach, we have
conducted field tests with a test group of 30 elderly people in the earliest
stages of dementia, under the supervision of gerontologists. In the
experiments, we have analysed the effect of stress and concentration in these
users. Those without cognitive impairment performed up to five times better. In
particular, the similarity metric varied between 0.03, for stressed and
unfocused participants, and 0.36, for relaxed and focused users. Finally, we
developed a Machine Learning algorithm based on textual analysis features for
automatic cognitive impairment detection, which attained accuracy, F-measure
and recall levels above 80%. We have thus validated the automatic approach to
detect cognitive impairment in elderly people based on entertainment content.",2024-05-28
"Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial
  Framework Driven by Large Language Models",2024-05-23 14:48:15+00:00,http://arxiv.org/abs/2405.14646v1,"Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li",cs.CL,dialogue,"The automatic evaluation of natural language generation (NLG) systems
presents a long-lasting challenge. Recent studies have highlighted various
neural metrics that align well with human evaluations. Yet, the robustness of
these evaluators against adversarial perturbations remains largely
under-explored due to the unique challenges in obtaining adversarial data for
different NLG evaluation tasks. To address the problem, we introduce AdvEval, a
novel black-box adversarial framework against NLG evaluators. AdvEval is
specially tailored to generate data that yield strong disagreements between
human and victim evaluators. Specifically, inspired by the recent success of
large language models (LLMs) in text generation and evaluation, we adopt strong
LLMs as both the data generator and gold evaluator. Adversarial data are
automatically optimized with feedback from the gold and victim evaluator. We
conduct experiments on 12 victim evaluators and 11 NLG datasets, spanning tasks
including dialogue, summarization, and question evaluation. The results show
that AdvEval can lead to significant performance degradation of various victim
metrics, thereby validating its efficacy.",2024-05-23
"Large Language Models (LLMs) Assisted Wireless Network Deployment in
  Urban Settings",2024-05-22 05:19:51+00:00,http://arxiv.org/abs/2405.13356v1,"Nurullah Sevim, Mostafa Ibrahim, Sabit Ekin",cs.AI,dialogue,"The advent of Large Language Models (LLMs) has revolutionized language
understanding and human-like text generation, drawing interest from many other
fields with this question in mind: What else are the LLMs capable of? Despite
their widespread adoption, ongoing research continues to explore new ways to
integrate LLMs into diverse systems.
  This paper explores new techniques to harness the power of LLMs for 6G (6th
Generation) wireless communication technologies, a domain where automation and
intelligent systems are pivotal. The inherent adaptability of LLMs to
domain-specific tasks positions them as prime candidates for enhancing wireless
systems in the 6G landscape.
  We introduce a novel Reinforcement Learning (RL) based framework that
leverages LLMs for network deployment in wireless communications. Our approach
involves training an RL agent, utilizing LLMs as its core, in an urban setting
to maximize coverage. The agent's objective is to navigate the complexities of
urban environments and identify the network parameters for optimal area
coverage. Additionally, we integrate LLMs with Convolutional Neural Networks
(CNNs) to capitalize on their strengths while mitigating their limitations. The
Deep Deterministic Policy Gradient (DDPG) algorithm is employed for training
purposes. The results suggest that LLM-assisted models can outperform CNN-based
models in some cases while performing at least as well in others.",2024-05-22
ProtT3: Protein-to-Text Generation for Text-based Protein Understanding,2024-05-21 08:06:13+00:00,http://arxiv.org/abs/2405.12564v1,"Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua","q-bio.QM, cs.CL, cs.MM",dialogue,"Language Models (LMs) excel in understanding textual descriptions of
proteins, as evident in biomedical question-answering tasks. However, their
capability falters with raw protein data, such as amino acid sequences, due to
a deficit in pretraining on such data. Conversely, Protein Language Models
(PLMs) can understand and convert protein data into high-quality
representations, but struggle to process texts. To address their limitations,
we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based
Protein Understanding. ProtT3 empowers an LM to understand protein sequences of
amino acids by incorporating a PLM as its protein understanding module,
enabling effective protein-to-text generation. This collaboration between PLM
and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges
the modality gap between the PLM's representation space and the LM's input
space. Unlike previous studies focusing on protein property prediction and
protein-text retrieval, we delve into the largely unexplored field of
protein-to-text generation. To facilitate comprehensive benchmarks and promote
future research, we establish quantitative evaluations for protein-text
modeling tasks, including protein captioning, protein question-answering, and
protein-text retrieval. Our experiments show that ProtT3 substantially
surpasses current baselines, with ablation studies further highlighting the
efficacy of its core components. Our code is available at
https://github.com/acharkq/ProtT3.",2024-05-21
SirLLM: Streaming Infinite Retentive LLM,2024-05-21 06:37:03+00:00,http://arxiv.org/abs/2405.12528v1,"Yao Yao, Zuchao Li, Hai Zhao",cs.CL,dialogue,"As Large Language Models (LLMs) become increasingly prevalent in various
domains, their ability to process inputs of any length and maintain a degree of
memory becomes essential. However, the one-off input of overly long texts is
limited, as studies have shown that when input lengths exceed the LLMs'
pre-trained text length, there is a dramatic decline in text generation
capabilities. Moreover, simply extending the length of pre-training texts is
impractical due to the difficulty in obtaining long text data and the
substantial memory consumption costs this would entail for LLMs. Recent efforts
have employed streaming inputs to alleviate the pressure of excessively long
text inputs, but this approach can significantly impair the model's long-term
memory capabilities.
  Motivated by this challenge, we introduce Streaming Infinite Retentive LLM
(SirLLM), which allows LLMs to maintain longer memory during infinite-length
dialogues without the need for fine-tuning. SirLLM utilizes the Token Entropy
metric and a memory decay mechanism to filter key phrases, endowing LLMs with
both long-lasting and flexible memory. We designed three distinct tasks and
constructed three datasets to measure the effectiveness of SirLLM from various
angles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors. Our
experimental results robustly demonstrate that SirLLM can achieve stable and
significant improvements across different LLMs and tasks, compellingly proving
its effectiveness. When having a coversation, ""A sir could forget himself,"" but
SirLLM never does! Our code is publicly available at
https://github.com/Zoeyyao27/SirLLM",2024-05-21
"Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue
  State Tracking",2024-05-21 03:04:14+00:00,http://arxiv.org/abs/2405.12468v1,"James D. Finch, Boxin Zhao, Jinho D. Choi",cs.CL,dialogue,"This work demonstrates that substantial gains in zero-shot dialogue state
tracking (DST) accuracy can be achieved by increasing the diversity of training
data using synthetic data generation techniques. Current DST training resources
are severely limited in the number of application domains and slot types they
cover due to the high costs of data collection, resulting in limited
adaptability to new domains. The presented work overcomes this challenge using
a novel, fully automatic data generation approach to create synthetic zero-shot
DST training resources. Unlike previous approaches for generating DST data, the
presented approach generates entirely new application domains to generate
dialogues, complete with silver dialogue state annotations and slot
descriptions. This approach is used to create the D0T dataset for training
zero-shot DST models, which covers an unprecedented 1,000+ domains. Experiments
performed on the MultiWOZ benchmark indicate that training models on diverse
synthetic data yields a performance improvement of +6.7% Joint Goal Accuracy,
achieving results competitive with much larger models.",2024-05-21
"Enhancing Dialogue State Tracking Models through LLM-backed User-Agents
  Simulation",2024-05-17 07:00:05+00:00,http://arxiv.org/abs/2405.13037v1,"Cheng Niu, Xingguang Wang, Xuxin Cheng, Juntong Song, Tong Zhang","cs.CL, cs.AI",dialogue,"Dialogue State Tracking (DST) is designed to monitor the evolving dialogue
state in the conversations and plays a pivotal role in developing task-oriented
dialogue systems. However, obtaining the annotated data for the DST task is
usually a costly endeavor. In this paper, we focus on employing LLMs to
generate dialogue data to reduce dialogue collection and annotation costs.
Specifically, GPT-4 is used to simulate the user and agent interaction,
generating thousands of dialogues annotated with DST labels. Then a two-stage
fine-tuning on LLaMA 2 is performed on the generated data and the real data for
the DST prediction. Experimental results on two public DST benchmarks show that
with the generated dialogue data, our model performs better than the baseline
trained solely on real data. In addition, our approach is also capable of
adapting to the dynamic demands in real-world scenarios, generating dialogues
in new domains swiftly. After replacing dialogue segments in any domain with
the corresponding generated ones, the model achieves comparable performance to
the model trained on real data.",2024-05-17
"A Systematic Evaluation of Large Language Models for Natural Language
  Generation Tasks",2024-05-16 16:56:54+00:00,http://arxiv.org/abs/2405.10251v1,"Xuanfan Ni, Piji Li",cs.CL,dialogue,"Recent efforts have evaluated large language models (LLMs) in areas such as
commonsense reasoning, mathematical reasoning, and code generation. However, to
the best of our knowledge, no work has specifically investigated the
performance of LLMs in natural language generation (NLG) tasks, a pivotal
criterion for determining model excellence. Thus, this paper conducts a
comprehensive evaluation of well-known and high-performing LLMs, namely
ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models,
in the context of NLG tasks. We select English and Chinese datasets
encompassing Dialogue Generation and Text Summarization. Moreover, we propose a
common evaluation setting that incorporates input templates and post-processing
strategies. Our study reports both automatic results, accompanied by a detailed
analysis.",2024-05-16
"Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource
  Dialogue Generation",2024-05-16 14:21:33+00:00,http://arxiv.org/abs/2405.10121v1,"Bo Zhang, Hui Ma, Jian Ding, Jian Wang, Bo Xu, Hongfei Lin","cs.CL, cs.MM",dialogue,"Integrating multimodal knowledge into large language models (LLMs) represents
a significant advancement in dialogue generation capabilities. However, the
effective incorporation of such knowledge in zero-resource scenarios remains a
substantial challenge due to the scarcity of diverse, high-quality dialogue
datasets. To address this, we propose the Visual Implicit Knowledge
Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs
for enriched dialogue generation in zero-resource contexts by leveraging
implicit multimodal knowledge. VIKDF comprises two main stages: knowledge
distillation, using an Implicit Query Transformer to extract and encode visual
implicit knowledge from image-text pairs into knowledge vectors; and knowledge
integration, employing a novel Bidirectional Variational Information Fusion
technique to seamlessly integrate these distilled vectors into LLMs. This
enables the LLMs to generate dialogues that are not only coherent and engaging
but also exhibit a deep understanding of the context through implicit
multimodal cues, effectively overcoming the limitations of zero-resource
scenarios. Our extensive experimentation across two dialogue datasets shows
that VIKDF outperforms existing state-of-the-art models in generating
high-quality dialogues. The code will be publicly available following
acceptance.",2024-05-16
DEBATE: Devil's Advocate-Based Assessment and Text Evaluation,2024-05-16 09:41:12+00:00,http://arxiv.org/abs/2405.09935v2,"Alex Kim, Keonwoo Kim, Sangwon Yoon","cs.CL, cs.AI",dialogue,"As natural language generation (NLG) models have become prevalent,
systematically assessing the quality of machine-generated texts has become
increasingly important. Recent studies introduce LLM-based evaluators that
operate as reference-free metrics, demonstrating their capability to adeptly
handle novel tasks. However, these models generally rely on a single-agent
approach, which, we argue, introduces an inherent limit to their performance.
This is because there exist biases in LLM agent's responses, including
preferences for certain text structure or content. In this work, we propose
DEBATE, an NLG evaluation framework based on multi-agent scoring system
augmented with a concept of Devil's Advocate. Within the framework, one agent
is instructed to criticize other agents' arguments, potentially resolving the
bias in LLM agent's answers. DEBATE substantially outperforms the previous
state-of-the-art methods in two meta-evaluation benchmarks in NLG evaluation,
SummEval and TopicalChat. We also show that the extensiveness of debates among
agents and the persona of an agent can influence the performance of evaluators.",2024-05-16
Layout Generation Agents with Large Language Models,2024-05-13 06:27:23+00:00,http://arxiv.org/abs/2405.08037v1,"Yuichi Sasazawa, Yasuhiro Sogawa","cs.HC, cs.AI",dialogue,"In recent years, there has been an increasing demand for customizable 3D
virtual spaces. Due to the significant human effort required to create these
virtual spaces, there is a need for efficiency in virtual space creation. While
existing studies have proposed methods for automatically generating layouts
such as floor plans and furniture arrangements, these methods only generate
text indicating the layout structure based on user instructions, without
utilizing the information obtained during the generation process. In this
study, we propose an agent-driven layout generation system using the GPT-4V
multimodal large language model and validate its effectiveness. Specifically,
the language model manipulates agents to sequentially place objects in the
virtual space, thus generating layouts that reflect user instructions.
Experimental results confirm that our proposed method can generate virtual
spaces reflecting user instructions with a high success rate. Additionally, we
successfully identified elements contributing to the improvement in behavior
generation performance through ablation study.",2024-05-13
"Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat
  Trick in Legislation",2024-05-07 13:55:11+00:00,http://arxiv.org/abs/2405.04325v1,"Atharvan Dogra, Ameet Deshpande, John Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran",cs.CL,dialogue,"Recent developments in large language models (LLMs), while offering a
powerful foundation for developing natural language agents, raise safety
concerns about them and the autonomous agents built upon them. Deception is one
potential capability of AI agents of particular concern, which we refer to as
an act or statement that misleads, hides the truth, or promotes a belief that
is not true in its entirety or in part. We move away from the conventional
understanding of deception through straight-out lying, making objective selfish
decisions, or giving false information, as seen in previous AI safety research.
We target a specific category of deception achieved through obfuscation and
equivocation. We broadly explain the two types of deception by analogizing them
with the rabbit-out-of-hat magic trick, where (i) the rabbit either comes out
of a hidden trap door or (ii) (our focus) the audience is completely distracted
to see the magician bring out the rabbit right in front of them using sleight
of hand or misdirection. Our novel testbed framework displays intrinsic
deception capabilities of LLM agents in a goal-driven environment when directed
to be deceptive in their natural language generations in a two-agent
adversarial dialogue system built upon the legislative task of ""lobbying"" for a
bill. Along the lines of a goal-driven environment, we show developing
deceptive capacity through a reinforcement learning setup, building it around
the theories of language philosophy and cognitive psychology. We find that the
lobbyist agent increases its deceptive capabilities by ~ 40% (relative) through
subsequent reinforcement trials of adversarial interactions, and our deception
detection mechanism shows a detection capability of up to 92%. Our results
highlight potential issues in agent-human interaction, with agents potentially
manipulating humans towards its programmed end-goal.",2024-05-07
"Large Language Models as Instruments of Power: New Regimes of Autonomous
  Manipulation and Control",2024-05-06 19:52:57+00:00,http://arxiv.org/abs/2405.03813v1,"Yaqub Chaudhary, Jonnie Penn","cs.SI, cs.CY",dialogue,"Large language models (LLMs) can reproduce a wide variety of rhetorical
styles and generate text that expresses a broad spectrum of sentiments. This
capacity, now available at low cost, makes them powerful tools for manipulation
and control. In this paper, we consider a set of underestimated societal harms
made possible by the rapid and largely unregulated adoption of LLMs. Rather
than consider LLMs as isolated digital artefacts used to displace this or that
area of work, we focus on the large-scale computational infrastructure upon
which they are instrumentalised across domains. We begin with discussion on how
LLMs may be used to both pollute and uniformize information environments and
how these modalities may be leveraged as mechanisms of control. We then draw
attention to several areas of emerging research, each of which compounds the
capabilities of LLMs as instruments of power. These include (i) persuasion
through the real-time design of choice architectures in conversational
interfaces (e.g., via ""AI personas""), (ii) the use of LLM-agents as
computational models of human agents (e.g., ""silicon subjects""), (iii) the use
of LLM-agents as computational models of human agent populations (e.g.,
""silicon societies"") and finally, (iv) the combination of LLMs with
reinforcement learning to produce controllable and steerable strategic dialogue
models. We draw these strands together to discuss how these areas may be
combined to build LLM-based systems that serve as powerful instruments of
individual, social and political control via the simulation and disingenuous
""prediction"" of human behaviour, intent, and action.",2024-05-06
Online Personalizing White-box LLMs Generation with Neural Bandits,2024-04-24 18:13:12+00:00,http://arxiv.org/abs/2404.16115v1,"Zekai Chen, Weeden Daniel, Po-yu Chen, Francois Buet-Golfouse","cs.CL, cs.AI, cs.LG",dialogue,"The advent of personalized content generation by LLMs presents a novel
challenge: how to efficiently adapt text to meet individual preferences without
the unsustainable demand of creating a unique model for each user. This study
introduces an innovative online method that employs neural bandit algorithms to
dynamically optimize soft instruction embeddings based on user feedback,
enhancing the personalization of open-ended text generation by white-box LLMs.
Through rigorous experimentation on various tasks, we demonstrate significant
performance improvements over baseline strategies. NeuralTS, in particular,
leads to substantial enhancements in personalized news headline generation,
achieving up to a 62.9% improvement in terms of best ROUGE scores and up to
2.76% increase in LLM-agent evaluation against the baseline.",2024-04-24
"Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal
  LLMs",2024-04-23 18:00:09+00:00,http://arxiv.org/abs/2404.15406v1,"Davide Caffagni, Federico Cocchi, Nicholas Moratelli, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara","cs.CV, cs.AI, cs.CL, cs.MM",dialogue,"Multimodal LLMs are the natural evolution of LLMs, and enlarge their
capabilities so as to work beyond the pure textual modality. As research is
being carried out to design novel architectures and vision-and-language
adapters, in this paper we concentrate on endowing such models with the
capability of answering questions that require external knowledge. Our
approach, termed Wiki-LLaVA, aims at integrating an external knowledge source
of multimodal documents, which is accessed through a hierarchical retrieval
pipeline. Relevant passages, using this approach, are retrieved from the
external knowledge source and employed as additional context for the LLM,
augmenting the effectiveness and precision of generated dialogues. We conduct
extensive experiments on datasets tailored for visual question answering with
external data and demonstrate the appropriateness of our approach.",2024-04-23
"Can We Catch the Elephant? The Evolvement of Hallucination Evaluation on
  Natural Language Generation: A Survey",2024-04-18 09:52:18+00:00,http://arxiv.org/abs/2404.12041v1,"Siya Qi, Yulan He, Zheng Yuan","cs.CL, cs.AI",dialogue,"Hallucination in Natural Language Generation (NLG) is like the elephant in
the room, obvious but often overlooked until recent achievements significantly
improved the fluency and grammatical accuracy of generated text. For Large
Language Models (LLMs), hallucinations can happen in various downstream tasks
and casual conversations, which need accurate assessment to enhance reliability
and safety. However, current studies on hallucination evaluation vary greatly,
and people still find it difficult to sort out and select the most appropriate
evaluation methods. Moreover, as NLP research gradually shifts to the domain of
LLMs, it brings new challenges to this direction. This paper provides a
comprehensive survey on the evolvement of hallucination evaluation methods,
aiming to address three key aspects: 1) Diverse definitions and granularity of
facts; 2) The categories of automatic evaluators and their applicability; 3)
Unresolved issues and future directions.",2024-04-18
"LaDiC: Are Diffusion Models Really Inferior to Autoregressive
  Counterparts for Image-to-Text Generation?",2024-04-16 17:47:16+00:00,http://arxiv.org/abs/2404.10763v1,"Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun","cs.AI, cs.CL, cs.CV",dialogue,"Diffusion models have exhibited remarkable capabilities in text-to-image
generation. However, their performance in image-to-text generation,
specifically image captioning, has lagged behind Auto-Regressive (AR) models,
casting doubt on their applicability for such tasks. In this work, we revisit
diffusion models, highlighting their capacity for holistic context modeling and
parallel decoding. With these benefits, diffusion models can alleviate the
inherent limitations of AR methods, including their slow inference speed, error
propagation, and unidirectional constraints. Furthermore, we identify the prior
underperformance of diffusion models stemming from the absence of an effective
latent space for image-text alignment, and the discrepancy between continuous
diffusion processes and discrete textual data. In response, we introduce a
novel architecture, LaDiC, which utilizes a split BERT to create a dedicated
latent space for captions and integrates a regularization module to manage
varying text lengths. Our framework also includes a diffuser for semantic
image-to-text conversion and a Back&Refine technique to enhance token
interactivity during inference. LaDiC achieves state-of-the-art performance for
diffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2
CIDEr, demonstrating exceptional performance without pre-training or ancillary
modules. This indicates strong competitiveness with AR models, revealing the
previously untapped potential of diffusion models in image-to-text generation.",2024-04-16
"White Men Lead, Black Women Help: Uncovering Gender, Racial, and
  Intersectional Bias in Language Agency",2024-04-16 12:27:54+00:00,http://arxiv.org/abs/2404.10508v1,"Yixin Wan, Kai-Wei Chang","cs.CL, cs.AI, cs.CY",dialogue,"Social biases can manifest in language agency. For instance, White
individuals and men are often described as ""agentic"" and achievement-oriented,
whereas Black individuals and women are frequently described as ""communal"" and
as assisting roles. This study establishes agency as an important aspect of
studying social biases in both human-written and Large Language Model
(LLM)-generated texts. To accurately measure ""language agency"" at sentence
level, we propose a Language Agency Classification dataset to train reliable
agency classifiers. We then use an agency classifier to reveal notable language
agency biases in 6 datasets of human- or LLM-written texts, including
biographies, professor reviews, and reference letters. While most prior NLP
research on agency biases focused on single dimensions, we comprehensively
explore language agency biases in gender, race, and intersectional identities.
We observe that (1) language agency biases in human-written texts align with
real-world social observations; (2) LLM-generated texts demonstrate remarkably
higher levels of language agency bias than human-written texts; and (3)
critical biases in language agency target people of minority groups -- for
instance, languages used to describe Black females exhibit the lowest level of
agency across datasets. Our findings reveal intricate social biases in human-
and LLM-written texts through the lens of language agency, warning against
using LLM generations in social contexts without scrutiny.",2024-04-16
Towards Enhancing Health Coaching Dialogue in Low-Resource Settings,2024-04-13 03:23:15+00:00,http://arxiv.org/abs/2404.08888v1,"Yue Zhou, Barbara Di Eugenio, Brian Ziebart, Lisa Sharp, Bing Liu, Ben Gerber, Nikolaos Agadakos, Shweta Yadav","cs.CL, cs.LG",dialogue,"Health coaching helps patients identify and accomplish lifestyle-related
goals, effectively improving the control of chronic diseases and mitigating
mental health conditions. However, health coaching is cost-prohibitive due to
its highly personalized and labor-intensive nature. In this paper, we propose
to build a dialogue system that converses with the patients, helps them create
and accomplish specific goals, and can address their emotions with empathy.
However, building such a system is challenging since real-world health coaching
datasets are limited and empathy is subtle. Thus, we propose a modularized
health coaching dialogue system with simplified NLU and NLG frameworks combined
with mechanism-conditioned empathetic response generation. Through automatic
and human evaluation, we show that our system generates more empathetic,
fluent, and coherent responses and outperforms the state-of-the-art in NLU
tasks while requiring less annotation. We view our approach as a key step
towards building automated and more accessible health coaching systems.",2024-04-13
Audio Dialogues: Dialogues dataset for audio and music understanding,2024-04-11 10:08:34+00:00,http://arxiv.org/abs/2404.07616v1,"Arushi Goel, Zhifeng Kong, Rafael Valle, Bryan Catanzaro","cs.CL, cs.SD, eess.AS",dialogue,"Existing datasets for audio understanding primarily focus on single-turn
interactions (i.e. audio captioning, audio question answering) for describing
audio in natural language, thus limiting understanding audio via interactive
dialogue. To address this gap, we introduce Audio Dialogues: a multi-turn
dialogue dataset containing 163.8k samples for general audio sounds and music.
In addition to dialogues, Audio Dialogues also has question-answer pairs to
understand and compare multiple input audios together. Audio Dialogues
leverages a prompting-based approach and caption annotations from existing
datasets to generate multi-turn dialogues using a Large Language Model (LLM).
We evaluate existing audio-augmented large language models on our proposed
dataset to demonstrate the complexity and applicability of Audio Dialogues. Our
code for generating the dataset will be made publicly available. Detailed
prompts and generated dialogues can be found on the demo website
https://audiodialogues.github.io/.",2024-04-11
"Control-DAG: Constrained Decoding for Non-Autoregressive Directed
  Acyclic T5 using Weighted Finite State Automata",2024-04-10 09:28:14+00:00,http://arxiv.org/abs/2404.06854v1,"Jinghong Chen, Weizhe Lin, Jingbiao Mei, Bill Byrne","cs.CL, I.2",dialogue,"The Directed Acyclic Transformer is a fast non-autoregressive (NAR) model
that performs well in Neural Machine Translation. Two issues prevent its
application to general Natural Language Generation (NLG) tasks: frequent
Out-Of-Vocabulary (OOV) errors and the inability to faithfully generate entity
names. We introduce Control-DAG, a constrained decoding algorithm for our
Directed Acyclic T5 (DA-T5) model which offers lexical, vocabulary and length
control. We show that Control-DAG significantly enhances DA-T5 on the Schema
Guided Dialogue and the DART datasets, establishing strong NAR results for
Task-Oriented Dialogue and Data-to-Text NLG.",2024-04-10
"CoVoMix: Advancing Zero-Shot Speech Generation for Human-like
  Multi-talker Conversations",2024-04-10 02:32:58+00:00,http://arxiv.org/abs/2404.06690v1,"Leying Zhang, Yao Qian, Long Zhou, Shujie Liu, Dongmei Wang, Xiaofei Wang, Midia Yousefi, Yanmin Qian, Jinyu Li, Lei He, Sheng Zhao, Michael Zeng","eess.AS, cs.AI, cs.CL, cs.LG, cs.SD",dialogue,"Recent advancements in zero-shot text-to-speech (TTS) modeling have led to
significant strides in generating high-fidelity and diverse speech. However,
dialogue generation, along with achieving human-like naturalness in speech,
continues to be a challenge in the field. In this paper, we introduce CoVoMix:
Conversational Voice Mixture Generation, a novel model for zero-shot,
human-like, multi-speaker, multi-round dialogue speech generation. CoVoMix is
capable of first converting dialogue text into multiple streams of discrete
tokens, with each token stream representing semantic information for individual
talkers. These token streams are then fed into a flow-matching based acoustic
model to generate mixed mel-spectrograms. Finally, the speech waveforms are
produced using a HiFi-GAN model. Furthermore, we devise a comprehensive set of
metrics for measuring the effectiveness of dialogue modeling and generation.
Our experimental results show that CoVoMix can generate dialogues that are not
only human-like in their naturalness and coherence but also involve multiple
talkers engaging in multiple rounds of conversation. These dialogues, generated
within a single channel, are characterized by seamless speech transitions,
including overlapping speech, and appropriate paralinguistic behaviors such as
laughter. Audio samples are available at https://aka.ms/covomix.",2024-04-10
Pitfalls of Conversational LLMs on News Debiasing,2024-04-09 17:42:59+00:00,http://arxiv.org/abs/2404.06488v1,"Ipek Baris Schlicht, Defne Altiok, Maryanne Taouk, Lucie Flek","cs.CL, cs.AI",dialogue,"This paper addresses debiasing in news editing and evaluates the
effectiveness of conversational Large Language Models in this task. We designed
an evaluation checklist tailored to news editors' perspectives, obtained
generated texts from three popular conversational models using a subset of a
publicly available dataset in media bias, and evaluated the texts according to
the designed checklist. Furthermore, we examined the models as evaluator for
checking the quality of debiased model outputs. Our findings indicate that none
of the LLMs are perfect in debiasing. Notably, some models, including ChatGPT,
introduced unnecessary changes that may impact the author's style and create
misinformation. Lastly, we show that the models do not perform as proficiently
as domain experts in evaluating the quality of debiased outputs.",2024-04-09
"MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended
  Text Evaluation",2024-03-28 10:41:47+00:00,http://arxiv.org/abs/2403.19305v2,"Yu Li, Shenyu Zhang, Rui Wu, Xiutian Huang, Yongrui Chen, Wenhao Xu, Guilin Qi, Dehai Min","cs.CL, cs.AI",dialogue,"Recent advancements in generative Large Language Models(LLMs) have been
remarkable, however, the quality of the text generated by these models often
reveals persistent issues. Evaluating the quality of text generated by these
models, especially in open-ended text, has consistently presented a significant
challenge. Addressing this, recent work has explored the possibility of using
LLMs as evaluators. While using a single LLM as an evaluation agent shows
potential, it is filled with significant uncertainty and instability. To
address these issues, we propose the MATEval: A ""Multi-Agent Text Evaluation
framework"" where all agents are played by LLMs like GPT-4. The MATEval
framework emulates human collaborative discussion methods, integrating multiple
agents' interactions to evaluate open-ended text. Our framework incorporates
self-reflection and Chain-of-Thought (CoT) strategies, along with feedback
mechanisms, enhancing the depth and breadth of the evaluation process and
guiding discussions towards consensus, while the framework generates
comprehensive evaluation reports, including error localization, error types and
scoring. Experimental results show that our framework outperforms existing
open-ended text evaluation methods and achieves the highest correlation with
human evaluation, which confirms the effectiveness and advancement of our
framework in addressing the uncertainties and instabilities in evaluating
LLMs-generated text. Furthermore, our framework significantly improves the
efficiency of text evaluation and model iteration in industrial scenarios.",2024-03-28
Outcome-Constrained Large Language Models for Countering Hate Speech,2024-03-25 19:44:06+00:00,http://arxiv.org/abs/2403.17146v1,"Lingzi Hong, Pengcheng Luo, Eduardo Blanco, Xiaoying Song",cs.CL,dialogue,"Counterspeech that challenges or responds to hate speech has been seen as an
alternative to mitigate the negative impact of hate speech and foster
productive online communications. Research endeavors have been directed to
using language models for the automatic generation of counterspeech to assist
efforts in combating online hate. Existing research focuses on the generation
of counterspeech with certain linguistic attributes, such as being polite,
informative, and intent-driven. However, it remains unclear what impact the
counterspeech might have in an online environment. We first explore methods
that utilize large language models (LLM) to generate counterspeech constrained
by potential conversation outcomes. We build two conversation outcome
classifiers that predict the incivility level and the hater reentry behavior
following replies to hate with Reddit data, then propose four methods to
incorporate the desired outcomes, i.e., low conversation incivility and
non-hateful hater reentry, into the text generation process, including Prompt
with Instructions, Prompt and Select, LLM finetune, and LLM transformer
reinforcement learning (TRL). Evaluation results show effective strategies to
generate outcome-constrained counterspeech and the linguistic characteristics
of texts generated by different methods.",2024-03-25
"Grammatical vs Spelling Error Correction: An Investigation into the
  Responsiveness of Transformer-based Language Models using BART and MarianMT",2024-03-25 11:45:21+00:00,http://arxiv.org/abs/2403.16655v1,"Rohit Raju, Peeta Basa Pati, SA Gandheesh, Gayatri Sanjana Sannala, Suriya KS",cs.CL,dialogue,"Text continues to remain a relevant form of representation for information.
Text documents are created either in digital native platforms or through the
conversion of other media files such as images and speech. While the digital
native text is invariably obtained through physical or virtual keyboards,
technologies such as OCR and speech recognition are utilized to transform the
images and speech signals into text content. All these variety of mechanisms of
text generation also introduce errors into the captured text.
  This project aims at analyzing different kinds of error that occurs in text
documents. The work employs two of the advanced deep neural network-based
language models, namely, BART and MarianMT, to rectify the anomalies present in
the text. Transfer learning of these models with available dataset is performed
to finetune their capacity for error correction. A comparative study is
conducted to investigate the effectiveness of these models in handling each of
the defined error categories. It is observed that while both models can bring
down the erroneous sentences by 20+%, BART can handle spelling errors far
better (24.6%) than grammatical errors (8.8%).",2024-03-25
"Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk
  Assessment Proposal",2024-03-20 05:17:22+00:00,http://arxiv.org/abs/2403.13309v1,"Rahul Pankajakshan, Sumitra Biswal, Yuvaraj Govindarajulu, Gilad Gressel","cs.CR, cs.AI",dialogue,"The rapid integration of Large Language Models (LLMs) across diverse sectors
has marked a transformative era, showcasing remarkable capabilities in text
generation and problem-solving tasks. However, this technological advancement
is accompanied by significant risks and vulnerabilities. Despite ongoing
security enhancements, attackers persistently exploit these weaknesses, casting
doubts on the overall trustworthiness of LLMs. Compounding the issue,
organisations are deploying LLM-integrated systems without understanding the
severity of potential consequences. Existing studies by OWASP and MITRE offer a
general overview of threats and vulnerabilities but lack a method for directly
and succinctly analysing the risks for security practitioners, developers, and
key decision-makers who are working with this novel technology. To address this
gap, we propose a risk assessment process using tools like the OWASP risk
rating methodology which is used for traditional systems. We conduct scenario
analysis to identify potential threat agents and map the dependent system
components against vulnerability factors. Through this analysis, we assess the
likelihood of a cyberattack. Subsequently, we conduct a thorough impact
analysis to derive a comprehensive threat matrix. We also map threats against
three key stakeholder groups: developers engaged in model fine-tuning,
application developers utilizing third-party APIs, and end users. The proposed
threat matrix provides a holistic evaluation of LLM-related risks, enabling
stakeholders to make informed decisions for effective mitigation strategies.
Our outlined process serves as an actionable and comprehensive tool for
security practitioners, offering insights for resource management and enhancing
the overall system security.",2024-03-20
ConvSDG: Session Data Generation for Conversational Search,2024-03-17 20:34:40+00:00,http://arxiv.org/abs/2403.11335v1,"Fengran Mo, Bole Yi, Kelong Mao, Chen Qu, Kaiyu Huang, Jian-Yun Nie","cs.IR, cs.CL",dialogue,"Conversational search provides a more convenient interface for users to
search by allowing multi-turn interaction with the search engine. However, the
effectiveness of the conversational dense retrieval methods is limited by the
scarcity of training data required for their fine-tuning. Thus, generating more
training conversational sessions with relevant labels could potentially improve
search performance. Based on the promising capabilities of large language
models (LLMs) on text generation, we propose ConvSDG, a simple yet effective
framework to explore the feasibility of boosting conversational search by using
LLM for session data generation. Within this framework, we design
dialogue/session-level and query-level data generation with unsupervised and
semi-supervised learning, according to the availability of relevance judgments.
The generated data are used to fine-tune the conversational dense retriever.
Extensive experiments on four widely used datasets demonstrate the
effectiveness and broad applicability of our ConvSDG framework compared with
several strong baselines.",2024-03-17
"Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient
  Generative Inference",2024-03-14 02:42:42+00:00,http://arxiv.org/abs/2403.09054v1,"Muhammad Adnan, Akhil Arunkumar, Gaurav Jain, Prashant J. Nair, Ilya Soloveychik, Purushotham Kamath","cs.LG, cs.AI, cs.AR, cs.CL, 68U35, I.2.7; C.0",dialogue,"Transformers have emerged as the underpinning architecture for Large Language
Models (LLMs). In generative language models, the inference process involves
two primary phases: prompt processing and token generation. Token generation,
which constitutes the majority of the computational workload, primarily entails
vector-matrix multiplications and interactions with the Key-Value (KV) Cache.
This phase is constrained by memory bandwidth due to the overhead of
transferring weights and KV cache values from the memory system to the
computing units. This memory bottleneck becomes particularly pronounced in
applications that require long-context and extensive text generation, both of
which are increasingly crucial for LLMs.
  This paper introduces ""Keyformer"", an innovative inference-time approach, to
mitigate the challenges associated with KV cache size and memory bandwidth
utilization. Keyformer leverages the observation that approximately 90% of the
attention weight in generative inference focuses on a specific subset of
tokens, referred to as ""key"" tokens. Keyformer retains only the key tokens in
the KV cache by identifying these crucial tokens using a novel score function.
This approach effectively reduces both the KV cache size and memory bandwidth
usage without compromising model accuracy. We evaluate Keyformer's performance
across three foundational models: GPT-J, Cerebras-GPT, and MPT, which employ
various positional embedding algorithms. Our assessment encompasses a variety
of tasks, with a particular emphasis on summarization and conversation tasks
involving extended contexts. Keyformer's reduction of KV cache reduces
inference latency by 2.1x and improves token generation throughput by 2.4x,
while preserving the model's accuracy.",2024-03-14
"MAP-Elites with Transverse Assessment for Multimodal Problems in
  Creative Domains",2024-03-11 21:50:22+00:00,http://arxiv.org/abs/2403.07182v1,"Marvin Zammit, Antonios Liapis, Georgios N. Yannakakis",cs.NE,dialogue,"The recent advances in language-based generative models have paved the way
for the orchestration of multiple generators of different artefact types (text,
image, audio, etc.) into one system. Presently, many open-source pre-trained
models combine text with other modalities, thus enabling shared vector
embeddings to be compared across different generators. Within this context we
propose a novel approach to handle multimodal creative tasks using Quality
Diversity evolution. Our contribution is a variation of the MAP-Elites
algorithm, MAP-Elites with Transverse Assessment (MEliTA), which is tailored
for multimodal creative tasks and leverages deep learned models that assess
coherence across modalities. MEliTA decouples the artefacts' modalities and
promotes cross-pollination between elites. As a test bed for this algorithm, we
generate text descriptions and cover images for a hypothetical video game and
assign each artefact a unique modality-specific behavioural characteristic.
Results indicate that MEliTA can improve text-to-image mappings within the
solution space, compared to a baseline MAP-Elites algorithm that strictly
treats each image-text pair as one solution. Our approach represents a
significant step forward in multimodal bottom-up orchestration and lays the
groundwork for more complex systems coordinating multimodal creative agents in
the future.",2024-03-11
"MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging
  Knowledge Graphs",2024-03-09 06:28:48+00:00,http://arxiv.org/abs/2403.05814v1,"Yerin Hwang, Yongil Kim, Yunah Jang, Jeesoo Bang, Hyunkyung Bae, Kyomin Jung","cs.CL, cs.AI",dialogue,"Despite advancements in on-topic dialogue systems, effectively managing topic
shifts within dialogues remains a persistent challenge, largely attributed to
the limited availability of training datasets. To address this issue, we
propose Multi-Passage to Dialogue (MP2D), a data generation framework that
automatically creates conversational question-answering datasets with natural
topic transitions. By leveraging the relationships between entities in a
knowledge graph, MP2D maps the flow of topics within a dialogue, effectively
mirroring the dynamics of human conversation. It retrieves relevant passages
corresponding to the topics and transforms them into dialogues through the
passage-to-dialogue method. Through quantitative and qualitative experiments,
we demonstrate MP2D's efficacy in generating dialogue with natural topic
shifts. Furthermore, this study introduces a novel benchmark for topic shift
dialogues, TS-WikiDialog. Utilizing the dataset, we demonstrate that even Large
Language Models (LLMs) struggle to handle topic shifts in dialogue effectively,
and we showcase the performance improvements of models trained on datasets
generated by MP2D across diverse topic shift dialogue tasks.",2024-03-09
"Emotional Manipulation Through Prompt Engineering Amplifies
  Disinformation Generation in AI Large Language Models",2024-03-06 08:50:25+00:00,http://arxiv.org/abs/2403.03550v1,"Rasita Vinay, Giovanni Spitale, Nikola Biller-Andorno, Federico Germani","cs.AI, cs.CY, cs.HC",dialogue,"This study investigates the generation of synthetic disinformation by
OpenAI's Large Language Models (LLMs) through prompt engineering and explores
their responsiveness to emotional prompting. Leveraging various LLM iterations
using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed
experiments to assess their success in producing disinformation. Our findings,
based on a corpus of 19,800 synthetic disinformation social media posts, reveal
that all LLMs by OpenAI can successfully produce disinformation, and that they
effectively respond to emotional prompting, indicating their nuanced
understanding of emotional cues in text generation. When prompted politely, all
examined LLMs consistently generate disinformation at a high frequency.
Conversely, when prompted impolitely, the frequency of disinformation
production diminishes, as the models often refuse to generate disinformation
and instead caution users that the tool is not intended for such purposes. This
research contributes to the ongoing discourse surrounding responsible
development and application of AI technologies, particularly in mitigating the
spread of disinformation and promoting transparency in AI-generated content.",2024-03-06
"BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning
  Diverse Responses",2024-03-02 10:34:11+00:00,http://arxiv.org/abs/2403.01163v1,"Weihao Zeng, Keqing He, Yejie Wang, Dayuan Fu, Weiran Xu",cs.CL,dialogue,"Pre-trained language models have been successful in many scenarios. However,
their usefulness in task-oriented dialogues is limited due to the intrinsic
linguistic differences between general text and task-oriented dialogues.
Current task-oriented dialogue pre-training methods rely on a contrastive
framework, which faces challenges such as selecting true positives and hard
negatives, as well as lacking diversity. In this paper, we propose a novel
dialogue pre-training model called BootTOD. It learns task-oriented dialogue
representations via a self-bootstrapping framework. Unlike contrastive
counterparts, BootTOD aligns context and context+response representations and
dismisses the requirements of contrastive pairs. BootTOD also uses multiple
appropriate response targets to model the intrinsic one-to-many diversity of
human conversations. Experimental results show that BootTOD outperforms strong
TOD baselines on diverse downstream dialogue tasks.",2024-03-02
Gender Bias in Large Language Models across Multiple Languages,2024-03-01 04:47:16+00:00,http://arxiv.org/abs/2403.00277v1,"Jinman Zhao, Yitian Ding, Chen Jia, Yining Wang, Zifan Qian",cs.CL,dialogue,"With the growing deployment of large language models (LLMs) across various
applications, assessing the influence of gender biases embedded in LLMs becomes
crucial. The topic of gender bias within the realm of natural language
processing (NLP) has gained considerable focus, particularly in the context of
English. Nonetheless, the investigation of gender bias in languages other than
English is still relatively under-explored and insufficiently analyzed. In this
work, We examine gender bias in LLMs-generated outputs for different languages.
We use three measurements: 1) gender bias in selecting descriptive words given
the gender-related context. 2) gender bias in selecting gender-related pronouns
(she/he) given the descriptive words. 3) gender bias in the topics of
LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs
in various languages using our three measurement methods. Our findings revealed
significant gender biases across all the languages we examined.",2024-03-01
Do LLMs Implicitly Determine the Suitable Text Difficulty for Users?,2024-02-22 11:16:23+00:00,http://arxiv.org/abs/2402.14453v1,"Seiji Gobara, Hidetaka Kamigaito, Taro Watanabe",cs.CL,dialogue,"Education that suits the individual learning level is necessary to improve
students' understanding. The first step in achieving this purpose by using
large language models (LLMs) is to adjust the textual difficulty of the
response to students. This work analyzes how LLMs can implicitly adjust text
difficulty between user input and its generated text. To conduct the
experiments, we created a new dataset from Stack-Overflow to explore the
performance of question-answering-based conversation. Experimental results on
the Stack-Overflow dataset and the TSCC dataset, including multi-turn
conversation show that LLMs can implicitly handle text difficulty between user
input and its generated response. We also observed that some LLMs can surpass
humans in handling text difficulty and the importance of instruction-tuning.",2024-02-22
"CHATATC: Large Language Model-Driven Conversational Agents for
  Supporting Strategic Air Traffic Flow Management",2024-02-20 01:59:11+00:00,http://arxiv.org/abs/2402.14850v1,"Sinan Abdulhak, Wayne Hubbard, Karthik Gopalakrishnan, Max Z. Li","cs.CL, cs.AI",dialogue,"Generative artificial intelligence (AI) and large language models (LLMs) have
gained rapid popularity through publicly available tools such as ChatGPT. The
adoption of LLMs for personal and professional use is fueled by the natural
interactions between human users and computer applications such as ChatGPT,
along with powerful summarization and text generation capabilities. Given the
widespread use of such generative AI tools, in this work we investigate how
these tools can be deployed in a non-safety critical, strategic traffic flow
management setting. Specifically, we train an LLM, CHATATC, based on a large
historical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023
and consisting of over 80,000 GDP implementations, revisions, and
cancellations. We test the query and response capabilities of CHATATC,
documenting successes (e.g., providing correct GDP rates, durations, and
reason) and shortcomings (e.g,. superlative questions). We also detail the
design of a graphical user interface for future users to interact and
collaborate with the CHATATC conversational agent.",2024-02-20
Neural paraphrasing by automatically crawled and aligned sentence pairs,2024-02-16 10:40:38+00:00,http://arxiv.org/abs/2402.10558v1,"Achille Globo, Antonio Trevisi, Andrea Zugarini, Leonardo Rigutini, Marco Maggini, Stefano Melacci",cs.CL,dialogue,"Paraphrasing is the task of re-writing an input text using other words,
without altering the meaning of the original content. Conversational systems
can exploit automatic paraphrasing to make the conversation more natural, e.g.,
talking about a certain topic using different paraphrases in different time
instants. Recently, the task of automatically generating paraphrases has been
approached in the context of Natural Language Generation (NLG). While many
existing systems simply consist in rule-based models, the recent success of the
Deep Neural Networks in several NLG tasks naturally suggests the possibility of
exploiting such networks for generating paraphrases. However, the main obstacle
toward neural-network-based paraphrasing is the lack of large datasets with
aligned pairs of sentences and paraphrases, that are needed to efficiently
train the neural models. In this paper we present a method for the automatic
generation of large aligned corpora, that is based on the assumption that news
and blog websites talk about the same events using different narrative styles.
We propose a similarity search procedure with linguistic constraints that,
given a reference sentence, is able to locate the most similar candidate
paraphrases out from millions of indexed sentences. The data generation process
is evaluated in the case of the Italian language, performing experiments using
pointer-based deep neural architectures.",2024-02-16
AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns,2024-02-15 05:49:22+00:00,http://arxiv.org/abs/2402.09728v1,"Ashfak Md Shibli, Mir Mehedi A. Pritom, Maanak Gupta","cs.CR, cs.AI",dialogue,"SMS phishing, also known as ""smishing"", is a growing threat that tricks users
into disclosing private information or clicking into URLs with malicious
content through fraudulent mobile text messages. In recent past, we have also
observed a rapid advancement of conversational generative AI chatbot services
(e.g., OpenAI's ChatGPT, Google's BARD), which are powered by pre-trained large
language models (LLMs). These AI chatbots certainly have a lot of utilities but
it is not systematically understood how they can play a role in creating
threats and attacks. In this paper, we propose AbuseGPT method to show how the
existing generative AI-based chatbot services can be exploited by attackers in
real world to create smishing texts and eventually lead to craftier smishing
campaigns. To the best of our knowledge, there is no pre-existing work that
evidently shows the impacts of these generative text-based models on creating
SMS phishing. Thus, we believe this study is the first of its kind to shed
light on this emerging cybersecurity threat. We have found strong empirical
evidences to show that attackers can exploit ethical standards in the existing
generative AI-based chatbot services by crafting prompt injection attacks to
create newer smishing campaigns. We also discuss some future research
directions and guidelines to protect the abuse of generative AI-based services
and safeguard users from smishing attacks.",2024-02-15
Measuring and Controlling Persona Drift in Language Model Dialogs,2024-02-13 20:10:29+00:00,http://arxiv.org/abs/2402.10962v1,"Kenneth Li, Tianle Liu, Naomi Bashkansky, David Bau, Fernanda Viégas, Hanspeter Pfister, Martin Wattenberg","cs.CL, cs.AI, cs.LG",dialogue,"Prompting is a standard tool for customizing language-model chatbots,
enabling them to take on a specific ""persona"". An implicit assumption in the
use of prompts is that they will be stable, so the chatbot will continue to
generate text according to the stipulated persona for the duration of a
conversation. We propose a quantitative benchmark to test this assumption,
evaluating persona stability via self-chats between two personalized chatbots.
Testing popular models like LLaMA2-chat-70B, we reveal a significant persona
drift within eight rounds of conversations. An empirical and theoretical
analysis of this phenomenon suggests the transformer attention mechanism plays
a role, due to attention decay over long exchanges. To combat attention decay
and persona drift, we propose a lightweight method called split-softmax, which
compares favorably against two strong baselines.",2024-02-13
"Can LLMs Produce Faithful Explanations For Fact-checking? Towards
  Faithful Explainable Fact-Checking via Multi-Agent Debate",2024-02-12 04:32:33+00:00,http://arxiv.org/abs/2402.07401v1,"Kyungha Kim, Sangyun Lee, Kung-Hsiang Huang, Hou Pong Chan, Manling Li, Heng Ji",cs.CL,dialogue,"Fact-checking research has extensively explored verification but less so the
generation of natural-language explanations, crucial for user trust. While
Large Language Models (LLMs) excel in text generation, their capability for
producing faithful explanations in fact-checking remains underexamined. Our
study investigates LLMs' ability to generate such explanations, finding that
zero-shot prompts often result in unfaithfulness. To address these challenges,
we propose the Multi-Agent Debate Refinement (MADR) framework, leveraging
multiple LLMs as agents with diverse roles in an iterative refining process
aimed at enhancing faithfulness in generated explanations. MADR ensures that
the final explanation undergoes rigorous validation, significantly reducing the
likelihood of unfaithful elements and aligning closely with the provided
evidence. Experimental results demonstrate that MADR significantly improves the
faithfulness of LLM-generated explanations to the evidence, advancing the
credibility and trustworthiness of these explanations.",2024-02-12
"GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph
  Alignment via Neighborhood Partitioning and Generative Subgraph Encoding",2024-02-09 19:53:29+00:00,http://arxiv.org/abs/2402.06764v2,"Stefan Dernbach, Khushbu Agarwal, Alejandro Zuniga, Michael Henry, Sutanay Choudhury",cs.AI,dialogue,"Integrating large language models (LLMs) with knowledge graphs derived from
domain-specific data represents an important advancement towards more powerful
and factual reasoning. As these models grow more capable, it is crucial to
enable them to perform multi-step inferences over real-world knowledge graphs
while minimizing hallucination. While large language models excel at
conversation and text generation, their ability to reason over
domain-specialized graphs of interconnected entities remains limited. For
example, can we query a LLM to identify the optimal contact in a professional
network for a specific goal, based on relationships and attributes in a private
database? The answer is no--such capabilities lie beyond current methods.
However, this question underscores a critical technical gap that must be
addressed. Many high-value applications in areas such as science, security, and
e-commerce rely on proprietary knowledge graphs encoding unique structures,
relationships, and logical constraints. We introduce a fine-tuning framework
for developing Graph-aligned LAnguage Models (GLaM) that transforms a knowledge
graph into an alternate text representation with labeled question-answer pairs.
We demonstrate that grounding the models in specific graph-based knowledge
expands the models' capacity for structure-based reasoning. Our methodology
leverages the large-language model's generative capabilities to create the
dataset and proposes an efficient alternate to retrieval-augmented generation
styled methods.",2024-02-09
"Parameter-Efficient Conversational Recommender System as a Language
  Processing Task",2024-01-25 14:07:34+00:00,http://arxiv.org/abs/2401.14194v1,"Mathieu Ravaut, Hao Zhang, Lu Xu, Aixin Sun, Yong Liu",cs.CL,dialogue,"Conversational recommender systems (CRS) aim to recommend relevant items to
users by eliciting user preference through natural language conversation. Prior
work often utilizes external knowledge graphs for items' semantic information,
a language model for dialogue generation, and a recommendation module for
ranking relevant items. This combination of multiple components suffers from a
cumbersome training process, and leads to semantic misalignment issues between
dialogue generation and item recommendation. In this paper, we represent items
in natural language and formulate CRS as a natural language processing task.
Accordingly, we leverage the power of pre-trained language models to encode
items, understand user intent via conversation, perform item recommendation
through semantic matching, and generate dialogues. As a unified model, our
PECRS (Parameter-Efficient CRS), can be optimized in a single stage, without
relying on non-textual metadata such as a knowledge graph. Experiments on two
benchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness of
PECRS on recommendation and conversation. Our code is available at:
https://github.com/Ravoxsg/efficient_unified_crs.",2024-01-25
"Large Language Models for Scientific Information Extraction: An
  Empirical Study for Virology",2024-01-18 15:04:55+00:00,http://arxiv.org/abs/2401.10040v1,"Mahsa Shamsabadi, Jennifer D'Souza, Sören Auer","cs.CL, cs.AI, cs.DL, cs.IT, math.IT",dialogue,"In this paper, we champion the use of structured and semantic content
representation of discourse-based scholarly communication, inspired by tools
like Wikipedia infoboxes or structured Amazon product descriptions. These
representations provide users with a concise overview, aiding scientists in
navigating the dense academic landscape. Our novel automated approach leverages
the robust text generation capabilities of LLMs to produce structured scholarly
contribution summaries, offering both a practical solution and insights into
LLMs' emergent abilities.
  For LLMs, the prime focus is on improving their general intelligence as
conversational agents. We argue that these models can also be applied
effectively in information extraction (IE), specifically in complex IE tasks
within terse domains like Science. This paradigm shift replaces the traditional
modular, pipelined machine learning approach with a simpler objective expressed
through instructions. Our results show that finetuned FLAN-T5 with 1000x fewer
parameters than the state-of-the-art GPT-davinci is competitive for the task.",2024-01-18
"PersonalityChat: Conversation Distillation for Personalized Dialog
  Modeling with Facts and Traits",2024-01-14 20:35:33+00:00,http://arxiv.org/abs/2401.07363v1,"Ehsan Lotfi, Maxime De Bruyn, Jeska Buhmann, Walter Daelemans",cs.CL,dialogue,"The new wave of Large Language Models (LLM) has offered an efficient tool to
curate sizeable conversational datasets. So far studies have mainly focused on
task-oriented or generic open-domain dialogs, and have not fully explored the
ability of LLMs in following complicated prompts. In this work, we focus on
personalization, and employ LLMs to curate a dataset which is difficult and
costly to crowd-source: PersonalityChat is a synthetic conversational dataset
based upon the popular PersonaChat dataset, but conditioned on both personas
and (Big-5) personality traits. Evaluating models fine-tuned on this dataset,
we show that the personality trait labels can be used for trait-based
personalization of generative dialogue models. We also perform a head-to-head
comparison between PersonalityChat and PersonaChat, and show that training on
the distilled dataset results in more fluent and coherent dialog agents in the
small-model regime.",2024-01-14
Natural Language Processing for Dialects of a Language: A Survey,2024-01-11 03:04:38+00:00,http://arxiv.org/abs/2401.05632v1,"Aditya Joshi, Raj Dabre, Diptesh Kanojia, Zhuang Li, Haolan Zhan, Gholamreza Haffari, Doris Dippold",cs.CL,dialogue,"State-of-the-art natural language processing (NLP) models are trained on
massive training corpora, and report a superlative performance on evaluation
datasets. This survey delves into an important attribute of these datasets: the
dialect of a language. Motivated by the performance degradation of NLP models
for dialectic datasets and its implications for the equity of language
technologies, we survey past research in NLP for dialects in terms of datasets,
and approaches. We describe a wide range of NLP tasks in terms of two
categories: natural language understanding (NLU) (for tasks such as dialect
classification, sentiment analysis, parsing, and NLU benchmarks) and natural
language generation (NLG) (for summarisation, machine translation, and dialogue
systems). The survey is also broad in its coverage of languages which include
English, Arabic, German among others. We observe that past work in NLP
concerning dialects goes deeper than mere dialect classification, and . This
includes early approaches that used sentence transduction that lead to the
recent approaches that integrate hypernetworks into LoRA. We expect that this
survey will be useful to NLP researchers interested in building equitable
language technologies by rethinking LLM benchmarks and model architectures.",2024-01-11
Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk,2024-01-10 09:49:10+00:00,http://arxiv.org/abs/2401.05033v1,"Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Justin Sun, Xibin Gao, Yi Zhang","cs.CL, cs.AI",dialogue,"Large language models (LLMs) are powerful dialogue agents, but specializing
them towards fulfilling a specific function can be challenging. Instructing
tuning, i.e. tuning models on instruction and sample responses generated by
humans (Ouyang et al., 2022), has proven as an effective method to do so, yet
requires a number of data samples that a) might not be available or b) costly
to generate. Furthermore, this cost increases when the goal is to make the LLM
follow a specific workflow within a dialogue instead of single instructions.
Inspired by the self-play technique in reinforcement learning and the use of
LLMs to simulate human agents, we propose a more effective method for data
collection through LLMs engaging in a conversation in various roles. This
approach generates a training data via ""self-talk"" of LLMs that can be refined
and utilized for supervised fine-tuning. We introduce an automated way to
measure the (partial) success of a dialogue. This metric is used to filter the
generated conversational data that is fed back in LLM for training. Based on
our automated and human evaluations of conversation quality, we demonstrate
that such self-talk data improves results. In addition, we examine the various
characteristics that showcase the quality of generated dialogues and how they
can be connected to their potential utility as training data.",2024-01-10
"Automating Knowledge Acquisition for Content-Centric Cognitive Agents
  Using LLMs",2023-12-27 02:31:51+00:00,http://arxiv.org/abs/2312.16378v1,"Sanjay Oruganti, Sergei Nirenburg, Jesse English, Marjorie McShane","cs.CL, cs.AI",dialogue,"The paper describes a system that uses large language model (LLM) technology
to support the automatic learning of new entries in an intelligent agent's
semantic lexicon. The process is bootstrapped by an existing non-toy lexicon
and a natural language generator that converts formal, ontologically-grounded
representations of meaning into natural language sentences. The learning method
involves a sequence of LLM requests and includes an automatic quality control
step. To date, this learning method has been applied to learning multiword
expressions whose meanings are equivalent to those of transitive verbs in the
agent's lexicon. The experiment demonstrates the benefits of a hybrid learning
architecture that integrates knowledge-based methods and resources with both
traditional data analytics and LLMs.",2023-12-27
"A Comprehensive Analysis of the Effectiveness of Large Language Models
  as Automatic Dialogue Evaluators",2023-12-24 04:50:57+00:00,http://arxiv.org/abs/2312.15407v1,"Chen Zhang, Luis Fernando D'Haro, Yiming Chen, Malu Zhang, Haizhou Li",cs.CL,dialogue,"Automatic evaluation is an integral aspect of dialogue system research. The
traditional reference-based NLG metrics are generally found to be unsuitable
for dialogue assessment. Consequently, recent studies have suggested various
unique, reference-free neural metrics that better align with human evaluations.
Notably among them, large language models (LLMs), particularly the
instruction-tuned variants like ChatGPT, are shown to be promising substitutes
for human judges. Yet, existing works on utilizing LLMs for automatic dialogue
evaluation are limited in their scope in terms of the number of meta-evaluation
datasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains
inconclusive how effective these LLMs are. To this end, we conduct a
comprehensive study on the application of LLMs for automatic dialogue
evaluation. Specifically, we analyze the multi-dimensional evaluation
capability of 30 recently emerged LLMs at both turn and dialogue levels, using
a comprehensive set of 12 meta-evaluation datasets. Additionally, we probe the
robustness of the LLMs in handling various adversarial perturbations at both
turn and dialogue levels. Finally, we explore how model-level and
dimension-level ensembles impact the evaluation performance. All resources are
available at https://github.com/e0397123/comp-analysis.",2023-12-24
Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue,2023-12-23 18:14:56+00:00,http://arxiv.org/abs/2312.15316v1,"Guan-Ting Lin, Prashanth Gurunath Shivakumar, Ankur Gandhe, Chao-Han Huck Yang, Yile Gu, Shalini Ghosh, Andreas Stolcke, Hung-yi Lee, Ivan Bulyko","cs.CL, eess.AS",dialogue,"Large Language Models (LLMs) have demonstrated superior abilities in tasks
such as chatting, reasoning, and question-answering. However, standard LLMs may
ignore crucial paralinguistic information, such as sentiment, emotion, and
speaking style, which are essential for achieving natural, human-like spoken
conversation, especially when such information is conveyed by acoustic cues. We
therefore propose Paralinguistics-enhanced Generative Pretrained Transformer
(ParalinGPT), an LLM utilizes text and speech modality to better model the
linguistic content and paralinguistic attribute of spoken response. The model
takes the conversational context of text, speech embeddings, and paralinguistic
attributes as input prompts within a serialized multitasking multi-modal
framework. Specifically, our framework serializes tasks in the order of current
paralinguistic attribute prediction, response paralinguistic attribute
prediction, and response text generation with autoregressive conditioning. We
utilize the Switchboard-1 corpus, including its sentiment labels to be the
paralinguistic attribute, as our spoken dialogue dataset. Experimental results
indicate the proposed serialized multitasking method outperforms typical
sequence classification techniques on current and response sentiment
classification. Furthermore, leveraging conversational context and speech
embeddings significantly improves both response text generation and sentiment
prediction. Our proposed framework achieves relative improvements of 6.7%,
12.0%, and 3.5% in current sentiment accuracy, response sentiment accuracy, and
response text BLEU score, respectively.",2023-12-23
Team Irisapu Project Description for DRC2023,2023-12-21 11:44:13+00:00,http://arxiv.org/abs/2312.13765v1,"Reon Ohashi, Shinjitsu Agatsuma, Kazuya Tsubokura, Yurie Iribe","cs.RO, cs.AI",dialogue,"This paper describes the dialog robot system designed by Team Irisapu for the
preliminary round of the Dialogue Robot Competition 2023 (DRC2023). In order to
generate dialogue responses flexibly while adhering to predetermined scenarios,
we attempted to generate dialogue response sentences using OpenAI's GPT-3. We
aimed to create a system that can appropriately respond to users by dividing
the dialogue scenario into five sub-scenarios, and creating prompts for each
sub-scenario. Also, we incorporated a recovery strategy that can handle
dialogue breakdowns flexibly. Our research group has been working on research
related to dialogue breakdown detection, and we incorporated our findings to
date in this competition. As a result of the preliminary round, a bug in our
system affected the outcome and we were not able to achieve a satisfactory
result. However, in the evaluation category of ""reliability of provided
information"", we ranked third among all teams.",2023-12-21
"InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large
  Multimodal and Language Models",2023-12-21 00:44:45+00:00,http://arxiv.org/abs/2312.13503v1,"Bingbing Wen, Zhengyuan Yang, Jianfeng Wang, Zhe Gan, Bill Howe, Lijuan Wang","cs.CV, cs.AI",dialogue,"In this paper, we build a visual dialogue dataset, named InfoVisDial, which
provides rich informative answers in each round even with external knowledge
related to the visual content. Different from existing datasets where the
answer is compact and short, InfoVisDial contains long free-form answers with
rich information in each round of dialogue. For effective data collection, the
key idea is to bridge the large-scale multimodal model (e.g., GIT) and the
language models (e.g., GPT-3). GIT can describe the image content even with
scene text, while GPT-3 can generate informative dialogue based on the image
description and appropriate prompting techniques. With such automatic pipeline,
we can readily generate informative visual dialogue data at scale. Then, we ask
human annotators to rate the generated dialogues to filter the low-quality
conversations.Human analyses show that InfoVisDial covers informative and
diverse dialogue topics: $54.4\%$ of the dialogue rounds are related to image
scene texts, and $36.7\%$ require external knowledge. Each round's answer is
also long and open-ended: $87.3\%$ of answers are unique with an average length
of $8.9$, compared with $27.37\%$ and $2.9$ in VisDial. Last, we propose a
strong baseline by adapting the GIT model for the visual dialogue task and
fine-tune the model on InfoVisDial. Hopefully, our work can motivate more
effort on this direction.",2023-12-21
"External Knowledge Augmented Polyphone Disambiguation Using Large
  Language Model",2023-12-19 08:00:10+00:00,http://arxiv.org/abs/2312.11920v1,Chen Li,cs.CL,dialogue,"One of the key issues in Mandarin Chinese text-to-speech (TTS) systems is
polyphone disambiguation when doing grapheme-to-phoneme (G2P) conversion. In
this paper, we introduce a novel method to solve the problem as a generation
task. Following the trending research of large language models (LLM) and prompt
learning, the proposed method consists of three modules. Retrieval module
incorporates external knowledge which is a multi-level semantic dictionary of
Chinese polyphonic characters to format the sentence into a prompt. Generation
module adopts the decoder-only Transformer architecture to induce the target
text. Postprocess module corrects the generated text into a valid result if
needed. Experimental results show that our method outperforms the existing
methods on a public dataset called CPP. We also empirically study the impacts
of different templates of the prompt, different sizes of training data, and
whether to incorporate external knowledge.",2023-12-19
A Survey of Text Watermarking in the Era of Large Language Models,2023-12-13 06:11:42+00:00,http://arxiv.org/abs/2312.07913v2,"Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu","cs.CL, 68T50, I.2.7",dialogue,"In recent years, significant advancements have been made in the text
generation capabilities of Large Language Models (LLMs), demonstrating
exceptional performance in downstream tasks such as abstract summarization,
dialogue generation, and data-to-text conversion. However, their generative
abilities also pose risks such as the rapid spread of fake news, infringement
of datasets/LLM copyrights, and challenges to academic integrity. Text
watermarking technology emerges as a potential solution. By embedding invisible
yet detectable patterns in generated texts, it helps in tracking and verifying
text origins, thus preventing misuse and piracy.
  This survey aims to comprehensively summarize current text watermarking
technologies, covering three main aspects: (1) an overview and comparison of
different text watermarking techniques; (2) evaluation methods for text
watermarking algorithms, including their success rate, impact on text quality,
robustness, and unforgeability; (3) potential applications of text watermarking
technologies. This survey aims to help researchers thoroughly understanding the
text watermarking technologies, thereby fostering further development.",2023-12-13
"NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark
  Dataset for Generative Language Models in Norwegian",2023-12-03 08:09:45+00:00,http://arxiv.org/abs/2312.01314v1,"Peng Liu, Lemei Zhang, Terje Nissen Farup, Even W. Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, Zhirong Yang",cs.CL,dialogue,"Recent advancements in Generative Language Models (GLMs) have transformed
Natural Language Processing (NLP) by showcasing the effectiveness of the
""pre-train, prompt, and predict"" paradigm in utilizing pre-trained GLM
knowledge for diverse applications. Despite their potential, these capabilities
lack adequate quantitative characterization due to the absence of comprehensive
benchmarks, particularly for low-resource languages. Existing low-resource
benchmarks focus on discriminative language models like BERT, neglecting the
evaluation of generative language models. Moreover, current benchmarks often
overlook measuring generalization performance across multiple tasks, a crucial
metric for GLMs.
  To bridge these gaps, we introduce NLEBench, a comprehensive benchmark
tailored for evaluating natural language generation capabilities in Norwegian,
a low-resource language. We use Norwegian as a case study to explore whether
current GLMs and benchmarks in mainstream languages like English can reveal the
unique characteristics of underrepresented languages. NLEBench encompasses a
suite of real-world NLP tasks ranging from news storytelling, summarization,
open-domain conversation, natural language understanding, instruction
fine-tuning, toxicity and bias evaluation, to self-curated Chain-of-Thought
investigation. It features two high-quality, human-annotated datasets: an
instruction dataset covering traditional Norwegian cultures, idioms, slang, and
special expressions, and a document-grounded multi-label dataset for topic
classification, question answering, and summarization. This paper also
introduces foundational Norwegian Generative Language Models (NorGLMs)
developed with diverse parameter scales and Transformer-based architectures.
Systematic evaluations on the proposed benchmark suite provide insights into
the capabilities and scalability of NorGLMs across various downstream tasks.",2023-12-03
"CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable
  Evaluation of Large Language Model Generation",2023-11-30 16:52:42+00:00,http://arxiv.org/abs/2311.18702v1,"Pei Ke, Bosi Wen, Zhuoer Feng, Xiao Liu, Xuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang","cs.CL, cs.AI",dialogue,"Since the natural language processing (NLP) community started to make large
language models (LLMs), such as GPT-4, act as a critic to evaluate the quality
of generated texts, most of them only train a critique generation model of a
specific scale on specific datasets. We argue that a comprehensive
investigation on the key factor of LLM-based evaluation models, such as scaling
properties, is lacking, so that it is still inconclusive whether these models
have potential to replace GPT-4's evaluation in practical scenarios. In this
paper, we propose a new critique generation model called CritiqueLLM, which
includes a dialogue-based prompting method for high-quality referenced /
reference-free evaluation data. Experimental results show that our model can
achieve comparable evaluation performance to GPT-4 especially in system-level
correlations, and even outperform GPT-4 in 3 out of 8 tasks in a challenging
reference-free setting. We conduct detailed analysis to show promising scaling
properties of our model in the quality of generated critiques. We also
demonstrate that our generated critiques can act as scalable feedback to
directly improve the generation quality of LLMs.",2023-11-30
"LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language
  Models",2023-11-30 03:59:31+00:00,http://arxiv.org/abs/2311.18232v1,"Marwa Abdulhai, Isadora White, Charlie Snell, Charles Sun, Joey Hong, Yuexiang Zhai, Kelvin Xu, Sergey Levine","cs.CL, cs.AI, cs.LG",dialogue,"Large language models (LLMs) provide excellent text-generation capabilities,
but standard prompting and generation methods generally do not lead to
intentional or goal-directed agents and might necessitate considerable prompt
tuning. This becomes particularly apparent in multi-turn conversations: even
the best current LLMs rarely ask clarifying questions, engage in explicit
information gathering, or take actions now that lead to better decisions after
multiple turns. Reinforcement learning has the potential to leverage the
powerful modeling capabilities of LLMs, as well as their internal
representation of textual interactions, to create capable goal-directed
language agents. This can enable intentional and temporally extended
interactions, such as with humans, through coordinated persuasion and carefully
crafted questions, or in goal-directed play through text games to bring about
desired final outcomes. However, enabling this requires the community to
develop stable and reliable reinforcement learning algorithms that can
effectively train LLMs. Developing such algorithms requires tasks that can
gauge progress on algorithm design, provide accessible and reproducible
evaluations for multi-turn interactions, and cover a range of task properties
and challenges in improving reinforcement learning algorithms. Our paper
introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,
together with an open-source research framework containing a basic toolkit for
getting started on multi-turn RL with offline value-based and policy-based RL
methods. Our benchmark consists of 8 different language tasks, which require
multiple rounds of language interaction and cover a range of tasks in
open-ended dialogue and text games.",2023-11-30
"CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue
  Generation",2023-11-24 15:10:56+00:00,http://arxiv.org/abs/2311.14539v1,"Zhijie Qu, Juan Li, Zerui Ma, Jianqiang Li","cs.CL, cs.AI",dialogue,"Medical dialogue generation relies on natural language generation techniques
to enable online medical consultations. Recently, the widespread adoption of
large-scale models in the field of natural language processing has facilitated
rapid advancements in this technology. Existing medical dialogue models are
mostly based on BERT and pre-trained on English corpora, but there is a lack of
high-performing models on the task of Chinese medical dialogue generation. To
solve the above problem, this paper proposes CMed-GPT, which is the GPT
pre-training language model based on Chinese medical domain text. The model is
available in two versions, namely, base and large, with corresponding
perplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and
entity embeddings into the dialogue text in a uniform manner to meet the
requirements of downstream dialogue generation tasks. By applying both
fine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.
This study not only confirms the exceptional performance of the CMed-GPT model
in generating Chinese biomedical text but also highlights the advantages of
p-tuning over traditional fine-tuning with prefix prompts. Furthermore, we
validate the significance of incorporating external information in medical
dialogue generation, which enhances the quality of dialogue generation.",2023-11-24
"Evaluation Metrics of Language Generation Models for Synthetic Traffic
  Generation Tasks",2023-11-21 11:26:26+00:00,http://arxiv.org/abs/2311.12534v1,"Simone Filice, Jason Ingyu Choi, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko",cs.CL,dialogue,"Many Natural Language Generation (NLG) tasks aim to generate a single output
text given an input prompt. Other settings require the generation of multiple
texts, e.g., for Synthetic Traffic Generation (STG). This generation task is
crucial for training and evaluating QA systems as well as conversational
agents, where the goal is to generate multiple questions or utterances
resembling the linguistic variability of real users. In this paper, we show
that common NLG metrics, like BLEU, are not suitable for evaluating STG. We
propose and evaluate several metrics designed to compare the generated traffic
to the distribution of real user texts. We validate our metrics with an
automatic procedure to verify whether they capture different types of quality
issues of generated data; we also run human annotations to verify the
correlation with human judgements. Experiments on three tasks, i.e., Shopping
Utterance Generation, Product Question Generation and Query Auto Completion,
demonstrate that our metrics are effective for evaluating STG tasks, and
improve the agreement with human judgement up to 20% with respect to common NLG
metrics. We believe these findings can pave the way towards better solutions
for estimating the representativeness of synthetic text data.",2023-11-21
"LLMs as Visual Explainers: Advancing Image Classification with Evolving
  Visual Descriptions",2023-11-20 16:37:45+00:00,http://arxiv.org/abs/2311.11904v1,"Songhao Han, Le Zhuo, Yue Liao, Si Liu","cs.CV, cs.CL, cs.LG",dialogue,"Vision-language models (VLMs) offer a promising paradigm for image
classification by comparing the similarity between images and class embeddings.
A critical challenge lies in crafting precise textual representations for class
names. While previous studies have leveraged recent advancements in large
language models (LLMs) to enhance these descriptors, their outputs often suffer
from ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent
reliance on textual interactions with LLMs, leading to a mismatch between the
generated text and the visual content in VLMs' latent space - a phenomenon we
term the ""explain without seeing"" dilemma. 2) The oversight of the inter-class
relationships, resulting in descriptors that fail to differentiate similar
classes effectively. To address these issues, we propose a novel image
classification framework combining VLMs with LLMs, named Iterative Optimization
with Visual Feedback. In particular, our method develops an LLM-based agent,
employing an evolutionary optimization strategy to refine class descriptors.
Crucially, we incorporate visual feedback from VLM classification metrics,
thereby guiding the optimization process with concrete visual data. Our method
leads to improving accuracy on a wide range of image classification benchmarks,
with 3.47\% average gains over state-of-the-art methods. We also highlight the
resulting descriptions serve as explainable and robust features that can
consistently improve the performance across various backbone models.",2023-11-20
Can Language Model Moderators Improve the Health of Online Discourse?,2023-11-16 11:14:22+00:00,http://arxiv.org/abs/2311.10781v1,"Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May","cs.CL, cs.AI",dialogue,"Human moderation of online conversation is essential to maintaining civility
and focus in a dialogue, but is challenging to scale and harmful to moderators.
The inclusion of sophisticated natural language generation modules as a force
multiplier aid moderators is a tantalizing prospect, but adequate evaluation
approaches have so far been elusive. In this paper, we establish a systematic
definition of conversational moderation effectiveness through a
multidisciplinary lens that incorporates insights from social science. We then
propose a comprehensive evaluation framework that uses this definition to asses
models' moderation capabilities independently of human intervention. With our
framework, we conduct the first known study of conversational dialogue models
as moderators, finding that appropriately prompted models can provide specific
and fair feedback on toxic behavior but struggle to influence users to increase
their levels of respect and cooperation.",2023-11-16
GRIM: GRaph-based Interactive narrative visualization for gaMes,2023-11-15 18:55:45+00:00,http://arxiv.org/abs/2311.09213v1,"Jorge Leandro, Sudha Rao, Michael Xu, Weijia Xu, Nebosja Jojic, Chris Brockett, Bill Dolan",cs.CL,dialogue,"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The
narratives of these may take years to write and typically involve a large
creative team. In this work, we demonstrate the potential of large generative
text models to assist this process. \textbf{GRIM}, a prototype
\textbf{GR}aph-based \textbf{I}nteractive narrative visualization system for
ga\textbf{M}es, generates a rich narrative graph with branching storylines that
match a high-level narrative description and constraints provided by the
designer. Game designers can interactively edit the graph by automatically
generating new sub-graphs that fit the edits within the original narrative and
constraints. We illustrate the use of \textbf{GRIM} in conjunction with GPT-4,
generating branching narratives for four well-known stories with different
contextual constraints.",2023-11-15
"X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented
  Instruction Tuning with Auxiliary Evaluation Aspects",2023-11-15 09:01:55+00:00,http://arxiv.org/abs/2311.08788v1,"Minqian Liu, Ying Shen, Zhiyang Xu, Yixin Cao, Eunah Cho, Vaibhav Kumar, Reza Ghanadan, Lifu Huang","cs.CL, cs.AI, cs.LG",dialogue,"Natural Language Generation (NLG) typically involves evaluating the generated
text in various aspects (e.g., consistency and naturalness) to obtain a
comprehensive assessment. However, multi-aspect evaluation remains challenging
as it may require the evaluator to generalize to any given evaluation aspect
even if it's absent during training. In this paper, we introduce X-Eval, a
two-stage instruction tuning framework to evaluate the text in both seen and
unseen aspects customized by end users. X-Eval consists of two learning stages:
the vanilla instruction tuning stage that improves the model's ability to
follow evaluation instructions, and an enhanced instruction tuning stage that
exploits the connections between fine-grained evaluation aspects to better
assess text quality. To support the training of X-Eval, we collect
AspectInstruct, the first instruction tuning dataset tailored for multi-aspect
NLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance
task diversity, we devise an augmentation strategy that converts human rating
annotations into diverse forms of NLG evaluation tasks, including scoring,
comparison, ranking, and Boolean question answering. Extensive experiments
across three essential categories of NLG tasks: dialogue generation,
summarization, and data-to-text coupled with 21 aspects in meta-evaluation,
demonstrate that our X-Eval enables even a lightweight language model to
achieve a comparable if not higher correlation with human judgments compared to
the state-of-the-art NLG evaluators, such as GPT-4.",2023-11-15
Workflow-Guided Response Generation for Task-Oriented Dialogue,2023-11-14 16:44:33+00:00,http://arxiv.org/abs/2311.08300v1,"Do June Min, Paloma Sodhi, Ramya Ramakrishnan","cs.CL, cs.AI",dialogue,"Task-oriented dialogue (TOD) systems aim to achieve specific goals through
interactive dialogue. Such tasks usually involve following specific workflows,
i.e. executing a sequence of actions in a particular order. While prior work
has focused on supervised learning methods to condition on past actions, they
do not explicitly optimize for compliance to a desired workflow. In this paper,
we propose a novel framework based on reinforcement learning (RL) to generate
dialogue responses that are aligned with a given workflow. Our framework
consists of ComplianceScorer, a metric designed to evaluate how well a
generated response executes the specified action, combined with an RL
opimization process that utilizes an interactive sampling technique. We
evaluate our approach on two TOD datasets, Action-Based Conversations Dataset
(ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of
automated and human evaluation metrics. Our findings indicate that our RL-based
framework outperforms baselines and is effective at enerating responses that
both comply with the intended workflows while being expressed in a natural and
fluent manner.",2023-11-14
Measuring Entrainment in Spontaneous Code-switched Speech,2023-11-13 19:41:34+00:00,http://arxiv.org/abs/2311.07703v1,"Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg","cs.CL, cs.SD, eess.AS",dialogue,"It is well-known that interlocutors who entrain to one another have more
successful conversations than those who do not. Previous research has shown
that interlocutors entrain on linguistic features in both written and spoken
monolingual domains. More recent work on code-switched communication has also
shown preliminary evidence of entrainment on certain aspects of code-switching
(CSW). However, such studies of entrainment in code-switched domains have been
extremely few and restricted to human-machine textual interactions. Our work
studies code-switched spontaneous speech between humans by answering the
following questions: 1) Do patterns of written and spoken entrainment in
monolingual settings generalize to code-switched settings? 2) Do patterns of
entrainment on code-switching in generated text generalize to spontaneous
code-switched speech? We find evidence of affirmative answers to both of these
questions, with important implications for the potentially ""universal"" nature
of entrainment as a communication phenomenon, and potential applications in
inclusive and interactive speech technology.",2023-11-13
"TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for
  Human-Aligned LLMs",2023-11-09 13:58:59+00:00,http://arxiv.org/abs/2311.05374v1,"Shuyi Xie, Wenlin Yao, Yong Dai, Shaobo Wang, Donlin Zhou, Lifeng Jin, Xinhua Feng, Pengzhi Wei, Yujie Lin, Zhichao Hu, Dong Yu, Zhengyou Zhang, Jing Nie, Yuhong Liu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) have shown impressive capabilities across
various natural language tasks. However, evaluating their alignment with human
preferences remains a challenge. To this end, we propose a comprehensive human
evaluation framework to assess LLMs' proficiency in following instructions on
diverse real-world tasks. We construct a hierarchical task tree encompassing 7
major areas covering over 200 categories and over 800 tasks, which covers
diverse capabilities such as question answering, reasoning, multiturn dialogue,
and text generation, to evaluate LLMs in a comprehensive and in-depth manner.
We also design detailed evaluation standards and processes to facilitate
consistent, unbiased judgments from human evaluators. A test set of over 3,000
instances is released, spanning different difficulty levels and knowledge
domains. Our work provides a standardized methodology to evaluate human
alignment in LLMs for both English and Chinese. We also analyze the feasibility
of automating parts of evaluation with a strong LLM (GPT-4). Our framework
supports a thorough assessment of LLMs as they are integrated into real-world
applications. We have made publicly available the task tree, TencentLLMEval
dataset, and evaluation methodology which have been demonstrated as effective
in assessing the performance of Tencent Hunyuan LLMs. By doing so, we aim to
facilitate the benchmarking of advances in the development of safe and
human-aligned LLMs.",2023-11-09
"Multitask Multimodal Prompted Training for Interactive Embodied Task
  Completion",2023-11-07 15:27:52+00:00,http://arxiv.org/abs/2311.04067v1,"Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia","cs.LG, cs.AI, cs.CV",dialogue,"Interactive and embodied tasks pose at least two fundamental challenges to
existing Vision & Language (VL) models, including 1) grounding language in
trajectories of actions and observations, and 2) referential disambiguation. To
tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a
unified encoder-decoder model that reasons over images and trajectories, and
casts action prediction as multimodal text generation. By unifying all tasks as
text generation, EMMA learns a language of actions which facilitates transfer
across tasks. Different to previous modular approaches with independently
trained components, we use a single multitask model where each task contributes
to goal completion. EMMA performs on par with similar models on several VL
benchmarks and sets a new state-of-the-art performance (36.81% success rate) on
the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided
agents in the Alexa Arena",2023-11-07
"LitCab: Lightweight Calibration of Language Models on Outputs of Varied
  Lengths",2023-10-30 00:30:34+00:00,http://arxiv.org/abs/2310.19208v1,"Xin Liu, Muhammad Khalifa, Lu Wang",cs.CL,dialogue,"A model is considered well-calibrated when its probability estimate aligns
with the actual likelihood of the output being correct. Calibrating language
models (LMs) is crucial, as it plays a vital role in detecting and mitigating
hallucinations, a common issue of LMs, as well as building more trustworthy
models. Yet, popular neural model calibration techniques are not well-suited
for LMs due to their lack of flexibility in discerning answer correctness and
their high computational costs. For instance, post-processing methods like
temperature scaling are often unable to reorder the candidate generations.
Moreover, training-based methods require finetuning the entire model, which is
impractical due to the increasing sizes of modern LMs. In this paper, we
present LitCab, a lightweight calibration mechanism consisting of a single
linear layer taking the input text representation and manipulateing the LM
output logits. LitCab improves model calibration by only adding < 2% of the
original model parameters. For evaluation, we construct CaT, a benchmark
consisting of 7 text generation tasks, covering responses ranging from short
phrases to paragraphs. We test LitCab with Llama2-7B, where it improves
calibration across all tasks, by reducing the average ECE score by 20%. We
further conduct a comprehensive evaluation with 7 popular open-sourced LMs from
GPT and LLaMA families, yielding the following key findings: (1) Larger models
within the same family exhibit better calibration on tasks with short
generation tasks, but not necessarily for longer ones. (2) GPT-family models
show superior calibration compared to LLaMA, Llama2 and Vicuna models despite
having much fewer parameters. (3) Finetuning pretrained model (e.g., LLaMA)
with samples of limited purpose (e.g., conversations) may lead to worse
calibration, highlighting the importance of finetuning setups for calibrating
LMs.",2023-10-30
"Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded
  Dialogue Generation",2023-10-28 19:42:28+00:00,http://arxiv.org/abs/2310.18794v1,"Yixin Wan, Fanyou Wu, Weijie Xu, Srinivasan H. Sengamedu","cs.CL, cs.AI",dialogue,"Model hallucination has been a crucial interest of research in Natural
Language Generation (NLG). In this work, we propose sequence-level certainty as
a common theme over hallucination in NLG, and explore the correlation between
sequence-level certainty and the level of hallucination in model responses. We
categorize sequence-level certainty into two aspects: probabilistic certainty
and semantic certainty, and reveal through experiments on Knowledge-Grounded
Dialogue Generation (KGDG) task that both a higher level of probabilistic
certainty and a higher level of semantic certainty in model responses are
significantly correlated with a lower level of hallucination. What's more, we
provide theoretical proof and analysis to show that semantic certainty is a
good estimator of probabilistic certainty, and therefore has the potential as
an alternative to probability-based certainty estimation in black-box
scenarios. Based on the observation on the relationship between certainty and
hallucination, we further propose Certainty-based Response Ranking (CRR), a
decoding-time method for mitigating hallucination in NLG. Based on our
categorization of sequence-level certainty, we propose 2 types of CRR approach:
Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually
sampled model responses using their arithmetic mean log-probability of the
entire sequence. S-CRR approaches certainty estimation from meaning-space, and
ranks a number of model response candidates based on their semantic certainty
level, which is estimated by the entailment-based Agreement Score (AS). Through
extensive experiments across 3 KGDG datasets, 3 decoding methods, and on 4
different models, we validate the effectiveness of our 2 proposed CRR methods
to reduce model hallucination.",2023-10-28
"INA: An Integrative Approach for Enhancing Negotiation Strategies with
  Reward-Based Dialogue System",2023-10-27 15:31:16+00:00,http://arxiv.org/abs/2310.18207v1,"Zishan Ahmad, Suman Saurabh, Vaishakh Sreekanth Menon, Asif Ekbal, Roshni Ramnani, Anutosh Maitra",cs.CL,dialogue,"In this paper, we propose a novel negotiation dialogue agent designed for the
online marketplace. Our agent is integrative in nature i.e, it possesses the
capability to negotiate on price as well as other factors, such as the addition
or removal of items from a deal bundle, thereby offering a more flexible and
comprehensive negotiation experience. We create a new dataset called
Integrative Negotiation Dataset (IND) to enable this functionality. For this
dataset creation, we introduce a new semi-automated data creation method, which
combines defining negotiation intents, actions, and intent-action simulation
between users and the agent to generate potential dialogue flows. Finally, the
prompting of GPT-J, a state-of-the-art language model, is done to generate
dialogues for a given intent, with a human-in-the-loop process for post-editing
and refining minor errors to ensure high data quality. We employ a set of novel
rewards, specifically tailored for the negotiation task to train our
Negotiation Agent, termed as the Integrative Negotiation Agent (INA). These
rewards incentivize the chatbot to learn effective negotiation strategies that
can adapt to various contextual requirements and price proposals. By leveraging
the IND, we train our model and conduct experiments to evaluate the
effectiveness of our reward-based dialogue system for negotiation. Our results
demonstrate that the proposed approach and reward system significantly enhance
the agent's negotiation capabilities. The INA successfully engages in
integrative negotiations, displaying the ability to dynamically adjust prices
and negotiate the inclusion or exclusion of items in a bundle deal",2023-10-27
"Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based
  Constructive Communication to Improve Communicative Competence for EFL
  earners",2023-10-27 14:29:36+00:00,http://arxiv.org/abs/2311.00718v1,Wei Zhou,cs.HC,dialogue,"Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)
language models, which have received specialized training to produce text based
on natural language inputs. Its purpose is to imitate human-like conversation
and can be implemented in multiple applications, such as chatbots, virtual
assistants, and language translation systems, starting with an introduction to
the new trends and differences between artificial intelligence, machine
learning, and artificial neural networks, and highlighting the rigorous
language logic and powerful text generation capabilities of Chat GPT. This
paper delves into how advances in artificial intelligence will shape e-learning
in the coming decades, particularly in terms of Chat- GPT's ability to improve
learners' Communicative Competence when English is a second language. The
combination of new trends in artificial intelligence, mainly in the particular
case of English as a second language, and, at the academic level, chatbot
technology, will be the next step in the replacement of the human academic
community by virtual assistants, apparently until a certain point. Despite the
controversy, this very innovative solution will be able to bridge the gap
between technology and education. Moreover, such innovative practices
facilitate communication by enabling its inclusion in various applications,
including virtual assistants, chatbots, and language education. Keyword: Chat
GPT, artificial intelligence, Communicative Competence, Communicative Language
Teaching (CLT)",2023-10-27
"""Honey, Tell Me What's Wrong"", Global Explanation of Textual
  Discriminative Models through Cooperative Generation",2023-10-27 11:26:27+00:00,http://arxiv.org/abs/2310.18063v1,"Antoine Chaffin, Julien Delaunay","cs.CL, cs.LG, I.2.7",dialogue,"The ubiquity of complex machine learning has raised the importance of
model-agnostic explanation algorithms. These methods create artificial
instances by slightly perturbing real instances, capturing shifts in model
decisions. However, such methods rely on initial data and only provide
explanations of the decision for these. To tackle these problems, we propose
Therapy, the first global and model-agnostic explanation method adapted to text
which requires no input dataset. Therapy generates texts following the
distribution learned by a classifier through cooperative generation. Because it
does not rely on initial samples, it allows to generate explanations even when
data is absent (e.g., for confidentiality reasons). Moreover, conversely to
existing methods that combine multiple local explanations into a global one,
Therapy offers a global overview of the model behavior on the input space. Our
experiments show that although using no input data to generate samples, Therapy
provides insightful information about features used by the classifier that is
competitive with the ones from methods relying on input samples and outperforms
them when input samples are not specific to the studied model.",2023-10-27
"Fidelity-Enriched Contrastive Search: Reconciling the
  Faithfulness-Diversity Trade-Off in Text Generation",2023-10-23 14:27:45+00:00,http://arxiv.org/abs/2310.14981v1,"Wei-Lin Chen, Cheng-Kuang Wu, Hsin-Hsi Chen, Chung-Chi Chen",cs.CL,dialogue,"In this paper, we address the hallucination problem commonly found in natural
language generation tasks. Language models often generate fluent and convincing
content but can lack consistency with the provided source, resulting in
potential inaccuracies. We propose a new decoding method called
Fidelity-Enriched Contrastive Search (FECS), which augments the contrastive
search framework with context-aware regularization terms. FECS promotes tokens
that are semantically similar to the provided source while penalizing
repetitiveness in the generated text. We demonstrate its effectiveness across
two tasks prone to hallucination: abstractive summarization and dialogue
generation. Results show that FECS consistently enhances faithfulness across
various language model sizes while maintaining output diversity comparable to
well-performing decoding algorithms.",2023-10-23
"NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling
  Social Norm Adherence and Violation",2023-10-23 04:38:34+00:00,http://arxiv.org/abs/2310.14563v2,"Oliver Li, Mallika Subramanian, Arkadiy Saakyan, Sky CH-Wang, Smaranda Muresan","cs.CL, cs.CY",dialogue,"Social norms fundamentally shape interpersonal communication. We present
NormDial, a high-quality dyadic dialogue dataset with turn-by-turn annotations
of social norm adherences and violations for Chinese and American cultures.
Introducing the task of social norm observance detection, our dataset is
synthetically generated in both Chinese and English using a human-in-the-loop
pipeline by prompting large language models with a small collection of
expert-annotated social norms. We show that our generated dialogues are of high
quality through human evaluation and further evaluate the performance of
existing large language models on this task. Our findings point towards new
directions for understanding the nuances of social norms as they manifest in
conversational contexts that span across languages and cultures.",2023-10-23
"Information Value: Measuring Utterance Predictability as Distance from
  Plausible Alternatives",2023-10-20 17:25:36+00:00,http://arxiv.org/abs/2310.13676v1,"Mario Giulianelli, Sarenne Wallbridge, Raquel Fernández",cs.CL,dialogue,"We present information value, a measure which quantifies the predictability
of an utterance relative to a set of plausible alternatives. We introduce a
method to obtain interpretable estimates of information value using neural text
generators, and exploit their psychometric predictive power to investigate the
dimensions of predictability that drive human comprehension behaviour.
Information value is a stronger predictor of utterance acceptability in written
and spoken dialogue than aggregates of token-level surprisal and it is
complementary to surprisal for predicting eye-tracked reading times.",2023-10-20
BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues,2023-10-20 16:53:51+00:00,http://arxiv.org/abs/2310.13650v1,"Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, Kai Chen",cs.CL,dialogue,"Interacting with human via high-quality multi-turn dialogues is a key feature
of large language models (LLMs). However, human-based evaluation of such
capability involves intensive manual labor. This report provides a preliminary
evaluation of existing large language models for human-style multi-turn
chatting, through an LLM-based approach. We start from real-world human
dialogues and keep the very first utterances as the ChatSEED. Then we prompt
LLMs to generate a full multi-turn dialogue (tens of utterances) based on the
ChatSEED, utterance by utterance. Finally, we adopt state-of-the-art LLMs
(GPT-4, \etc) as the judge to evaluate the generated dialogues. With different
evaluation protocols, we come to substantially identical conclusions. We find
that GPT-4 can generate human-style multi-turn dialogues with impressive
quality, significantly outperforms its counterparts. It's difficult for a
discriminator to distinguish between GPT-4 generated dialogues and human
dialogues. In contrast, other LLMs struggle to generate multi-turn dialogues of
satisfactory quality due to poor instruction-following capability, tendency to
generate lengthy utterances, or limited general capability. All data and codes
will be provided in https://github.com/open-compass/BotChat/ and we hope they
can serve as a valuable resource for evaluating multi-turn chatting
capabilities of LLMs.",2023-10-20
"DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for
  Emotion Recognition in Conversations",2023-10-17 16:15:34+00:00,http://arxiv.org/abs/2310.11374v1,"Yazhou Zhang, Mengyao Wang, Prayag Tiwari, Qiuchi Li, Benyou Wang, Jing Qin",cs.CL,dialogue,"Large language models (LLMs) and their variants have shown extraordinary
efficacy across numerous downstream natural language processing (NLP) tasks,
which has presented a new vision for the development of NLP. Despite their
remarkable performance in natural language generating (NLG), LLMs lack a
distinct focus on the emotion understanding domain. As a result, using LLMs for
emotion recognition may lead to suboptimal and inadequate precision. Another
limitation of LLMs is that they are typical trained without leveraging
multi-modal information. To overcome these limitations, we propose DialogueLLM,
a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA
models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.
The visual information is considered as the supplementary knowledge to
construct high-quality instructions. We offer a comprehensive evaluation of our
proposed model on three benchmarking emotion recognition in conversations (ERC)
datasets and compare the results against the SOTA baselines and other SOTA
LLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB
A100 GPU in 5 hours, facilitating reproducibility for other researchers.",2023-10-17
"BiLL-VTG: Bridging Large Language Models and Lightweight Visual Tools
  for Video-based Texts Generation",2023-10-16 17:05:56+00:00,http://arxiv.org/abs/2310.10586v1,"Ji Qi, Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, Lei Hou, Juanzi Li","cs.CV, cs.CL",dialogue,"Building models that generate textual responses to user instructions for
videos is a practical and challenging topic, as it requires both vision
understanding and knowledge reasoning. Compared to language and image
modalities, training efficiency remains a serious problem as existing studies
train models on massive sparse videos aligned with brief descriptions. In this
paper, we introduce BiLL-VTG, a fast adaptive framework that leverages large
language models (LLMs) to reasoning on videos based on essential lightweight
visual tools. Specifically, we reveal the key to response specific instructions
is the concentration on relevant video events, and utilize two visual tools of
structured scene graph generation and descriptive image caption generation to
gather and represent the events information. Thus, a LLM equipped with world
knowledge is adopted as the reasoning agent to achieve the response by
performing multiple reasoning steps on specified video events.To address the
difficulty of specifying events from agent, we further propose an
Instruction-oriented Video Events Recognition (InsOVER) algorithm based on the
efficient Hungarian matching to localize corresponding video events using
linguistic instructions, enabling LLMs to interact with long videos. Extensive
experiments on two typical video-based texts generations tasks show that our
tuning-free framework outperforms the pre-trained models including
Flamingo-80B, to achieve the state-of-the-art performance.",2023-10-16
Character-LLM: A Trainable Agent for Role-Playing,2023-10-16 07:58:56+00:00,http://arxiv.org/abs/2310.10158v1,"Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) can be used to serve as agents to simulate human
behaviors, given the powerful ability to understand human instructions and
provide high-quality generated texts. Such ability stimulates us to wonder
whether LLMs can simulate a person in a higher form than simple human
behaviors. Therefore, we aim to train an agent with the profile, experience,
and emotional states of a specific person instead of using limited prompts to
instruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs
to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,
etc. Our method focuses on editing profiles as experiences of a certain
character and training models to be personal simulacra with these experiences.
To assess the effectiveness of our approach, we build a test playground that
interviews trained agents and evaluates whether the agents \textit{memorize}
their characters and experiences. Experimental results show interesting
observations that help build future simulacra of humankind.",2023-10-16
"KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level
  Hallucination Detection",2023-10-13 12:12:34+00:00,http://arxiv.org/abs/2310.09044v1,"Sehyun Choi, Tianqing Fang, Zhaowei Wang, Yangqiu Song","cs.CL, cs.AI, cs.LG",dialogue,"Large Language Models (LLMs) have demonstrated remarkable human-level natural
language generation capabilities. However, their potential to generate
misinformation, often called the hallucination problem, poses a significant
risk to their deployment. A common approach to address this issue is to
retrieve relevant knowledge and fine-tune the LLM with the knowledge in its
input. Unfortunately, this method incurs high training costs and may cause
catastrophic forgetting for multi-tasking models. To overcome these
limitations, we propose a knowledge-constrained decoding method called KCTS
(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text
aligned with the reference knowledge at each decoding step using a knowledge
classifier score and MCTS (Monte-Carlo Tree Search). To adapt the
sequence-level knowledge classifier to token-level guidance, we also propose a
novel token-level hallucination detection method called RIPA (Reward Inflection
Point Approximation). Our empirical results on knowledge-grounded dialogue and
abstractive summarization demonstrate the strength of KCTS as a plug-and-play,
model-agnostic decoding method that can effectively reduce hallucinations in
natural language generation.",2023-10-13
"Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task
  Instruction Tuning",2023-10-12 09:39:17+00:00,http://arxiv.org/abs/2310.08166v1,"Junyu Lu, Dixiang Zhang, Xiaojun Wu, Xinyu Gao, Ruyi Gan, Jiaxing Zhang, Yan Song, Pingjian Zhang",cs.CL,dialogue,"Recent advancements enlarge the capabilities of large language models (LLMs)
in zero-shot image-to-text generation and understanding by integrating
multi-modal inputs. However, such success is typically limited to English
scenarios due to the lack of large-scale and high-quality non-English
multi-modal resources, making it extremely difficult to establish competitive
counterparts in other languages. In this paper, we introduce the Ziya-VL
series, a set of bilingual large-scale vision-language models (LVLMs) designed
to incorporate visual semantics into LLM for multi-modal dialogue. Composed of
Ziya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from
BLIP-2, further exploring the assistance of optimization schemes such as
instruction tuning, multi-stage training and low-rank adaptation module for
visual-language alignment. In addition, we stimulate the understanding ability
of GPT-4 in multi-modal scenarios, translating our gathered English image-text
datasets into Chinese and generating instruction-response through the
in-context learning method. The experiment results demonstrate that compared to
the existing LVLMs, Ziya-VL achieves competitive performance across a wide
range of English-only tasks including zero-shot image-text retrieval, image
captioning, and visual question answering. The evaluation leaderboard accessed
by GPT-4 also indicates that our models possess satisfactory image-text
understanding and generation capabilities in Chinese multi-modal scenario
dialogues. Code, demo and models are available at
~\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.",2023-10-12
"Harnessing Large Language Models' Empathetic Response Generation
  Capabilities for Online Mental Health Counselling Support",2023-10-12 03:33:06+00:00,http://arxiv.org/abs/2310.08017v1,"Siyuan Brandon Loh, Aravind Sesagiri Raamkumar","cs.CL, I.2",dialogue,"Large Language Models (LLMs) have demonstrated remarkable performance across
various information-seeking and reasoning tasks. These computational systems
drive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also
carry substantial promise in meeting the growing demands of mental health care,
albeit relatively unexplored. As such, this study sought to examine LLMs'
capability to generate empathetic responses in conversations that emulate those
in a mental health counselling setting. We selected five LLMs: version 3.5 and
version 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways
Language Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple
instructional prompt, these models responded to utterances derived from the
EmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we
compared their responses to those from traditional response generation dialogue
systems, which were fine-tuned on the ED dataset, along with human-generated
responses. Notably, we discovered that responses from the LLMs were remarkably
more empathetic in most scenarios. We position our findings in light of
catapulting advancements in creating empathetic conversational systems.",2023-10-12
Dobby: A Conversational Service Robot Driven by GPT-4,2023-10-10 04:34:00+00:00,http://arxiv.org/abs/2310.06303v1,"Carson Stark, Bohkyung Chun, Casey Charleston, Varsha Ravi, Luis Pabon, Surya Sunkari, Tarun Mohan, Peter Stone, Justin Hart","cs.RO, cs.AI",dialogue,"This work introduces a robotics platform which embeds a conversational AI
agent in an embodied system for natural language understanding and intelligent
decision-making for service tasks; integrating task planning and human-like
conversation. The agent is derived from a large language model, which has
learned from a vast corpus of general knowledge. In addition to generating
dialogue, this agent can interface with the physical world by invoking commands
on the robot; seamlessly merging communication and behavior. This system is
demonstrated in a free-form tour-guide scenario, in an HRI study combining
robots with and without conversational AI capabilities. Performance is measured
along five dimensions: overall effectiveness, exploration abilities,
scrutinization abilities, receptiveness to personification, and adaptability.",2023-10-10
Aligning Language Models with Human Preferences via a Bayesian Approach,2023-10-09 15:15:05+00:00,http://arxiv.org/abs/2310.05782v1,"Jiashuo Wang, Haozhao Wang, Shichao Sun, Wenjie Li",cs.CL,dialogue,"In the quest to advance human-centric natural language generation (NLG)
systems, ensuring alignment between NLG models and human preferences is
crucial. For this alignment, current popular methods leverage a reinforcement
learning (RL) approach with a reward model trained on feedback from humans.
However, inherent disagreements due to the subjective nature of human
preferences pose a significant challenge for training the reward model,
resulting in a deterioration of the NLG performance. To tackle this issue,
previous approaches typically rely on majority voting or averaging to
consolidate multiple inconsistent preferences into a merged one. Although
straightforward to understand and execute, such methods suffer from an
inability to capture the nuanced degrees of disaggregation among humans and may
only represent a specialized subset of individuals, thereby lacking the ability
to quantitatively disclose the universality of human preferences. To address
this challenge, this paper proposes a novel approach, which employs a Bayesian
framework to account for the distribution of disagreements among human
preferences as training a preference model, and names it as d-PM. Besides,
considering the RL strategy's inefficient and complex training process over the
training efficiency, we further propose utilizing the contrastive learning
strategy to train the NLG model with the preference scores derived from the
d-PM model. Extensive experiments on two human-centric NLG tasks, i.e.,
emotional support conversation and integrity ""Rule-of-Thumb"" generation, show
that our method consistently exceeds previous SOTA models in both automatic and
human evaluations.",2023-10-09
"Improving the Reliability of Large Language Models by Leveraging
  Uncertainty-Aware In-Context Learning",2023-10-07 12:06:53+00:00,http://arxiv.org/abs/2310.04782v1,"Yuchen Yang, Houqiang Li, Yanfeng Wang, Yu Wang",cs.CL,dialogue,"In recent years, large-scale language models (LLMs) have gained attention for
their impressive text generation capabilities. However, these models often face
the challenge of ""hallucination,"" which undermines their reliability. In this
study, we introduce an uncertainty-aware in-context learning framework to
empower the model to enhance or reject its output in response to uncertainty.
Human-defined methods for estimating uncertainty typically assume that
""uncertainty is lower when the model's response is correct compared to when it
is incorrect."" However, setting a precise threshold to distinguish correctness
is challenging. Therefore, we introduce uncertainty information as an
intermediary variable that implicitly influences the model's behavior. Our
innovative uncertainty-aware in-context learning framework involves fine-tuning
the LLM using a calibration dataset. Our aim is to improve the model's
responses by filtering out answers with high uncertainty while considering the
model's knowledge limitations. We evaluate the model's knowledge by examining
multiple responses to the same question for the presence of a correct answer.
When the model lacks relevant knowledge, the response should indicate that the
question cannot be answered. Conversely, when the model has relevant knowledge,
the response should provide the correct answer. Extensive experiments confirm
the effectiveness of our framework, leading to two key findings. First, the
logit output values of the LLM partly reflect inherent uncertainty. Second, our
model autonomously recognizes uncertainty, resulting in improved responses.",2023-10-07
"Controlling Topic-Focus Articulation in Meaning-to-Text Generation using
  Graph Neural Networks",2023-10-03 13:51:01+00:00,http://arxiv.org/abs/2310.02053v1,"Chunliu Wang, Rik van Noord, Johan Bos",cs.CL,dialogue,"A bare meaning representation can be expressed in various ways using natural
language, depending on how the information is structured on the surface level.
We are interested in finding ways to control topic-focus articulation when
generating text from meaning. We focus on distinguishing active and passive
voice for sentences with transitive verbs. The idea is to add pragmatic
information such as topic to the meaning representation, thereby forcing either
active or passive voice when given to a natural language generation system. We
use graph neural models because there is no explicit information about word
order in a meaning represented by a graph. We try three different methods for
topic-focus articulation (TFA) employing graph neural models for a
meaning-to-text generation task. We propose a novel encoding strategy about
node aggregation in graph neural models, which instead of traditional encoding
by aggregating adjacent node information, learns node representations by using
depth-first search. The results show our approach can get competitive
performance with state-of-art graph models on general text generation, and lead
to significant improvements on the task of active-passive conversion compared
to traditional adjacency-based aggregation strategies. Different types of TFA
can have a huge impact on the performance of the graph models.",2023-10-03
"Curriculum-Driven Edubot: A Framework for Developing Language Learning
  Chatbots Through Synthesizing Conversational Data",2023-09-28 19:14:18+00:00,http://arxiv.org/abs/2309.16804v1,"Yu Li, Shang Qu, Jili Shen, Shangchao Min, Zhou Yu",cs.CL,dialogue,"Chatbots have become popular in educational settings, revolutionizing how
students interact with material and how teachers teach. We present
Curriculum-Driven EduBot, a framework for developing a chatbot that combines
the interactive features of chatbots with the systematic material of English
textbooks to assist students in enhancing their conversational skills. We begin
by extracting pertinent topics from textbooks and then using large language
models to generate dialogues related to these topics. We then fine-tune an
open-source LLM using our generated conversational data to create our
curriculum-driven chatbot. User studies demonstrate that our chatbot
outperforms ChatGPT in leading curriculum-based dialogues and adapting its
dialogue to match the user's English proficiency level. By combining
traditional textbook methodologies with conversational AI, our approach offers
learners an interactive tool that aligns with their curriculum and provides
user-tailored conversation practice. This facilitates meaningful student-bot
dialogues and enriches the overall learning experience within the curriculum's
pedagogical framework.",2023-09-28
"When Automated Assessment Meets Automated Content Generation: Examining
  Text Quality in the Era of GPTs",2023-09-25 19:32:18+00:00,http://arxiv.org/abs/2309.14488v1,"Marialena Bevilacqua, Kezia Oketch, Ruiyang Qin, Will Stamey, Xinyuan Zhang, Yi Gan, Kai Yang, Ahmed Abbasi","cs.CL, cs.AI",dialogue,"The use of machine learning (ML) models to assess and score textual data has
become increasingly pervasive in an array of contexts including natural
language processing, information retrieval, search and recommendation, and
credibility assessment of online content. A significant disruption at the
intersection of ML and text are text-generating large-language models such as
generative pre-trained transformers (GPTs). We empirically assess the
differences in how ML-based scoring models trained on human content assess the
quality of content generated by humans versus GPTs. To do so, we propose an
analysis framework that encompasses essay scoring ML-models, human and
ML-generated essays, and a statistical model that parsimoniously considers the
impact of type of respondent, prompt genre, and the ML model used for
assessment model. A rich testbed is utilized that encompasses 18,460
human-generated and GPT-based essays. Results of our benchmark analysis reveal
that transformer pretrained language models (PLMs) more accurately score human
essay quality as compared to CNN/RNN and feature-based ML methods.
Interestingly, we find that the transformer PLMs tend to score GPT-generated
text 10-15\% higher on average, relative to human-authored documents.
Conversely, traditional deep learning and feature-based ML models score human
text considerably higher. Further analysis reveals that although the
transformer PLMs are exclusively fine-tuned on human text, they more
prominently attend to certain tokens appearing only in GPT-generated text,
possibly due to familiarity/overlap in pre-training. Our framework and results
have implications for text classification settings where automated scoring of
text is likely to be disrupted by generative AI.",2023-09-25
"BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment
  of Continuation Writing",2023-09-02 11:46:05+00:00,http://arxiv.org/abs/2309.00916v1,"Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang","cs.CL, cs.SD, eess.AS",dialogue,"The emergence of large language models (LLMs) has sparked significant
interest in extending their remarkable language capabilities to speech.
However, modality alignment between speech and text still remains an open
problem. Current solutions can be categorized into two strategies. One is a
cascaded approach where outputs (tokens or states) of a separately trained
speech recognition system are used as inputs for LLMs, which limits their
potential in modeling alignment between speech and text. The other is an
end-to-end approach that relies on speech instruction data, which is very
difficult to collect in large quantities. In this paper, we address these
issues and propose the BLSP approach that Bootstraps Language-Speech
Pre-training via behavior alignment of continuation writing. We achieve this by
learning a lightweight modality adapter between a frozen speech encoder and an
LLM, ensuring that the LLM exhibits the same generation behavior regardless of
the modality of input: a speech segment or its transcript. The training process
can be divided into two steps. The first step prompts an LLM to generate texts
with speech transcripts as prefixes, obtaining text continuations. In the
second step, these continuations are used as supervised signals to train the
modality adapter in an end-to-end manner. We demonstrate that this
straightforward process can extend the capabilities of LLMs to speech, enabling
speech recognition, speech translation, spoken language understanding, and
speech conversation, even in zero-shot cross-lingual scenarios.",2023-09-02
"Sparkles: Unlocking Chats Across Multiple Images for Multimodal
  Instruction-Following Models",2023-08-31 05:15:27+00:00,http://arxiv.org/abs/2308.16463v1,"Yupan Huang, Zaiqiao Meng, Fangyu Liu, Yixuan Su, Nigel Collier, Yutong Lu","cs.CV, cs.CL",dialogue,"Large language models exhibit enhanced zero-shot performance on various tasks
when fine-tuned with instruction-following data. Multimodal
instruction-following models extend these capabilities by integrating both text
and images. However, existing models such as MiniGPT-4 face challenges in
maintaining dialogue coherence in scenarios involving multiple images. A
primary reason is the lack of a specialized dataset for this critical
application. To bridge these gaps, we present SparklesChat, a multimodal
instruction-following model for open-ended dialogues across multiple images. To
support the training, we introduce SparklesDialogue, the first
machine-generated dialogue dataset tailored for word-level interleaved
multi-image and text interactions. Furthermore, we construct SparklesEval, a
GPT-assisted benchmark for quantitatively assessing a model's conversational
competence across multiple images and dialogue turns. Our experiments validate
the effectiveness of SparklesChat in understanding and reasoning across
multiple images and dialogue turns. Specifically, SparklesChat outperformed
MiniGPT-4 on established vision-and-language benchmarks, including the BISON
binary image selection task and the NLVR2 visual reasoning task. Moreover,
SparklesChat scored 8.56 out of 10 on SparklesEval, substantially exceeding
MiniGPT-4's score of 3.91 and nearing GPT-4's score of 9.26. Qualitative
evaluations further demonstrate SparklesChat's generality in handling
real-world applications. All resources will be available at
https://github.com/HYPJUDY/Sparkles.",2023-08-31
"Out of the Cage: How Stochastic Parrots Win in Cyber Security
  Environments",2023-08-23 12:11:27+00:00,http://arxiv.org/abs/2308.12086v2,"Maria Rigaki, Ondřej Lukáš, Carlos A. Catania, Sebastian Garcia","cs.CR, cs.AI, cs.CL",dialogue,"Large Language Models (LLMs) have gained widespread popularity across diverse
domains involving text generation, summarization, and various natural language
processing tasks. Despite their inherent limitations, LLM-based designs have
shown promising capabilities in planning and navigating open-world scenarios.
This paper introduces a novel application of pre-trained LLMs as agents within
cybersecurity network environments, focusing on their utility for sequential
decision-making processes.
  We present an approach wherein pre-trained LLMs are leveraged as attacking
agents in two reinforcement learning environments. Our proposed agents
demonstrate similar or better performance against state-of-the-art agents
trained for thousands of episodes in most scenarios and configurations. In
addition, the best LLM agents perform similarly to human testers of the
environment without any additional training process. This design highlights the
potential of LLMs to efficiently address complex decision-making tasks within
cybersecurity.
  Furthermore, we introduce a new network security environment named
NetSecGame. The environment is designed to eventually support complex
multi-agent scenarios within the network security domain. The proposed
environment mimics real network attacks and is designed to be highly modular
and adaptable for various scenarios.",2023-08-23
"Enhancing Performance on Seen and Unseen Dialogue Scenarios using
  Retrieval-Augmented End-to-End Task-Oriented System",2023-08-16 06:52:10+00:00,http://arxiv.org/abs/2308.08169v1,"Jianguo Zhang, Stephen Roller, Kun Qian, Zhiwei Liu, Rui Meng, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong","cs.CL, cs.AI",dialogue,"End-to-end task-oriented dialogue (TOD) systems have achieved promising
performance by leveraging sophisticated natural language understanding and
natural language generation capabilities of pre-trained models. This work
enables the TOD systems with more flexibility through a simple cache. The cache
provides the flexibility to dynamically update the TOD systems and handle both
existing and unseen dialogue scenarios. Towards this end, we first fine-tune a
retrieval module to effectively retrieve the most relevant information entries
from the cache. We then train end-to-end TOD models that can refer to and
ground on both dialogue history and retrieved information during TOD
generation. The cache is straightforward to construct, and the backbone models
of TOD systems are compatible with existing pre-trained generative models.
Extensive experiments demonstrate the superior performance of our framework,
with a notable improvement in non-empty joint goal accuracy by 6.7% compared to
strong baselines.",2023-08-16
ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,2023-08-14 15:13:04+00:00,http://arxiv.org/abs/2308.07201v1,"Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu",cs.CL,dialogue,"Text evaluation has historically posed significant challenges, often
demanding substantial labor and time cost. With the emergence of large language
models (LLMs), researchers have explored LLMs' potential as alternatives for
human evaluation. While these single-agent-based approaches show promise,
experimental results suggest that further advancements are needed to bridge the
gap between their current effectiveness and human-level evaluation quality.
Recognizing that best practices of human evaluation processes often involve
multiple human annotators collaborating in the evaluation, we resort to a
multi-agent debate framework, moving beyond single-agent prompting strategies.
The multi-agent-based approach enables a group of LLMs to synergize with an
array of intelligent counterparts, harnessing their distinct capabilities and
expertise to enhance efficiency and effectiveness in handling intricate tasks.
In this paper, we construct a multi-agent referee team called ChatEval to
autonomously discuss and evaluate the quality of generated responses from
different models on open-ended questions and traditional natural language
generation (NLG) tasks. Our analysis shows that ChatEval transcends mere
textual scoring, offering a human-mimicking evaluation process for reliable
assessments. Our code is available at https://github.com/chanchimin/ChatEval.",2023-08-14
Dataflow Dialogue Generation,2023-08-04 13:40:54+00:00,http://arxiv.org/abs/2308.02323v1,"Joram Meron, Victor Guimarães",cs.CL,dialogue,"We demonstrate task-oriented dialogue generation within the dataflow dialogue
paradigm. We show an example of agenda driven dialogue generation for the
MultiWOZ domain, and an example of generation without an agenda for the
SMCalFlow domain, where we show an improvement in the accuracy of the
translation of user requests to dataflow expressions when the generated
dialogues are used to augment the translation training dataset.",2023-08-04
"Controllable Generation of Dialogue Acts for Dialogue Systems via
  Few-Shot Response Generation and Ranking",2023-07-26 18:16:45+00:00,http://arxiv.org/abs/2307.14440v1,"Angela Ramirez, Karik Agarwal, Juraj Juraska, Utkarsh Garg, Marilyn A. Walker",cs.CL,dialogue,"Dialogue systems need to produce responses that realize multiple types of
dialogue acts (DAs) with high semantic fidelity. In the past, natural language
generators (NLGs) for dialogue were trained on large parallel corpora that map
from a domain-specific DA and its semantic attributes to an output utterance.
Recent work shows that pretrained language models (LLMs) offer new
possibilities for controllable NLG using prompt-based learning. Here we develop
a novel few-shot overgenerate-and-rank approach that achieves the controlled
generation of DAs. We compare eight few-shot prompt styles that include a novel
method of generating from textual pseudo-references using a textual style
transfer approach. We develop six automatic ranking functions that identify
outputs with both the correct DA and high semantic accuracy at generation time.
We test our approach on three domains and four LLMs. To our knowledge, this is
the first work on NLG for dialogue that automatically ranks outputs using both
DA and attribute accuracy. For completeness, we compare our results to
fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results
show that several prompt settings achieve perfect DA accuracy, and near perfect
semantic accuracy (99.81%) and perform better than few-shot fine-tuning.",2023-07-26
Adversarial Conversational Shaping for Intelligent Agents,2023-07-20 12:44:47+00:00,http://arxiv.org/abs/2307.11785v1,"Piotr Tarasiewicz, Sultan Kenjeyev, Ilana Sebag, Shehab Alshehabi","cs.CL, cs.LG",dialogue,"The recent emergence of deep learning methods has enabled the research
community to achieve state-of-the art results in several domains including
natural language processing. However, the current robocall system remains
unstable and inaccurate: text generator and chat-bots can be tedious and
misunderstand human-like dialogue. In this work, we study the performance of
two models able to enhance an intelligent conversational agent through
adversarial conversational shaping: a generative adversarial network with
policy gradient (GANPG) and a generative adversarial network with reward for
every generation step (REGS) based on the REGS model presented in Li et al.
[18] . This model is able to assign rewards to both partially and fully
generated text sequences. We discuss performance with different training
details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning
framework.",2023-07-20
"A Dialogue System for Assessing Activities of Daily Living: Improving
  Consistency with Grounded Knowledge",2023-07-15 22:41:59+00:00,http://arxiv.org/abs/2307.07544v1,"Zhecheng Sheng, Raymond Finzel, Michael Lucke, Sheena Dufresne, Maria Gini, Serguei Pakhomov","cs.CL, cs.AI",dialogue,"In healthcare, the ability to care for oneself is reflected in the
""Activities of Daily Living (ADL),"" which serve as a measure of functional
ability (functioning). A lack of functioning may lead to poor living conditions
requiring personal care and assistance. To accurately identify those in need of
support, assistance programs continuously evaluate participants' functioning
across various domains. However, the assessment process may encounter
consistency issues when multiple assessors with varying levels of expertise are
involved. Novice assessors, in particular, may lack the necessary preparation
for real-world interactions with participants. To address this issue, we
developed a dialogue system that simulates interactions between assessors and
individuals of varying functioning in a natural and reproducible way. The
dialogue system consists of two major modules, one for natural language
understanding (NLU) and one for natural language generation (NLG),
respectively. In order to generate responses consistent with the underlying
knowledge base, the dialogue system requires both an understanding of the
user's query and of biographical details of an individual being simulated. To
fulfill this requirement, we experimented with query classification and
generated responses based on those biographical details using some recently
released InstructGPT-like models.",2023-07-15
Zero-shot NLG evaluation through Pairware Comparisons with LLMs,2023-07-15 22:02:12+00:00,http://arxiv.org/abs/2307.07889v1,"Adian Liusie, Potsawee Manakul, Mark J. F. Gales",cs.CL,dialogue,"Evaluating Natural Language Generation (NLG) outputs is crucial but laborious
and expensive. While various automatic NLG assessment methods have been
proposed, they often are quite task-specific and have to be engineered with a
particular domain and attribute in mind. In this work, we propose a robust
zero-shot approach to NLG evaluation using pairwise comparative judgment with
open-source Large Language Models (LLMs). The motivation for this approach is
that even as humans, it is easier to determine which of two options are better,
than it is to independently objectively score each option. We use this insight
and leverage the emergent abilities of LLMs, where we probe FlanT5 to determine
which of two candidate responses is better, rather than assigning absolute
scores. Our results demonstrate that comparative assessment is a more effective
approach than absolute scoring, enabling smaller open-source LLMs to achieve
comparable performance to larger public access APIs. We evaluate systems on
both summary evaluation and dialogue response generation, and show that
opensource LLMs can lead to good correlations with human scores for a range of
different attributes.",2023-07-15
"DIALGEN: Collaborative Human-LM Generated Dialogues for Improved
  Understanding of Human-Human Conversations",2023-07-13 20:02:50+00:00,http://arxiv.org/abs/2307.07047v1,"Bo-Ru Lu, Nikita Haduong, Chia-Hsuan Lee, Zeqiu Wu, Hao Cheng, Paul Koester, Jean Utke, Tao Yu, Noah A. Smith, Mari Ostendorf",cs.CL,dialogue,"Applications that could benefit from automatic understanding of human-human
conversations often come with challenges associated with private information in
real-world data such as call center or clinical conversations. Working with
protected data also increases costs of annotation, which limits technology
development. To address these challenges, we propose DIALGEN, a
human-in-the-loop semi-automated dialogue generation framework. DIALGEN uses a
language model (ChatGPT) that can follow schema and style specifications to
produce fluent conversational text, generating a complex conversation through
iteratively generating subdialogues and using human feedback to correct
inconsistencies or redirect the flow. In experiments on structured
summarization of agent-client information gathering calls, framed as dialogue
state tracking, we show that DIALGEN data enables significant improvement in
model performance.",2023-07-13
"DecompEval: Evaluating Generated Texts as Unsupervised Decomposed
  Question Answering",2023-07-13 16:16:51+00:00,http://arxiv.org/abs/2307.06869v1,"Pei Ke, Fei Huang, Fei Mi, Yasheng Wang, Qun Liu, Xiaoyan Zhu, Minlie Huang","cs.CL, cs.AI",dialogue,"Existing evaluation metrics for natural language generation (NLG) tasks face
the challenges on generalization ability and interpretability. Specifically,
most of the well-performed metrics are required to train on evaluation datasets
of specific NLG tasks and evaluation dimensions, which may cause over-fitting
to task-specific datasets. Furthermore, existing metrics only provide an
evaluation score for each dimension without revealing the evidence to interpret
how this score is obtained. To deal with these challenges, we propose a simple
yet effective metric called DecompEval. This metric formulates NLG evaluation
as an instruction-style question answering task and utilizes instruction-tuned
pre-trained language models (PLMs) without training on evaluation datasets,
aiming to enhance the generalization ability. To make the evaluation process
more interpretable, we decompose our devised instruction-style question about
the quality of generated texts into the subquestions that measure the quality
of each sentence. The subquestions with their answers generated by PLMs are
then recomposed as evidence to obtain the evaluation result. Experimental
results show that DecompEval achieves state-of-the-art performance in untrained
metrics for evaluating text summarization and dialogue generation, which also
exhibits strong dimension-level / task-level generalization ability and
interpretability.",2023-07-13
"Learning to Generate Equitable Text in Dialogue from Biased Training
  Data",2023-07-10 01:44:13+00:00,http://arxiv.org/abs/2307.04303v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.AI",dialogue,"The ingrained principles of fairness in a dialogue system's decision-making
process and generated responses are crucial for user engagement, satisfaction,
and task achievement. Absence of equitable and inclusive principles can hinder
the formation of common ground, which in turn negatively impacts the overall
performance of the system. For example, misusing pronouns in a user interaction
may cause ambiguity about the intended subject. Yet, there is no comprehensive
study of equitable text generation in dialogue. Aptly, in this work, we use
theories of computational learning to study this problem. We provide formal
definitions of equity in text generation, and further, prove formal connections
between learning human-likeness and learning equity: algorithms for improving
equity ultimately reduce to algorithms for improving human-likeness (on
augmented data). With this insight, we also formulate reasonable conditions
under which text generation algorithms can learn to generate equitable text
without any modifications to the biased training data on which they learn. To
exemplify our theory in practice, we look at a group of algorithms for the
GuessWhat?! visual dialogue game and, using this example, test our theory
empirically. Our theory accurately predicts relative-performance of multiple
algorithms in generating equitable text as measured by both human and automated
evaluation.",2023-07-10
"Opening up ChatGPT: Tracking openness, transparency, and accountability
  in instruction-tuned text generators",2023-07-08 07:08:20+00:00,http://arxiv.org/abs/2307.05532v1,"Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse",cs.CL,dialogue,"Large language models that exhibit instruction-following behaviour represent
one of the biggest recent upheavals in conversational interfaces, a trend in
large part fuelled by the release of OpenAI's ChatGPT, a proprietary large
language model for text generation fine-tuned through reinforcement learning
from human feedback (LLM+RLHF). We review the risks of relying on proprietary
software and survey the first crop of open-source projects of comparable
architecture and functionality. The main contribution of this paper is to show
that openness is differentiated, and to offer scientific documentation of
degrees of openness in this fast-moving field. We evaluate projects in terms of
openness of code, training data, model weights, RLHF data, licensing,
scientific documentation, and access methods. We find that while there is a
fast-growing list of projects billing themselves as 'open source', many inherit
undocumented data of dubious legality, few share the all-important
instruction-tuning (a key site where human annotation labour is involved), and
careful scientific documentation is exceedingly rare. Degrees of openness are
relevant to fairness and accountability at all points, from data collection and
curation to model architecture, and from training and fine-tuning to release
and deployment.",2023-07-08
"Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement
  Learning",2023-07-05 19:48:03+00:00,http://arxiv.org/abs/2307.02620v1,"Colin Bellinger, Mark Crowley, Isaac Tamblyn","cs.LG, cs.AI, 68T01, I.2.0",dialogue,"Reinforcement learning (RL) has been shown to learn sophisticated control
policies for complex tasks including games, robotics, heating and cooling
systems and text generation. The action-perception cycle in RL, however,
generally assumes that a measurement of the state of the environment is
available at each time step without a cost. In applications such as deep-sea
and planetary robot exploration, materials design and medicine, however, there
can be a high cost associated with measuring, or even approximating, the state
of the environment. In this paper, we survey the recently growing literature
that adopts the perspective that an RL agent might not need, or even want, a
costly measurement at each time step. Within this context, we propose the Deep
Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the
literature and empirically evaluate it on OpenAI gym and Atari Pong
environments. Our results, show that DMSOA learns a better policy with fewer
decision steps and measurements than the considered alternative from the
literature.",2023-07-05
"Knowledge-Aware Audio-Grounded Generative Slot Filling for Limited
  Annotated Data",2023-07-04 15:05:42+00:00,http://arxiv.org/abs/2307.01764v1,"Guangzhi Sun, Chao Zhang, Ivan Vulić, Paweł Budzianowski, Philip C. Woodland",cs.CL,dialogue,"Manually annotating fine-grained slot-value labels for task-oriented dialogue
(ToD) systems is an expensive and time-consuming endeavour. This motivates
research into slot-filling methods that operate with limited amounts of
labelled data. Moreover, the majority of current work on ToD is based solely on
text as the input modality, neglecting the additional challenges of imperfect
automatic speech recognition (ASR) when working with spoken language. In this
work, we propose a Knowledge-Aware Audio-Grounded generative slot-filling
framework, termed KA2G, that focuses on few-shot and zero-shot slot filling for
ToD with speech input. KA2G achieves robust and data-efficient slot filling for
speech-based ToD by 1) framing it as a text generation task, 2) grounding text
generation additionally in the audio modality, and 3) conditioning on available
external knowledge (e.g. a predefined list of possible slot values). We show
that combining both modalities within the KA2G framework improves the
robustness against ASR errors. Further, the knowledge-aware slot-value
generator in KA2G, implemented via a pointer generator mechanism, particularly
benefits few-shot and zero-shot learning. Experiments, conducted on the
standard speech-based single-turn SLURP dataset and a multi-turn dataset
extracted from a commercial ToD system, display strong and consistent gains
over prior work, especially in few-shot and zero-shot setups.",2023-07-04
Knowledge Graph for NLG in the context of conversational agents,2023-07-04 08:03:33+00:00,http://arxiv.org/abs/2307.01548v1,"Hussam Ghanem, Massinissa Atmani, Christophe Cruz",cs.AI,dialogue,"The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness
of the responses provided by a conversational agent. While generating answers
during conversations consists in generating text from these KGs, it is still
regarded as a challenging task that has gained significant attention in recent
years. In this document, we provide a review of different architectures used
for knowledge graph-to-text generation including: Graph Neural Networks, the
Graph Transformer, and linearization with seq2seq models. We discuss the
advantages and limitations of each architecture and conclude that the choice of
architecture will depend on the specific requirements of the task at hand. We
also highlight the importance of considering constraints such as execution time
and model validity, particularly in the context of conversational agents. Based
on these constraints and the availability of labeled data for the domains of
DAVI, we choose to use seq2seq Transformer-based models (PLMs) for the
Knowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of
kg-to-text generation on PLMs and to explore the emotional and multilingual
dimensions in our future work. Overall, this review provides insights into the
different approaches for knowledge graph-to-text generation and outlines future
directions for research in this area.",2023-07-04
"PatternGPT :A Pattern-Driven Framework for Large Language Model Text
  Generation",2023-07-02 04:32:41+00:00,http://arxiv.org/abs/2307.00470v4,"Le Xiao, Xin Shan","cs.CL, cs.AI",dialogue,"Large language models(LLMS)have shown excellent text generation capabilities,
capable of generating fluent human-like responses for many downstream tasks.
However, applying large language models to real-world critical tasks remains
challenging due to their susceptibility to hallucinations and inability to
directly use external knowledge. To cope with the above challenges, this paper
proposes PatternGPT, a pattern-driven text generation framework for Large
Language Models. Firstly, the framework utilizes the extraction capability of
Large Language Models to generate rich and diversified structured and
formalized patterns, which facilitates the introduction of external knowledge
to do the computation, and then draws on the idea of federated learning to use
multiple agents to achieve the sharing in order to obtain more diversified
patterns, and finally uses judgment criteria and optimization algorithm to
search for high-quality patterns to guide the generation of models. Finally,
external knowledge such as judgment criteria and optimization algorithms are
used to search for high-quality patterns, and the searched patterns are used to
guide model generation. This framework has the advantages of generating
diversified patterns, protecting data privacy, combining external knowledge,
and improving the quality of generation, which provides an effective method to
optimize the text generation capability of large language models, and make it
better applied to the field of intelligent dialogue and content generation.",2023-07-02
Personality Traits in Large Language Models,2023-07-01 00:58:51+00:00,http://arxiv.org/abs/2307.00184v1,"Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, Maja Matarić","cs.CL, cs.AI, cs.CY, cs.HC, 68T35, I.2.7",dialogue,"The advent of large language models (LLMs) has revolutionized natural
language processing, enabling the generation of coherent and contextually
relevant text. As LLMs increasingly power conversational agents, the
synthesized personality embedded in these models by virtue of their training on
large amounts of human-generated data draws attention. Since personality is an
important factor determining the effectiveness of communication, we present a
comprehensive method for administering validated psychometric tests and
quantifying, analyzing, and shaping personality traits exhibited in text
generated from widely-used LLMs. We find that: 1) personality simulated in the
outputs of some LLMs (under specific prompting configurations) is reliable and
valid; 2) evidence of reliability and validity of LLM-simulated personality is
stronger for larger and instruction fine-tuned models; and 3) personality in
LLM outputs can be shaped along desired dimensions to mimic specific
personality profiles. We also discuss potential applications and ethical
implications of our measurement and shaping framework, especially regarding
responsible use of LLMs.",2023-07-01
Open-Domain Text Evaluation via Meta Distribution Modeling,2023-06-20 20:37:54+00:00,http://arxiv.org/abs/2306.11879v1,"Sidi Lu, Asli Celikyilmaz, Tianlu Wang, Nanyun Peng",cs.CL,dialogue,"Recent advances in open-domain text generation models powered by large
pre-trained language models (LLMs) have achieved remarkable performance.
However, evaluating and controlling these models for desired attributes remains
a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and
METEOR are insufficient for open-ended generation tasks. Similarly, while
trainable discriminator-based evaluation metrics show promise, obtaining
high-quality training data is a non-trivial task. In this paper, we introduce a
novel approach to evaluate open-domain generation - the Meta-Distribution
Methods (MDM). Drawing on the correlation between the rising parameter counts
and the improving performance of LLMs, MDM creates a mapping from the contrast
of two probabilistic distributions -- one known to be superior to the other --
to quality measures, which can be viewed as a distribution of distributions
i.e. Meta-Distribution. We investigate MDM for open-domain text generation
evaluation under two paradigms: 1) \emph{Generative} MDM, which leverages the
Meta-Distribution Methods to generate in-domain negative samples for training
discriminator-based metrics; 2) \emph{Discriminative} MDM, which directly uses
distribution discrepancies between two language models for evaluation. Our
experiments on multi-turn dialogue and factuality in abstractive summarization
demonstrate that MDMs correlate better with human judgment than existing
automatic evaluation metrics on both tasks, highlighting the strong performance
and generalizability of such methods.",2023-06-20
Learning to Generate Better Than Your LLM,2023-06-20 18:19:17+00:00,http://arxiv.org/abs/2306.11816v1,"Jonathan D. Chang, Kiante Brantley, Rajkumar Ramamurthy, Dipendra Misra, Wen Sun","cs.LG, cs.AI, cs.CL",dialogue,"Reinforcement learning (RL) has emerged as a powerful paradigm for
fine-tuning Large Language Models (LLMs) for conditional text generation. In
particular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent
conversations with users by incorporating RL and feedback from humans. Inspired
by learning-to-search algorithms and capitalizing on key properties of text
generation, we seek to investigate reinforcement learning algorithms beyond
general purpose algorithms such as Proximal policy optimization (PPO). In
particular, we extend RL algorithms to allow them to interact with a dynamic
black-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a
suite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive
review and CommonGen text generation task from the GRUE benchmark. We show that
our RL algorithms achieve higher performance than supervised learning (SL) and
default PPO baselines, demonstrating the benefit of interaction with the guide
LLM. On CommonGen, we not only outperform our SL baselines but also improve
beyond PPO across a variety of lexical and semantic metrics beyond the one we
optimized for. Notably, on the IMDB dataset, we show that our GPT-2 based
policy outperforms the zero-shot GPT-3 oracle, indicating that our algorithms
can learn from a powerful, black-box GPT-3 oracle with a simpler, cheaper, and
publicly available GPT-2 model while gaining performance.",2023-06-20
"ChatGPT is not Enough: Enhancing Large Language Models with Knowledge
  Graphs for Fact-aware Language Modeling",2023-06-20 12:21:06+00:00,http://arxiv.org/abs/2306.11489v1,"Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, Xindong Wu","cs.CL, cs.AI",dialogue,"Recently, ChatGPT, a representative large language model (LLM), has gained
considerable attention due to its powerful emergent abilities. Some researchers
suggest that LLMs could potentially replace structured knowledge bases like
knowledge graphs (KGs) and function as parameterized knowledge bases. However,
while LLMs are proficient at learning probabilistic language patterns based on
large corpus and engaging in conversations with humans, they, like previous
smaller pre-trained language models (PLMs), still have difficulty in recalling
facts while generating knowledge-grounded contents. To overcome these
limitations, researchers have proposed enhancing data-driven PLMs with
knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus
improving their performance to generate texts requiring factual knowledge and
providing more informed responses to user queries. This paper reviews the
studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced
pre-trained language models (KGPLMs) as well as their applications. Inspired by
existing studies on KGPLM, this paper proposes to enhance LLMs with KGs by
developing knowledge graph-enhanced large language models (KGLLMs). KGLLM
provides a solution to enhance LLMs' factual reasoning ability, opening up new
avenues for LLM research.",2023-06-20
"FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for
  Task-Oriented Dialogue",2023-06-17 10:40:07+00:00,http://arxiv.org/abs/2306.10315v1,"Weihao Zeng, Keqing He, Yejie Wang, Chen Zeng, Jingang Wang, Yunsen Xian, Weiran Xu",cs.CL,dialogue,"Pre-trained language models based on general text enable huge success in the
NLP scenario. But the intrinsical difference of linguistic patterns between
general text and task-oriented dialogues makes existing pre-trained language
models less useful in practice. Current dialogue pre-training methods rely on a
contrastive framework and face the challenges of both selecting true positives
and hard negatives. In this paper, we propose a novel dialogue pre-training
model, FutureTOD, which distills future knowledge to the representation of the
previous dialogue context using a self-training framework. Our intuition is
that a good dialogue representation both learns local context information and
predicts future information. Extensive experiments on diverse downstream
dialogue tasks demonstrate the effectiveness of our model, especially the
generalization, robustness, and learning discriminative dialogue
representations capabilities.",2023-06-17
On the N-gram Approximation of Pre-trained Language Models,2023-06-12 06:42:08+00:00,http://arxiv.org/abs/2306.06892v1,"Aravind Krishnan, Jesujoba Alabi, Dietrich Klakow",cs.CL,dialogue,"Large pre-trained language models (PLMs) have shown remarkable performance
across various natural language understanding (NLU) tasks, particularly in
low-resource settings. Nevertheless, their potential in Automatic Speech
Recognition (ASR) remains largely unexplored. This study investigates the
potential usage of PLMs for language modelling in ASR. We compare the
application of large-scale text sampling and probability conversion for
approximating GPT-2 into an n-gram model. Furthermore, we introduce a
vocabulary-restricted decoding method for random sampling, and evaluate the
effects of domain difficulty and data size on the usability of generated text.
Our findings across eight domain-specific corpora support the use of
sampling-based approximation and show that interpolating with a large sampled
corpus improves test perplexity over a baseline trigram by 15%. Our
vocabulary-restricted decoding method pushes this improvement further by 5% in
domain-specific settings.",2023-06-12
Emotion and Sentiment Guided Paraphrasing,2023-06-08 20:59:40+00:00,http://arxiv.org/abs/2306.05556v1,"Justin J. Xie, Ameeta Agrawal","cs.CL, cs.LG",dialogue,"Paraphrase generation, a.k.a. paraphrasing, is a common and important task in
natural language processing. Emotional paraphrasing, which changes the emotion
embodied in a piece of text while preserving its meaning, has many potential
applications, including moderating online dialogues and preventing
cyberbullying. We introduce a new task of fine-grained emotional paraphrasing
along emotion gradients, that is, altering the emotional intensities of the
paraphrases in fine-grained settings following smooth variations in affective
dimensions while preserving the meaning of the original text. We reconstruct
several widely used paraphrasing datasets by augmenting the input and target
texts with their fine-grained emotion labels. Then, we propose a framework for
emotion and sentiment guided paraphrasing by leveraging pre-trained language
models for conditioned text generation. Extensive evaluation of the fine-tuned
models suggests that including fine-grained emotion labels in the paraphrase
task significantly improves the likelihood of obtaining high-quality
paraphrases that reflect the desired emotions while achieving consistently
better scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.",2023-06-08
"IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for
  multilayer summarization of clinical conversations?",2023-06-07 10:47:33+00:00,http://arxiv.org/abs/2306.04328v1,Dhananjay Srivastava,cs.CL,dialogue,"Clinical conversation summarization has become an important application of
Natural language Processing. In this work, we intend to analyze summarization
model ensembling approaches, that can be utilized to improve the overall
accuracy of the generated medical report called chart note. The work starts
with a single summarization model creating the baseline. Then leads to an
ensemble of summarization models trained on a separate section of the chart
note. This leads to the final approach of passing the generated results to
another summarization model in a multi-layer/stage fashion for better coherency
of the generated text. Our results indicate that although an ensemble of models
specialized in each section produces better results, the multi-layer/stage
approach does not improve accuracy. The code for the above paper is available
at https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git",2023-06-07
"Correction of Errors in Preference Ratings from Automated Metrics for
  Text Generation",2023-06-06 17:09:29+00:00,http://arxiv.org/abs/2306.03866v1,"Jan Deriu, Pius von Däniken, Don Tuggener, Mark Cieliebak","cs.CL, cs.AI",dialogue,"A major challenge in the field of Text Generation is evaluation: Human
evaluations are cost-intensive, and automated metrics often display
considerable disagreement with human judgments. In this paper, we propose a
statistical model of Text Generation evaluation that accounts for the
error-proneness of automated metrics when used to generate preference rankings
between system outputs. We show that existing automated metrics are generally
over-confident in assigning significant differences between systems in this
setting. However, our model enables an efficient combination of human and
automated ratings to remedy the error-proneness of the automated metrics. We
show that using this combination, we only require about 50% of the human
annotations typically used in evaluations to arrive at robust and statistically
significant results while yielding the same evaluation outcome as the pure
human evaluation in 95% of cases. We showcase the benefits of approach for
three text generation tasks: dialogue systems, machine translation, and text
summarization.",2023-06-06
"Injecting knowledge into language generation: a case study in
  auto-charting after-visit care instructions from medical dialogue",2023-06-06 13:13:27+00:00,http://arxiv.org/abs/2306.03652v1,"Maksim Eremeev, Ilya Valmianski, Xavier Amatriain, Anitha Kannan",cs.CL,dialogue,"Factual correctness is often the limiting factor in practical applications of
natural language generation in high-stakes domains such as healthcare. An
essential requirement for maintaining factuality is the ability to deal with
rare tokens. This paper focuses on rare tokens that appear in both the source
and the reference sequences, and which, when missed during generation, decrease
the factual correctness of the output text. For high-stake domains that are
also knowledge-rich, we show how to use knowledge to (a) identify which rare
tokens that appear in both source and reference are important and (b) uplift
their conditional probability. We introduce the ``utilization rate'' that
encodes knowledge and serves as a regularizer by maximizing the marginal
probability of selected tokens. We present a study in a knowledge-rich domain
of healthcare, where we tackle the problem of generating after-visit care
instructions based on patient-doctor dialogues. We verify that, in our dataset,
specific medical concepts with high utilization rates are underestimated by
conventionally trained sequence-to-sequence models. We observe that correcting
this with our approach to knowledge injection reduces the uncertainty of the
model as well as improves factuality and coherence without negatively impacting
fluency.",2023-06-06
"Diverse and Faithful Knowledge-Grounded Dialogue Generation via
  Sequential Posterior Inference",2023-06-01 21:23:13+00:00,http://arxiv.org/abs/2306.01153v1,"Yan Xu, Deqian Kong, Dehong Xu, Ziwei Ji, Bo Pang, Pascale Fung, Ying Nian Wu",cs.CL,dialogue,"The capability to generate responses with diversity and faithfulness using
factual knowledge is paramount for creating a human-like, trustworthy dialogue
system. Common strategies either adopt a two-step paradigm, which optimizes
knowledge selection and response generation separately, and may overlook the
inherent correlation between these two tasks, or leverage conditional
variational method to jointly optimize knowledge selection and response
generation by employing an inference network. In this paper, we present an
end-to-end learning framework, termed Sequential Posterior Inference (SPI),
capable of selecting knowledge and generating dialogues by approximately
sampling from the posterior distribution. Unlike other methods, SPI does not
require the inference network or assume a simple geometry of the posterior
distribution. This straightforward and intuitive inference procedure of SPI
directly queries the response generation model, allowing for accurate knowledge
selection and generation of faithful responses. In addition to modeling
contributions, our experimental results on two common dialogue datasets (Wizard
of Wikipedia and Holl-E) demonstrate that SPI outperforms previous strong
baselines according to both automatic and human evaluation metrics.",2023-06-01
"Deliberate then Generate: Enhanced Prompting Framework for Text
  Generation",2023-05-31 13:23:04+00:00,http://arxiv.org/abs/2305.19835v1,"Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan, Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian, JingBo Zhu","cs.CL, cs.AI",dialogue,"Large language models (LLMs) have shown remarkable success across a wide
range of natural language generation tasks, where proper prompt designs make
great impacts. While existing prompting methods are normally restricted to
providing correct information, in this paper, we encourage the model to
deliberate by proposing a novel Deliberate then Generate (DTG) prompting
framework, which consists of error detection instructions and candidates that
may contain errors. DTG is a simple yet effective technique that can be applied
to various text generation tasks with minimal modifications. We conduct
extensive experiments on 20+ datasets across 7 text generation tasks, including
summarization, translation, dialogue, and more. We show that DTG consistently
outperforms existing prompting methods and achieves state-of-the-art
performance on multiple text generation tasks. We also provide in-depth
analyses to reveal the underlying mechanisms of DTG, which may inspire future
research on prompting for LLMs.",2023-05-31
"Knowledge Graph-Augmented Language Models for Knowledge-Grounded
  Dialogue Generation",2023-05-30 08:36:45+00:00,http://arxiv.org/abs/2305.18846v1,"Minki Kang, Jin Myung Kwak, Jinheon Baek, Sung Ju Hwang","cs.CL, cs.AI, cs.LG",dialogue,"Language models have achieved impressive performances on dialogue generation
tasks. However, when generating responses for a conversation that requires
factual knowledge, they are far from perfect, due to an absence of mechanisms
to retrieve, encode, and reflect the knowledge in the generated responses. Some
knowledge-grounded dialogue generation methods tackle this problem by
leveraging facts from Knowledge Graphs (KGs); however, they do not guarantee
that the model utilizes a relevant piece of knowledge from the KG. To overcome
this limitation, we propose SUbgraph Retrieval-augmented GEneration (SURGE), a
framework for generating context-relevant and knowledge-grounded dialogues with
the KG. Specifically, our SURGE framework first retrieves the relevant subgraph
from the KG, and then enforces consistency across facts by perturbing their
word embeddings conditioned by the retrieved subgraph. Then, we utilize
contrastive learning to ensure that the generated texts have high similarity to
the retrieved subgraphs. We validate our SURGE framework on OpendialKG and
KOMODIS datasets, showing that it generates high-quality dialogues that
faithfully reflect the knowledge from KG.",2023-05-30
Perceived Trustworthiness of Natural Language Generators,2023-05-29 16:09:58+00:00,http://arxiv.org/abs/2305.18176v1,"Beatriz Cabrero-Daniel, Andrea Sanagustín Cabrero","cs.HC, cs.AI, cs.CL",dialogue,"Natural Language Generation tools, such as chatbots that can generate
human-like conversational text, are becoming more common both for personal and
professional use. However, there are concerns about their trustworthiness and
ethical implications. The paper addresses the problem of understanding how
different users (e.g., linguists, engineers) perceive and adopt these tools and
their perception of machine-generated text quality. It also discusses the
perceived advantages and limitations of Natural Language Generation tools, as
well as users' beliefs on governance strategies. The main findings of this
study include the impact of users' field and level of expertise on the
perceived trust and adoption of Natural Language Generation tools, the users'
assessment of the accuracy, fluency, and potential biases of machine-generated
text in comparison to human-written text, and an analysis of the advantages and
ethical risks associated with these tools as identified by the participants.
Moreover, this paper discusses the potential implications of these findings for
enhancing the AI development process. The paper sheds light on how different
user characteristics shape their beliefs on the quality and overall
trustworthiness of machine-generated text. Furthermore, it examines the
benefits and risks of these tools from the perspectives of different users.",2023-05-29
"GripRank: Bridging the Gap between Retrieval and Generation via the
  Generative Knowledge Improved Passage Ranking",2023-05-29 15:15:53+00:00,http://arxiv.org/abs/2305.18144v1,"Jiaqi Bai, Hongcheng Guo, Jiaheng Liu, Jian Yang, Xinnian Liang, Zhao Yan, Zhoujun Li","cs.CL, cs.AI",dialogue,"Retrieval-enhanced text generation, which aims to leverage passages retrieved
from a large passage corpus for delivering a proper answer given the input
query, has shown remarkable progress on knowledge-intensive language tasks such
as open-domain question answering and knowledge-enhanced dialogue generation.
However, the retrieved passages are not ideal for guiding answer generation
because of the discrepancy between retrieval and generation, i.e., the
candidate passages are all treated equally during the retrieval procedure
without considering their potential to generate the proper answers. This
discrepancy makes a passage retriever deliver a sub-optimal collection of
candidate passages to generate answers. In this paper, we propose the
GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing
the above challenge by distilling knowledge from a generative passage estimator
(GPE) to a passage ranker, where the GPE is a generative language model used to
measure how likely the candidate passages can generate the proper answer. We
realize the distillation procedure by teaching the passage ranker learning to
rank the passages ordered by the GPE. Furthermore, we improve the distillation
quality by devising a curriculum knowledge distillation mechanism, which allows
the knowledge provided by the GPE can be progressively distilled to the ranker
through an easy-to-hard curriculum, enabling the passage ranker to correctly
recognize the provenance of the answer from many plausible candidates. We
conduct extensive experiments on four datasets across three knowledge-intensive
language tasks. Experimental results show advantages over the state-of-the-art
methods for both passage ranking and answer generation on the KILT benchmark.",2023-05-29
"A Unified Framework for Slot based Response Generation in a Multimodal
  Dialogue System",2023-05-27 10:06:03+00:00,http://arxiv.org/abs/2305.17433v1,"Mauajama Firdaus, Avinash Madasu, Asif Ekbal","cs.CV, cs.CL",dialogue,"Natural Language Understanding (NLU) and Natural Language Generation (NLG)
are the two critical components of every conversational system that handles the
task of understanding the user by capturing the necessary information in the
form of slots and generating an appropriate response in accordance with the
extracted information. Recently, dialogue systems integrated with complementary
information such as images, audio, or video have gained immense popularity. In
this work, we propose an end-to-end framework with the capability to extract
necessary slot values from the utterance and generate a coherent response,
thereby assisting the user to achieve their desired goals in a multimodal
dialogue system having both textual and visual information. The task of
extracting the necessary information is dependent not only on the text but also
on the visual cues present in the dialogue. Similarly, for the generation, the
previous dialog context comprising multimodal information is significant for
providing coherent and informative responses. We employ a multimodal
hierarchical encoder using pre-trained DialoGPT and also exploit the knowledge
base (Kb) to provide a stronger context for both the tasks. Finally, we design
a slot attention mechanism to focus on the necessary information in a given
utterance. Lastly, a decoder generates the corresponding response for the given
dialogue context and the extracted slot values. Experimental results on the
Multimodal Dialogue Dataset (MMD) show that the proposed framework outperforms
the baselines approaches in both the tasks. The code is available at
https://github.com/avinashsai/slot-gpt.",2023-05-27
Generating Images with Multimodal Language Models,2023-05-26 19:22:03+00:00,http://arxiv.org/abs/2305.17216v1,"Jing Yu Koh, Daniel Fried, Ruslan Salakhutdinov","cs.CL, cs.CV, cs.LG",dialogue,"We propose a method to fuse frozen text-only large language models (LLMs)
with pre-trained image encoder and decoder models, by mapping between their
embedding spaces. Our model demonstrates a wide suite of multimodal
capabilities: image retrieval, novel image generation, and multimodal dialogue.
Ours is the first approach capable of conditioning on arbitrarily interleaved
image and text inputs to generate coherent image (and text) outputs. To achieve
strong performance on image generation, we propose an efficient mapping network
to ground the LLM to an off-the-shelf text-to-image generation model. This
mapping network translates hidden representations of text into the embedding
space of the visual models, enabling us to leverage the strong text
representations of the LLM for visual outputs. Our approach outperforms
baseline generation models on tasks with longer and more complex language. In
addition to novel image generation, our model is also capable of image
retrieval from a prespecified dataset, and decides whether to retrieve or
generate at inference time. This is done with a learnt decision module which
conditions on the hidden representations of the LLM. Our model exhibits a wider
range of capabilities compared to prior multimodal language models. It can
process image-and-text inputs, and produce retrieved images, generated images,
and generated text -- outperforming non-LLM based generation models across
several text-to-image tasks that measure context dependence.",2023-05-26
"Distinguishing Human Generated Text From ChatGPT Generated Text Using
  Machine Learning",2023-05-26 09:27:43+00:00,http://arxiv.org/abs/2306.01761v1,"Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya, Monowara Tabassum Maisha, Dewan Md Farid","cs.CL, cs.AI, cs.LG",dialogue,"ChatGPT is a conversational artificial intelligence that is a member of the
generative pre-trained transformer of the large language model family. This
text generative model was fine-tuned by both supervised learning and
reinforcement learning so that it can produce text documents that seem to be
written by natural intelligence. Although there are numerous advantages of this
generative model, it comes with some reasonable concerns as well. This paper
presents a machine learning-based solution that can identify the ChatGPT
delivered text from the human written text along with the comparative analysis
of a total of 11 machine learning and deep learning algorithms in the
classification process. We have tested the proposed model on a Kaggle dataset
consisting of 10,000 texts out of which 5,204 texts were written by humans and
collected from news and social media. On the corpus generated by GPT-3.5, the
proposed algorithm presents an accuracy of 77%.",2023-05-26
"Response Generation in Longitudinal Dialogues: Which Knowledge
  Representation Helps?",2023-05-25 10:13:53+00:00,http://arxiv.org/abs/2305.15908v1,"Seyed Mahed Mousavi, Simone Caldarella, Giuseppe Riccardi",cs.CL,dialogue,"Longitudinal Dialogues (LD) are the most challenging type of conversation for
human-machine dialogue systems. LDs include the recollections of events,
personal thoughts, and emotions specific to each individual in a sparse
sequence of dialogue sessions. Dialogue systems designed for LDs should
uniquely interact with the users over multiple sessions and long periods of
time (e.g. weeks), and engage them in personal dialogues to elaborate on their
feelings, thoughts, and real-life events. In this paper, we study the task of
response generation in LDs. We evaluate whether general-purpose Pre-trained
Language Models (PLM) are appropriate for this purpose. We fine-tune two PLMs,
GePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different
representations of the personal knowledge extracted from LDs for grounded
response generation, including the graph representation of the mentioned events
and participants. We evaluate the performance of the models via automatic
metrics and the contribution of the knowledge via the Integrated Gradients
technique. We categorize the natural language generation errors via human
evaluations of contextualization, appropriateness and engagement of the user.",2023-05-25
MERGE: Fast Private Text Generation,2023-05-25 06:27:19+00:00,http://arxiv.org/abs/2305.15769v1,"Zi Liang, Pinghui Wang, Ruofei Zhang, Nuo Xu, Shuo Zhang","cs.CL, cs.AI",dialogue,"Recent years have seen increasing concerns about the private inference of NLP
services and Transformer models. However, existing two-party privacy-preserving
methods solely consider NLU scenarios, while the private inference of text
generation such as translation, dialogue, and code completion remains unsolved.
Besides, while migrated to NLG models, existing privacy-preserving methods
perform poorly in terms of inference speed, and suffer from the convergence
problem during the training stage. To address these issues, we propose MERGE, a
fast private text generation framework for Transformer-based language models.
Specifically, MERGE reuse the output hidden state as the word embedding to
bypass the embedding computation, and reorganize the linear operations in the
Transformer module to accelerate the forward procedure. Based on these two
optimizations, extensive experiments show that MERGE can achieve a 26.5x
speedup under the sequence length 512, and reduce 80\% communication bytes,
with an up to 10x speedup to existing state-of-art models.",2023-05-25
Revisiting Sentence Union Generation as a Testbed for Text Consolidation,2023-05-24 22:34:01+00:00,http://arxiv.org/abs/2305.15605v1,"Eran Hirsch, Valentina Pyatkin, Ruben Wolhandler, Avi Caciularu, Asi Shefer, Ido Dagan",cs.CL,dialogue,"Tasks involving text generation based on multiple input texts, such as
multi-document summarization, long-form question answering and contemporary
dialogue applications, challenge models for their ability to properly
consolidate partly-overlapping multi-text information. However, these tasks
entangle the consolidation phase with the often subjective and ill-defined
content selection requirement, impeding proper assessment of models'
consolidation capabilities. In this paper, we suggest revisiting the sentence
union generation task as an effective well-defined testbed for assessing text
consolidation capabilities, decoupling the consolidation challenge from
subjective content selection. To support research on this task, we present
refined annotation methodology and tools for crowdsourcing sentence union,
create the largest union dataset to date and provide an analysis of its rich
coverage of various consolidation aspects. We then propose a comprehensive
evaluation protocol for union generation, including both human and automatic
evaluation. Finally, as baselines, we evaluate state-of-the-art language models
on the task, along with a detailed analysis of their capacity to address
multi-text consolidation challenges and their limitations.",2023-05-24
"RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs
  and for GPTs",2023-05-24 10:30:42+00:00,http://arxiv.org/abs/2305.14994v2,"Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, Zili Wang, Shusen Wang, Hai Zhao",cs.CL,dialogue,"General chat models, like ChatGPT, have attained impressive capability to
resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with
high-quality instruction data. However, collecting human-written high-quality
data, especially multi-turn dialogues, is expensive and unattainable for most
people. Though previous studies have used powerful LLMs to generate the
dialogues automatically, but they all suffer from generating untruthful
dialogues because of the LLMs hallucination. Therefore, we propose a method
called RefGPT to generate enormous truthful and customized dialogues without
worrying about factual errors caused by the model hallucination. RefGPT solves
the model hallucination in dialogue generation by restricting the LLMs to
leverage the given reference instead of reciting their own knowledge to
generate dialogues. Additionally, RefGPT adds detailed controls on every
utterances to enable highly customization capability, which previous studies
have ignored. On the basis of RefGPT, we also propose two high-quality dialogue
datasets generated by GPT-4, namely RefGPT-Fact and RefGPT-Code. RefGPT-Fact is
100k multi-turn dialogue datasets based on factual knowledge and RefGPT-Code is
76k multi-turn dialogue dataset covering a wide range of coding scenarios. Our
code and datasets are released in https://github.com/ziliwangnlp/RefGPT",2023-05-24
Dolphin: A Challenging and Diverse Benchmark for Arabic NLG,2023-05-24 10:24:10+00:00,http://arxiv.org/abs/2305.14989v1,"El Moatez Billah Nagoudi, Ahmed El-Shangiti, AbdelRahim Elmadany, Muhammad Abdul-Mageed",cs.CL,dialogue,"We present Dolphin, a novel benchmark that addresses the need for an
evaluation framework for the wide collection of Arabic languages and varieties.
The proposed benchmark encompasses a broad range of 13 different NLG tasks,
including text summarization, machine translation, question answering, and
dialogue generation, among others. Dolphin comprises a substantial corpus of 40
diverse and representative public datasets across 50 test splits, carefully
curated to reflect real-world scenarios and the linguistic richness of Arabic.
It sets a new standard for evaluating the performance and generalization
capabilities of Arabic and multilingual models, promising to enable researchers
to push the boundaries of current methodologies. We provide an extensive
analysis of Dolphin, highlighting its diversity and identifying gaps in current
Arabic NLG research. We also evaluate several Arabic and multilingual models on
our benchmark, allowing us to set strong baselines against which researchers
can compare.",2023-05-24
"In-Context Impersonation Reveals Large Language Models' Strengths and
  Biases",2023-05-24 09:13:15+00:00,http://arxiv.org/abs/2305.14930v1,"Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, Zeynep Akata","cs.AI, cs.CL, cs.LG",dialogue,"In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.",2023-05-24
"Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented
  Dialogues and Annotations",2023-05-23 22:31:01+00:00,http://arxiv.org/abs/2305.14556v1,"Tiziano Labruna, Sofia Brenna, Andrea Zaninello, Bernardo Magnini","cs.CL, cs.AI",dialogue,"Large pre-trained language models have exhibited unprecedented capabilities
in producing high-quality text via prompting techniques. This fact introduces
new possibilities for data collection and annotation, particularly in
situations where such data is scarce, complex to gather, expensive, or even
sensitive. In this paper, we explore the potential of these models to generate
and annotate goal-oriented dialogues, and conduct an in-depth analysis to
evaluate their quality. Our experiments employ ChatGPT, and encompass three
categories of goal-oriented dialogues (task-oriented, collaborative, and
explanatory), two generation modes (interactive and one-shot), and two
languages (English and Italian). Based on extensive human-based evaluations, we
demonstrate that the quality of generated dialogues and annotations is on par
with those generated by humans.",2023-05-23
Reducing Sensitivity on Speaker Names for Text Generation from Dialogues,2023-05-23 08:53:33+00:00,http://arxiv.org/abs/2305.13833v1,"Qi Jia, Haifeng Tang, Kenny Q. Zhu",cs.CL,dialogue,"Changing speaker names consistently throughout a dialogue should not affect
its meaning and corresponding outputs for text generation from dialogues.
However, pre-trained language models, serving as the backbone for
dialogue-processing tasks, have shown to be sensitive to nuances. This may
result in unfairness in real-world applications. No comprehensive analysis of
this problem has been done in the past. In this work, we propose to
quantitatively measure a model's sensitivity on speaker names, and
comprehensively evaluate a number of known methods for reducing speaker name
sensitivity, including a novel approach of our own. Extensive experiments on
multiple datasets provide a benchmark for this problem and show the favorable
performance of our approach in sensitivity reduction and quality of generation.",2023-05-23
"DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text
  Diffusion",2023-05-19 08:30:11+00:00,http://arxiv.org/abs/2305.11517v1,"Chao-Hong Tan, Jia-Chen Gu, Zhen-Hua Ling","cs.CL, cs.AI",dialogue,"Diffusion models have emerged as the new state-of-the-art family of deep
generative models, and their promising potentials for text generation have
recently attracted increasing attention. Existing studies mostly adopt a single
encoder architecture with partially noising processes for conditional text
generation, but its degree of flexibility for conditional modeling is limited.
In fact, the encoder-decoder architecture is naturally more flexible for its
detachable encoder and decoder modules, which is extensible to multilingual and
multimodal generation tasks for conditions and target texts. However, the
encoding process of conditional texts lacks the understanding of target texts.
To this end, a spiral interaction architecture for encoder-decoder text
diffusion (DiffuSIA) is proposed. Concretely, the conditional information from
encoder is designed to be captured by the diffusion decoder, while the target
information from decoder is designed to be captured by the conditional encoder.
These two types of information flow run through multilayer interaction spirally
for deep fusion and understanding. DiffuSIA is evaluated on four text
generation tasks, including paraphrase, text simplification, question
generation, and open-domain dialogue generation. Experimental results show that
DiffuSIA achieves competitive performance among previous methods on all four
tasks, demonstrating the effectiveness and generalization ability of the
proposed method.",2023-05-19
TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks,2023-05-19 04:59:34+00:00,http://arxiv.org/abs/2305.11430v1,"Shubhra Kanti Karmaker Santu, Dongji Feng","cs.AI, cs.CL, cs.IR, cs.LG, I.2.7",dialogue,"While LLMs have shown great success in understanding and generating text in
traditional conversational settings, their potential for performing ill-defined
complex tasks is largely under-studied. Indeed, we are yet to conduct
comprehensive benchmarking studies with multiple LLMs that are exclusively
focused on a complex task. However, conducting such benchmarking studies is
challenging because of the large variations in LLMs' performance when different
prompt types/styles are used and different degrees of detail are provided in
the prompts. To address this issue, the paper proposes a general taxonomy that
can be used to design prompts with specific properties in order to perform a
wide range of complex tasks. This taxonomy will allow future benchmarking
studies to report the specific categories of prompts used as part of the study,
enabling meaningful comparisons across different studies. Also, by establishing
a common standard through this taxonomy, researchers will be able to draw more
accurate conclusions about LLMs' performance on a specific complex task.",2023-05-19
"CHBias: Bias Evaluation and Mitigation of Chinese Conversational
  Language Models",2023-05-18 18:58:30+00:00,http://arxiv.org/abs/2305.11262v1,"Jiaxu Zhao, Meng Fang, Zijing Shi, Yitong Li, Ling Chen, Mykola Pechenizkiy",cs.CL,dialogue,"\textit{\textbf{\textcolor{red}{Warning}:} This paper contains content that
may be offensive or upsetting.} Pretrained conversational agents have been
exposed to safety issues, exhibiting a range of stereotypical human biases such
as gender bias. However, there are still limited bias categories in current
research, and most of them only focus on English. In this paper, we introduce a
new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese
conversational language models. Apart from those previous well-explored bias
categories, CHBias includes under-explored bias categories, such as ageism and
appearance biases, which received less attention. We evaluate two popular
pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias.
Furthermore, to mitigate different biases, we apply several debiasing methods
to the Chinese pretrained models. Experimental results show that these Chinese
pretrained models are potentially risky for generating texts that contain
social biases, and debiasing methods using the proposed dataset can make
response generation less biased while preserving the models' conversational
capabilities.",2023-05-18
Boosting Event Extraction with Denoised Structure-to-Text Augmentation,2023-05-16 16:52:07+00:00,http://arxiv.org/abs/2305.09598v1,"bo wang, Heyan Huang, Xiaochi Wei, Ge Shi, Xiao Liu, Chong Feng, Tong Zhou, Shuaiqiang Wang, Dawei Yin",cs.CL,dialogue,"Event extraction aims to recognize pre-defined event triggers and arguments
from texts, which suffer from the lack of high-quality annotations. In most NLP
applications, involving a large scale of synthetic training data is a practical
and effective approach to alleviate the problem of data scarcity. However, when
applying to the task of event extraction, recent data augmentation methods
often neglect the problem of grammatical incorrectness, structure misalignment,
and semantic drifting, leading to unsatisfactory performances. In order to
solve these problems, we propose a denoised structure-to-text augmentation
framework for event extraction DAEE, which generates additional training data
through the knowledge-based structure-to-text generation model and selects the
effective subset from the generated data iteratively with a deep reinforcement
learning agent. Experimental results on several datasets demonstrate that the
proposed method generates more diverse text representations for event
extraction and achieves comparable results with the state-of-the-art.",2023-05-16
"Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice
  and Feedback",2023-05-15 19:48:59+00:00,http://arxiv.org/abs/2305.08982v1,"Shang-Ling Hsu, Raj Sanjay Shah, Prathik Senthil, Zahra Ashktorab, Casey Dugan, Werner Geyer, Diyi Yang","cs.HC, cs.CL",dialogue,"Millions of users come to online peer counseling platforms to seek support on
diverse topics ranging from relationship stress to anxiety. However, studies
show that online peer support groups are not always as effective as expected
largely due to users' negative experiences with unhelpful counselors. Peer
counselors are key to the success of online peer counseling platforms, but most
of them often do not have systematic ways to receive guidelines or supervision.
In this work, we introduce CARE: an interactive AI-based tool to empower peer
counselors through automatic suggestion generation. During the practical
training stage, CARE helps diagnose which specific counseling strategies are
most suitable in the given context and provides tailored example responses as
suggestions. Counselors can choose to select, modify, or ignore any suggestion
before replying to the support seeker. Building upon the Motivational
Interviewing framework, CARE utilizes large-scale counseling conversation data
together with advanced natural language generation techniques to achieve these
functionalities. We demonstrate the efficacy of CARE by performing both
quantitative evaluations and qualitative user studies through simulated chats
and semi-structured interviews. We also find that CARE especially helps novice
counselors respond better in challenging situations.",2023-05-15
"NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric
  Preference Checklist",2023-05-15 11:51:55+00:00,http://arxiv.org/abs/2305.08566v3,"Iftitahu Ni'mah, Meng Fang, Vlado Menkovski, Mykola Pechenizkiy",cs.CL,dialogue,"In this study, we analyze NLG automatic metrics based on whether human
evaluation aspect is used as context or objective to compute the metrics: (i)
Task-agnostic and (ii) Human-aligned. Task-agnostic metrics, such as
Perplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverse
NLG tasks, yet they have a weak correlation with human. Human-aligned metrics
(CTC, CtrlEval, UniEval) improves correlation level by incorporating desirable
human-like qualities as training objective. However, their effectiveness at
discerning system-level performance and quality of system outputs remain
unclear.
  We present metric preference checklist as a framework to assess the
discriminative power of automatic metrics in three NLG tasks: Text
Summarization, Dialogue Response Generation, and Controlled Generation. We show
that multi-aspect human-aligned metric (UniEval) is not necessarily dominant
over single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnostic
metrics (BLEU, BERTScore), particularly when a disagreement between human
evaluation aspects is present. We also show particular use cases in which
automatic metrics provide a better guidance than human on discriminating
system-level performance. Our proposed framework provides access: (i) for
verifying whether automatic metrics are faithful to human preference,
regardless their correlation level to human; and (ii) for scrutinizing the
strengths and limitations of NLG systems, which are often obscured by a
standard averaging method of evaluation scores.",2023-05-15
"ProKnow: Process Knowledge for Safety Constrained and Explainable
  Question Generation for Mental Health Diagnostic Assistance",2023-05-13 21:31:02+00:00,http://arxiv.org/abs/2305.08010v1,"Kaushik Roy, Manas Gaur, Misagh Soltani, Vipula Rawte, Ashwin Kalyan, Amit Sheth",cs.CL,dialogue,"Current Virtual Mental Health Assistants (VMHAs) provide counseling and
suggestive care. They refrain from patient diagnostic assistance because they
lack training in safety-constrained and specialized clinical process knowledge.
In this work, we define Proknow as an ordered set of information that maps to
evidence-based guidelines or categories of conceptual understanding to experts
in a domain. We also introduce a new dataset of diagnostic conversations guided
by safety constraints and Proknow that healthcare professionals use. We develop
a method for natural language question generation (NLG) that collects
diagnostic information from the patient interactively. We demonstrate the
limitations of using state-of-the-art large-scale language models (LMs) on this
dataset. Our algorithm models the process knowledge through explicitly modeling
safety, knowledge capture, and explainability. LMs augmented with ProKnow
guided method generated 89% safer questions in the depression and anxiety
domain. The Explainability of the generated question is assessed by computing
similarity with concepts in depression and anxiety knowledge bases. Overall,
irrespective of the type of LMs augmented with our ProKnow, we achieved an
average 82% improvement over simple pre-trained LMs on safety, explainability,
and process-guided question generation. We qualitatively and quantitatively
evaluate the efficacy of the proposed ProKnow-guided methods by introducing
three new evaluation metrics for safety, explainability, and process knowledge
adherence.",2023-05-13
"Dialogue Planning via Brownian Bridge Stochastic Process for
  Goal-directed Proactive Dialogue",2023-05-09 09:28:23+00:00,http://arxiv.org/abs/2305.05290v1,"Jian Wang, Dongding Lin, Wenjie Li","cs.CL, cs.LG",dialogue,"Goal-directed dialogue systems aim to proactively reach a pre-determined
target through multi-turn conversations. The key to achieving this task lies in
planning dialogue paths that smoothly and coherently direct conversations
towards the target. However, this is a challenging and under-explored task. In
this work, we propose a coherent dialogue planning approach that uses a
stochastic process to model the temporal dynamics of dialogue paths. We define
a latent space that captures the coherence of goal-directed behavior using a
Brownian bridge process, which allows us to incorporate user feedback flexibly
in dialogue planning. Based on the derived latent trajectories, we generate
dialogue paths explicitly using pre-trained language models. We finally employ
these paths as natural language prompts to guide dialogue generation. Our
experiments show that our approach generates more coherent utterances and
achieves the goal with a higher success rate.",2023-05-09
Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System,2023-05-04 00:17:49+00:00,http://arxiv.org/abs/2305.02468v1,"Namo Bang, Jeehyun Lee, Myoung-Wan Koo",cs.CL,dialogue,"Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks
by tracking dialogue states and generating appropriate responses to help users
achieve defined goals. Recently, end-to-end dialogue models pre-trained based
on large datasets have shown promising performance in the conversational
system. However, they share the same parameters to train tasks of the dialogue
system (NLU, DST, NLG), so debugging each task is challenging. Also, they
require a lot of effort to fine-tune large parameters to create a task-oriented
chatbot, making it difficult for non-experts to handle. Therefore, we intend to
train relatively lightweight and fast models compared to PLM. In this paper, we
propose an End-to-end TOD system with Task-Optimized Adapters which learn
independently per task, adding only small number of parameters after fixed
layers of pre-trained network. We also enhance the performance of the DST and
NLG modules through reinforcement learning, overcoming the learning curve that
has lacked at the adapter learning and enabling the natural and consistent
response generation that is appropriate for the goal. Our method is a
model-agnostic approach and does not require prompt-tuning as only input data
without a prompt. As results of the experiment, our method shows competitive
performance on the MultiWOZ benchmark compared to the existing end-to-end
models. In particular, we attain state-of-the-art performance on the DST task
of 2.2 dataset.",2023-05-04
Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory,2023-05-03 21:40:54+00:00,http://arxiv.org/abs/2305.02437v1,"Xin Cheng, Di Luo, Xiuying Chen, Lemao Liu, Dongyan Zhao, Rui Yan","cs.CL, cs.AI",dialogue,"With direct access to human-written reference as memory, retrieval-augmented
generation has achieved much progress in a wide range of text generation tasks.
Since better memory would typically prompt better generation~(we define this as
primal problem), previous works mainly focus on how to retrieve better memory.
However, one fundamental limitation exists for current literature: the memory
is retrieved from a fixed corpus and is bounded by the quality of the corpus.
Due to the finite retrieval space, bounded memory would greatly limit the
potential of the memory-augmented generation model. In this paper, by exploring
the duality of the primal problem: better generation also prompts better
memory, we propose a framework called Selfmem, which iteratively adopts a
retrieval-augmented generator itself to generate an unbounded memory pool and
uses a memory selector to pick one generated memory for the next generation
round. By combining the primal and dual problem, a retrieval-augmented
generation model could lift itself up with its own output in the infinite
generation space. To verify our framework, we conduct extensive experiments
across various text generation scenarios including neural machine translation,
abstractive summarization and dialogue generation over seven datasets and
achieve state-of-the-art results in JRC-Acquis(four directions), XSum(50.3
ROUGE-1) and BigPatent(62.9 ROUGE-1).",2023-05-03
"CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to
  Guardrail Models for Virtual Assistants",2023-04-27 17:39:11+00:00,http://arxiv.org/abs/2304.14364v1,"Albert Yu Sun, Varun Nair, Elliot Schumacher, Anitha Kannan","cs.CL, cs.AI, cs.LG",dialogue,"A wave of new task-based virtual assistants has been fueled by increasingly
powerful large language models, such as GPT-4. These conversational agents can
be customized to serve customer-specific use cases, but ensuring that
agent-generated text conforms to designer-specified rules included in prompt
instructions alone is challenging. Therefore, chatbot designers often use
another model, called a guardrail model, to verify that the agent output aligns
with their rules and constraints. We explore using a distillation approach to
guardrail models to monitor the output of the first model using training data
from GPT-4. We find two crucial steps to our CONSCENDI process:
scenario-augmented generation and contrastive training examples. When
generating conversational data, we generate a set of rule-breaking scenarios,
which enumerate a diverse set of high-level ways a rule can be violated. This
scenario-guided approach produces a diverse training set of rule-violating
conversations, and it provides chatbot designers greater control over the
classification process. We also prompt GPT-4 to also generate contrastive
examples by altering conversations with violations into acceptable
conversations. This set of borderline, contrastive examples enables the
distilled model to learn finer-grained distinctions between what is acceptable
and what is not. We find that CONSCENDI results in guardrail models that
improve over baselines.",2023-04-27
"Which Factors Predict the Chat Experience of a Natural Language
  Generation Dialogue Service?",2023-04-21 07:29:07+00:00,http://arxiv.org/abs/2304.10785v1,Eason Chen,"cs.CL, cs.HC",dialogue,"In this paper, we proposed a conceptual model to predict the chat experience
in a natural language generation dialog system. We evaluated the model with 120
participants with Partial Least Squares Structural Equation Modeling (PLS-SEM)
and obtained an R-square (R2) with 0.541. The model considers various factors,
including the prompts used for generation; coherence, sentiment, and similarity
in the conversation; and users' perceived dialog agents' favorability. We then
further explore the effectiveness of the subset of our proposed model. The
results showed that users' favorability and coherence, sentiment, and
similarity in the dialogue are positive predictors of users' chat experience.
Moreover, we found users may prefer dialog agents with characteristics of
Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism.
Through our research, an adaptive dialog system might use collected data to
infer factors in our model, predict the chat experience for users through these
factors, and optimize it by adjusting prompts.",2023-04-21
"An In-depth Investigation of User Response Simulation for Conversational
  Search",2023-04-17 01:55:40+00:00,http://arxiv.org/abs/2304.07944v1,"Zhenduo Wang, Zhichao Xu, Qingyao Ai, Vivek Srikumar",cs.IR,dialogue,"Conversational search has seen increased recent attention in both the IR and
NLP communities. It seeks to clarify and solve a user's search need through
multi-turn natural language interactions. However, most existing systems are
trained and demonstrated with recorded or artificial conversation logs.
Eventually, conversational search systems should be trained, evaluated, and
deployed in an open-ended setting with unseen conversation trajectories. A key
challenge is that training and evaluating such systems both require a
human-in-the-loop, which is expensive and does not scale. One strategy for this
is to simulate users, thereby reducing the scaling costs. However, current user
simulators are either limited to only respond to yes-no questions from the
conversational search system, or unable to produce high quality responses in
general.
  In this paper, we show that current state-of-the-art user simulation system
could be significantly improved by replacing it with a smaller but advanced
natural language generation model. But rather than merely reporting this new
state-of-the-art, we present an in-depth investigation of the task of
simulating user response for conversational search. Our goal is to supplement
existing works with an insightful hand-analysis of what challenges are still
unsolved by the advanced model, as well as to propose our solutions for them.
The challenges we identified include (1) dataset noise, (2) a blind spot that
is difficult for existing models to learn, and (3) a specific type of
misevaluation in the standard empirical setup. Except for the dataset noise
issue, we propose solutions to cover the training blind spot and to avoid the
misevaluation. Our proposed solutions lead to further improvements. Our best
system improves the previous state-of-the-art significantly.",2023-04-17
"Emergent autonomous scientific research capabilities of large language
  models",2023-04-11 16:50:17+00:00,http://arxiv.org/abs/2304.05332v1,"Daniil A. Boiko, Robert MacKnight, Gabe Gomes","physics.chem-ph, cs.CL",dialogue,"Transformer-based large language models are rapidly advancing in the field of
machine learning research, with applications spanning natural language,
biology, chemistry, and computer programming. Extreme scaling and reinforcement
learning from human feedback have significantly improved the quality of
generated text, enabling these models to perform various tasks and reason about
their choices. In this paper, we present an Intelligent Agent system that
combines multiple large language models for autonomous design, planning, and
execution of scientific experiments. We showcase the Agent's scientific
research capabilities with three distinct examples, with the most complex being
the successful performance of catalyzed cross-coupling reactions. Finally, we
discuss the safety implications of such systems and propose measures to prevent
their misuse.",2023-04-11
Pragmatically Appropriate Diversity for Dialogue Evaluation,2023-04-06 01:24:18+00:00,http://arxiv.org/abs/2304.02812v1,"Katherine Stasaski, Marti A. Hearst",cs.CL,dialogue,"Linguistic pragmatics state that a conversation's underlying speech acts can
constrain the type of response which is appropriate at each turn in the
conversation. When generating dialogue responses, neural dialogue agents
struggle to produce diverse responses. Currently, dialogue diversity is
assessed using automatic metrics, but the underlying speech acts do not inform
these metrics.
  To remedy this, we propose the notion of Pragmatically Appropriate Diversity,
defined as the extent to which a conversation creates and constrains the
creation of multiple diverse responses. Using a human-created multi-response
dataset, we find significant support for the hypothesis that speech acts
provide a signal for the diversity of the set of next responses. Building on
this result, we propose a new human evaluation task where creative writers
predict the extent to which conversations inspire the creation of multiple
diverse responses. Our studies find that writers' judgments align with the
Pragmatically Appropriate Diversity of conversations. Our work suggests that
expectations for diversity metric scores should vary depending on the speech
act.",2023-04-06
"Dialog-to-Actions: Building Task-Oriented Dialogue System via
  Action-Level Generation",2023-04-03 11:09:20+00:00,http://arxiv.org/abs/2304.00884v1,"Yuncheng Hua, Xiangyu Xi, Zheng Jiang, Guanwei Zhang, Chaobo Sun, Guanglu Wan, Wei Ye",cs.CL,dialogue,"End-to-end generation-based approaches have been investigated and applied in
task-oriented dialogue systems. However, in industrial scenarios, existing
methods face the bottlenecks of controllability (e.g., domain-inconsistent
responses, repetition problem, etc) and efficiency (e.g., long computation
time, etc). In this paper, we propose a task-oriented dialogue system via
action-level generation. Specifically, we first construct dialogue actions from
large-scale dialogues and represent each natural language (NL) response as a
sequence of dialogue actions. Further, we train a Sequence-to-Sequence model
which takes the dialogue history as input and outputs sequence of dialogue
actions. The generated dialogue actions are transformed into verbal responses.
Experimental results show that our light-weighted method achieves competitive
performance, and has the advantage of controllability and efficiency.",2023-04-03
"PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue
  Model",2023-04-02 18:23:13+00:00,http://arxiv.org/abs/2304.00592v1,"Cheng Deng, Bo Tong, Luoyi Fu, Jiaxin Ding, Dexing Cao, Xinbing Wang, Chenghu Zhou","cs.CL, I.2.7; F.4.1",dialogue,"In the research of end-to-end dialogue systems, using real-world knowledge to
generate natural, fluent, and human-like utterances with correct answers is
crucial. However, domain-specific conversational dialogue systems may be
incoherent and introduce erroneous external information to answer questions due
to the out-of-vocabulary issue or the wrong knowledge from the parameters of
the neural network. In this work, we propose PK-Chat, a Pointer network guided
Knowledge-driven generative dialogue model, incorporating a unified pretrained
language model and a pointer network over knowledge graphs. The words generated
by PK-Chat in the dialogue are derived from the prediction of word lists and
the direct prediction of the external knowledge graph knowledge. Moreover,
based on the PK-Chat, a dialogue system is built for academic scenarios in the
case of geosciences. Finally, an academic dialogue benchmark is constructed to
evaluate the quality of dialogue systems in academic scenarios and the source
code is available online.",2023-04-02
G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment,2023-03-29 12:46:54+00:00,http://arxiv.org/abs/2303.16634v2,"Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, Chenguang Zhu","cs.CL, cs.AI",dialogue,"The quality of texts generated by natural language generation (NLG) systems
is hard to measure automatically. Conventional reference-based metrics, such as
BLEU and ROUGE, have been shown to have relatively low correlation with human
judgments, especially for tasks that require creativity and diversity. Recent
studies suggest using large language models (LLMs) as reference-free metrics
for NLG evaluation, which have the benefit of being applicable to new tasks
that lack human references. However, these LLM-based evaluators still have
lower human correspondence than medium-size neural evaluators. In this work, we
present G-Eval, a framework of using large language models with
chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of
NLG outputs. We experiment with two generation tasks, text summarization and
dialogue generation. We show that G-Eval with GPT-4 as the backbone model
achieves a Spearman correlation of 0.514 with human on summarization task,
outperforming all previous methods by a large margin. We also propose
preliminary analysis on the behavior of LLM-based evaluators, and highlight the
potential issue of LLM-based evaluators having a bias towards the LLM-generated
texts.",2023-03-29
Dialogue-to-Video Retrieval,2023-03-23 02:52:45+00:00,http://arxiv.org/abs/2303.16761v1,"Chenyang Lyu, Manh-Duy Nguyen, Van-Tu Ninh, Liting Zhou, Cathal Gurrin, Jennifer Foster","cs.IR, cs.AI",dialogue,"Recent years have witnessed an increasing amount of dialogue/conversation on
the web especially on social media. That inspires the development of
dialogue-based retrieval, in which retrieving videos based on dialogue is of
increasing interest for recommendation systems. Different from other video
retrieval tasks, dialogue-to-video retrieval uses structured queries in the
form of user-generated dialogue as the search descriptor. We present a novel
dialogue-to-video retrieval system, incorporating structured conversational
information. Experiments conducted on the AVSD dataset show that our proposed
approach using plain-text queries improves over the previous counterpart model
by 15.8% on R@1. Furthermore, our approach using dialogue as a query, improves
retrieval performance by 4.2%, 6.2%, 8.6% on R@1, R@5 and R@10 and outperforms
the state-of-the-art model by 0.7%, 3.6% and 6.0% on R@1, R@5 and R@10
respectively.",2023-03-23
"Generate labeled training data using Prompt Programming and GPT-3. An
  example of Big Five Personality Classification",2023-03-22 03:12:40+00:00,http://arxiv.org/abs/2303.12279v1,Eason Chen,"cs.HC, cs.AI",dialogue,"We generated 25000 conversations labeled with Big Five Personality traits
using prompt programming at GPT-3. Then we train Big Five classification models
with these data and evaluate them with 2500 data from generated dialogues and
real conversational datasets labeled in Big Five by human annotators. The
results indicated that this approach is promising for creating effective
training data. We then compare the performance by different training approaches
and models. Our results suggest that using Adapter-Transformers and transfer
learning from pre-trained RoBERTa sentiment analysis model will perform best
with the generated data. Our best model obtained an accuracy of 0.71 in
generated data and 0.65 in real datasets. Finally, we discuss this approach's
potential limitations and confidence metric.",2023-03-22
cTBL: Augmenting Large Language Models for Conversational Tables,2023-03-21 17:04:44+00:00,http://arxiv.org/abs/2303.12024v2,"Anirudh S Sundar, Larry Heck","cs.CL, cs.AI",dialogue,"An open challenge in multimodal conversational AI requires augmenting large
language models with information from textual and non-textual sources for
multi-turn dialogue. To address this problem, this paper introduces
Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve
tabular information and generate dialogue responses grounded on the retrieved
information. cTBL uses Transformer encoder embeddings for Dense Table Retrieval
and obtains up to 5% relative improvement in Top-1 and Top-3 accuracy over
sparse retrieval on the HyrbiDialogue dataset. Additionally, cTBL performs
tabular knowledge retrieval using both encoder and decoder models, resulting in
up to 46% relative improvement in ROUGE scores and better human evaluation for
response generation on HyrbiDialogue.",2023-03-21
Code-Switching Text Generation and Injection in Mandarin-English ASR,2023-03-20 09:13:27+00:00,http://arxiv.org/abs/2303.10949v1,"Haibin Yu, Yuxuan Hu, Yao Qian, Ma Jin, Linquan Liu, Shujie Liu, Yu Shi, Yanmin Qian, Edward Lin, Michael Zeng","eess.AS, cs.CL, cs.SD",dialogue,"Code-switching speech refers to a means of expression by mixing two or more
languages within a single utterance. Automatic Speech Recognition (ASR) with
End-to-End (E2E) modeling for such speech can be a challenging task due to the
lack of data. In this study, we investigate text generation and injection for
improving the performance of an industry commonly-used streaming model,
Transformer-Transducer (T-T), in Mandarin-English code-switching speech
recognition. We first propose a strategy to generate code-switching text data
and then investigate injecting generated text into T-T model explicitly by
Text-To-Speech (TTS) conversion or implicitly by tying speech and text latent
spaces. Experimental results on the T-T model trained with a dataset containing
1,800 hours of real Mandarin-English code-switched speech show that our
approaches to inject generated code-switching text significantly boost the
performance of T-T models, i.e., 16% relative Token-based Error Rate (TER)
reduction averaged on three evaluation sets, and the approach of tying speech
and text latent spaces is superior to that of TTS conversion on the evaluation
set which contains more homogeneous data with the training set.",2023-03-20
Can AI-Generated Text be Reliably Detected?,2023-03-17 17:53:19+00:00,http://arxiv.org/abs/2303.11156v1,"Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, Soheil Feizi","cs.CL, cs.AI, cs.LG",dialogue,"The rapid progress of Large Language Models (LLMs) has made them capable of
performing astonishingly well on various tasks including document completion
and question answering. The unregulated use of these models, however, can
potentially lead to malicious consequences such as plagiarism, generating fake
news, spamming, etc. Therefore, reliable detection of AI-generated text can be
critical to ensure the responsible use of LLMs. Recent works attempt to tackle
this problem either using certain model signatures present in the generated
text outputs or by applying watermarking techniques that imprint specific
patterns onto them. In this paper, both empirically and theoretically, we show
that these detectors are not reliable in practical scenarios. Empirically, we
show that paraphrasing attacks, where a light paraphraser is applied on top of
the generative text model, can break a whole range of detectors, including the
ones using the watermarking schemes as well as neural network-based detectors
and zero-shot classifiers. We then provide a theoretical impossibility result
indicating that for a sufficiently good language model, even the best-possible
detector can only perform marginally better than a random classifier. Finally,
we show that even LLMs protected by watermarking schemes can be vulnerable
against spoofing attacks where adversarial humans can infer hidden watermarking
signatures and add them to their generated text to be detected as text
generated by the LLMs, potentially causing reputational damages to their
developers. We believe these results can open an honest conversation in the
community regarding the ethical and reliable use of AI-generated text.",2023-03-17
"Reinforcement Learning-based Counter-Misinformation Response Generation:
  A Case Study of COVID-19 Vaccine Misinformation",2023-03-11 15:55:01+00:00,http://arxiv.org/abs/2303.06433v1,"Bing He, Mustaque Ahamad, Srijan Kumar","cs.SI, cs.LG",dialogue,"The spread of online misinformation threatens public health, democracy, and
the broader society. While professional fact-checkers form the first line of
defense by fact-checking popular false claims, they do not engage directly in
conversations with misinformation spreaders. On the other hand, non-expert
ordinary users act as eyes-on-the-ground who proactively counter misinformation
-- recent research has shown that 96% counter-misinformation responses are made
by ordinary users. However, research also found that 2/3 times, these responses
are rude and lack evidence. This work seeks to create a counter-misinformation
response generation model to empower users to effectively correct
misinformation. This objective is challenging due to the absence of datasets
containing ground-truth of ideal counter-misinformation responses, and the lack
of models that can generate responses backed by communication theories. In this
work, we create two novel datasets of misinformation and counter-misinformation
response pairs from in-the-wild social media and crowdsourcing from
college-educated students. We annotate the collected data to distinguish poor
from ideal responses that are factual, polite, and refute misinformation. We
propose MisinfoCorrect, a reinforcement learning-based framework that learns to
generate counter-misinformation responses for an input misinformation post. The
model rewards the generator to increase the politeness, factuality, and
refutation attitude while retaining text fluency and relevancy. Quantitative
and qualitative evaluation shows that our model outperforms several baselines
by generating high-quality counter-responses. This work illustrates the promise
of generative text models for social good -- here, to help create a safe and
reliable information ecosystem. The code and data is accessible on
https://github.com/claws-lab/MisinfoCorrect.",2023-03-11
"POSGen: Personalized Opening Sentence Generation for Online Insurance
  Sales",2023-02-10 01:40:03+00:00,http://arxiv.org/abs/2302.06470v1,"Yu Li, Yi Zhang, Weijia Wu, Zimu Zhou, Qiang Li","cs.CL, Online Insurance Recommendation, Transfer Learning, Data-to-text
  Generation",dialogue,"The insurance industry is shifting their sales mode from offline to online,
in expectation to reach massive potential customers in the digitization era.
Due to the complexity and the nature of insurance products, a cost-effective
online sales solution is to exploit chatbot AI to raise customers' attention
and pass those with interests to human agents for further sales. For high
response and conversion rates of customers, it is crucial for the chatbot to
initiate a conversation with personalized opening sentences, which are
generated with user-specific topic selection and ordering. Such personalized
opening sentence generation is challenging because (i) there are limited
historical samples for conversation topic recommendation in online insurance
sales and (ii) existing text generation schemes often fail to support
customized topic ordering based on user preferences. We design POSGen, a
personalized opening sentence generation scheme dedicated for online insurance
sales. It transfers user embeddings learned from auxiliary online user
behaviours to enhance conversation topic recommendation, and exploits a context
management unit to arrange the recommended topics in user-specific ordering for
opening sentence generation. POSGen is deployed on a real-world online
insurance platform. It achieves 2.33x total insurance premium improvement
through a two-month global test.",2023-02-10
"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based
  Learning",2023-02-08 02:45:21+00:00,http://arxiv.org/abs/2302.03848v1,"Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker",cs.CL,dialogue,"Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.",2023-02-08
Grounding Language Models to Images for Multimodal Generation,2023-01-31 18:33:44+00:00,http://arxiv.org/abs/2301.13823v1,"Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried","cs.CL, cs.AI, cs.CV, cs.LG",dialogue,"We propose an efficient method to ground pretrained text-only language models
to the visual domain, enabling them to process and generate arbitrarily
interleaved image-and-text data. Our method leverages the abilities of language
models learnt from large scale text-only pretraining, such as in-context
learning and free-form text generation. We keep the language model frozen, and
finetune input and output linear layers to enable cross-modality interactions.
This allows our model to process arbitrarily interleaved image-and-text inputs,
and generate free-form text interleaved with retrieved images. We achieve
strong zero-shot performance on grounded tasks such as contextual image
retrieval and multimodal dialogue, and showcase compelling interactive
abilities. Our approach works with any off-the-shelf language model and paves
the way towards an effective, general solution for leveraging pretrained
language models in visually grounded settings.",2023-01-31
"Response-act Guided Reinforced Dialogue Generation for Mental Health
  Counseling",2023-01-30 08:53:35+00:00,http://arxiv.org/abs/2301.12729v1,"Aseem Srivastava, Ishan Pandey, Md. Shad Akhtar, Tanmoy Chakraborty",cs.CL,dialogue,"Virtual Mental Health Assistants (VMHAs) have become a prevalent method for
receiving mental health counseling in the digital healthcare space. An
assistive counseling conversation commences with natural open-ended topics to
familiarize the client with the environment and later converges into more
fine-grained domain-specific topics. Unlike other conversational systems, which
are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid
conversational flow. These counseling bots need to comprehend various aspects
of the conversation, such as dialogue-acts, intents, etc., to engage the client
in an effective conversation. Although the surge in digital health research
highlights applications of many general-purpose response generation systems,
they are barely suitable in the mental health domain -- the prime reason is the
lack of understanding in mental health counseling. Moreover, in general,
dialogue-act guided response generators are either limited to a template-based
paradigm or lack appropriate semantics. To this end, we propose READER -- a
REsponse-Act guided reinforced Dialogue genERation model for the mental health
counseling conversations. READER is built on transformer to jointly predict a
potential dialogue-act d(t+1) for the next utterance (aka response-act) and to
generate an appropriate response u(t+1). Through the
transformer-reinforcement-learning (TRL) with Proximal Policy Optimization
(PPO), we guide the response generator to abide by d(t+1) and ensure the
semantic richness of the responses via BERTScore in our reward computation. We
evaluate READER on HOPE, a benchmark counseling conversation dataset and
observe that it outperforms several baselines across several evaluation metrics
-- METEOR, ROUGE, and BERTScore. We also furnish extensive qualitative and
quantitative analyses on results, including error analysis, human evaluation,
etc.",2023-01-30
"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental
  Health on Social Media",2023-01-26 09:26:01+00:00,http://arxiv.org/abs/2301.11004v1,"Muskan Garg, Chandni Saxena, Usman Naseem, Bonnie J Dorr",cs.CL,dialogue,"Interactions among humans on social media often convey intentions behind
their actions, yielding a psychological language resource for Mental Health
Analysis (MHA) of online users. The success of Computational Intelligence
Techniques (CIT) for inferring mental illness from such social media resources
points to NLP as a lens for causal analysis and perception mining. However, we
argue that more consequential and explainable research is required for optimal
impact on clinical psychology practice and personalized mental healthcare. To
bridge this gap, we posit two significant dimensions: (1) Causal analysis to
illustrate a cause and effect relationship in the user generated text; (2)
Perception mining to infer psychological perspectives of social effects on
online users intentions. Within the scope of Natural Language Processing (NLP),
we further explore critical areas of inquiry associated with these two
dimensions, specifically through recent advancements in discourse analysis.
This position paper guides the community to explore solutions in this space and
advance the state of practice in developing conversational agents for inferring
mental health from social media. We advocate for a more explainable approach
toward modeling computational psychology problems through the lens of language
as we observe an increased number of research contributions in dataset and
problem formulation for causal relation extraction and perception enhancements
while inferring mental states.",2023-01-26
Distilling Text into Circuits,2023-01-25 13:56:34+00:00,http://arxiv.org/abs/2301.10595v1,"Vincent Wang-Mascianica, Jonathon Liu, Bob Coecke","cs.CL, cs.AI, cs.LO, math.CT",dialogue,"This paper concerns the structure of meanings within natural language.
Earlier, a framework named DisCoCirc was sketched that (1) is compositional and
distributional (a.k.a. vectorial); (2) applies to general text; (3) captures
linguistic `connections' between meanings (cf. grammar) (4) updates word
meanings as text progresses; (5) structures sentence types; (6) accommodates
ambiguity. Here, we realise DisCoCirc for a substantial fragment of English.
  When passing to DisCoCirc's text circuits, some `grammatical bureaucracy' is
eliminated, that is, DisCoCirc displays a significant degree of (7) inter- and
intra-language independence. That is, e.g., independence from word-order
conventions that differ across languages, and independence from choices like
many short sentences vs. few long sentences. This inter-language independence
means our text circuits should carry over to other languages, unlike the
language-specific typings of categorial grammars. Hence, text circuits are a
lean structure for the `actual substance of text', that is, the inner-workings
of meanings within text across several layers of expressiveness (cf. words,
sentences, text), and may capture that what is truly universal beneath grammar.
The elimination of grammatical bureaucracy also explains why DisCoCirc: (8)
applies beyond language, e.g. to spatial, visual and other cognitive modes.
While humans could not verbally communicate in terms of text circuits, machines
can.
  We first define a `hybrid grammar' for a fragment of English, i.e. a
purpose-built, minimal grammatical formalism needed to obtain text circuits. We
then detail a translation process such that all text generated by this grammar
yields a text circuit. Conversely, for any text circuit obtained by freely
composing the generators, there exists a text (with hybrid grammar) that gives
rise to it. Hence: (9) text circuits are generative for text.",2023-01-25
"UserSimCRS: A User Simulation Toolkit for Evaluating Conversational
  Recommender Systems",2023-01-13 13:41:20+00:00,http://arxiv.org/abs/2301.05544v2,"Jafar Afzali, Aleksander Mark Drzewiecki, Krisztian Balog, Shuo Zhang",cs.IR,dialogue,"We present an extensible user simulation toolkit to facilitate automatic
evaluation of conversational recommender systems. It builds on an established
agenda-based approach and extends it with several novel elements, including
user satisfaction prediction, persona and context modeling, and conditional
natural language generation. We showcase the toolkit with a pre-existing movie
recommender system and demonstrate its ability to simulate dialogues that mimic
real conversations, while requiring only a handful of manually annotated
dialogues as training data.",2023-01-13
Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models,2023-01-08 23:12:46+00:00,http://arxiv.org/abs/2301.03119v2,"Mariam Bangura, Kristina Barabashova, Anna Karnysheva, Sarah Semczuk, Yifan Wang",cs.CL,dialogue,"This study is devoted to the automatic generation of German drama texts. We
suggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the
outline model) to generate outlines of scenes based on keywords and fine-tuning
a second model (the generation model) to generate scenes from the scene
outline. The input for the neural model comprises two datasets: the German
Drama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).
In order to estimate the effectiveness of the proposed method, our models are
compared with baseline GPT-2 models. Our models perform well according to
automatic quantitative evaluation, but, conversely, manual qualitative analysis
reveals a poor quality of generated texts. This may be due to the quality of
the dataset or training inputs.",2023-01-08
TextBox 2.0: A Text Generation Library with Pre-trained Language Models,2022-12-26 03:50:36+00:00,http://arxiv.org/abs/2212.13005v1,"Tianyi Tang, Junyi Li, Zhipeng Chen, Yiwen Hu, Zhuohao Yu, Wenxun Dai, Zican Dong, Xiaoxue Cheng, Yuhao Wang, Wayne Xin Zhao, Jian-Yun Nie, Ji-Rong Wen",cs.CL,dialogue,"To facilitate research on text generation, this paper presents a
comprehensive and unified library, TextBox 2.0, focusing on the use of
pre-trained language models (PLMs). To be comprehensive, our library covers
$13$ common text generation tasks and their corresponding $83$ datasets and
further incorporates $45$ PLMs covering general, translation, Chinese,
dialogue, controllable, distilled, prompting, and lightweight PLMs. We also
implement $4$ efficient training strategies and provide $4$ generation
objectives for pre-training new PLMs from scratch. To be unified, we design the
interfaces to support the entire research pipeline (from data loading to
training and evaluation), ensuring that each step can be fulfilled in a unified
way. Despite the rich functionality, it is easy to use our library, either
through the friendly Python API or command line. To validate the effectiveness
of our library, we conduct extensive experiments and exemplify four types of
research scenarios. The project is released at the link:
https://github.com/RUCAIBox/TextBox.",2022-12-26
"On Realization of Intelligent Decision-Making in the Real World: A
  Foundation Decision Model Perspective",2022-12-24 06:16:45+00:00,http://arxiv.org/abs/2212.12669v1,"Ying Wen, Ziyu Wan, Ming Zhou, Shufang Hou, Zhe Cao, Chenyang Le, Jingxiao Chen, Zheng Tian, Weinan Zhang, Jun Wang","cs.AI, cs.LG",dialogue,"Our situated environment is full of uncertainty and highly dynamic, thus
hindering the widespread adoption of machine-led Intelligent Decision-Making
(IDM) in real world scenarios. This means IDM should have the capability of
continuously learning new skills and efficiently generalizing across wider
applications. IDM benefits from any new approaches and theoretical
breakthroughs that exhibit Artificial General Intelligence (AGI) breaking the
barriers between tasks and applications. Recent research has well-examined
neural architecture, Transformer, as a backbone foundation model and its
generalization to various tasks, including computer vision, natural language
processing, and reinforcement learning. We therefore argue that a foundation
decision model (FDM) can be established by formulating various decision-making
tasks as a sequence decoding task using the Transformer architecture; this
would be a promising solution to advance the applications of IDM in more
complex real world tasks. In this paper, we elaborate on how a foundation
decision model improves the efficiency and generalization of IDM. We also
discuss potential applications of a FDM in multi-agent game AI, production
scheduling, and robotics tasks. Finally, through a case study, we demonstrate
our realization of the FDM, DigitalBrain (DB1) with 1.2 billion parameters,
which achieves human-level performance over 453 tasks, including text
generation, images caption, video games playing, robotic control, and traveling
salesman problems. As a foundation decision model, DB1 would be a baby step
towards more autonomous and efficient real world IDM applications.",2022-12-24
Ontologically Faithful Generation of Non-Player Character Dialogues,2022-12-20 19:48:10+00:00,http://arxiv.org/abs/2212.10618v1,"Nathaniel Weir, Ryan Thomas, Randolph D'Amore, Kellie Hill, Benjamin Van Durme, Harsh Jhamtani",cs.CL,dialogue,"We introduce a language generation task grounded in a popular video game
environment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)
involves generating dialogue trees conditioned on an ontology captured in
natural language passages providing quest and entity specifications. KNUDGE is
constructed from side quest dialogues drawn directly from game data of Obsidian
Entertainment's The Outer Worlds, leading to real-world complexities in
generation: (1) dialogues are branching trees as opposed to linear chains of
utterances; (2) utterances must remain faithful to the game lore--character
personas, backstories, and entity relationships; and (3) a dialogue must
accurately reveal new quest-related details to the human player. We report
results for supervised and in-context learning techniques, finding there is
significant room for future work on creating realistic game-quality dialogues.",2022-12-20
Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog,2022-12-20 05:51:47+00:00,http://arxiv.org/abs/2212.10008v1,"Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao, Zhu Zhang","cs.CL, cs.AI",dialogue,"Many efforts have been made to construct dialog systems for different types
of conversations, such as task-oriented dialog (TOD) and open-domain dialog
(ODD). To better mimic human-level conversations that usually fuse various
dialog modes, it is essential to build a system that can effectively handle
both TOD and ODD and access different knowledge sources. To address the lack of
available data for the fused task, we propose a framework for automatically
generating dialogues that combine knowledge-grounded ODDs and TODs in various
settings. Additionally, we introduce a unified model PivotBot that is capable
of appropriately adopting TOD and ODD modes and accessing different knowledge
sources in order to effectively tackle the fused task. Evaluation results
demonstrate the superior ability of the proposed model to switch seamlessly
between TOD and ODD tasks.",2022-12-20
"Future Sight: Dynamic Story Generation with Large Pretrained Language
  Models",2022-12-20 01:53:26+00:00,http://arxiv.org/abs/2212.09947v1,"Brian D. Zimmerman, Gaurav Sahu, Olga Vechtomova","cs.CL, cs.AI, cs.LG",dialogue,"Recent advances in deep learning research, such as transformers, have
bolstered the ability for automated agents to generate creative texts similar
to those that a human would write. By default, transformer decoders can only
generate new text with respect to previously generated text. The output
distribution of candidate tokens at any position is conditioned on previously
selected tokens using a self-attention mechanism to emulate the property of
autoregression. This is inherently limiting for tasks such as controllable
story generation where it may be necessary to condition on future plot events
when writing a story. In this work, we propose Future Sight, a method for
finetuning a pretrained generative transformer on the task of future
conditioning. Transformer decoders are typically pretrained on the task of
completing a context, one token at a time, by means of self-attention. Future
Sight additionally enables a decoder to attend to an encoded future plot event.
This motivates the decoder to expand on the context in a way that logically
concludes with the provided future. During inference, the future plot event can
be written by a human author to steer the narrative being generated in a
certain direction. We evaluate the efficacy of our approach on a story
generation task with human evaluators.",2022-12-20
SEScore2: Retrieval Augmented Pretraining for Text Generation Evaluation,2022-12-19 09:02:16+00:00,http://arxiv.org/abs/2212.09305v1,"Wenda Xu, Xian Qian, Mingxuan Wang, Lei Li, William Yang Wang",cs.CL,dialogue,"Is it possible to leverage large scale raw and raw parallel corpora to build
a general learned metric? Existing learned metrics have gaps to human
judgements, are model-dependent or are limited to the domains or tasks where
human ratings are available. In this paper, we propose SEScore2, a model-based
metric pretrained over million-scale synthetic dataset constructed by our novel
retrieval augmented data synthesis pipeline. SEScore2 achieves high correlation
to human judgements without any human rating supervisions. Importantly, our
unsupervised SEScore2 can outperform supervised metrics, which are trained on
the News human ratings, at the TED domain. We evaluate SEScore2 over four text
generation tasks across three languages. SEScore2 outperforms all prior
unsupervised evaluation metrics in machine translation, speech translation,
data-to-text and dialogue generation, with average Kendall improvements 0.158.
SEScore2 even outperforms SOTA supervised BLEURT at data-to-text, dialogue
generation and overall correlation.",2022-12-19
ChatGPT: The End of Online Exam Integrity?,2022-12-19 08:15:16+00:00,http://arxiv.org/abs/2212.09292v1,Teo Susnjak,"cs.AI, cs.CL",dialogue,"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",2022-12-19
"Rainproof: An Umbrella To Shield Text Generators From
  Out-Of-Distribution Data",2022-12-18 21:22:28+00:00,http://arxiv.org/abs/2212.09171v1,"Maxime Darrin, Pablo Piantanida, Pierre Colombo",cs.CL,dialogue,"As more and more conversational and translation systems are deployed in
production, it is essential to implement and to develop effective control
mechanisms guaranteeing their proper functioning and security. An essential
component to ensure safe system behavior is out-of-distribution (OOD)
detection, which aims at detecting whether an input sample is statistically far
from the training distribution. Although OOD detection is a widely covered
topic in classification tasks, it has received much less attention in text
generation. This paper addresses the problem of OOD detection for machine
translation and dialog generation from an operational perspective. Our
contributions include: (i) RAINPROOF a Relative informAItioN Projection ODD
detection framework; and (ii) a more operational evaluation setting for OOD
detection. Surprisingly, we find that OOD detection is not necessarily aligned
with task-specific measures. The OOD detector may filter out samples that are
well processed by the model and keep samples that are not, leading to weaker
performance. Our results show that RAINPROOF breaks this curse and achieve good
results in OOD detection while increasing performance.",2022-12-18
Plansformer: Generating Symbolic Plans using Transformers,2022-12-16 19:06:49+00:00,http://arxiv.org/abs/2212.08681v1,"Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava, Francesco Fabiano, Andrea Loreggia",cs.AI,dialogue,"Large Language Models (LLMs) have been the subject of active research,
significantly advancing the field of Natural Language Processing (NLP). From
BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural
language tasks such as question answering, summarization, and text generation.
Many ongoing efforts focus on understanding LLMs' capabilities, including their
knowledge of the world, syntax, and semantics. However, extending the textual
prowess of LLMs to symbolic reasoning has been slow and predominantly focused
on tackling problems related to the mathematical field. In this paper, we
explore the use of LLMs for automated planning - a branch of AI concerned with
the realization of action sequences (plans) to achieve a goal, typically
executed by intelligent agents, autonomous robots, and unmanned vehicles. We
introduce Plansformer; an LLM fine-tuned on planning problems and capable of
generating plans with favorable behavior in terms of correctness and length
with reduced knowledge-engineering efforts. We also demonstrate the
adaptability of Plansformer in solving different planning domains with varying
complexities, owing to the transfer learning abilities of LLMs. For one
configuration of Plansformer, we achieve ~97% valid plans, out of which ~95%
are optimal for Towers of Hanoi - a puzzle-solving domain.",2022-12-16
"ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data
  Format",2022-11-30 16:37:42+00:00,http://arxiv.org/abs/2211.17148v1,"Qi Zhu, Christian Geishauser, Hsien-chin Lin, Carel van Niekerk, Baolin Peng, Zheng Zhang, Michael Heck, Nurul Lubis, Dazhen Wan, Xiaochen Zhu, Jianfeng Gao, Milica Gašić, Minlie Huang","cs.CL, cs.AI",dialogue,"Diverse data formats and ontologies of task-oriented dialogue (TOD) datasets
hinder us from developing general dialogue models that perform well on many
datasets and studying knowledge transfer between datasets. To address this
issue, we present ConvLab-3, a flexible dialogue system toolkit based on a
unified TOD data format. In ConvLab-3, different datasets are transformed into
one unified format and loaded by models in the same way. As a result, the cost
of adapting a new model or dataset is significantly reduced. Compared to the
previous releases of ConvLab (Lee et al., 2019b; Zhu et al., 2020b), ConvLab-3
allows developing dialogue systems with much more datasets and enhances the
utility of the reinforcement learning (RL) toolkit for dialogue policies. To
showcase the use of ConvLab-3 and inspire future work, we present a
comprehensive study with various settings. We show the benefit of pre-training
on other datasets for few-shot fine-tuning and RL, and encourage evaluating
policy with diverse user simulators.",2022-11-30
"MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous
  Informal Texts",2022-11-25 05:05:29+00:00,http://arxiv.org/abs/2211.13896v1,"Xiangyu Xi, Jianwei Lv, Shuaipeng Liu, Wei Ye, Fan Yang, Guanglu Wan",cs.CL,dialogue,"Event detection (ED) identifies and classifies event triggers from
unstructured texts, serving as a fundamental task for information extraction.
Despite the remarkable progress achieved in the past several years, most
research efforts focus on detecting events from formal texts (e.g., news
articles, Wikipedia documents, financial announcements). Moreover, the texts in
each dataset are either from a single source or multiple yet relatively
homogeneous sources. With massive amounts of user-generated text accumulating
on the Web and inside enterprises, identifying meaningful events in these
informal texts, usually from multiple heterogeneous sources, has become a
problem of significant practical value. As a pioneering exploration that
expands event detection to the scenarios involving informal and heterogeneous
texts, we propose a new large-scale Chinese event detection dataset based on
user reviews, text conversations, and phone conversations in a leading
e-commerce platform for food service. We carefully investigate the proposed
dataset's textual informality and multi-source heterogeneity characteristics by
inspecting data samples quantitatively and qualitatively. Extensive experiments
with state-of-the-art event detection methods verify the unique challenges
posed by these characteristics, indicating that multi-source informal event
detection remains an open problem and requires further efforts. Our benchmark
and code are released at \url{https://github.com/myeclipse/MUSIED}.",2022-11-25
"Human-Machine Collaboration Approaches to Build a Dialogue Dataset for
  Hate Speech Countering",2022-11-07 10:37:13+00:00,http://arxiv.org/abs/2211.03433v1,"Helena Bonaldi, Sara Dellantonio, Serra Sinem Tekiroglu, Marco Guerini","cs.CL, cs.CY",dialogue,"Fighting online hate speech is a challenge that is usually addressed using
Natural Language Processing via automatic detection and removal of hate
content. Besides this approach, counter narratives have emerged as an effective
tool employed by NGOs to respond to online hate on social media platforms. For
this reason, Natural Language Generation is currently being studied as a way to
automatize counter narrative writing. However, the existing resources necessary
to train NLG models are limited to 2-turn interactions (a hate speech and a
counter narrative as response), while in real life, interactions can consist of
multiple turns. In this paper, we present a hybrid approach for dialogical data
collection, which combines the intervention of human expert annotators over
machine generated dialogues obtained using 19 different configurations. The
result of this work is DIALOCONAN, the first dataset comprising over 3000
fictitious multi-turn dialogues between a hater and an NGO operator, covering 6
targets of hate.",2022-11-07
"Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with
  User Simulator",2022-10-26 07:41:32+00:00,http://arxiv.org/abs/2210.14529v1,"Qinyuan Cheng, Linyang Li, Guofeng Quan, Feng Gao, Xiaofeng Mou, Xipeng Qiu",cs.CL,dialogue,"Task-Oriented Dialogue (TOD) systems are drawing more and more attention in
recent studies. Current methods focus on constructing pre-trained models or
fine-tuning strategies while the evaluation of TOD is limited by a policy
mismatch problem. That is, during evaluation, the user utterances are from the
annotated dataset while these utterances should interact with previous
responses which can have many alternatives besides annotated texts. Therefore,
in this work, we propose an interactive evaluation framework for TOD. We first
build a goal-oriented user simulator based on pre-trained models and then use
the user simulator to interact with the dialogue system to generate dialogues.
Besides, we introduce a sentence-level and a session-level score to measure the
sentence fluency and session coherence in the interactive evaluation.
Experimental results show that RL-based TOD systems trained by our proposed
user simulator can achieve nearly 98% inform and success rates in the
interactive evaluation of MultiWOZ dataset and the proposed scores measure the
response quality besides the inform and success rates. We are hoping that our
work will encourage simulator-based interactive evaluations in the TOD task.",2022-10-26
"Are Current Decoding Strategies Capable of Facing the Challenges of
  Visual Dialogue?",2022-10-24 07:34:39+00:00,http://arxiv.org/abs/2210.12997v1,"Amit Kumar Chaudhary, Alex J. Lucassen, Ioanna Tsani, Alberto Testoni","cs.CL, cs.CV",dialogue,"Decoding strategies play a crucial role in natural language generation
systems. They are usually designed and evaluated in open-ended text-only tasks,
and it is not clear how different strategies handle the numerous challenges
that goal-oriented multimodal systems face (such as grounding and
informativeness). To answer this question, we compare a wide variety of
different decoding strategies and hyper-parameter configurations in a Visual
Dialogue referential game. Although none of them successfully balance lexical
richness, accuracy in the task, and visual grounding, our in-depth analysis
allows us to highlight the strengths and weaknesses of each decoding strategy.
We believe our findings and suggestions may serve as a starting point for
designing more effective decoding algorithms that handle the challenges of
Visual Dialogue tasks.",2022-10-24
Language Detoxification with Attribute-Discriminative Latent Space,2022-10-19 06:54:42+00:00,http://arxiv.org/abs/2210.10329v1,"Jin Myung Kwak, Minseon Kim, Sung Ju Hwang","cs.CL, cs.AI",dialogue,"Transformer-based Language Models (LMs) achieve remarkable performances on a
variety of NLU tasks, but are also prone to generating toxic texts such as
insults, threats, and profanities which limit their adaptations to the
real-world applications. To overcome this issue, a few text generation
approaches aim to detoxify toxic texts with additional LMs or perturbations.
However, previous methods require excessive memory, computations, and time
which are serious bottlenecks in their real-world application. To address such
limitations, we propose an effective yet efficient method for language
detoxification using an attribute-discriminative latent space. Specifically, we
project the latent space of an original Transformer LM to a discriminative
latent space on which the texts are well-separated by their attributes, with
the help of a projection block and a discriminator. This allows the LM to
control the text generation to be non-toxic with minimal memory and computation
overhead. We validate our model, Attribute-Discriminative Language Model (ADLM)
on detoxified language and dialogue generation tasks, on which our method
significantly outperforms baselines both in performance and efficiency.",2022-10-19
"Team Flow at DRC2022: Pipeline System for Travel Destination
  Recommendation Task in Spoken Dialogue",2022-10-18 01:11:16+00:00,http://arxiv.org/abs/2210.09518v1,"Ryu Hirai, Atsumoto Ohashi, Ao Guo, Hideki Shiroma, Xulin Zhou, Yukihiko Tone, Shinya Iizuka, Ryuichiro Higashinaka","cs.CL, cs.AI, cs.RO",dialogue,"To improve the interactive capabilities of a dialogue system, e.g., to adapt
to different customers, the Dialogue Robot Competition (DRC2022) was held. As
one of the teams, we built a dialogue system with a pipeline structure
containing four modules. The natural language understanding (NLU) and natural
language generation (NLG) modules were GPT-2 based models, and the dialogue
state tracking (DST) and policy modules were designed on the basis of
hand-crafted rules. After the preliminary round of the competition, we found
that the low variation in training examples for the NLU and failed
recommendation due to the policy used were probably the main reasons for the
limited performance of the system.",2022-10-18
"LEATHER: A Framework for Learning to Generate Human-like Text in
  Dialogue",2022-10-14 13:05:11+00:00,http://arxiv.org/abs/2210.07777v1,"Anthony Sicilia, Malihe Alikhani","cs.CL, cs.LG",dialogue,"Algorithms for text-generation in dialogue can be misguided. For example, in
task-oriented settings, reinforcement learning that optimizes only task-success
can lead to abysmal lexical diversity. We hypothesize this is due to poor
theoretical understanding of the objectives in text-generation and their
relation to the learning process (i.e., model training). To this end, we
propose a new theoretical framework for learning to generate text in dialogue.
Compared to existing theories of learning, our framework allows for analysis of
the multi-faceted goals inherent to text-generation. We use our framework to
develop theoretical guarantees for learners that adapt to unseen data. As an
example, we apply our theory to study data-shift within a cooperative learning
algorithm proposed for the GuessWhat?! visual dialogue game. From this insight,
we propose a new algorithm, and empirically, we demonstrate our proposal
improves both task-success and human-likeness of the generated text. Finally,
we show statistics from our theory are empirically predictive of multiple
qualities of the generated dialogue, suggesting our theory is useful for
model-selection when human evaluations are not available.",2022-10-14
Towards a Unified Multi-Dimensional Evaluator for Text Generation,2022-10-13 17:17:03+00:00,http://arxiv.org/abs/2210.07197v1,"Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, Jiawei Han",cs.CL,dialogue,"Multi-dimensional evaluation is the dominant paradigm for human evaluation in
Natural Language Generation (NLG), i.e., evaluating the generated text from
multiple explainable dimensions, such as coherence and fluency. However,
automatic evaluation in NLG is still dominated by similarity-based metrics, and
we lack a reliable framework for a more comprehensive evaluation of advanced
models. In this paper, we propose a unified multi-dimensional evaluator UniEval
for NLG. We re-frame NLG evaluation as a Boolean Question Answering (QA) task,
and by guiding the model with different questions, we can use one evaluator to
evaluate from multiple dimensions. Furthermore, thanks to the unified Boolean
QA format, we are able to introduce an intermediate learning phase that enables
UniEval to incorporate external knowledge from multiple related tasks and gain
further improvement. Experiments on three typical NLG tasks show that UniEval
correlates substantially better with human judgments than existing metrics.
Specifically, compared to the top-performing unified evaluators, UniEval
achieves a 23% higher correlation on text summarization, and over 43% on
dialogue response generation. Also, UniEval demonstrates a strong zero-shot
learning ability for unseen evaluation dimensions and tasks. Source code, data
and all pre-trained evaluators are available on our GitHub repository
(https://github.com/maszhongming/UniEval).",2022-10-13
Controllable Dialogue Simulation with In-Context Learning,2022-10-09 06:32:58+00:00,http://arxiv.org/abs/2210.04185v1,"Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, Xifeng Yan","cs.CL, cs.AI",dialogue,"Building dialogue systems requires a large corpus of annotated dialogues.
Such datasets are usually created via crowdsourcing, which is expensive and
time-consuming. In this paper, we propose a novel method for dialogue
simulation based on language model in-context learning, dubbed as
\textsc{Dialogic}. Seeded with a few annotated dialogues, \textsc{Dialogic}
automatically selects in-context examples for demonstration and prompts GPT-3
to generate new dialogues and their annotations in a controllable way.
Leveraging the strong in-context learning ability of GPT-3, our method can be
used to rapidly expand a small set of dialogue data without requiring
\textit{human involvement} or \textit{parameter update}, and is thus much more
cost-efficient and time-saving than crowdsourcing. Experimental results on the
MultiWOZ dataset demonstrate that training a model on the simulated dialogues
leads to even better performance than using the same amount of human-generated
dialogues in the low-resource settings, with as few as 85 dialogues as the seed
data. Human evaluation results also show that our simulated dialogues has high
language fluency and annotation accuracy. The code and data are available at
\href{https://github.com/Leezekun/dialogic}{https://github.com/Leezekun/dialogic}.",2022-10-09
"Unsupervised Neural Stylistic Text Generation using Transfer learning
  and Adapters",2022-10-07 00:09:22+00:00,http://arxiv.org/abs/2210.03264v1,"Vinayshekhar Bannihatti Kumar, Rashmi Gangadharaiah, Dan Roth",cs.CL,dialogue,"Research has shown that personality is a key driver to improve engagement and
user experience in conversational systems. Conversational agents should also
maintain a consistent persona to have an engaging conversation with a user.
However, text generation datasets are often crowd sourced and thereby have an
averaging effect where the style of the generation model is an average style of
all the crowd workers that have contributed to the dataset. While one can
collect persona-specific datasets for each task, it would be an expensive and
time consuming annotation effort. In this work, we propose a novel transfer
learning framework which updates only $0.3\%$ of model parameters to learn
style specific attributes for response generation. For the purpose of this
study, we tackle the problem of stylistic story ending generation using the ROC
stories Corpus. We learn style specific attributes from the
PERSONALITY-CAPTIONS dataset. Through extensive experiments and evaluation
metrics we show that our novel training procedure can improve the style
generation by 200 over Encoder-Decoder baselines while maintaining on-par
content relevance metrics with",2022-10-07
"Learning functional sections in medical conversations: iterative
  pseudo-labeling and human-in-the-loop approach",2022-10-06 03:33:00+00:00,http://arxiv.org/abs/2210.02658v2,"Mengqian Wang, Ilya Valmianski, Xavier Amatriain, Anitha Kannan",cs.CL,dialogue,"Medical conversations between patients and medical professionals have
implicit functional sections, such as ""history taking"", ""summarization"",
""education"", and ""care plan."" In this work, we are interested in learning to
automatically extract these sections. A direct approach would require
collecting large amounts of expert annotations for this task, which is
inherently costly due to the contextual inter-and-intra variability between
these sections. This paper presents an approach that tackles the problem of
learning to classify medical dialogue into functional sections without
requiring a large number of annotations. Our approach combines pseudo-labeling
and human-in-the-loop. First, we bootstrap using weak supervision with
pseudo-labeling to generate dialogue turn-level pseudo-labels and train a
transformer-based model, which is then applied to individual sentences to
create noisy sentence-level labels. Second, we iteratively refine
sentence-level labels using a cluster-based human-in-the-loop approach. Each
iteration requires only a few dozen annotator decisions. We evaluate the
results on an expert-annotated dataset of 100 dialogues and find that while our
models start with 69.5% accuracy, we can iteratively improve it to 82.5%. The
code used to perform all experiments described in this paper can be found here:
https://github.com/curai/curai-research/tree/main/functional-sections.",2022-10-06
"Dancing with the Unexpected and Beyond: The Use of AI Assistance in
  Design Fiction Creation",2022-10-03 11:26:39+00:00,http://arxiv.org/abs/2210.00829v1,"Yiying Wu, Yunye Yu, Pengcheng An",cs.HC,dialogue,"The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology.",2022-10-03
"Co-Writing Screenplays and Theatre Scripts with Language Models: An
  Evaluation by Industry Professionals",2022-09-29 17:26:22+00:00,http://arxiv.org/abs/2209.14958v1,"Piotr Mirowski, Kory W. Mathewson, Jaylen Pittman, Richard Evans","cs.HC, cs.CL",dialogue,"Language models are increasingly attracting interest from writers. However,
such models lack long-range semantic coherence, limiting their usefulness for
longform creative writing. We address this limitation by applying language
models hierarchically, in a system we call Dramatron. By building structural
context via prompt chaining, Dramatron can generate coherent scripts and
screenplays complete with title, characters, story beats, location
descriptions, and dialogue. We illustrate Dramatron's usefulness as an
interactive co-creative system with a user study of 15 theatre and film
industry professionals. Participants co-wrote theatre scripts and screenplays
with Dramatron and engaged in open-ended interviews. We report critical
reflections both from our interviewees and from independent reviewers who
watched stagings of the works to illustrate how both Dramatron and hierarchical
text generation could be useful for human-machine co-creativity. Finally, we
discuss the suitability of Dramatron for co-creativity, ethical considerations
-- including plagiarism and bias -- and participatory models for the design and
deployment of such tools.",2022-09-29
"A Benchmark for Understanding and Generating Dialogue between Characters
  in Stories",2022-09-18 10:19:04+00:00,http://arxiv.org/abs/2209.08524v1,"Jianzhu Yao, Ziqi Liu, Jian Guan, Minlie Huang","cs.CL, cs.AI",dialogue,"Many classical fairy tales, fiction, and screenplays leverage dialogue to
advance story plots and establish characters. We present the first study to
explore whether machines can understand and generate dialogue in stories, which
requires capturing traits of different characters and the relationships between
them. To this end, we propose two new tasks including Masked Dialogue
Generation and Dialogue Speaker Recognition, i.e., generating missing dialogue
turns and predicting speakers for specified dialogue turns, respectively. We
build a new dataset DialStory, which consists of 105k Chinese stories with a
large amount of dialogue weaved into the plots to support the evaluation. We
show the difficulty of the proposed tasks by testing existing models with
automatic and manual evaluation on DialStory. Furthermore, we propose to learn
explicit character representations to improve performance on these tasks.
Extensive experiments and case studies show that our approach can generate more
coherent and informative dialogue, and achieve higher speaker recognition
accuracy than strong baselines.",2022-09-18
"Adaptive Natural Language Generation for Task-oriented Dialogue via
  Reinforcement Learning",2022-09-16 12:08:57+00:00,http://arxiv.org/abs/2209.07873v1,"Atsumoto Ohashi, Ryuichiro Higashinaka","cs.CL, cs.AI",dialogue,"When a natural language generation (NLG) component is implemented in a
real-world task-oriented dialogue system, it is necessary to generate not only
natural utterances as learned on training data but also utterances adapted to
the dialogue environment (e.g., noise from environmental sounds) and the user
(e.g., users with low levels of understanding ability). Inspired by recent
advances in reinforcement learning (RL) for language generation tasks, we
propose ANTOR, a method for Adaptive Natural language generation for
Task-Oriented dialogue via Reinforcement learning. In ANTOR, a natural language
understanding (NLU) module, which corresponds to the user's understanding of
system utterances, is incorporated into the objective function of RL. If the
NLG's intentions are correctly conveyed to the NLU, which understands a
system's utterances, the NLG is given a positive reward. We conducted
experiments on the MultiWOZ dataset, and we confirmed that ANTOR could generate
adaptive utterances against speech recognition errors and the different
vocabulary levels of users.",2022-09-16
"OPAL: Ontology-Aware Pretrained Language Model for End-to-End
  Task-Oriented Dialogue",2022-09-10 04:38:27+00:00,http://arxiv.org/abs/2209.04595v1,"Zhi Chen, Yuncong Liu, Lu Chen, Su Zhu, Mengyue Wu, Kai Yu",cs.CL,dialogue,"This paper presents an ontology-aware pretrained language model (OPAL) for
end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models,
task-oriented dialogue models fulfill at least two task-specific modules:
dialogue state tracker (DST) and response generator (RG). The dialogue state
consists of the domain-slot-value triples, which are regarded as the user's
constraints to search the domain-related databases. The large-scale
task-oriented dialogue data with the annotated structured dialogue state
usually are inaccessible. It prevents the development of the pretrained
language model for the task-oriented dialogue. We propose a simple yet
effective pretraining method to alleviate this problem, which consists of two
pretraining phases. The first phase is to pretrain on large-scale contextual
text data, where the structured information of the text is extracted by the
information extracting tool. To bridge the gap between the pretraining method
and downstream tasks, we design two pretraining tasks: ontology-like triple
recovery and next-text generation, which simulates the DST and RG,
respectively. The second phase is to fine-tune the pretrained model on the TOD
data. The experimental results show that our proposed method achieves an
exciting boost and get competitive performance even without any TOD data on
CamRest676 and MultiWOZ benchmarks.",2022-09-10
Unified Knowledge Prompt Pre-training for Customer Service Dialogues,2022-08-31 06:23:53+00:00,http://arxiv.org/abs/2208.14652v1,"Keqing He, Jingang Wang, Chaobo Sun, Wei Wu",cs.CL,dialogue,"Dialogue bots have been widely applied in customer service scenarios to
provide timely and user-friendly experience. These bots must classify the
appropriate domain of a dialogue, understand the intent of users, and generate
proper responses. Existing dialogue pre-training models are designed only for
several dialogue tasks and ignore weakly-supervised expert knowledge in
customer service dialogues. In this paper, we propose a novel unified knowledge
prompt pre-training framework, UFA (\textbf{U}nified Model \textbf{F}or
\textbf{A}ll Tasks), for customer service dialogues. We formulate all the tasks
of customer service dialogues as a unified text-to-text generation task and
introduce a knowledge-driven prompt strategy to jointly learn from a mixture of
distinct dialogue tasks. We pre-train UFA on a large-scale Chinese customer
service corpus collected from practical scenarios and get significant
improvements on both natural language understanding (NLU) and natural language
generation (NLG) benchmarks.",2022-08-31
"GenTUS: Simulating User Behaviour and Language in Task-oriented
  Dialogues with Generative Transformers",2022-08-23 09:01:17+00:00,http://arxiv.org/abs/2208.10817v1,"Hsien-Chin Lin, Christian Geishauser, Shutong Feng, Nurul Lubis, Carel van Niekerk, Michael Heck, Milica Gašić",cs.CL,dialogue,"User simulators (USs) are commonly used to train task-oriented dialogue
systems (DSs) via reinforcement learning. The interactions often take place on
semantic level for efficiency, but there is still a gap from semantic actions
to natural language, which causes a mismatch between training and deployment
environment. Incorporating a natural language generation (NLG) module with USs
during training can partly deal with this problem. However, since the policy
and NLG of USs are optimised separately, these simulated user utterances may
not be natural enough in a given context. In this work, we propose a generative
transformer-based user simulator (GenTUS). GenTUS consists of an
encoder-decoder structure, which means it can optimise both the user policy and
natural language generation jointly. GenTUS generates both semantic actions and
natural language utterances, preserving interpretability and enhancing language
variation. In addition, by representing the inputs and outputs as word
sequences and by using a large pre-trained language model we can achieve
generalisability in feature representation. We evaluate GenTUS with automatic
metrics and human evaluation. Our results show that GenTUS generates more
natural language and is able to transfer to an unseen ontology in a zero-shot
fashion. In addition, its behaviour can be further shaped with reinforcement
learning opening the door to training specialised user simulators.",2022-08-23
"Efficient Task-Oriented Dialogue Systems with Response Selection as an
  Auxiliary Task",2022-08-15 09:59:44+00:00,http://arxiv.org/abs/2208.07097v1,"Radostin Cholakov, Todor Kolev","cs.CL, cs.AI",dialogue,"The adoption of pre-trained language models in task-oriented dialogue systems
has resulted in significant enhancements of their text generation abilities.
However, these architectures are slow to use because of the large number of
trainable parameters and can sometimes fail to generate diverse responses. To
address these limitations, we propose two models with auxiliary tasks for
response selection - (1) distinguishing distractors from ground truth responses
and (2) distinguishing synthetic responses from ground truth labels. They
achieve state-of-the-art results on the MultiWOZ 2.1 dataset with combined
scores of 107.5 and 108.3 and outperform a baseline with three times more
parameters. We publish reproducible code and checkpoints and discuss the
effects of applying auxiliary tasks to T5-based architectures.",2022-08-15
"Dynamically Retrieving Knowledge via Query Generation for informative
  dialogue response",2022-07-30 03:05:43+00:00,http://arxiv.org/abs/2208.00128v1,"Zhongtian Hu, Yangqi Chen, Yushuang Liu, Lifang Wang",cs.CL,dialogue,"Knowledge-driven dialogue generation has recently made remarkable
breakthroughs. Compared with general dialogue systems, superior
knowledge-driven dialogue systems can generate more informative and
knowledgeable responses with pre-provided knowledge. However, in practical
applications, the dialogue system cannot be provided with corresponding
knowledge in advance. In order to solve the problem, we design a
knowledge-driven dialogue system named DRKQG (\emph{Dynamically Retrieving
Knowledge via Query Generation for informative dialogue response}).
Specifically, the system can be divided into two modules: query generation
module and dialogue generation module. First, a time-aware mechanism is
utilized to capture context information and a query can be generated for
retrieving knowledge. Then, we integrate copy Mechanism and Transformers, which
allows the response generation module produces responses derived from the
context and retrieved knowledge. Experimental results at LIC2022, Language and
Intelligence Technology Competition, show that our module outperforms the
baseline model by a large margin on automatic evaluation metrics, while human
evaluation by Baidu Linguistics team shows that our system achieves impressive
results in Factually Correct and Knowledgeable.",2022-07-30
Sequence to sequence pretraining for a less-resourced Slovenian language,2022-07-28 10:08:50+00:00,http://arxiv.org/abs/2207.13988v1,"Matej Ulčar, Marko Robnik-Šikonja",cs.CL,dialogue,"Large pretrained language models have recently conquered the area of natural
language processing. As an alternative to predominant masked language modelling
introduced in BERT, the T5 model has introduced a more general training
objective, namely sequence to sequence transformation, which includes masked
language model but more naturally fits text generation tasks such as machine
translation, summarization, open-domain question answering, text
simplification, dialogue systems, etc. The monolingual variants of T5 models
have been limited to well-resourced languages, while the massively multilingual
T5 model supports 101 languages. In contrast, we trained two different sized
T5-type sequence to sequence models for morphologically rich Slovene language
with much less resources and analyzed their behavior. Concerning classification
tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa
model but are to be considered for the generative tasks.",2022-07-28
A Multi-Party Dialogue Ressource in French,2022-07-25 13:02:54+00:00,http://arxiv.org/abs/2207.12162v1,"Maria Boritchev, Maxime Amblard",cs.AI,dialogue,"We present Dialogues in Games (DinG), a corpus of manual transcriptions of
real-life, oral, spontaneous multi-party dialogues between French-speaking
players of the board game Catan. Our objective is to make available a quality
resource for French, composed of long dialogues, to facilitate their study in
the style of (Asher et al., 2016). In a general dialogue setting, participants
share personal information, which makes it impossible to disseminate the
resource freely and openly. In DinG, the attention of the participants is
focused on the game, which prevents them from talking about themselves. In
addition, we are conducting a study on the nature of the questions in dialogue,
through annotation (Cruz Blandon et al., 2019), in order to develop more
natural automatic dialogue systems.",2022-07-25
Towards a Sentiment-Aware Conversational Agent,2022-07-24 16:59:44+00:00,http://arxiv.org/abs/2207.11774v1,"Isabel Dias, Ricardo Rei, Patrícia Pereira, Luisa Coheur",cs.CL,dialogue,"In this paper, we propose an end-to-end sentiment-aware conversational agent
based on two models: a reply sentiment prediction model, which leverages the
context of the dialogue to predict an appropriate sentiment for the agent to
express in its reply; and a text generation model, which is conditioned on the
predicted sentiment and the context of the dialogue, to produce a reply that is
both context and sentiment appropriate. Additionally, we propose to use a
sentiment classification model to evaluate the sentiment expressed by the agent
during the development of the model. This allows us to evaluate the agent in an
automatic way. Both automatic and human evaluation results show that explicitly
guiding the text generation model with a pre-defined set of sentences leads to
clear improvements, both regarding the expressed sentiment and the quality of
the generated text.",2022-07-24
"TalkToModel: Understanding Machine Learning Models With Open Ended
  Dialogues",2022-07-08 23:42:56+00:00,http://arxiv.org/abs/2207.04154v1,"Dylan Slack, Satyapriya Krishna, Himabindu Lakkaraju, Sameer Singh","cs.LG, cs.AI, cs.CL",dialogue,"Machine Learning (ML) models are increasingly used to make critical decisions
in real-world applications, yet they have also become more complex, making them
harder to understand. To this end, several techniques to explain model
predictions have been proposed. However, practitioners struggle to leverage
explanations because they often do not know which to use, how to interpret the
results, and may have insufficient data science experience to obtain
explanations. In addition, most current works focus on generating one-shot
explanations and do not allow users to follow up and ask fine-grained questions
about the explanations, which can be frustrating. In this work, we address
these challenges by introducing TalkToModel: an open-ended dialogue system for
understanding machine learning models. Specifically, TalkToModel comprises
three key components: 1) a natural language interface for engaging in
dialogues, making understanding ML models highly accessible, 2) a dialogue
engine that adapts to any tabular model and dataset, interprets natural
language, maps it to appropriate operations (e.g., feature importance
explanations, counterfactual explanations, showing model errors), and generates
text responses, and 3) an execution component that run the operations and
ensures explanations are accurate. We carried out quantitative and human
subject evaluations of TalkToModel. We found the system understands user
questions on novel datasets and models with high accuracy, demonstrating the
system's capacity to generalize to new situations. In human evaluations, 73% of
healthcare workers (e.g., doctors and nurses) agreed they would use TalkToModel
over baseline point-and-click systems, and 84.6% of ML graduate students agreed
TalkToModel was easier to use.",2022-07-08
Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk,2022-07-02 04:30:07+00:00,http://arxiv.org/abs/2207.00735v1,"Benyou Wang, Xiangbo Wu, Xiaokang Liu, Jianquan Li, Prayag Tiwari, Qianqian Xie",cs.CL,dialogue,"Language is the principal tool for human communication, in which humor is one
of the most attractive parts. Producing natural language like humans using
computers, a.k.a, Natural Language Generation (NLG), has been widely used for
dialogue systems, chatbots, machine translation, as well as computer-aid
creation e.g., idea generations, scriptwriting. However, the humor aspect of
natural language is relatively under-investigated, especially in the age of
pre-trained language models. In this work, we aim to preliminarily test whether
NLG can generate humor as humans do. We build a new dataset consisting of
numerous digitized Chinese Comical Crosstalk scripts (called C$^3$ in short),
which is for a popular Chinese performing art called `Xiangsheng' since 1800s.
(For convenience for non-Chinese speakers, we called `crosstalk' for
`Xiangsheng' in this paper.) We benchmark various generation approaches
including training-from-scratch Seq2seq, fine-tuned middle-scale PLMs, and
large-scale PLMs (with and without fine-tuning). Moreover, we also conduct a
human assessment, showing that 1) large-scale pretraining largely improves
crosstalk generation quality; and 2) even the scripts generated from the best
PLM is far from what we expect, with only 65% quality of human-created
crosstalk. We conclude, humor generation could be largely improved using
large-scaled PLMs, but it is still in its infancy.
  The data and benchmarking code is publicly available in
\url{https://github.com/anonNo2/crosstalk-generation}.",2022-07-02
"Comparing informativeness of an NLG chatbot vs graphical app in
  diet-information domain",2022-06-23 07:15:58+00:00,http://arxiv.org/abs/2206.13435v1,"Simone Balloccu, Ehud Reiter","cs.CL, cs.AI",dialogue,"Visual representation of data like charts and tables can be challenging to
understand for readers. Previous work showed that combining visualisations with
text can improve the communication of insights in static contexts, but little
is known about interactive ones. In this work we present an NLG chatbot that
processes natural language queries and provides insights through a combination
of charts and text. We apply it to nutrition, a domain communication quality is
critical. Through crowd-sourced evaluation we compare the informativeness of
our chatbot against traditional, static diet-apps. We find that the
conversational context significantly improved users' understanding of dietary
data in various tasks, and that users considered the chatbot as more useful and
quick to use than traditional apps.",2022-06-23
"Automatic Summarization of Russian Texts: Comparison of Extractive and
  Abstractive Methods",2022-06-18 17:28:04+00:00,http://arxiv.org/abs/2206.09253v1,"Valeriya Goloviznina, Evgeny Kotelnikov",cs.CL,dialogue,"The development of large and super-large language models, such as GPT-3, T5,
Switch Transformer, ERNIE, etc., has significantly improved the performance of
text generation. One of the important research directions in this area is the
generation of texts with arguments. The solution of this problem can be used in
business meetings, political debates, dialogue systems, for preparation of
student essays. One of the main domains for these applications is the economic
sphere. The key problem of the argument text generation for the Russian
language is the lack of annotated argumentation corpora. In this paper, we use
translated versions of the Argumentative Microtext, Persuasive Essays and UKP
Sentential corpora to fine-tune RuBERT model. Further, this model is used to
annotate the corpus of economic news by argumentation. Then the annotated
corpus is employed to fine-tune the ruGPT-3 model, which generates argument
texts. The results show that this approach improves the accuracy of the
argument generation by more than 20 percentage points (63.2% vs. 42.5%)
compared to the original ruGPT-3 model.",2022-06-18
Argumentative Text Generation in Economic Domain,2022-06-18 17:22:06+00:00,http://arxiv.org/abs/2206.09251v1,"Irina Fishcheva, Dmitriy Osadchiy, Klavdiya Bochenina, Evgeny Kotelnikov",cs.CL,dialogue,"The development of large and super-large language models, such as GPT-3, T5,
Switch Transformer, ERNIE, etc., has significantly improved the performance of
text generation. One of the important research directions in this area is the
generation of texts with arguments. The solution of this problem can be used in
business meetings, political debates, dialogue systems, for preparation of
student essays. One of the main domains for these applications is the economic
sphere. The key problem of the argument text generation for the Russian
language is the lack of annotated argumentation corpora. In this paper, we use
translated versions of the Argumentative Microtext, Persuasive Essays and UKP
Sentential corpora to fine-tune RuBERT model. Further, this model is used to
annotate the corpus of economic news by argumentation. Then the annotated
corpus is employed to fine-tune the ruGPT-3 model, which generates argument
texts. The results show that this approach improves the accuracy of the
argument generation by more than 20 percentage points (63.2\% vs. 42.5\%)
compared to the original ruGPT-3 model.",2022-06-18
"Offline RL for Natural Language Generation with Implicit Language Q
  Learning",2022-06-05 18:38:42+00:00,http://arxiv.org/abs/2206.11871v1,"Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine","cs.CL, cs.LG",dialogue,"Large language models distill broad knowledge from text corpora. However,
they can be inconsistent when it comes to completing user specified tasks. This
issue can be addressed by finetuning such models via supervised learning on
curated datasets, or via reinforcement learning. In this work, we propose a
novel offline RL motivated method, implicit language Q-learning (ILQL),
designed for use on language models, that combines both the flexible utility
optimization framework of traditional RL algorithms with supervised learning's
ability to leverage existing data and its simplicity and stability. Our method,
based on dynamic programming, employs a blend of value conservatism alongside
an implicit dataset support constraint in learning value functions, which are
then used to guide language model generations towards maximizing utility. In
addition to empirically validating ILQL, we present a detailed empirical
analysis of situations where offline RL can be useful in natural language
generation settings, demonstrating how it can be a more effective utility
optimizer than prior approaches for end-to-end dialogue, and how it can
effectively optimize high variance reward functions based on subjective
judgement, such as whether to label a comment as an example of toxic speech or
not.",2022-06-05
"Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for
  Text-to-Speech",2022-06-05 10:50:34+00:00,http://arxiv.org/abs/2206.02147v1,"Ziyue Jiang, Su Zhe, Zhou Zhao, Qian Yang, Yi Ren, Jinglin Liu, Zhenhui Ye","eess.AS, cs.CL, cs.SD",dialogue,"Polyphone disambiguation aims to capture accurate pronunciation knowledge
from natural text sequences for reliable Text-to-speech (TTS) systems. However,
previous approaches require substantial annotated training data and additional
efforts from language experts, making it difficult to extend high-quality
neural TTS systems to out-of-domain daily conversations and countless languages
worldwide. This paper tackles the polyphone disambiguation problem from a
concise and novel perspective: we propose Dict-TTS, a semantic-aware generative
text-to-speech model with an online website dictionary (the existing prior
information in the natural language). Specifically, we design a
semantics-to-pronunciation attention (S2PA) module to match the semantic
patterns between the input text sequence and the prior semantics in the
dictionary and obtain the corresponding pronunciations; The S2PA module can be
easily trained with the end-to-end TTS model without any annotated phoneme
labels. Experimental results in three languages show that our model outperforms
several strong baseline models in terms of pronunciation accuracy and improves
the prosody modeling of TTS systems. Further extensive analyses with different
linguistic encoders demonstrate that each design in Dict-TTS is effective.
Audio samples are available at \url{https://dicttts.github.io/DictTTS-Demo/}.",2022-06-05
"Findings of the The RuATD Shared Task 2022 on Artificial Text Detection
  in Russian",2022-06-03 14:12:33+00:00,http://arxiv.org/abs/2206.01583v1,"Tatiana Shamardina, Vladislav Mikhailov, Daniil Chernianskii, Alena Fenogenova, Marat Saidov, Anastasiya Valeeva, Tatiana Shavrina, Ivan Smurov, Elena Tutubalina, Ekaterina Artemova",cs.CL,dialogue,"We present the shared task on artificial text detection in Russian, which is
organized as a part of the Dialogue Evaluation initiative, held in 2022. The
shared task dataset includes texts from 14 text generators, i.e., one human
writer and 13 text generative models fine-tuned for one or more of the
following generation tasks: machine translation, paraphrase generation, text
summarization, text simplification. We also consider back-translation and
zero-shot generation approaches. The human-written texts are collected from
publicly available resources across multiple domains. The shared task consists
of two sub-tasks: (i) to determine if a given text is automatically generated
or written by a human; (ii) to identify the author of a given text. The first
task is framed as a binary classification problem. The second task is a
multi-class classification problem. We provide count-based and BERT-based
baselines, along with the human evaluation on the first sub-task. A total of 30
and 8 systems have been submitted to the binary and multi-class sub-tasks,
correspondingly. Most teams outperform the baselines by a wide margin. We
publicly release our codebase, human evaluation results, and other materials in
our GitHub repository (https://github.com/dialogue-evaluation/RuATD).",2022-06-03
Clinical Dialogue Transcription Error Correction using Seq2Seq Models,2022-05-26 18:27:17+00:00,http://arxiv.org/abs/2205.13572v1,"Gayani Nanayakkara, Nirmalie Wiratunga, David Corsar, Kyle Martin, Anjana Wijekoon","cs.CL, cs.AI",dialogue,"Good communication is critical to good healthcare. Clinical dialogue is a
conversation between health practitioners and their patients, with the explicit
goal of obtaining and sharing medical information. This information contributes
to medical decision-making regarding the patient and plays a crucial role in
their healthcare journey. The reliance on note taking and manual scribing
processes are extremely inefficient and leads to manual transcription errors
when digitizing notes. Automatic Speech Recognition (ASR) plays a significant
role in speech-to-text applications, and can be directly used as a text
generator in conversational applications. However, recording clinical dialogue
presents a number of general and domain-specific challenges. In this paper, we
present a seq2seq learning approach for ASR transcription error correction of
clinical dialogues. We introduce a new Gastrointestinal Clinical Dialogue (GCD)
Dataset which was gathered by healthcare professionals from a NHS Inflammatory
Bowel Disease clinic and use this in a comparative study with four commercial
ASR systems. Using self-supervision strategies, we fine-tune a seq2seq model on
a mask-filling task using a domain-specific PubMed dataset which we have shared
publicly for future research. The BART model fine-tuned for mask-filling was
able to correct transcription errors and achieve lower word error rates for
three out of four commercial ASR outputs.",2022-05-26
"The Dialog Must Go On: Improving Visual Dialog via Generative
  Self-Training",2022-05-25 05:40:00+00:00,http://arxiv.org/abs/2205.12502v1,"Gi-Cheon Kang, Sungdong Kim, Jin-Hwa Kim, Donghyun Kwak, Byoung-Tak Zhang","cs.CV, cs.CL, cs.LG",dialogue,"Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).",2022-05-25
"CORAL: Contextual Response Retrievability Loss Function for Training
  Dialog Generation Models",2022-05-21 10:36:22+00:00,http://arxiv.org/abs/2205.10558v1,"Bishal Santra, Ravi Ghadia, Arpit Dwivedi, Manish Gupta, Pawan Goyal",cs.CL,dialogue,"Natural Language Generation (NLG) represents a large collection of tasks in
the field of NLP. While many of these tasks have been tackled well by the
cross-entropy (CE) loss, the task of dialog generation poses a few unique
challenges for this loss function. First, CE loss assumes that for any given
input, the only possible output is the one available as the ground truth in the
training dataset. In general, this is not true for any task, as there can be
multiple semantically equivalent sentences, each with a different surface form.
This problem gets exaggerated further for the dialog generation task, as there
can be multiple valid responses (for a given context) that not only have
different surface forms but are also not semantically equivalent. Second, CE
loss does not take the context into consideration while processing the response
and, hence, it treats all ground truths with equal importance irrespective of
the context. But, we may want our final agent to avoid certain classes of
responses (e.g. bland, non-informative or biased responses) and give relatively
higher weightage for more context-specific responses. To circumvent these
shortcomings of the CE loss, in this paper, we propose a novel loss function,
CORAL, that directly optimizes recently proposed estimates of human preference
for generated responses. Using CORAL, we can train dialog generation models
without assuming non-existence of response other than the ground-truth. Also,
the CORAL loss is computed based on both the context and the response.
Extensive comparisons on two benchmark datasets show that the proposed methods
outperform strong state-of-the-art baseline models of different sizes.",2022-05-21
Self-augmented Data Selection for Few-shot Dialogue Generation,2022-05-19 16:25:50+00:00,http://arxiv.org/abs/2205.09661v1,"Wanyu Du, Hanjie Chen, Yangfeng Ji",cs.CL,dialogue,"The natural language generation (NLG) module in task-oriented dialogue
systems translates structured meaning representations (MRs) into text
responses, which has a great impact on users' experience as the human-machine
interaction interface. However, in practice, developers often only have a few
well-annotated data and confront a high data collection cost to build the NLG
module. In this work, we adopt the self-training framework to deal with the
few-shot MR-to-Text generation problem. We leverage the pre-trained language
model to self-augment many pseudo-labeled data. To prevent the gradual drift
from target data distribution to noisy augmented data distribution, we propose
a novel data selection strategy to select the data that our generation model is
most uncertain about. Compared with existing data selection methods, our method
is: (1) parameter-efficient, which does not require training any additional
neural models, (2) computation-efficient, which only needs to apply several
stochastic forward passes of the model to estimate the uncertainty. We conduct
empirical experiments on two benchmark datasets: FewShotWOZ and FewShotSGD, and
show that our proposed framework consistently outperforms other baselines in
terms of BLEU and ERR.",2022-05-19
Diversifying Neural Dialogue Generation via Negative Distillation,2022-05-05 17:14:56+00:00,http://arxiv.org/abs/2205.02795v1,"Yiwei Li, Shaoxiong Feng, Bin Sun, Kan Li","cs.CL, cs.AI",dialogue,"Generative dialogue models suffer badly from the generic response problem,
limiting their applications to a few toy scenarios. Recently, an interesting
approach, namely negative training, has been proposed to alleviate this problem
by reminding the model not to generate high-frequency responses during
training. However, its performance is hindered by two issues, ignoring
low-frequency but generic responses and bringing low-frequency but meaningless
responses. In this paper, we propose a novel negative training paradigm, called
negative distillation, to keep the model away from the undesirable generic
responses while avoiding the above problems. First, we introduce a negative
teacher model that can produce query-wise generic responses, and then the
student model is required to maximize the distance with multi-level negative
knowledge. Empirical results show that our method outperforms previous negative
training methods significantly.",2022-05-05
AI Personification: Estimating the Personality of Language Models,2022-04-25 23:53:53+00:00,http://arxiv.org/abs/2204.12000v1,"Saketh Reddy Karra, Son Nguyen, Theja Tulabandhula","cs.CL, cs.AI",dialogue,"Technology for open-ended language generation, a key application of
artificial intelligence, has advanced to a great extent in recent years.
Large-scale language models, which are trained on large corpora of text, are
being used in a wide range of applications everywhere, from virtual assistants
to conversational bots. While these language models output fluent text,
existing research shows that these models can and do capture human biases. Many
of these biases, especially those that could potentially cause harm, are being
well investigated. On the other hand, studies that infer and change personality
traits inherited by these models have been scarce or non-existent. In this
work, we explore the personality traits of several large-scale language models
designed for open-ended text generation and the datasets used for training
them. Our work builds on the popular Big Five factors and develops robust
methods that quantify the personality traits of these models and their
underlying datasets. In particular, we trigger the models with a questionnaire
designed for personality assessment and subsequently classify the text
responses into quantifiable traits using a Zero-shot classifier. Our
classification sheds light on an important anthropomorphic element found in
such AI models and can help stakeholders decide how they should be applied and
how society could perceive them. We augment our analysis by studying approaches
that can alter these personalities.",2022-04-25
SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues,2022-04-22 09:31:13+00:00,http://arxiv.org/abs/2204.10591v1,"Ssu Chiu, Maolin Li, Yen-Ting Lin, Yun-Nung Chen","cs.CL, cs.AI",dialogue,"Dialogue systems are usually categorized into two types, open-domain and
task-oriented. The first one focuses on chatting with users and making them
engage in the conversations, where selecting a proper topic to fit the dialogue
context is essential for a successful dialogue. The other one focuses on a
specific task instead of casual talks, e.g., finding a movie on Friday night,
or playing a song. These two directions have been studied separately due to
their different purposes. However, how smoothly transitioning from social
chatting to task-oriented dialogues is important for triggering business
opportunities, and there is no public data focusing on such scenarios. Hence,
this paper focuses on investigating the conversations starting from open-domain
social chatting and then gradually transitioning to task-oriented purposes, and
releases a large-scale dataset with detailed annotations for encouraging this
research direction. To achieve this goal, this paper proposes a framework to
automatically generate many dialogues without human involvement, in which any
powerful open-domain dialogue generation model can be easily leveraged. The
human evaluation shows that our generated dialogue data has a natural flow at a
reasonable quality, showing that our released data has a great potential of
guiding future research directions and commercial activities. Furthermore, the
released models allow researchers to automatically generate unlimited dialogues
in the target scenarios, which can greatly benefit semi-supervised and
unsupervised approaches.",2022-04-22
Event Transition Planning for Open-ended Text Generation,2022-04-20 13:37:51+00:00,http://arxiv.org/abs/2204.09453v1,"Qintong Li, Piji Li, Wei Bi, Zhaochun Ren, Yuxuan Lai, Lingpeng Kong",cs.CL,dialogue,"Open-ended text generation tasks, such as dialogue generation and story
completion, require models to generate a coherent continuation given limited
preceding context. The open-ended nature of these tasks brings new challenges
to the neural auto-regressive text generators nowadays. Despite these neural
models are good at producing human-like text, it is difficult for them to
arrange causalities and relations between given facts and possible ensuing
events. To bridge this gap, we propose a novel two-stage method which
explicitly arranges the ensuing events in open-ended text generation. Our
approach can be understood as a specially-trained coarse-to-fine algorithm,
where an event transition planner provides a ""coarse"" plot skeleton and a text
generator in the second stage refines the skeleton. Experiments on two
open-ended text generation tasks demonstrate that our proposed method
effectively improves the quality of the generated text, especially in coherence
and diversity. The code is available at:
\url{https://github.com/qtli/EventPlanforTextGen}.",2022-04-20
"A Survey on Non-Autoregressive Generation for Neural Machine Translation
  and Beyond",2022-04-20 07:25:22+00:00,http://arxiv.org/abs/2204.09269v1,"Yisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, Tie-yan Liu","cs.CL, cs.LG",dialogue,"Non-autoregressive (NAR) generation, which is first proposed in neural
machine translation (NMT) to speed up inference, has attracted much attention
in both machine learning and natural language processing communities. While NAR
generation can significantly accelerate inference speed for machine
translation, the speedup comes at the cost of sacrificed translation accuracy
compared to its counterpart, auto-regressive (AR) generation. In recent years,
many new models and algorithms have been designed/proposed to bridge the
accuracy gap between NAR generation and AR generation. In this paper, we
conduct a systematic survey with comparisons and discussions of various
non-autoregressive translation (NAT) models from different aspects.
Specifically, we categorize the efforts of NAT into several groups, including
data manipulation, modeling methods, training criterion, decoding algorithms,
and the benefit from pre-trained models. Furthermore, we briefly review other
applications of NAR models beyond machine translation, such as dialogue
generation, text summarization, grammar error correction, semantic parsing,
speech synthesis, and automatic speech recognition. In addition, we also
discuss potential directions for future exploration, including releasing the
dependency of KD, dynamic length prediction, pre-training for NAR, and wider
applications, etc. We hope this survey can help researchers capture the latest
progress in NAR generation, inspire the design of advanced NAR models and
algorithms, and enable industry practitioners to choose appropriate solutions
for their applications. The web page of this survey is at
\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}.",2022-04-20
"Evaluating Mixed-initiative Conversational Search Systems via User
  Simulation",2022-04-17 16:27:33+00:00,http://arxiv.org/abs/2204.08046v1,"Ivan Sekulić, Mohammad Aliannejadi, Fabio Crestani","cs.CL, cs.IR",dialogue,"Clarifying the underlying user information need by asking clarifying
questions is an important feature of modern conversational search system.
However, evaluation of such systems through answering prompted clarifying
questions requires significant human effort, which can be time-consuming and
expensive. In this paper, we propose a conversational User Simulator, called
USi, for automatic evaluation of such conversational search systems. Given a
description of an information need, USi is capable of automatically answering
clarifying questions about the topic throughout the search session. Through a
set of experiments, including automated natural language generation metrics and
crowdsourcing studies, we show that responses generated by USi are both inline
with the underlying information need and comparable to human-generated answers.
Moreover, we make the first steps towards multi-turn interactions, where
conversational search systems asks multiple questions to the (simulated) user
with a goal of clarifying the user need. To this end, we expand on currently
available datasets for studying clarifying questions, i.e., Qulac and ClariQ,
by performing a crowdsourcing-based multi-turn data acquisition. We show that
our generative, GPT2-based model, is capable of providing accurate and natural
answers to unseen clarifying questions in the single-turn setting and discuss
capabilities of our model in the multi-turn setting. We provide the code, data,
and the pre-trained model to be used for further research on the topic.",2022-04-17
UniDU: Towards A Unified Generative Dialogue Understanding Framework,2022-04-10 09:32:34+00:00,http://arxiv.org/abs/2204.04637v1,"Zhi Chen, Lu Chen, Bei Chen, Libo Qin, Yuncong Liu, Su Zhu, Jian-Guang Lou, Kai Yu",cs.CL,dialogue,"With the development of pre-trained language models, remarkable success has
been witnessed in dialogue understanding (DU) direction. However, the current
DU approaches just employ an individual model for each DU task, independently,
without considering the shared knowledge across different DU tasks. In this
paper, we investigate a unified generative dialogue understanding framework,
namely UniDU, to achieve information exchange among DU tasks. Specifically, we
reformulate the DU tasks into unified generative paradigm. In addition, to
consider different training data for each task, we further introduce
model-agnostic training strategy to optimize unified model in a balanced
manner. We conduct the experiments on ten dialogue understanding datasets,
which span five fundamental tasks: dialogue summary, dialogue completion, slot
filling, intent detection and dialogue state tracking. The proposed UniDU
framework outperforms task-specific well-designed methods on all 5 tasks. We
further conduct comprehensive analysis experiments to study the effect factors.
The experimental results also show that the proposed method obtains promising
performance on unseen dialogue domain.",2022-04-10
"BioBART: Pretraining and Evaluation of A Biomedical Generative Language
  Model",2022-04-08 08:07:42+00:00,http://arxiv.org/abs/2204.03905v1,"Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, Sheng Yu",cs.CL,dialogue,"Pretrained language models have served as important backbones for natural
language processing. Recently, in-domain pretraining has been shown to benefit
various domain-specific downstream tasks. In the biomedical domain, natural
language generation (NLG) tasks are of critical importance, while understudied.
Approaching natural language understanding (NLU) tasks as NLG achieves
satisfying performance in the general domain through constrained language
generation or language prompting. We emphasize the lack of in-domain generative
language models and the unsystematic generative downstream benchmarks in the
biomedical domain, hindering the development of the research community. In this
work, we introduce the generative language model BioBART that adapts BART to
the biomedical domain. We collate various biomedical language generation tasks
including dialogue, summarization, entity linking, and named entity
recognition. BioBART pretrained on PubMed abstracts has enhanced performance
compared to BART and set strong baselines on several tasks. Furthermore, we
conduct ablation studies on the pretraining tasks for BioBART and find that
sentence permutation has negative effects on downstream tasks.",2022-04-08
A Roadmap for Big Model,2022-03-26 15:38:00+00:00,http://arxiv.org/abs/2203.14101v1,"Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangxiao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao, Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning Ding, Yongming Rao, Yizhao Gao, Liang Zhang, Ming Ding, Cong Fang, Yisen Wang, Mingsheng Long, Jing Zhang, Yinpeng Dong, Tianyu Pang, Peng Cui, Lingxiao Huang, Zheng Liang, Huawei Shen, Hui Zhang, Quanshi Zhang, Qingxiu Dong, Zhixing Tan, Mingxuan Wang, Shuo Wang, Long Zhou, Haoran Li, Junwei Bao, Yingwei Pan, Weinan Zhang, Zhou Yu, Rui Yan, Chence Shi, Minghao Xu, Zuobai Zhang, Guoqiang Wang, Xiang Pan, Mengjie Li, Xiaoyu Chu, Zijun Yao, Fangwei Zhu, Shulin Cao, Weicheng Xue, Zixuan Ma, Zhengyan Zhang, Shengding Hu, Yujia Qin, Chaojun Xiao, Zheni Zeng, Ganqu Cui, Weize Chen, Weilin Zhao, Yuan Yao, Peng Li, Wenzhao Zheng, Wenliang Zhao, Ziyi Wang, Borui Zhang, Nanyi Fei, Anwen Hu, Zenan Ling, Haoyang Li, Boxi Cao, Xianpei Han, Weidong Zhan, Baobao Chang, Hao Sun, Jiawen Deng, Juanzi Li, Lei Hou, Xigang Cao, Jidong Zhai, Zhiyuan Liu, Maosong Sun, Jiwen Lu, Zhiwu Lu, Qin Jin, Ruihua Song, Ji-Rong Wen, Zhouchen Lin, Liwei Wang, Hang Su, Jun Zhu, Zhifang Sui, Jiajun Zhang, Yang Liu, Xiaodong He, Minlie Huang, Jian Tang, Jie Tang","cs.LG, cs.AI, cs.CL",dialogue,"With the rapid development of deep learning, training Big Models (BMs) for
multiple downstream tasks becomes a popular paradigm. Researchers have achieved
various outcomes in the construction of BMs and the BM application in many
fields. At present, there is a lack of research work that sorts out the overall
progress of BMs and guides the follow-up research. In this paper, we cover not
only the BM technologies themselves but also the prerequisites for BM training
and applications with BMs, dividing the BM review into four parts: Resource,
Models, Key Technologies and Application. We introduce 16 specific BM-related
topics in those four parts, they are Data, Knowledge, Computing System,
Parallel Training System, Language Model, Vision Model, Multi-modal Model,
Theory&Interpretability, Commonsense Reasoning, Reliability&Security,
Governance, Evaluation, Machine Translation, Text Generation, Dialogue and
Protein Research. In each topic, we summarize clearly the current studies and
propose some future research directions. At the end of this paper, we conclude
the further development of BMs in a more general view.",2022-03-26
"GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate
  Degradation of Artificial Neural Language Models",2022-03-25 00:25:42+00:00,http://arxiv.org/abs/2203.13397v1,"Changye Li, David Knopman, Weizhe Xu, Trevor Cohen, Serguei Pakhomov",cs.CL,dialogue,"Deep learning (DL) techniques involving fine-tuning large numbers of model
parameters have delivered impressive performance on the task of discriminating
between language produced by cognitively healthy individuals, and those with
Alzheimer's disease (AD). However, questions remain about their ability to
generalize beyond the small reference sets that are publicly available for
research. As an alternative to fitting model parameters directly, we propose a
novel method by which a Transformer DL model (GPT-2) pre-trained on general
English text is paired with an artificially degraded version of itself (GPT-D),
to compute the ratio between these two models' \textit{perplexities} on
language from cognitively healthy and impaired individuals. This technique
approaches state-of-the-art performance on text data from a widely used ""Cookie
Theft"" picture description task, and unlike established alternatives also
generalizes well to spontaneous conversations. Furthermore, GPT-D generates
text with characteristics known to be associated with AD, demonstrating the
induction of dementia-related linguistic anomalies. Our study is a step toward
better understanding of the relationships between the inner workings of
generative neural language models, the language that they produce, and the
deleterious effects of dementia on human speech and language characteristics.",2022-03-25
Immersive Text Game and Personality Classification,2022-03-20 18:37:03+00:00,http://arxiv.org/abs/2203.10621v1,"Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi","cs.CL, cs.AI, cs.LG",dialogue,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",2022-03-20
"Time Dependency, Data Flow, and Competitive Advantage",2022-03-17 07:09:30+00:00,http://arxiv.org/abs/2203.09128v1,"Ehsan Valavi, Joel Hestness, Marco Iansiti, Newsha Ardalani, Feng Zhu, Karim R. Lakhani","cs.LG, cs.CL, econ.GN, q-fin.EC",dialogue,"Data is fundamental to machine learning-based products and services and is
considered strategic due to its externalities for businesses, governments,
non-profits, and more generally for society. It is renowned that the value of
organizations (businesses, government agencies and programs, and even
industries) scales with the volume of available data. What is often less
appreciated is that the data value in making useful organizational predictions
will range widely and is prominently a function of data characteristics and
underlying algorithms.
  In this research, our goal is to study how the value of data changes over
time and how this change varies across contexts and business areas (e.g. next
word prediction in the context of history, sports, politics). We focus on data
from Reddit.com and compare the value's time-dependency across various Reddit
topics (Subreddits). We make this comparison by measuring the rate at which
user-generated text data loses its relevance to the algorithmic prediction of
conversations. We show that different subreddits have different rates of
relevance decline over time.
  Relating the text topics to various business areas of interest, we argue that
competing in a business area in which data value decays rapidly alters
strategies to acquire competitive advantage. When data value decays rapidly,
access to a continuous flow of data will be more valuable than access to a
fixed stock of data. In this kind of setting, improving user engagement and
increasing user-base help creating and maintaining a competitive advantage.",2022-03-17
"TegTok: Augmenting Text Generation via Task-specific and Open-world
  Knowledge",2022-03-16 10:37:59+00:00,http://arxiv.org/abs/2203.08517v1,"Chao-Hong Tan, Jia-Chen Gu, Chongyang Tao, Zhen-Hua Ling, Can Xu, Huang Hu, Xiubo Geng, Daxin Jiang","cs.CL, cs.AI",dialogue,"Generating natural and informative texts has been a long-standing problem in
NLP. Much effort has been dedicated into incorporating pre-trained language
models (PLMs) with various open-world knowledge, such as knowledge graphs or
wiki pages. However, their ability to access and manipulate the task-specific
knowledge is still limited on downstream tasks, as this type of knowledge is
usually not well covered in PLMs and is hard to acquire. To address the
problem, we propose augmenting TExt Generation via Task-specific and Open-world
Knowledge (TegTok) in a unified framework. Our model selects knowledge entries
from two types of knowledge sources through dense retrieval and then injects
them into the input encoding and output decoding stages respectively on the
basis of PLMs. With the help of these two types of knowledge, our model can
learn what and how to generate. Experiments on two text generation tasks of
dialogue generation and question generation, and on two datasets show that our
method achieves better performance than various baseline models.",2022-03-16
"Faithfulness in Natural Language Generation: A Systematic Survey of
  Analysis, Evaluation and Optimization Methods",2022-03-10 08:28:32+00:00,http://arxiv.org/abs/2203.05227v1,"Wei Li, Wenhao Wu, Moye Chen, Jiachen Liu, Xinyan Xiao, Hua Wu",cs.CL,dialogue,"Natural Language Generation (NLG) has made great progress in recent years due
to the development of deep learning techniques such as pre-trained language
models. This advancement has resulted in more fluent, coherent and even
properties controllable (e.g. stylistic, sentiment, length etc.) generation,
naturally leading to development in downstream tasks such as abstractive
summarization, dialogue generation, machine translation, and data-to-text
generation. However, the faithfulness problem that the generated text usually
contains unfaithful or non-factual information has become the biggest
challenge, which makes the performance of text generation unsatisfactory for
practical applications in many real-world scenarios. Many studies on analysis,
evaluation, and optimization methods for faithfulness problems have been
proposed for various tasks, but have not been organized, compared and discussed
in a combined manner. In this survey, we provide a systematic overview of the
research progress on the faithfulness problem of NLG, including problem
analysis, evaluation metrics and optimization methods. We organize the
evaluation and optimization methods for different tasks into a unified taxonomy
to facilitate comparison and learning across tasks. Several research trends are
discussed further.",2022-03-10
"Towards Generalized Models for Task-oriented Dialogue Modeling on Spoken
  Conversations",2022-03-08 12:26:57+00:00,http://arxiv.org/abs/2203.04045v1,"Ruijie Yan, Shuang Peng, Haitao Mi, Liang Jiang, Shihui Yang, Yuchi Zhang, Jiajun Li, Liangrui Peng, Yongliang Wang, Zujie Wen",cs.CL,dialogue,"Building robust and general dialogue models for spoken conversations is
challenging due to the gap in distributions of spoken and written data. This
paper presents our approach to build generalized models for the
Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations
Challenge of DSTC-10. In order to mitigate the discrepancies between spoken and
written text, we mainly employ extensive data augmentation strategies on
written data, including artificial error injection and round-trip text-speech
transformation. To train robust models for spoken conversations, we improve
pre-trained language models, and apply ensemble algorithms for each sub-task.
Typically, for the detection task, we fine-tune \roberta and ELECTRA, and run
an error-fixing ensemble algorithm. For the selection task, we adopt a
two-stage framework that consists of entity tracking and knowledge ranking, and
propose a multi-task learning method to learn multi-level semantic information
by domain classification and entity selection. For the generation task, we
adopt a cross-validation data process to improve pre-trained generative
language models, followed by a consensus decoding algorithm, which can add
arbitrary features like relative \rouge metric, and tune associated feature
weights toward \bleu directly. Our approach ranks third on the objective
evaluation and second on the final official human evaluation.",2022-03-08
Deep Latent-Variable Models for Text Generation,2022-03-03 23:06:39+00:00,http://arxiv.org/abs/2203.02055v1,Xiaoyu Shen,cs.CL,dialogue,"Text generation aims to produce human-like natural language output for
down-stream tasks. It covers a wide range of applications like machine
translation, document summarization, dialogue generation and so on. Recently
deep neural network-based end-to-end architectures have been widely adopted.
The end-to-end approach conflates all sub-modules, which used to be designed by
complex handcrafted rules, into a holistic encode-decode architecture. Given
enough training data, it is able to achieve state-of-the-art performance yet
avoiding the need of language/domain-dependent knowledge. Nonetheless, deep
learning models are known to be extremely data-hungry, and text generated from
them usually suffer from low diversity, interpretability and controllability.
As a result, it is difficult to trust the output from them in real-life
applications. Deep latent-variable models, by specifying the probabilistic
distribution over an intermediate latent process, provide a potential way of
addressing these problems while maintaining the expressive power of deep neural
networks. This dissertation presents how deep latent-variable models can
improve over the standard encoder-decoder model for text generation.",2022-03-03
Capturing Failures of Large Language Models via Human Cognitive Biases,2022-02-24 18:58:52+00:00,http://arxiv.org/abs/2202.12299v1,"Erik Jones, Jacob Steinhardt","cs.CL, cs.AI, cs.LG",dialogue,"Large language models generate complex, open-ended outputs: instead of
outputting a single class, they can write summaries, generate dialogue, and
produce working code. In order to study the reliability of these open-ended
systems, we must understand not just when they fail, but also how they fail. To
approach this, we draw inspiration from human cognitive biases -- systematic
patterns of deviation from rational judgement. Specifically, we use cognitive
biases to (i) identify inputs that models are likely to err on, and (ii)
develop tests to qualitatively characterize their errors on these inputs. Using
code generation as a case study, we find that OpenAI's Codex errs predictably
based on how the input prompt is framed, adjusts outputs towards anchors, and
is biased towards outputs that mimic frequent training examples. We then use
our framework to uncover high-impact errors such as incorrectly deleting files.
Our experiments suggest that cognitive science can be a useful jumping-off
point to better understand how contemporary machine learning systems behave.",2022-02-24
"Integrating AI Planning with Natural Language Processing: A Combination
  of Explicit and Tacit Knowledge",2022-02-15 02:19:09+00:00,http://arxiv.org/abs/2202.07138v1,"Kebing Jin, Hankz Hankui Zhuo","cs.AI, cs.CL",dialogue,"Automated planning focuses on strategies, building domain models and
synthesizing plans to transit initial states to goals. Natural language
processing concerns with the interactions between agents and human language,
especially processing and analyzing large amounts of natural language data.
These two fields have abilities to generate explicit knowledge, e.g.,
preconditions and effects of action models, and learn from tacit knowledge,
e.g., neural models, respectively. Integrating AI planning and natural language
processing effectively improves the communication between human and intelligent
agents. This paper outlines the commons and relations between AI planning and
natural language processing, argues that each of them can effectively impact on
the other one by four areas: (1) planning-based text understanding, (2)
planning-based text generation, (3) text-based human-robot interaction, and (4)
text-based explainable planning. We also explore some potential future issues
between AI planning and natural language processing.",2022-02-15
Survey of Hallucination in Natural Language Generation,2022-02-08 03:55:01+00:00,http://arxiv.org/abs/2202.03629v1,"Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, Pascale Fung","cs.CL, A.1",dialogue,"Natural Language Generation (NLG) has improved exponentially in recent years
thanks to the development of deep learning technologies such as
Transformer-based language models. This advancement has led to more fluent and
coherent natural language generation, naturally leading to development in
downstream tasks such as abstractive summarization, dialogue generation and
data-to-text generation. However, it is also investigated that such generation
includes hallucinated texts, which makes the performances of text generation
fail to meet users' expectations in many real-world scenarios. In order to
address this issue, studies in evaluation and mitigation methods of
hallucinations have been presented in various tasks, but have not been reviewed
in a combined manner. In this survey, we provide a broad overview of the
research progress and challenges in the hallucination problem of NLG. The
survey is organized into two big divisions: (i) a general overview of metrics,
mitigation methods, and future directions; (ii) task-specific research progress
for hallucinations in a large set of downstream tasks: abstractive
summarization, dialogue generation, generative question answering, data-to-text
generation, and machine translation. This survey could facilitate collaborative
efforts among researchers in these tasks.",2022-02-08
Red Teaming Language Models with Language Models,2022-02-07 15:22:17+00:00,http://arxiv.org/abs/2202.03286v1,"Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, Geoffrey Irving","cs.CL, cs.AI, cs.CR, cs.LG",dialogue,"Language Models (LMs) often cannot be deployed because of their potential to
harm users in hard-to-predict ways. Prior work identifies harmful behaviors
before deployment by using human annotators to hand-write test cases. However,
human annotation is expensive, limiting the number and diversity of test cases.
In this work, we automatically find cases where a target LM behaves in a
harmful way, by generating test cases (""red teaming"") using another LM. We
evaluate the target LM's replies to generated test questions using a classifier
trained to detect offensive content, uncovering tens of thousands of offensive
replies in a 280B parameter LM chatbot. We explore several methods, from
zero-shot generation to reinforcement learning, for generating test cases with
varying levels of diversity and difficulty. Furthermore, we use prompt
engineering to control LM-generated test cases to uncover a variety of other
harms, automatically finding groups of people that the chatbot discusses in
offensive ways, personal and hospital phone numbers generated as the chatbot's
own contact info, leakage of private training data in generated text, and harms
that occur over the course of a conversation. Overall, LM-based red teaming is
one promising tool (among many needed) for finding and fixing diverse,
undesirable LM behaviors before impacting users.",2022-02-07
A Survey on Retrieval-Augmented Text Generation,2022-02-02 16:18:41+00:00,http://arxiv.org/abs/2202.01110v1,"Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu",cs.CL,dialogue,"Recently, retrieval-augmented text generation attracted increasing attention
of the computational linguistics community. Compared with conventional
generation models, retrieval-augmented text generation has remarkable
advantages and particularly has achieved state-of-the-art performance in many
NLP tasks. This paper aims to conduct a survey about retrieval-augmented text
generation. It firstly highlights the generic paradigm of retrieval-augmented
generation, and then it reviews notable approaches according to different tasks
including dialogue response generation, machine translation, and other
generation tasks. Finally, it points out some important directions on top of
recent methods to facilitate future research.",2022-02-02
"Language Generation for Broad-Coverage, Explainable Cognitive Systems",2022-01-25 16:09:19+00:00,http://arxiv.org/abs/2201.10422v1,"Marjorie McShane, Ivan Leon","cs.CL, cs.AI",dialogue,"This paper describes recent progress on natural language generation (NLG) for
language-endowed intelligent agents (LEIAs) developed within the OntoAgent
cognitive architecture. The approach draws heavily from past work on natural
language understanding in this paradigm: it uses the same knowledge bases,
theory of computational linguistics, agent architecture, and methodology of
developing broad-coverage capabilities over time while still supporting
near-term applications.",2022-01-25
Measuring Attribution in Natural Language Generation Models,2021-12-23 22:33:20+00:00,http://arxiv.org/abs/2112.12870v1,"Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, David Reitter",cs.CL,dialogue,"With recent improvements in natural language generation (NLG) models for
various applications, it has become imperative to have the means to identify
and evaluate whether NLG output is only sharing verifiable information about
the external world. In this work, we present a new evaluation framework
entitled Attributable to Identified Sources (AIS) for assessing the output of
natural language generation models, when such output pertains to the external
world. We first define AIS and introduce a two-stage annotation pipeline for
allowing annotators to appropriately evaluate model output according to AIS
guidelines. We empirically validate this approach on three generation datasets
(two in the conversational QA domain and one in summarization) via human
evaluation studies that suggest that AIS could serve as a common framework for
measuring whether model-generated statements are supported by underlying
sources. We release guidelines for the human evaluation studies.",2021-12-23
Taming Repetition in Dialogue Generation,2021-12-16 06:25:46+00:00,http://arxiv.org/abs/2112.08657v1,"Yadong Xi, Jiashu Pu, Xiaoxi Mao",cs.CL,dialogue,"The wave of pre-training language models has been continuously improving the
quality of the machine-generated conversations, however, some of the generated
responses still suffer from excessive repetition, sometimes repeating words
from utterance, sometimes repeating words within self-generated responses, or
both. Inappropriate repetition of words can significantly degrade the quality
of the generated texts. Penalized sampling is one popular solution, reducing
the sampling probability of existing words during inference, however, it is
highly vulnerable to the inappropriate setting of the static weight. Setting it
too high can yield strange and unrealistic sentences while setting it too low
makes the task of suppressing repetition trivial. To remedy the shortcomings of
the above methods, we design a context-aware classifier to explicitly decide
when to allow repetition and when to employ penalized sampling. Such a
classifier can be easily integrated with existing decoding methods, reducing
repetitions where appropriate while preserving the diversity of the text.
Experimental results demonstrate that our method can generate higher quality
and more authentic dialogues.",2021-12-16
DG2: Data Augmentation Through Document Grounded Dialogue Generation,2021-12-15 18:50:14+00:00,http://arxiv.org/abs/2112.08342v1,"Qingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis A. Lastras, Zhou Yu",cs.CL,dialogue,"Collecting data for training dialog systems can be extremely expensive due to
the involvement of human participants and need for extensive annotation.
Especially in document-grounded dialog systems, human experts need to carefully
read the unstructured documents to answer the users' questions. As a result,
existing document-grounded dialog datasets are relatively small-scale and
obstruct the effective training of dialogue systems. In this paper, we propose
an automatic data augmentation technique grounded on documents through a
generative dialogue model. The dialogue model consists of a user bot and agent
bot that can synthesize diverse dialogues given an input document, which are
then used to train a downstream model. When supplementing the original dataset,
our method achieves significant improvement over traditional data augmentation
methods. We also achieve great performance in the low-resource setting.",2021-12-15
Dynamic Human Evaluation for Relative Model Comparisons,2021-12-15 11:32:13+00:00,http://arxiv.org/abs/2112.08048v1,"Thórhildur Thorleiksdóttir, Cedric Renggli, Nora Hollenstein, Ce Zhang",cs.CL,dialogue,"Collecting human judgements is currently the most reliable evaluation method
for natural language generation systems. Automatic metrics have reported flaws
when applied to measure quality aspects of generated text and have been shown
to correlate poorly with human judgements. However, human evaluation is time
and cost-intensive, and we lack consensus on designing and conducting human
evaluation experiments. Thus there is a need for streamlined approaches for
efficient collection of human judgements when evaluating natural language
generation systems. Therefore, we present a dynamic approach to measure the
required number of human annotations when evaluating generated outputs in
relative comparison settings. We propose an agent-based framework of human
evaluation to assess multiple labelling strategies and methods to decide the
better model in a simulation and a crowdsourcing case study. The main results
indicate that a decision about the superior model can be made with high
probability across different labelling strategies, where assigning a single
random worker per task requires the least overall labelling effort and thus the
least cost.",2021-12-15
Controlled Cue Generation for Play Scripts,2021-12-13 19:00:17+00:00,http://arxiv.org/abs/2112.06953v1,"Alara Dirik, Hilal Donmez, Pinar Yanardag","cs.CL, cs.AI, cs.LG",dialogue,"In this paper, we use a large-scale play scripts dataset to propose the novel
task of theatrical cue generation from dialogues. Using over one million lines
of dialogue and cues, we approach the problem of cue generation as a controlled
text generation task, and show how cues can be used to enhance the impact of
dialogue using a language model conditioned on a dialogue/cue discriminator. In
addition, we explore the use of topic keywords and emotions for controlled text
generation. Extensive quantitative and qualitative experiments show that
language models can be successfully used to generate plausible and
attribute-controlled texts in highly specialised domains such as play scripts.
Supporting materials can be found at: https://catlab-team.github.io/cuegen.",2021-12-13
"Representation Learning for Conversational Data using Discourse Mutual
  Information Maximization",2021-12-04 13:17:07+00:00,http://arxiv.org/abs/2112.05787v1,"Bishal Santra, Sumegh Roychowdhury, Aishik Mandal, Vasu Gurram, Atharva Naik, Manish Gupta, Pawan Goyal",cs.CL,dialogue,"Although many pretrained models exist for text or images, there have been
relatively fewer attempts to train representations specifically for dialog
understanding. Prior works usually relied on finetuned representations based on
generic text representation models like BERT or GPT-2. But, existing
pretraining objectives do not take the structural information of text into
consideration. Although generative dialog models can learn structural features
too, we argue that the structure-unaware word-by-word generation is not
suitable for effective conversation modeling. We empirically demonstrate that
such representations do not perform consistently across various dialog
understanding tasks. Hence, we propose a structure-aware Mutual Information
based loss-function DMI (Discourse Mutual Information) for training
dialog-representation models, that additionally captures the inherent
uncertainty in response prediction. Extensive evaluation on nine diverse dialog
modeling tasks shows that our proposed DMI-based models outperform strong
baselines by significant margins, even with small-scale pretraining. Our models
show the most promising performance on the dialog evaluation task
DailyDialog++, in both random and adversarial negative scenarios.",2021-12-04
Realistic simulation of users for IT systems in cyber ranges,2021-11-23 10:53:29+00:00,http://arxiv.org/abs/2111.11785v1,"Alexandre Dey, Benjamin Costé, Éric Totel, Adrien Bécue","cs.AI, cs.CR",dialogue,"Generating user activity is a key capability for both evaluating security
monitoring tools as well as improving the credibility of attacker analysis
platforms (e.g., honeynets). In this paper, to generate this activity, we
instrument each machine by means of an external agent. This agent combines both
deterministic and deep learning based methods to adapt to different environment
(e.g., multiple OS, software versions, etc.), while maintaining high
performances. We also propose conditional text generation models to facilitate
the creation of conversations and documents to accelerate the definition of
coherent, system-wide, life scenarios.",2021-11-23
"MEDCOD: A Medically-Accurate, Emotive, Diverse, and Controllable Dialog
  System",2021-11-17 20:31:16+00:00,http://arxiv.org/abs/2111.09381v1,"Rhys Compton, Ilya Valmianski, Li Deng, Costa Huang, Namit Katariya, Xavier Amatriain, Anitha Kannan","cs.CL, cs.AI, cs.LG",dialogue,"We present MEDCOD, a Medically-Accurate, Emotive, Diverse, and Controllable
Dialog system with a unique approach to the natural language generator module.
MEDCOD has been developed and evaluated specifically for the history taking
task. It integrates the advantage of a traditional modular approach to
incorporate (medical) domain knowledge with modern deep learning techniques to
generate flexible, human-like natural language expressions. Two key aspects of
MEDCOD's natural language output are described in detail. First, the generated
sentences are emotive and empathetic, similar to how a doctor would communicate
to the patient. Second, the generated sentence structures and phrasings are
varied and diverse while maintaining medical consistency with the desired
medical concept (provided by the dialogue manager module of MEDCOD).
Experimental results demonstrate the effectiveness of our approach in creating
a human-like medical dialogue system. Relevant code is available at
https://github.com/curai/curai-research/tree/main/MEDCOD",2021-11-17
A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots,2021-11-02 08:07:55+00:00,http://arxiv.org/abs/2111.01414v1,"Atharv Singh Patlan, Shiven Tripathi, Shubham Korde","cs.CL, cs.AI",dialogue,"In spoken dialogue systems, we aim to deploy artificial intelligence to build
automated dialogue agents that can converse with humans. Dialogue systems are
increasingly being designed to move beyond just imitating conversation and also
improve from such interactions over time. In this survey, we present a broad
overview of methods developed to build dialogue systems over the years.
Different use cases for dialogue systems ranging from task-based systems to
open domain chatbots motivate and necessitate specific systems. Starting from
simple rule-based systems, research has progressed towards increasingly complex
architectures trained on a massive corpus of datasets, like deep learning
systems. Motivated with the intuition of resembling human dialogues, progress
has been made towards incorporating emotions into the natural language
generator, using reinforcement learning. While we see a trend of highly
marginal improvement on some metrics, we find that limited justification exists
for the metrics, and evaluation practices are not uniform. To conclude, we flag
these concerns and highlight possible research directions.",2021-11-02
"Dynamic population-based meta-learning for multi-agent communication
  with natural language",2021-10-27 07:50:02+00:00,http://arxiv.org/abs/2110.14241v1,"Abhinav Gupta, Marc Lanctot, Angeliki Lazaridou","cs.LG, cs.AI, cs.CL, cs.MA",dialogue,"In this work, our goal is to train agents that can coordinate with seen,
unseen as well as human partners in a multi-agent communication environment
involving natural language. Previous work using a single set of agents has
shown great progress in generalizing to known partners, however it struggles
when coordinating with unfamiliar agents. To mitigate that, recent work
explored the use of population-based approaches, where multiple agents interact
with each other with the goal of learning more generic protocols. These
methods, while able to result in good coordination between unseen partners,
still only achieve so in cases of simple languages, thus failing to adapt to
human partners using natural language. We attribute this to the use of static
populations and instead propose a dynamic population-based meta-learning
approach that builds such a population in an iterative manner. We perform a
holistic evaluation of our method on two different referential games, and show
that our agents outperform all prior work when communicating with seen partners
and humans. Furthermore, we analyze the natural language generation skills of
our agents, where we find that our agents also outperform strong baselines.
Finally, we test the robustness of our agents when communicating with
out-of-population agents and carefully test the importance of each component of
our method through ablation studies.",2021-10-27
"FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metricsfor
  Automatic Text Generation",2021-10-16 11:59:48+00:00,http://arxiv.org/abs/2110.08559v1,"Moussa Kamal Eddine, Guokan Shang, Antoine J. -P. Tixier, Michalis Vazirgiannis",cs.CL,dialogue,"Fast and reliable evaluation metrics are key to R&D progress. While
traditional natural language generation metrics are fast, they are not very
reliable. Conversely, new metrics based on large pretrained language models are
much more reliable, but require significant computational resources. In this
paper, we propose FrugalScore, an approach to learn a fixed, low cost version
of any expensive NLG metric, while retaining most of its original performance.
Experiments with BERTScore and MoverScore on summarization and translation show
that FrugalScore is on par with the original metrics (and sometimes better),
while having several orders of magnitude less parameters and running several
times faster. On average over all learned metrics, tasks, and variants,
FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35
times less parameters than the original metrics. We make our trained metrics
publicly available, to benefit the entire NLP community and in particular
researchers and practitioners with limited resources.",2021-10-16
"Hindsight: Posterior-guided training of retrievers for improved
  open-ended generation",2021-10-14 22:24:57+00:00,http://arxiv.org/abs/2110.07752v2,"Ashwin Paranjape, Omar Khattab, Christopher Potts, Matei Zaharia, Christopher D. Manning","cs.CL, cs.IR",dialogue,"Many text generation systems benefit from using a retriever to retrieve
passages from a textual knowledge corpus (e.g., Wikipedia) which are then
provided as additional context to the generator. For open-ended generation
tasks (like generating informative utterances in conversations) many varied
passages may be equally relevant and we find that existing methods that jointly
train the retriever and generator underperform: the retriever may not find
relevant passages even amongst the top-10 and hence the generator may not learn
a preference to ground its generated output in them. We propose using an
additional guide retriever that is allowed to use the target output and ""in
hindsight"" retrieve relevant passages during training. We model the guide
retriever after the posterior distribution Q of passages given the input and
the target output and train it jointly with the standard retriever and the
generator by maximizing the evidence lower bound (ELBo) in expectation over Q.
For informative conversations from the Wizard of Wikipedia dataset, with
posterior-guided training, the retriever finds passages with higher relevance
in the top-10 (23% relative improvement), the generator's responses are more
grounded in the retrieved passage (19% relative improvement) and the end-to-end
system produces better overall output (6.4% relative improvement).",2021-10-14
Federated Natural Language Generation for Personalized Dialogue System,2021-10-13 00:59:52+00:00,http://arxiv.org/abs/2110.06419v1,"Yujie Lu, Chao Huang, Huanli Zhan, Yong Zhuang","cs.CL, cs.AI",dialogue,"Neural conversational models have long suffered from the problem of
inconsistency and lacking coherent personality. To address the issue,
persona-based models capturing individual characteristics have been proposed,
but they still face the dilemma of model adaption and data privacy. To break
this dilemma, we propose a novel Federated Natural Language Generation (FedNLG)
framework, which learns personalized representations from various dataset on
distributed devices, and thus implements the personalized dialogue system
efficiently and safely. FedNLG first pre-trains parameters of standard neural
conversational model over a large dialogue corpus, and then fine-tune the model
parameters and persona embeddings on specific datasets, in a federated manner.
Thus, the model could simultaneously learn the persona embeddings in local
clients and learn shared model parameters by federated aggregation, which
achieves accuracyprivacy balance. By conducting extensive experiments, we
demonstrate the effectiveness of our model by pre-training model over Cornell
Movie-Dialogs Corpus and fine-tuning the model over two TV series dataset.",2021-10-13
"OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset
  with Visual Contexts",2021-09-27 02:10:29+00:00,http://arxiv.org/abs/2109.12761v2,"Shuhe Wang, Yuxian Meng, Xiaoya Li, Xiaofei Sun, Rongbin Ouyang, Jiwei Li",cs.CL,dialogue,"In order to better simulate the real human conversation process, models need
to generate dialogue utterances based on not only preceding textual contexts
but also visual contexts. However, with the development of multi-modal dialogue
learning, the dataset scale gradually becomes a bottleneck. In this report, we
release OpenViDial 2.0, a larger-scale open-domain multi-modal dialogue dataset
compared to the previous version OpenViDial 1.0. OpenViDial 2.0 contains a
total number of 5.6 million dialogue turns extracted from either movies or TV
series from different resources, and each dialogue turn is paired with its
corresponding visual context. We hope this large-scale dataset can help
facilitate future researches on open-domain multi-modal dialog generation,
e.g., multi-modal pretraining for dialogue generation.",2021-09-27
"An animated picture says at least a thousand words: Selecting Gif-based
  Replies in Multimodal Dialog",2021-09-24 21:48:27+00:00,http://arxiv.org/abs/2109.12212v1,"Xingyao Wang, David Jurgens","cs.CL, cs.CV, cs.CY",dialogue,"Online conversations include more than just text. Increasingly, image-based
responses such as memes and animated gifs serve as culturally recognized and
often humorous responses in conversation. However, while NLP has broadened to
multimodal models, conversational dialog systems have largely focused only on
generating text replies. Here, we introduce a new dataset of 1.56M text-gif
conversation turns and introduce a new multimodal conversational model Pepe the
King Prawn for selecting gif-based replies. We demonstrate that our model
produces relevant and high-quality gif responses and, in a large randomized
control trial of multiple models replying to real users, we show that our model
replies with gifs that are significantly better received by the community.",2021-09-24
Style Control for Schema-Guided Natural Language Generation,2021-09-24 21:47:58+00:00,http://arxiv.org/abs/2109.12211v1,"Alicia Y. Tsai, Shereen Oraby, Vittorio Perera, Jiun-Yu Kao, Yuheng Du, Anjali Narayan-Chen, Tagyoung Chung, Dilek Hakkani-Tur",cs.CL,dialogue,"Natural Language Generation (NLG) for task-oriented dialogue systems focuses
on communicating specific content accurately, fluently, and coherently. While
these attributes are crucial for a successful dialogue, it is also desirable to
simultaneously accomplish specific stylistic goals, such as response length,
point-of-view, descriptiveness, sentiment, formality, and empathy. In this
work, we focus on stylistic control and evaluation for schema-guided NLG, with
joint goals of achieving both semantic and stylistic control. We experiment in
detail with various controlled generation methods for large pretrained language
models: specifically, conditional training, guided fine-tuning, and guided
decoding. We discuss their advantages and limitations, and evaluate them with a
broad range of automatic and human evaluation metrics. Our results show that
while high style accuracy and semantic correctness are easier to achieve for
more lexically-defined styles with conditional training, stylistic control is
also achievable for more semantically complex styles using discriminator-based
guided decoding methods. The results also suggest that methods that are more
scalable (with less hyper-parameters tuning) and that disentangle content
generation and stylistic variations are more effective at achieving semantic
correctness and style accuracy.",2021-09-24
"Controllable Dialogue Generation with Disentangled Multi-grained Style
  Specification and Attribute Consistency Reward",2021-09-14 14:29:38+00:00,http://arxiv.org/abs/2109.06717v1,"Zhe Hu, Zhiwei Cao, Hou Pong Chan, Jiachen Liu, Xinyan Xiao, Jinsong Su, Hua Wu","cs.CL, cs.AI",dialogue,"Controllable text generation is an appealing but challenging task, which
allows users to specify particular attributes of the generated outputs. In this
paper, we propose a controllable dialogue generation model to steer response
generation under multi-attribute constraints. Specifically, we define and
categorize the commonly used control attributes into global and local ones,
which possess different granularities of effects on response generation. Then,
we significantly extend the conventional seq2seq framework by introducing a
novel two-stage decoder, which first uses a multi-grained style specification
layer to impose the stylistic constraints and determine word-level control
states of responses based on the attributes, and then employs a response
generation layer to generate final responses maintaining both semantic
relevancy to the contexts and fidelity to the attributes. Furthermore, we train
our model with an attribute consistency reward to promote response control with
explicit supervision signals. Extensive experiments and in-depth analyses on
two datasets indicate that our model can significantly outperform competitive
baselines in terms of response quality, content diversity and controllability.",2021-09-14
"End-to-End Conversational Search for Online Shopping with Utterance
  Transfer",2021-09-12 08:33:44+00:00,http://arxiv.org/abs/2109.05460v1,"Liqiang Xiao, Jun Ma2, Xin Luna Dong, Pascual Martinez-Gomez, Nasser Zalmout, Wei Chen, Tong Zhao, Hao He, Yaohui Jin","cs.CL, cs.AI",dialogue,"Successful conversational search systems can present natural, adaptive and
interactive shopping experience for online shopping customers. However,
building such systems from scratch faces real word challenges from both
imperfect product schema/knowledge and lack of training dialog data.In this
work we first propose ConvSearch, an end-to-end conversational search system
that deeply combines the dialog system with search. It leverages the text
profile to retrieve products, which is more robust against imperfect product
schema/knowledge compared with using product attributes alone. We then address
the lack of data challenges by proposing an utterance transfer approach that
generates dialogue utterances by using existing dialog from other domains, and
leveraging the search behavior data from e-commerce retailer. With utterance
transfer, we introduce a new conversational search dataset for online shopping.
Experiments show that our utterance transfer method can significantly improve
the availability of training dialogue data without crowd-sourcing, and the
conversational search system significantly outperformed the best tested
baseline.",2021-09-12
Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration,2021-09-12 04:17:53+00:00,http://arxiv.org/abs/2109.05426v1,"Chuanxin Tang, Chong Luo, Zhiyuan Zhao, Dacheng Yin, Yucheng Zhao, Wenjun Zeng","cs.SD, cs.AI, eess.AS",dialogue,"Given a piece of speech and its transcript text, text-based speech editing
aims to generate speech that can be seamlessly inserted into the given speech
by editing the transcript. Existing methods adopt a two-stage approach:
synthesize the input text using a generic text-to-speech (TTS) engine and then
transform the voice to the desired voice using voice conversion (VC). A major
problem of this framework is that VC is a challenging problem which usually
needs a moderate amount of parallel training data to work satisfactorily. In
this paper, we propose a one-stage context-aware framework to generate natural
and coherent target speech without any training data of the target speaker. In
particular, we manage to perform accurate zero-shot duration prediction for the
inserted text. The predicted duration is used to regulate both text embedding
and speech embedding. Then, based on the aligned cross-modality input, we
directly generate the mel-spectrogram of the edited speech with a
transformer-based decoder. Subjective listening tests show that despite the
lack of training data for the speaker, our method has achieved satisfactory
results. It outperforms a recent zero-shot TTS engine by a large margin.",2021-09-12
Refocusing on Relevance: Personalization in NLG,2021-09-10 23:50:02+00:00,http://arxiv.org/abs/2109.05140v1,"Shiran Dudy, Steven Bedrick, Bonnie Webber","cs.CL, cs.CY, cs.HC",dialogue,"Many NLG tasks such as summarization, dialogue response, or open domain
question answering focus primarily on a source text in order to generate a
target response. This standard approach falls short, however, when a user's
intent or context of work is not easily recoverable based solely on that source
text -- a scenario that we argue is more of the rule than the exception. In
this work, we argue that NLG systems in general should place a much higher
level of emphasis on making use of additional context, and suggest that
relevance (as used in Information Retrieval) be thought of as a crucial tool
for designing user-oriented text-generating tasks. We further discuss possible
harms and hazards around such personalization, and argue that value-sensitive
design represents a crucial path forward through these challenges.",2021-09-10
"Generating Self-Contained and Summary-Centric Question Answer Pairs via
  Differentiable Reward Imitation Learning",2021-09-10 06:34:55+00:00,http://arxiv.org/abs/2109.04689v1,"Li Zhou, Kevin Small, Yong Zhang, Sandeep Atluri","cs.CL, cs.AI, cs.LG",dialogue,"Motivated by suggested question generation in conversational news
recommendation systems, we propose a model for generating question-answer pairs
(QA pairs) with self-contained, summary-centric questions and
length-constrained, article-summarizing answers. We begin by collecting a new
dataset of news articles with questions as titles and pairing them with
summaries of varying length. This dataset is used to learn a QA pair generation
model producing summaries as answers that balance brevity with sufficiency
jointly with their corresponding questions. We then reinforce the QA pair
generation process with a differentiable reward function to mitigate exposure
bias, a common problem in natural language generation. Both automatic metrics
and human evaluation demonstrate these QA pairs successfully capture the
central gists of the articles and achieve high answer accuracy.",2021-09-10
"Hi, my name is Martha: Using names to measure and mitigate bias in
  generative dialogue models",2021-09-07 19:20:24+00:00,http://arxiv.org/abs/2109.03300v1,"Eric Michael Smith, Adina Williams",cs.CL,dialogue,"All AI models are susceptible to learning biases in data that they are
trained on. For generative dialogue models, being trained on real human
conversations containing unbalanced gender and race/ethnicity references can
lead to models that display learned biases, which we define here broadly as any
measurable differences in the distributions of words or semantic content of
conversations based on demographic groups. We measure the strength of such
biases by producing artificial conversations between two copies of a dialogue
model, conditioning one conversational partner to state a name commonly
associated with a certain gender and/or race/ethnicity. We find that larger
capacity models tend to exhibit more gender bias and greater stereotyping of
occupations by gender. We show that several methods of tuning these dialogue
models, specifically name scrambling, controlled generation, and unlikelihood
training, are effective in reducing bias in conversation, including on a
downstream conversational task. Name scrambling is also effective in lowering
differences in token usage across conversations where partners have names
associated with different genders or races/ethnicities.",2021-09-07
"Naturalness Evaluation of Natural Language Generation in Task-oriented
  Dialogues using BERT",2021-09-07 08:40:14+00:00,http://arxiv.org/abs/2109.02938v1,"Ye Liu, Wolfgang Maier, Wolfgang Minker, Stefan Ultes","cs.CL, cs.AI",dialogue,"This paper presents an automatic method to evaluate the naturalness of
natural language generation in dialogue systems. While this task was previously
rendered through expensive and time-consuming human labor, we present this
novel task of automatic naturalness evaluation of generated language. By
fine-tuning the BERT model, our proposed naturalness evaluation method shows
robust results and outperforms the baselines: support vector machines,
bi-directional LSTMs, and BLEURT. In addition, the training speed and
evaluation performance of naturalness model are improved by transfer learning
from quality and informativeness linguistic knowledge.",2021-09-07
"SideControl: Controlled Open-domain Dialogue Generation via Additive
  Side Networks",2021-09-05 01:15:26+00:00,http://arxiv.org/abs/2109.01958v1,"Wanyu Du, Yangfeng Ji",cs.CL,dialogue,"Transformer-based pre-trained language models boost the performance of
open-domain dialogue systems. Prior works leverage Transformer-based
pre-trained language models to generate texts with desired attributes in two
general approaches: (1) gradient-based methods: updating all latent
representations of pre-trained models with gradients from attribute models; (2)
weighted-decoding methods: re-ranking beam candidates from pre-trained models
with attribute functions. However, gradient-based methods lead to high
computation cost and can easily get overfitted on small training sets, while
weighted-decoding methods are inherently constrained by the low-variance
high-bias pre-trained model. In this work, we propose a novel approach to
control the generation of Transformer-based pre-trained language models: the
SideControl framework, which leverages a novel control attributes loss to
incorporate useful control signals, and is shown to perform well with very
limited training samples. We evaluate our proposed method on two benchmark
open-domain dialogue datasets, and results show that the SideControl framework
has better controllability, higher generation quality and better
sample-efficiency than existing gradient-based and weighted-decoding baselines.",2021-09-05
Task-Oriented Dialogue System as Natural Language Generation,2021-08-31 08:36:42+00:00,http://arxiv.org/abs/2108.13679v2,"Weizhi Wang, Zhirui Zhang, Junliang Guo, Yinpei Dai, Boxing Chen, Weihua Luo","cs.CL, cs.AI",dialogue,"In this paper, we propose to formulate the task-oriented dialogue system as
the purely natural language generation task, so as to fully leverage the
large-scale pre-trained models like GPT-2 and simplify complicated
delexicalization prepossessing. However, directly applying this method heavily
suffers from the dialogue entity inconsistency caused by the removal of
delexicalized tokens, as well as the catastrophic forgetting problem of the
pre-trained model during fine-tuning, leading to unsatisfactory performance. To
alleviate these problems, we design a novel GPT-Adapter-CopyNet network, which
incorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve
better performance on transfer learning and dialogue entity generation.
Experimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ
dataset demonstrate that our proposed approach significantly outperforms
baseline models with a remarkable performance on automatic and human
evaluations.",2021-08-31
Semantic-based Self-Critical Training For Question Generation,2021-08-26 20:33:35+00:00,http://arxiv.org/abs/2108.12026v1,"Loïc, Kwate Dassi","cs.CL, cs.AI",dialogue,"We present in this work a fully Transformer-based reinforcement learning
generator-evaluator architecture for neural question generation. Question
generation is a task that consists in generating questions given a context and
answer. To improve the quality of the generated question, we came up with a
semantic-based self-critical training layout in generator-evaluator
architecture, which goes beyond typical maximum likelihood training. Evaluation
metrics for language modeling only based on n-gram overlapping do not consider
semantic relations between reference and candidate strings. To improve the
evaluation step, we assess our model for both n-gram overlap using BLEU and
semantically using BERTScore and NUBIA, a novel state-of-the-art evaluation
metric for text generation. Question generation could be used in many
downstream applications, including in extending question answering datasets,
conversational systems, and educational assessment systems.",2021-08-26
"Just Say No: Analyzing the Stance of Neural Dialogue Generation in
  Offensive Contexts",2021-08-26 14:58:05+00:00,http://arxiv.org/abs/2108.11830v1,"Ashutosh Baheti, Maarten Sap, Alan Ritter, Mark Riedl",cs.CL,dialogue,"Dialogue models trained on human conversations inadvertently learn to
generate offensive responses. Moreover, models can insult anyone by agreeing
with an offensive context. To understand the dynamics of contextually offensive
language, we study the stance of dialogue model responses in offensive Reddit
conversations. Specifically, we crowd-annotate ToxiChat, a new dataset of 2,000
Reddit threads and model responses labeled with offensive language and stance.
Our analysis reveals that 42% of user responses agree with toxic comments; 3x
their agreement with safe comments (13%). Pre-trained transformer-based
classifiers fine-tuned on our dataset achieve 0.71 F1 for offensive labels and
0.53 Macro-F1 for stance labels. Finally, we analyze some existing controllable
text generation (CTG) methods to mitigate the contextual offensive behavior of
dialogue models. Compared to the baseline, our best CTG model obtains a 19%
reduction in agreement with offensive context and 29% fewer offensive
responses. This highlights the need for future work to characterize and analyze
more forms of inappropriate behavior in dialogue models to help make them
safer. Our code and corpus are available at
https://github.com/abaheti95/ToxiChat .",2021-08-26
Viola: A Topic Agnostic Generate-and-Rank Dialogue System,2021-08-25 06:20:34+00:00,http://arxiv.org/abs/2108.11063v1,"Hyundong Cho, Basel Shbita, Kartik Shenoy, Shuai Liu, Nikhil Patel, Hitesh Pindikanti, Jennifer Lee, Jonathan May",cs.CL,dialogue,"We present Viola, an open-domain dialogue system for spoken conversation that
uses a topic-agnostic dialogue manager based on a simple generate-and-rank
approach. Leveraging recent advances of generative dialogue systems powered by
large language models, Viola fetches a batch of response candidates from
various neural dialogue models trained with different datasets and
knowledge-grounding inputs. Additional responses originating from
template-based generators are also considered, depending on the user's input
and detected entities. The hand-crafted generators build on a dynamic knowledge
graph injected with rich content that is crawled from the web and automatically
processed on a daily basis. Viola's response ranker is a fine-tuned polyencoder
that chooses the best response given the dialogue history. While dedicated
annotations for the polyencoder alone can indirectly steer it away from
choosing problematic responses, we add rule-based safety nets to detect neural
degeneration and a dedicated classifier to filter out offensive content. We
analyze conversations that Viola took part in for the Alexa Prize Socialbot
Grand Challenge 4 and discuss the strengths and weaknesses of our approach.
Lastly, we suggest future work with a focus on curating conversation data
specifcially for socialbots that will contribute towards a more robust
data-driven socialbot.",2021-08-25
"Using BERT Encoding and Sentence-Level Language Model for Sentence
  Ordering",2021-08-24 23:03:36+00:00,http://arxiv.org/abs/2108.10986v1,"Melika Golestani, Seyedeh Zahra Razavi, Zeinab Borhanifard, Farnaz Tahmasebian, Hesham Faili",cs.CL,dialogue,"Discovering the logical sequence of events is one of the cornerstones in
Natural Language Understanding. One approach to learn the sequence of events is
to study the order of sentences in a coherent text. Sentence ordering can be
applied in various tasks such as retrieval-based Question Answering, document
summarization, storytelling, text generation, and dialogue systems.
Furthermore, we can learn to model text coherence by learning how to order a
set of shuffled sentences. Previous research has relied on RNN, LSTM, and
BiLSTM architecture for learning text language models. However, these networks
have performed poorly due to the lack of attention mechanisms. We propose an
algorithm for sentence ordering in a corpus of short stories. Our proposed
method uses a language model based on Universal Transformers (UT) that captures
sentences' dependencies by employing an attention mechanism. Our method
improves the previous state-of-the-art in terms of Perfect Match Ratio (PMR)
score in the ROCStories dataset, a corpus of nearly 100K short human-made
stories. The proposed model includes three components: Sentence Encoder,
Language Model, and Sentence Arrangement with Brute Force Search. The first
component generates sentence embeddings using SBERT-WK pre-trained model
fine-tuned on the ROCStories data. Then a Universal Transformer network
generates a sentence-level language model. For decoding, the network generates
a candidate sentence as the following sentence of the current sentence. We use
cosine similarity as a scoring function to assign scores to the candidate
embedding and the embeddings of other sentences in the shuffled set. Then a
Brute Force Search is employed to maximize the sum of similarities between
pairs of consecutive sentences.",2021-08-24
Taming the Beast: Learning to Control Neural Conversational Models,2021-08-24 07:58:16+00:00,http://arxiv.org/abs/2108.10561v1,Andrea Madotto,"cs.CL, cs.AI, cs.LG",dialogue,"This thesis investigates the controllability of deep learning-based,
end-to-end, generative dialogue systems in both task-oriented and chit-chat
scenarios. In particular, we study the different aspects of controlling
generative dialogue systems, including controlling styles and topics and
continuously adding and combining dialogue skills. In the three decades since
the first dialogue system was commercialized, the basic architecture of such
systems has remained substantially unchanged, consisting of four pipelined
basic components, namely, natural language understanding (NLU), dialogue state
tracking (DST), a dialogue manager (DM) and natural language generation (NLG).
The dialogue manager, which is the critical component of the modularized
system, controls the response content and style. This module is usually
programmed by rules and is designed to be highly controllable and easily
extendable. With the emergence of powerful ""deep learning"" architectures,
end-to-end generative dialogue systems have been proposed to optimize overall
system performance and simplify training. However, these systems cannot be
easily controlled and extended as the modularized dialogue manager can. This is
because a single neural system is used, which is usually a large pre-trained
language model (e.g., GPT-2), and thus it is hard to surgically change
desirable attributes (e.g., style, topics, etc.). More importantly,
uncontrollable dialogue systems can generate offensive and even toxic
responses. Therefore, in this thesis, we study controllable methods for
end-to-end generative dialogue systems in task-oriented and chit-chat
scenarios. Throughout the chapters, we describe 1) how to control the style and
topics of chit-chat models, 2) how to continuously control and extend
task-oriented dialogue systems, and 3) how to compose and control multi-skill
dialogue models.",2021-08-24
CGEMs: A Metric Model for Automatic Code Generation using GPT-3,2021-08-23 13:28:57+00:00,http://arxiv.org/abs/2108.10168v1,"Aishwarya Narasimhan, Krishna Prasad Agara Venkatesha Rao, Veena M B",cs.AI,dialogue,"Today, AI technology is showing its strengths in almost every industry and
walks of life. From text generation, text summarization, chatbots, NLP is being
used widely. One such paradigm is automatic code generation. An AI could be
generating anything; hence the output space is unconstrained. A self-driving
car is driven for 100 million miles to validate its safety, but tests cannot be
written to monitor and cover an unconstrained space. One of the solutions to
validate AI-generated content is to constrain the problem and convert it from
abstract to realistic, and this can be accomplished by either validating the
unconstrained algorithm using theoretical proofs or by using Monte-Carlo
simulation methods. In this case, we use the latter approach to test/validate a
statistically significant number of samples. This hypothesis of validating the
AI-generated code is the main motive of this work and to know if AI-generated
code is reliable, a metric model CGEMs is proposed. This is an extremely
challenging task as programs can have different logic with different naming
conventions, but the metrics must capture the structure and logic of the
program. This is similar to the importance grammar carries in AI-based text
generation, Q&A, translations, etc. The various metrics that are garnered in
this work to support the evaluation of generated code are as follows:
Compilation, NL description to logic conversion, number of edits needed, some
of the commonly used static-code metrics and NLP metrics. These metrics are
applied to 80 codes generated using OpenAI's GPT-3. Post which a Neural network
is designed for binary classification (acceptable/not acceptable quality of the
generated code). The inputs to this network are the values of the features
obtained from the metrics. The model achieves a classification accuracy of
76.92% and an F1 score of 55.56%. XAI is augmented for model interpretability.",2021-08-23
"A Neural Conversation Generation Model via Equivalent Shared Memory
  Investigation",2021-08-20 13:20:14+00:00,http://arxiv.org/abs/2108.09164v1,"Changzhen Ji, Yating Zhang, Xiaozhong Liu, Adam Jatowt, Changlong Sun, Conghui Zhu, Tiejun Zhao",cs.CL,dialogue,"Conversation generation as a challenging task in Natural Language Generation
(NLG) has been increasingly attracting attention over the last years. A number
of recent works adopted sequence-to-sequence structures along with external
knowledge, which successfully enhanced the quality of generated conversations.
Nevertheless, few works utilized the knowledge extracted from similar
conversations for utterance generation. Taking conversations in customer
service and court debate domains as examples, it is evident that essential
entities/phrases, as well as their associated logic and inter-relationships can
be extracted and borrowed from similar conversation instances. Such information
could provide useful signals for improving conversation generation. In this
paper, we propose a novel reading and memory framework called Deep Reading
Memory Network (DRMN) which is capable of remembering useful information of
similar conversations for improving utterance generation. We apply our model to
two large-scale conversation datasets of justice and e-commerce fields.
Experiments prove that the proposed model outperforms the state-of-the-art
approaches.",2021-08-20
Sentence Semantic Regression for Text Generation,2021-08-06 07:35:59+00:00,http://arxiv.org/abs/2108.02984v1,"Wei Wang, Piji Li, Hai-Tao Zheng",cs.CL,dialogue,"Recall the classical text generation works, the generation framework can be
briefly divided into two phases: \textbf{idea reasoning} and \textbf{surface
realization}. The target of idea reasoning is to figure out the main idea which
will be presented in the following talking/writing periods. Surface realization
aims to arrange the most appropriate sentence to depict and convey the
information distilled from the main idea. However, the current popular
token-by-token text generation methods ignore this crucial process and suffer
from many serious issues, such as idea/topic drift. To tackle the problems and
realize this two-phase paradigm, we propose a new framework named Sentence
Semantic Regression (\textbf{SSR}) based on sentence-level language modeling.
For idea reasoning, two architectures \textbf{SSR-AR} and \textbf{SSR-NonAR}
are designed to conduct sentence semantic regression autoregressively (like
GPT2/3) and bidirectionally (like BERT). In the phase of surface realization, a
mixed-granularity sentence decoder is designed to generate text with better
consistency by jointly incorporating the predicted sentence-level main idea as
well as the preceding contextual token-level information. We conduct
experiments on four tasks of story ending prediction, story ending generation,
dialogue generation, and sentence infilling. The results show that SSR can
obtain better performance in terms of automatic metrics and human evaluation.",2021-08-06
Internet-Augmented Dialogue Generation,2021-07-15 19:00:35+00:00,http://arxiv.org/abs/2107.07566v1,"Mojtaba Komeili, Kurt Shuster, Jason Weston","cs.AI, cs.CL",dialogue,"The largest store of continually updating knowledge on our planet can be
accessed via internet search. In this work we study giving access to this
information to conversational agents. Large language models, even though they
store an impressive amount of knowledge within their weights, are known to
hallucinate facts when generating dialogue (Shuster et al., 2021); moreover,
those facts are frozen in time at the point of model training. In contrast, we
propose an approach that learns to generate an internet search query based on
the context, and then conditions on the search results to finally generate a
response, a method that can employ up-to-the-minute relevant information. We
train and evaluate such models on a newly collected dataset of human-human
conversations whereby one of the speakers is given access to internet search
during knowledgedriven discussions in order to ground their responses. We find
that search-query based access of the internet in conversation provides
superior performance compared to existing approaches that either use no
augmentation or FAISS-based retrieval (Lewis et al., 2020).",2021-07-15
A Survey on Dialogue Summarization: Recent Advances and New Frontiers,2021-07-07 12:11:14+00:00,http://arxiv.org/abs/2107.03175v1,"Xiachong Feng, Xiaocheng Feng, Bing Qin",cs.CL,dialogue,"With the development of dialogue systems and natural language generation
techniques, the resurgence of dialogue summarization has attracted significant
research attentions, which aims to condense the original dialogue into a
shorter version covering salient information. However, there remains a lack of
comprehensive survey for this task. To this end, we take the first step and
present a thorough review of this research field. In detail, we provide an
overview of publicly available research datasets, summarize existing works
according to the domain of input dialogue as well as organize leaderboards
under unified metrics. Furthermore, we discuss some future directions and give
our thoughts. We hope that this first survey of dialogue summarization can
provide the community with a quick access and a general picture to this task
and motivate future researches.",2021-07-07
"Do Encoder Representations of Generative Dialogue Models Encode
  Sufficient Information about the Task ?",2021-06-20 04:52:37+00:00,http://arxiv.org/abs/2106.10622v1,"Prasanna Parthasarathi, Joelle Pineau, Sarath Chandar",cs.CL,dialogue,"Predicting the next utterance in dialogue is contingent on encoding of users'
input text to generate appropriate and relevant response in data-driven
approaches. Although the semantic and syntactic quality of the language
generated is evaluated, more often than not, the encoded representation of
input is not evaluated. As the representation of the encoder is essential for
predicting the appropriate response, evaluation of encoder representation is a
challenging yet important problem. In this work, we showcase evaluating the
text generated through human or automatic metrics is not sufficient to
appropriately evaluate soundness of the language understanding of dialogue
models and, to that end, propose a set of probe tasks to evaluate encoder
representation of different language encoders commonly used in dialogue models.
From experiments, we observe that some of the probe tasks are easier and some
are harder for even sophisticated model architectures to learn. And, through
experiments we observe that RNN based architectures have lower performance on
automatic metrics on text generation than transformer model but perform better
than the transformer model on the probe tasks indicating that RNNs might
preserve task information better than the Transformers.",2021-06-20
Local Explanation of Dialogue Response Generation,2021-06-11 17:58:36+00:00,http://arxiv.org/abs/2106.06528v1,"Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, William Yang Wang","cs.CL, stat.ML",dialogue,"In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose anew method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.",2021-06-11
"AUGNLG: Few-shot Natural Language Generation using Self-trained Data
  Augmentation",2021-06-10 08:45:28+00:00,http://arxiv.org/abs/2106.05589v1,"Xinnuo Xu, Guoyin Wang, Young-Bum Kim, Sungjin Lee",cs.CL,dialogue,"Natural Language Generation (NLG) is a key component in a task-oriented
dialogue system, which converts the structured meaning representation (MR) to
the natural language. For large-scale conversational systems, where it is
common to have over hundreds of intents and thousands of slots, neither
template-based approaches nor model-based approaches are scalable. Recently,
neural NLGs started leveraging transfer learning and showed promising results
in few-shot settings. This paper proposes AUGNLG, a novel data augmentation
approach that combines a self-trained neural retrieval model with a few-shot
learned NLU model, to automatically create MR-to-Text data from open-domain
texts. The proposed system mostly outperforms the state-of-the-art methods on
the FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm
improved results on the FewShotSGD data and provide comprehensive analysis
results on key components of our system. Our code and data are available at
https://github.com/XinnuoXu/AugNLG.",2021-06-10
Defending against Backdoor Attacks in Natural Language Generation,2021-06-03 13:00:28+00:00,http://arxiv.org/abs/2106.01810v1,"Chun Fan, Xiaoya Li, Yuxian Meng, Xiaofei Sun, Xiang Ao, Fei Wu, Jiwei Li, Tianwei Zhang",cs.CL,dialogue,"The frustratingly fragile nature of neural network models make current
natural language generation (NLG) systems prone to backdoor attacks and
generate malicious sequences that could be sexist or offensive. Unfortunately,
little effort has been invested to how backdoor attacks can affect current NLG
models and how to defend against these attacks. In this work, we investigate
this problem on two important NLG tasks, machine translation and dialogue
generation. By giving a formal definition for backdoor attack and defense, and
developing corresponding benchmarks, we design methods to attack NLG models,
which achieve high attack success to ask NLG models to generate malicious
sequences. To defend against these attacks, we propose to detect the attack
trigger by examining the effect of deleting or replacing certain words on the
generation outputs, which we find successful for certain types of attacks. We
will discuss the limitation of this work, and hope this work can raise the
awareness of backdoor risks concealed in deep NLG systems. (Code and data are
available at https://github.com/ShannonAI/backdoor_nlg.)",2021-06-03
"Generate, Prune, Select: A Pipeline for Counterspeech Generation against
  Online Hate Speech",2021-06-03 06:54:03+00:00,http://arxiv.org/abs/2106.01625v1,"Wanzheng Zhu, Suma Bhat",cs.CL,dialogue,"Countermeasures to effectively fight the ever increasing hate speech online
without blocking freedom of speech is of great social interest. Natural
Language Generation (NLG), is uniquely capable of developing scalable
solutions. However, off-the-shelf NLG methods are primarily
sequence-to-sequence neural models and they are limited in that they generate
commonplace, repetitive and safe responses regardless of the hate speech (e.g.,
""Please refrain from using such language."") or irrelevant responses, making
them ineffective for de-escalating hateful conversations. In this paper, we
design a three-module pipeline approach to effectively improve the diversity
and relevance. Our proposed pipeline first generates various counterspeech
candidates by a generative model to promote diversity, then filters the
ungrammatical ones using a BERT model, and finally selects the most relevant
counterspeech response using a novel retrieval-based method. Extensive
Experiments on three representative datasets demonstrate the efficacy of our
approach in generating diverse and relevant counterspeech.",2021-06-03
"Detecting Bot-Generated Text by Characterizing Linguistic Accommodation
  in Human-Bot Interactions",2021-06-02 14:10:28+00:00,http://arxiv.org/abs/2106.01170v1,"Paras Bhatt, Anthony Rios",cs.CL,dialogue,"Language generation models' democratization benefits many domains, from
answering health-related questions to enhancing education by providing
AI-driven tutoring services. However, language generation models'
democratization also makes it easier to generate human-like text at-scale for
nefarious activities, from spreading misinformation to targeting specific
groups with hate speech. Thus, it is essential to understand how people
interact with bots and develop methods to detect bot-generated text. This paper
shows that bot-generated text detection methods are more robust across datasets
and models if we use information about how people respond to it rather than
using the bot's text directly. We also analyze linguistic alignment, providing
insight into differences between human-human and human-bot conversations.",2021-06-02
"NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based
  Simulation",2021-05-30 07:54:54+00:00,http://arxiv.org/abs/2105.14454v1,"Sungdong Kim, Minsuk Chang, Sang-Woo Lee",cs.CL,dialogue,"We propose NeuralWOZ, a novel dialogue collection framework that uses
model-based dialogue simulation. NeuralWOZ has two pipelined models, Collector
and Labeler. Collector generates dialogues from (1) user's goal instructions,
which are the user context and task constraints in natural language, and (2)
system's API call results, which is a list of possible query responses for user
requests from the given knowledge base. Labeler annotates the generated
dialogue by formulating the annotation as a multiple-choice problem, in which
the candidate labels are extracted from goal instructions and API call results.
We demonstrate the effectiveness of the proposed method in the zero-shot domain
transfer learning for dialogue state tracking. In the evaluation, the synthetic
dialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with
improvements of 4.4% point joint goal accuracy on average across domains, and
improvements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1
dataset.",2021-05-30
