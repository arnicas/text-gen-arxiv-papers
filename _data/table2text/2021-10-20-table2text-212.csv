title,pubdate,id,authors,categories,search,abstract,displaydate
"An Open Natural Language Processing Development Framework for EHR-based
  Clinical Research: A case demonstration using the National COVID Cohort
  Collaborative (N3C)",2021-10-20 21:09:41+00:00,http://arxiv.org/abs/2110.10780v1,"Sijia Liu, Andrew Wen, Liwei Wang, Huan He, Sunyang Fu, Robert Miller, Andrew Williams, Daniel Harris, Ramakanth Kavuluru, Mei Liu, Noor Abu-el-rub, Rui Zhang, John D. Osborne, Masoud Rouhizadeh, Yongqun He, Emily Pfaff, Christopher G. Chute, Tim Duong, Melissa A. Haendel, Rafael Fuentes, Peter Szolovits, Hua Xu, Hongfang Liu","cs.CL, cs.IR",table2text,"While we pay attention to the latest advances in clinical natural language
processing (NLP), we can notice some resistance in the clinical and
translational research community to adopt NLP models due to limited
transparency, Interpretability and usability. Built upon our previous work, in
this study, we proposed an open natural language processing development
framework and evaluated it through the implementation of NLP algorithms for the
National COVID Cohort Collaborative (N3C). Based on the interests in
information extraction from COVID-19 related clinical notes, our work includes
1) an open data annotation process using COVID-19 signs and symptoms as the use
case, 2) a community-driven ruleset composing platform, and 3) a synthetic text
data generation workflow to generate texts for information extraction tasks
without involving human subjects. The generated corpora derived out of the
texts from multiple intuitions and gold standard annotation are tested on a
single institution's rule set has the performances in F1 score of 0.876, 0.706
and 0.694, respectively. The study as a consortium effort of the N3C NLP
subgroup demonstrates the feasibility of creating a federated NLP algorithm
development and benchmarking platform to enhance multi-institution clinical NLP
study.",2021-10-20
SciXGen: A Scientific Paper Dataset for Context-Aware Text Generation,2021-10-20 20:37:11+00:00,http://arxiv.org/abs/2110.10774v1,"Hong Chen, Hiroya Takamura, Hideki Nakayama",cs.CL,table2text,"Generating texts in scientific papers requires not only capturing the content
contained within the given input but also frequently acquiring the external
information called \textit{context}. We push forward the scientific text
generation by proposing a new task, namely \textbf{context-aware text
generation} in the scientific domain, aiming at exploiting the contributions of
context in generated texts. To this end, we present a novel challenging
large-scale \textbf{Sci}entific Paper Dataset for Conte\textbf{X}t-Aware Text
\textbf{Gen}eration (SciXGen), consisting of well-annotated 205,304 papers with
full references to widely-used objects (e.g., tables, figures, algorithms) in a
paper. We comprehensively benchmark, using state-of-the-arts, the efficacy of
our newly constructed SciXGen dataset in generating description and paragraph.
Our dataset and benchmarks will be made publicly available to hopefully
facilitate the scientific text generation research.",2021-10-20
Privacy in Open Search: A Review of Challenges and Solutions,2021-10-20 18:38:48+00:00,http://arxiv.org/abs/2110.10720v1,"Samuel Sousa, Roman Kern, Christian Guetl","cs.CR, cs.AI, cs.IR",table2text,"Privacy is of worldwide concern regarding activities and processes that
include sensitive data. For this reason, many countries and territories have
been recently approving regulations controlling the extent to which
organizations may exploit data provided by people. Artificial intelligence
areas, such as machine learning and natural language processing, have already
successfully employed privacy-preserving mechanisms in order to safeguard data
privacy in a vast number of applications. Information retrieval (IR) is
likewise prone to privacy threats, such as attacks and unintended disclosures
of documents and search history, which may cripple the security of users and be
penalized by data protection laws. This work aims at highlighting and
discussing open challenges for privacy in the recent literature of IR, focusing
on tasks featuring user-generated text data. Our contribution is threefold:
firstly, we present an overview of privacy threats to IR tasks; secondly, we
discuss applicable privacy-preserving mechanisms which may be employed in
solutions to restrain privacy hazards; finally, we bring insights on the
tradeoffs between privacy preservation and utility performance for IR tasks.",2021-10-20
"Permutation invariant graph-to-sequence model for template-free
  retrosynthesis and reaction prediction",2021-10-19 01:23:15+00:00,http://arxiv.org/abs/2110.09681v1,"Zhengkai Tu, Connor W. Coley",cs.LG,table2text,"Synthesis planning and reaction outcome prediction are two fundamental
problems in computer-aided organic chemistry for which a variety of data-driven
approaches have emerged. Natural language approaches that model each problem as
a SMILES-to-SMILES translation lead to a simple end-to-end formulation, reduce
the need for data preprocessing, and enable the use of well-optimized machine
translation model architectures. However, SMILES representations are not an
efficient representation for capturing information about molecular structures,
as evidenced by the success of SMILES augmentation to boost empirical
performance. Here, we describe a novel Graph2SMILES model that combines the
power of Transformer models for text generation with the permutation invariance
of molecular graph encoders that mitigates the need for input data
augmentation. As an end-to-end architecture, Graph2SMILES can be used as a
drop-in replacement for the Transformer in any task involving
molecule(s)-to-molecule(s) transformations. In our encoder, an
attention-augmented directed message passing neural network (D-MPNN) captures
local chemical environments, and the global attention encoder allows for
long-range and intermolecular interactions, enhanced by graph-aware positional
embedding. Graph2SMILES improves the top-1 accuracy of the Transformer
baselines by $1.7\%$ and $1.9\%$ for reaction outcome prediction on USPTO_480k
and USPTO_STEREO datasets respectively, and by $9.8\%$ for one-step
retrosynthesis on the USPTO_50k dataset.",2021-10-19
"Improving Compositional Generalization with Self-Training for
  Data-to-Text Generation",2021-10-16 04:26:56+00:00,http://arxiv.org/abs/2110.08467v1,"Sanket Vaibhav Mehta, Jinfeng Rao, Yi Tay, Mihir Kale, Ankur Parikh, Hongtao Zhong, Emma Strubell","cs.CL, cs.AI",table2text,"Data-to-text generation focuses on generating fluent natural language
responses from structured semantic representations. Such representations are
compositional, allowing for the combination of atomic meaning schemata in
various ways to express the rich semantics in natural language. Recently,
pretrained language models (LMs) have achieved impressive results on
data-to-text tasks, though it remains unclear the extent to which these LMs
generalize to new semantic representations. In this work, we systematically
study the compositional generalization of current state-of-the-art generation
models in data-to-text tasks. By simulating structural shifts in the
compositional Weather dataset, we show that T5 models fail to generalize to
unseen structures. Next, we show that template-based input representations
greatly improve the model performance and model scale does not trivially solve
the lack of generalization. To further improve the model's performance, we
propose an approach based on self-training using finetuned BLEURT for
pseudo-response selection. Extensive experiments on the few-shot Weather and
multi-domain SGD datasets demonstrate strong gains of our method.",2021-10-16
How Well Do You Know Your Audience? Reader-aware Question Generation,2021-10-16 02:10:16+00:00,http://arxiv.org/abs/2110.08445v1,"Ian Stewart, Rada Mihalcea","cs.CL, I.7",table2text,"When writing, a person may need to anticipate questions from their readers,
but different types of readers may ask very different types of questions. If
someone is writing for advice about a problem, what question will a domain
expert ask, and is this different from how a novice might react? In this paper,
we address the task of reader-aware question generation. We collect a new data
set of questions and posts from social media, augmented with background
information about the post readers. Based on predictive analysis and
descriptive differences, we find that different readers, such as experts and
novices, consistently ask different types of questions. We next develop several
text generation models that incorporate different types of reader background,
including discrete and continuous reader representations based on the readers'
prior behavior. We demonstrate that reader-aware models can perform on par or
slightly better than the text-only model in some cases, particularly in cases
where a post attracts very different questions from readers of different
groups. Our work has the potential to help writers anticipate the information
needs of different readers.",2021-10-16
"Open Domain Question Answering over Virtual Documents: A Unified
  Approach for Data and Text",2021-10-16 00:11:21+00:00,http://arxiv.org/abs/2110.08417v1,"Kaixin Ma, Hao Cheng, Xiaodong Liu, Eric Nyberg, Jianfeng Gao","cs.CL, cs.AI",table2text,"Due to its potential for a universal interface over both data and text,
data-to-text generation is becoming increasingly popular recently. However, few
previous work has focused on its application to downstream tasks, e.g. using
the converted data for grounding or reasoning. In this work, we aim to bridge
this gap and use the data-to-text method as a means for encoding structured
knowledge for knowledge-intensive applications, i.e. open-domain question
answering (QA). Specifically, we propose a verbalizer-retriever-reader
framework for open-domain QA over data and text where verbalized tables from
Wikipedia and triples from Wikidata are used as augmented knowledge sources. We
show that our Unified Data and Text QA, UDT-QA, can effectively benefit from
the expanded knowledge index, leading to large gains over text-only baselines.
Notably, our approach sets the single-model state-of-the-art on Natural
Questions. Furthermore, our analyses indicate that verbalized knowledge is
preferred for answer reasoning for both adapted and hot-swap settings.",2021-10-16
Control Prefixes for Text Generation,2021-10-15 19:32:17+00:00,http://arxiv.org/abs/2110.08329v1,"Jordan Clive, Kris Cao, Marek Rei","cs.CL, cs.AI, cs.LG",table2text,"Prompt learning methods adapt pre-trained language models to downstream
applications by using a task-specific prompt together with the input. Most of
the current work on prompt learning in text generation relies on a shared
dataset-level prompt for all examples in the dataset. We extend this approach
and propose a dynamic method, Control Prefixes, which allows for the inclusion
of conditional input-dependent information in each prompt. Control Prefixes is
at the intersection of prompt learning and controlled generation, empowering
the model to have finer-grained control during text generation. The method
incorporates attribute-level learnable representations into different layers of
a pre-trained transformer, allowing for the generated text to be guided in a
particular direction. We provide a systematic evaluation of the technique and
apply it to five datasets from the GEM benchmark for natural language
generation (NLG). We present state-of-the-art results on several data-to-text
datasets, including WebNLG.",2021-10-15
"Cross-Domain Data Integration for Named Entity Disambiguation in
  Biomedical Text",2021-10-15 17:38:16+00:00,http://arxiv.org/abs/2110.08228v1,"Maya Varma, Laurel Orr, Sen Wu, Megan Leszczynski, Xiao Ling, Christopher Ré","cs.CL, cs.AI",table2text,"Named entity disambiguation (NED), which involves mapping textual mentions to
structured entities, is particularly challenging in the medical domain due to
the presence of rare entities. Existing approaches are limited by the presence
of coarse-grained structural resources in biomedical knowledge bases as well as
the use of training datasets that provide low coverage over uncommon resources.
In this work, we address these issues by proposing a cross-domain data
integration method that transfers structural knowledge from a general text
knowledge base to the medical domain. We utilize our integration scheme to
augment structural resources and generate a large biomedical NED dataset for
pretraining. Our pretrained model with injected structural knowledge achieves
state-of-the-art performance on two benchmark medical NED datasets: MedMentions
and BC5CDR. Furthermore, we improve disambiguation of rare entities by up to 57
accuracy points.",2021-10-15
MReD: A Meta-Review Dataset for Controllable Text Generation,2021-10-14 15:48:03+00:00,http://arxiv.org/abs/2110.07474v1,"Chenhui Shen, Liying Cheng, Ran Zhou, Lidong Bing, Yang You, Luo Si",cs.CL,table2text,"When directly using existing text generation datasets for controllable
generation, we are facing the problem of not having the domain knowledge and
thus the aspects that could be controlled are limited.A typical example is when
using CNN/Daily Mail dataset for controllable text summarization, there is no
guided information on the emphasis of summary sentences. A more useful text
generator should leverage both the input text and control variables to guide
the generation, which can only be built with deep understanding of the domain
knowledge. Motivated by this vi-sion, our paper introduces a new text
generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews
and all its 45k meta-review sentences are manually annotated as one of the
carefully defined 9 categories, including abstract, strength, decision, etc. We
present experimental results on start-of-the-art summarization models, and
propose methods for controlled generation on both extractive and abstractive
models using our annotated data. By exploring various settings and analaysing
the model behavior with respect to the control inputs, we demonstrate the
challenges and values of our dataset. MReD allows us to have a better
understanding of the meta-review corpora and enlarge the research room for
controllable text generation.",2021-10-14
"Rethinking Self-Supervision Objectives for Generalizable Coherence
  Modeling",2021-10-14 07:44:14+00:00,http://arxiv.org/abs/2110.07198v1,"Prathyusha Jwalapuram, Shafiq Joty, Xiang Lin",cs.CL,table2text,"Although large-scale pre-trained neural models have shown impressive
performances in a variety of tasks, their ability to generate coherent text
that appropriately models discourse phenomena is harder to evaluate and less
understood. Given the claims of improved text generation quality across various
systems, we consider the coherence evaluation of machine generated text to be
one of the principal applications of coherence models that needs to be
investigated. We explore training data and self-supervision objectives that
result in a model that generalizes well across tasks and can be used
off-the-shelf to perform such evaluations. Prior work in neural coherence
modeling has primarily focused on devising new architectures, and trained the
model to distinguish coherent and incoherent text through pairwise
self-supervision on the permuted documents task. We instead use a basic model
architecture and show significant improvements over state of the art within the
same training regime. We then design a harder self-supervision objective by
increasing the ratio of negative samples within a contrastive learning setup,
and enhance the model further through automatic hard negative mining coupled
with a large global negative queue encoded by a momentum encoder. We show
empirically that increasing the density of negative samples improves the basic
model, and using a global negative queue further improves and stabilizes the
model while training with hard negative samples. We evaluate the coherence
model on task-independent test sets that resemble real-world use cases and show
significant improvements in coherence evaluations of downstream applications.",2021-10-14
Federated Natural Language Generation for Personalized Dialogue System,2021-10-13 00:59:52+00:00,http://arxiv.org/abs/2110.06419v1,"Yujie Lu, Chao Huang, Huanli Zhan, Yong Zhuang","cs.CL, cs.AI",table2text,"Neural conversational models have long suffered from the problem of
inconsistency and lacking coherent personality. To address the issue,
persona-based models capturing individual characteristics have been proposed,
but they still face the dilemma of model adaption and data privacy. To break
this dilemma, we propose a novel Federated Natural Language Generation (FedNLG)
framework, which learns personalized representations from various dataset on
distributed devices, and thus implements the personalized dialogue system
efficiently and safely. FedNLG first pre-trains parameters of standard neural
conversational model over a large dialogue corpus, and then fine-tune the model
parameters and persona embeddings on specific datasets, in a federated manner.
Thus, the model could simultaneously learn the persona embeddings in local
clients and learn shared model parameters by federated aggregation, which
achieves accuracyprivacy balance. By conducting extensive experiments, we
demonstrate the effectiveness of our model by pre-training model over Cornell
Movie-Dialogs Corpus and fine-tuning the model over two TV series dataset.",2021-10-13
Learning Compact Metrics for MT,2021-10-12 20:39:35+00:00,http://arxiv.org/abs/2110.06341v1,"Amy Pu, Hyung Won Chung, Ankur P. Parikh, Sebastian Gehrmann, Thibault Sellam",cs.CL,table2text,"Recent developments in machine translation and multilingual text generation
have led researchers to adopt trained metrics such as COMET or BLEURT, which
treat evaluation as a regression problem and use representations from
multilingual pre-trained models such as XLM-RoBERTa or mBERT. Yet studies on
related tasks suggest that these models are most efficient when they are large,
which is costly and impractical for evaluation. We investigate the trade-off
between multilinguality and model capacity with RemBERT, a state-of-the-art
multilingual language model, using data from the WMT Metrics Shared Task. We
present a series of experiments which show that model size is indeed a
bottleneck for cross-lingual transfer, then demonstrate how distillation can
help addressing this bottleneck, by leveraging synthetic data generation and
transferring knowledge from one teacher to multiple students trained on related
languages. Our method yields up to 10.5% improvement over vanilla fine-tuning
and reaches 92.6% of RemBERT's performance using only a third of its
parameters.",2021-10-12
"DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational
  Transformer",2021-10-12 13:41:06+00:00,http://arxiv.org/abs/2110.05999v1,"Haozhe Ji, Minlie Huang",cs.CL,table2text,"Despite the recent advances in applying pre-trained language models to
generate high-quality texts, generating long passages that maintain long-range
coherence is yet challenging for these models. In this paper, we propose
DiscoDVT, a discourse-aware discrete variational Transformer to tackle the
incoherence issue. DiscoDVT learns a discrete variable sequence that summarizes
the global structure of the text and then applies it to guide the generation
process at each decoding step. To further embed discourse-aware information
into the discrete latent representations, we introduce an auxiliary objective
to model the discourse relations within the text. We conduct extensive
experiments on two open story generation datasets and demonstrate that the
latent codes learn meaningful correspondence to the discourse structures that
guide the model to generate long texts with better long-range coherence.",2021-10-12
"Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and
  Few-Shot Learning",2021-10-10 07:40:22+00:00,http://arxiv.org/abs/2110.04725v2,"Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhang, Chong Shen, Hongli Liu, Feng Li, Hong Zhu, Jiangang Luo, Liang Xu, Xuanwei Zhang","cs.CL, cs.AI",table2text,"Recent work like GPT-3 has demonstrated excellent performance of Zero-Shot
and Few-Shot learning on many natural language processing (NLP) tasks by
scaling up model size, dataset size and the amount of computation. However,
training a model like GPT-3 requires huge amount of computational resources
which makes it challengeable to researchers. In this work, we propose a method
that incorporates large-scale distributed training performance into model
architecture design. With this method, Yuan 1.0, the current largest singleton
language model with 245B parameters, achieves excellent performance on
thousands GPUs during training, and the state-of-the-art results on NLP tasks.
A data processing method is designed to efficiently filter massive amount of
raw data. The current largest high-quality Chinese corpus with 5TB high quality
texts is built based on this method. In addition, a calibration and label
expansion method is proposed to improve the Zero-Shot and Few-Shot performance,
and steady improvement is observed on the accuracy of various tasks. Yuan 1.0
presents strong capacity of natural language generation, and the generated
articles are difficult to distinguish from the human-written ones.",2021-10-10
Cut the CARP: Fishing for zero-shot story evaluation,2021-10-06 23:50:46+00:00,http://arxiv.org/abs/2110.03111v1,"Shahbuland Matiana, JR Smith, Ryan Teehan, Louis Castricato, Stella Biderman, Leo Gao, Spencer Frazier",cs.CL,table2text,"Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
  Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.",2021-10-06
CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation,2021-10-06 09:55:19+00:00,http://arxiv.org/abs/2110.02624v1,"Aditya Sanghi, Hang Chu, Joseph G. Lambourne, Ye Wang, Chin-Yi Cheng, Marco Fumero","cs.CV, cs.AI, 68T07, I.2.10",table2text,"While recent progress has been made in text-to-image generation,
text-to-shape generation remains a challenging problem due to the
unavailability of paired text and shape data at a large scale. We present a
simple yet effective method for zero-shot text-to-shape generation based on a
two-stage training process, which only depends on an unlabelled shape dataset
and a pre-trained image-text network such as CLIP. Our method not only
demonstrates promising zero-shot generalization, but also avoids expensive
inference time optimization and can generate multiple shapes for a given text.",2021-10-06
Simulated annealing for optimization of graphs and sequences,2021-10-01 01:12:19+00:00,http://arxiv.org/abs/2110.01384v1,"Xianggen Liu, Pengyong Li, Fandong Meng, Hao Zhou, Huasong Zhong, Jie Zhou, Lili Mou, Sen Song","cs.LG, cs.AI",table2text,"Optimization of discrete structures aims at generating a new structure with
the better property given an existing one, which is a fundamental problem in
machine learning. Different from the continuous optimization, the realistic
applications of discrete optimization (e.g., text generation) are very
challenging due to the complex and long-range constraints, including both
syntax and semantics, in discrete structures. In this work, we present SAGS, a
novel Simulated Annealing framework for Graph and Sequence optimization. The
key idea is to integrate powerful neural networks into metaheuristics (e.g.,
simulated annealing, SA) to restrict the search space in discrete optimization.
We start by defining a sophisticated objective function, involving the property
of interest and pre-defined constraints (e.g., grammar validity). SAGS searches
from the discrete space towards this objective by performing a sequence of
local edits, where deep generative neural networks propose the editing content
and thus can control the quality of editing. We evaluate SAGS on paraphrase
generation and molecule generation for sequence optimization and graph
optimization, respectively. Extensive results show that our approach achieves
state-of-the-art performance compared with existing paraphrase generation
methods in terms of both automatic and human evaluations. Further, SAGS also
significantly outperforms all the previous methods in molecule generation.",2021-10-01
"Towards Reinforcement Learning for Pivot-based Neural Machine
  Translation with Non-autoregressive Transformer",2021-09-27 14:49:35+00:00,http://arxiv.org/abs/2109.13097v1,"Evgeniia Tokarchuk, Jan Rosendahl, Weiyue Wang, Pavel Petrushkov, Tomer Lancewicki, Shahram Khadivi, Hermann Ney",cs.CL,table2text,"Pivot-based neural machine translation (NMT) is commonly used in low-resource
setups, especially for translation between non-English language pairs. It
benefits from using high resource source-pivot and pivot-target language pairs
and an individual system is trained for both sub-tasks. However, these models
have no connection during training, and the source-pivot model is not optimized
to produce the best translation for the source-target task. In this work, we
propose to train a pivot-based NMT system with the reinforcement learning (RL)
approach, which has been investigated for various text generation tasks,
including machine translation (MT). We utilize a non-autoregressive transformer
and present an end-to-end pivot-based integrated model, enabling training on
source-target data.",2021-09-27
"Incorporating Linguistic Knowledge for Abstractive Multi-document
  Summarization",2021-09-23 08:13:35+00:00,http://arxiv.org/abs/2109.11199v1,"Congbo Ma, Wei Emma Zhang, Hu Wang, Shubham Gupta, Mingyu Guo",cs.CL,table2text,"Within natural language processing tasks, linguistic knowledge can always
serve an important role in assisting the model to learn excel representations
and better guide the natural language generation. In this work, we develop a
neural network based abstractive multi-document summarization (MDS) model which
leverages dependency parsing to capture cross-positional dependencies and
grammatical structures. More concretely, we process the dependency information
into the linguistic-guided attention mechanism and further fuse it with the
multi-head attention for better feature representation. With the help of
linguistic signals, sentence-level relations can be correctly captured, thus
improving MDS performance. Our model has two versions based on Flat-Transformer
and Hierarchical Transformer respectively. Empirical studies on both versions
demonstrate that this simple but effective method outperforms existing works on
the benchmark dataset. Extensive analyses examine different settings and
configurations of the proposed model which provide a good reference to the
community.",2021-09-23
"Exploiting Curriculum Learning in Unsupervised Neural Machine
  Translation",2021-09-23 07:18:06+00:00,http://arxiv.org/abs/2109.11177v1,"Jinliang Lu, Jiajun Zhang",cs.CL,table2text,"Back-translation (BT) has become one of the de facto components in
unsupervised neural machine translation (UNMT), and it explicitly makes UNMT
have translation ability. However, all the pseudo bi-texts generated by BT are
treated equally as clean data during optimization without considering the
quality diversity, leading to slow convergence and limited translation
performance. To address this problem, we propose a curriculum learning method
to gradually utilize pseudo bi-texts based on their quality from multiple
granularities. Specifically, we first apply cross-lingual word embedding to
calculate the potential translation difficulty (quality) for the monolingual
sentences. Then, the sentences are fed into UNMT from easy to hard batch by
batch. Furthermore, considering the quality of sentences/tokens in a particular
batch are also diverse, we further adopt the model itself to calculate the
fine-grained quality scores, which are served as learning factors to balance
the contributions of different parts when computing loss and encourage the UNMT
model to focus on pseudo data with higher quality. Experimental results on WMT
14 En-Fr, WMT 16 En-De, WMT 16 En-Ro, and LDC En-Zh translation tasks
demonstrate that the proposed method achieves consistent improvements with
faster convergence speed.",2021-09-23
"TrOCR: Transformer-based Optical Character Recognition with Pre-trained
  Models",2021-09-21 16:01:56+00:00,http://arxiv.org/abs/2109.10282v3,"Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei","cs.CL, cs.CV",table2text,"Text recognition is a long-standing research problem for document
digitalization. Existing approaches for text recognition are usually built
based on CNN for image understanding and RNN for char-level text generation. In
addition, another language model is usually needed to improve the overall
accuracy as a post-processing step. In this paper, we propose an end-to-end
text recognition approach with pre-trained image Transformer and text
Transformer models, namely TrOCR, which leverages the Transformer architecture
for both image understanding and wordpiece-level text generation. The TrOCR
model is simple but effective, and can be pre-trained with large-scale
synthetic data and fine-tuned with human-labeled datasets. Experiments show
that the TrOCR model outperforms the current state-of-the-art models on both
printed and handwritten text recognition tasks. The code and models will be
publicly available at https://aka.ms/TrOCR.",2021-09-21
Let the CAT out of the bag: Contrastive Attributed explanations for Text,2021-09-16 13:44:55+00:00,http://arxiv.org/abs/2109.07983v1,"Saneem Chemmengath, Amar Prakash Azad, Ronny Luss, Amit Dhurandhar","cs.CL, cs.AI",table2text,"Contrastive explanations for understanding the behavior of black box models
has gained a lot of attention recently as they provide potential for recourse.
In this paper, we propose a method Contrastive Attributed explanations for Text
(CAT) which provides contrastive explanations for natural language text data
with a novel twist as we build and exploit attribute classifiers leading to
more semantically meaningful explanations. To ensure that our contrastive
generated text has the fewest possible edits with respect to the original text,
while also being fluent and close to a human generated contrastive, we resort
to a minimal perturbation approach regularized using a BERT language model and
attribute classifiers trained on available attributes. We show through
qualitative examples and a user study that our method not only conveys more
insight because of these attributes, but also leads to better quality
(contrastive) text. Moreover, quantitatively we show that our method is more
efficient than other state-of-the-art methods with it also scoring higher on
benchmark metrics such as flip rate, (normalized) Levenstein distance, fluency
and content preservation.",2021-09-16
Scaling Laws for Neural Machine Translation,2021-09-16 06:15:20+00:00,http://arxiv.org/abs/2109.07740v1,"Behrooz Ghorbani, Orhan Firat, Markus Freitag, Ankur Bapna, Maxim Krikun, Xavier Garcia, Ciprian Chelba, Colin Cherry","cs.LG, cs.AI, cs.CL",table2text,"We present an empirical study of scaling properties of encoder-decoder
Transformer models used in neural machine translation (NMT). We show that
cross-entropy loss as a function of model size follows a certain scaling law.
Specifically (i) We propose a formula which describes the scaling behavior of
cross-entropy loss as a bivariate function of encoder and decoder size, and
show that it gives accurate predictions under a variety of scaling approaches
and languages; we show that the total number of parameters alone is not
sufficient for such purposes. (ii) We observe different power law exponents
when scaling the decoder vs scaling the encoder, and provide recommendations
for optimal allocation of encoder/decoder capacity based on this observation.
(iii) We also report that the scaling behavior of the model is acutely
influenced by composition bias of the train/test sets, which we define as any
deviation from naturally generated text (either via machine generated or human
translated text). We observe that natural text on the target side enjoys
scaling, which manifests as successful reduction of the cross-entropy loss.
(iv) Finally, we investigate the relationship between the cross-entropy loss
and the quality of the generated translations. We find two different behaviors,
depending on the nature of the test data. For test sets which were originally
translated from target language to source language, both loss and BLEU score
improve as model size increases. In contrast, for test sets originally
translated from source language to target language, the loss improves, but the
BLEU score stops improving after a certain threshold. We release generated text
from all models used in this study.",2021-09-16
On the Limits of Minimal Pairs in Contrastive Evaluation,2021-09-15 17:59:15+00:00,http://arxiv.org/abs/2109.07465v1,"Jannis Vamvas, Rico Sennrich",cs.CL,table2text,"Minimal sentence pairs are frequently used to analyze the behavior of
language models. It is often assumed that model behavior on contrastive pairs
is predictive of model behavior at large. We argue that two conditions are
necessary for this assumption to hold: First, a tested hypothesis should be
well-motivated, since experiments show that contrastive evaluation can lead to
false positives. Secondly, test data should be chosen such as to minimize
distributional discrepancy between evaluation time and deployment time. For a
good approximation of deployment-time decoding, we recommend that minimal pairs
are created based on machine-generated text, as opposed to human-written
references. We present a contrastive evaluation suite for English-German MT
that implements this recommendation.",2021-09-15
"Attention Is Indeed All You Need: Semantically Attention-Guided Decoding
  for Data-to-Text NLG",2021-09-15 01:42:51+00:00,http://arxiv.org/abs/2109.07043v1,"Juraj Juraska, Marilyn Walker","cs.CL, cs.LG",table2text,"Ever since neural models were adopted in data-to-text language generation,
they have invariably been reliant on extrinsic components to improve their
semantic accuracy, because the models normally do not exhibit the ability to
generate text that reliably mentions all of the information provided in the
input. In this paper, we propose a novel decoding method that extracts
interpretable information from encoder-decoder models' cross-attention, and
uses it to infer which attributes are mentioned in the generated text, which is
subsequently used to rescore beam hypotheses. Using this decoding method with
T5 and BART, we show on three datasets its ability to dramatically reduce
semantic errors in the generated outputs, while maintaining their
state-of-the-art quality.",2021-09-15
"Compression, Transduction, and Creation: A Unified Framework for
  Evaluating Natural Language Generation",2021-09-14 01:00:42+00:00,http://arxiv.org/abs/2109.06379v1,"Mingkai Deng, Bowen Tan, Zhengzhong Liu, Eric P. Xing, Zhiting Hu","cs.CL, cs.LG",table2text,"Natural language generation (NLG) spans a broad range of tasks, each of which
serves for specific objectives and desires different properties of generated
text. The complexity makes automatic evaluation of NLG particularly
challenging. Previous work has typically focused on a single task and developed
individual evaluation metrics based on specific intuitions. In this paper, we
propose a unifying perspective based on the nature of information change in NLG
tasks, including compression (e.g., summarization), transduction (e.g., text
rewriting), and creation (e.g., dialog). Information alignment between input,
context, and output text plays a common central role in characterizing the
generation. With automatic alignment prediction models, we develop a family of
interpretable metrics that are suitable for evaluating key aspects of different
NLG tasks, often without need of gold reference data. Experiments show the
uniformly designed metrics achieve stronger or comparable correlations with
human judgement compared to state-of-the-art metrics in each of diverse tasks,
including text summarization, style transfer, and knowledge-grounded dialog.",2021-09-14
"UniMS: A Unified Framework for Multimodal Summarization with Knowledge
  Distillation",2021-09-13 09:36:04+00:00,http://arxiv.org/abs/2109.05812v1,"Zhengkun Zhang, Xiaojun Meng, Yasheng Wang, Xin Jiang, Qun Liu, Zhenglu Yang",cs.CL,table2text,"With the rapid increase of multimedia data, a large body of literature has
emerged to work on multimodal summarization, the majority of which target at
refining salient information from textual and visual modalities to output a
pictorial summary with the most relevant images. Existing methods mostly focus
on either extractive or abstractive summarization and rely on qualified image
captions to build image references. We are the first to propose a Unified
framework for Multimodal Summarization grounding on BART, UniMS, that
integrates extractive and abstractive objectives, as well as selecting the
image output. Specially, we adopt knowledge distillation from a vision-language
pretrained model to improve image selection, which avoids any requirement on
the existence and quality of image captions. Besides, we introduce a visual
guided decoder to better integrate textual and visual modalities in guiding
abstractive text generation. Results show that our best model achieves a new
state-of-the-art result on a large-scale benchmark dataset. The newly involved
extractive objective as well as the knowledge distillation technique are proven
to bring a noticeable improvement to the multimodal summarization task.",2021-09-13
Perturbation CheckLists for Evaluating NLG Evaluation Metrics,2021-09-13 08:26:26+00:00,http://arxiv.org/abs/2109.05771v1,"Ananya B. Sai, Tanay Dixit, Dev Yashpal Sheth, Sreyas Mohan, Mitesh M. Khapra",cs.CL,table2text,"Natural Language Generation (NLG) evaluation is a multifaceted task requiring
assessment of multiple desirable criteria, e.g., fluency, coherency, coverage,
relevance, adequacy, overall quality, etc. Across existing datasets for 6 NLG
tasks, we observe that the human evaluation scores on these multiple criteria
are often not correlated. For example, there is a very low correlation between
human scores on fluency and data coverage for the task of structured data to
text generation. This suggests that the current recipe of proposing new
automatic evaluation metrics for NLG by showing that they correlate well with
scores assigned by humans for a single criteria (overall quality) alone is
inadequate. Indeed, our extensive study involving 25 automatic evaluation
metrics across 6 different tasks and 18 different evaluation criteria shows
that there is no single metric which correlates well with human scores on all
desirable criteria, for most NLG tasks. Given this situation, we propose
CheckLists for better design and evaluation of automatic metrics. We design
templates which target a specific criteria (e.g., coverage) and perturb the
output such that the quality gets affected only along this specific criteria
(e.g., the coverage drops). We show that existing evaluation metrics are not
robust against even such simple perturbations and disagree with scores assigned
by humans to the perturbed output. The proposed templates thus allow for a
fine-grained assessment of automatic evaluation metrics exposing their
limitations and will facilitate better design, analysis and evaluation of such
metrics.",2021-09-13
Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration,2021-09-12 04:17:53+00:00,http://arxiv.org/abs/2109.05426v1,"Chuanxin Tang, Chong Luo, Zhiyuan Zhao, Dacheng Yin, Yucheng Zhao, Wenjun Zeng","cs.SD, cs.AI, eess.AS",table2text,"Given a piece of speech and its transcript text, text-based speech editing
aims to generate speech that can be seamlessly inserted into the given speech
by editing the transcript. Existing methods adopt a two-stage approach:
synthesize the input text using a generic text-to-speech (TTS) engine and then
transform the voice to the desired voice using voice conversion (VC). A major
problem of this framework is that VC is a challenging problem which usually
needs a moderate amount of parallel training data to work satisfactorily. In
this paper, we propose a one-stage context-aware framework to generate natural
and coherent target speech without any training data of the target speaker. In
particular, we manage to perform accurate zero-shot duration prediction for the
inserted text. The predicted duration is used to regulate both text embedding
and speech embedding. Then, based on the aligned cross-modality input, we
directly generate the mel-spectrogram of the edited speech with a
transformer-based decoder. Subjective listening tests show that despite the
lack of training data for the speaker, our method has achieved satisfactory
results. It outperforms a recent zero-shot TTS engine by a large margin.",2021-09-12
"Implicit Premise Generation with Discourse-aware Commonsense Knowledge
  Models",2021-09-11 19:54:39+00:00,http://arxiv.org/abs/2109.05358v1,"Tuhin Chakrabarty, Aadit Trivedi, Smaranda Muresan",cs.CL,table2text,"Enthymemes are defined as arguments where a premise or conclusion is left
implicit. We tackle the task of generating the implicit premise in an
enthymeme, which requires not only an understanding of the stated conclusion
and premise but also additional inferences that could depend on commonsense
knowledge. The largest available dataset for enthymemes (Habernal et al., 2018)
consists of 1.7k samples, which is not large enough to train a neural text
generation model. To address this issue, we take advantage of a similar task
and dataset: Abductive reasoning in narrative text (Bhagavatula et al., 2020).
However, we show that simply using a state-of-the-art seq2seq model fine-tuned
on this data might not generate meaningful implicit premises associated with
the given enthymemes. We demonstrate that encoding discourse-aware commonsense
during fine-tuning improves the quality of the generated implicit premises and
outperforms all other baselines both in automatic and human evaluations on
three different datasets.",2021-09-11
"CINS: Comprehensive Instruction for Few-shot Learning in
  Task-orientedDialog Systems",2021-09-10 03:23:06+00:00,http://arxiv.org/abs/2109.04645v1,"Fei Mi, Yitong Li, Yasheng Wang, Xin Jiang, Qun Liu","cs.CL, cs.LG",table2text,"As labeling cost for different modules in task-oriented dialog (ToD) systems
is high, a major challenge in practice is to learn different tasks with the
least amount of labeled data. Recently, prompting methods over pre-trained
language models (PLMs) have shown promising results for few-shot learning in
ToD. To better utilize the power of PLMs, this paper proposes Comprehensive
Instruction (CINS) that exploits PLMs with extra task-specific instructions. We
design a schema(definition, constraint, prompt) of instructions and their
customized realizations for three important downstream tasks in ToD, i.e.
intent classification, dialog state tracking, and natural language generation.
A sequence-to-sequence model (T5)is adopted to solve these three tasks in a
unified framework. Extensive experiments are conducted on these ToD tasks in
realistic few-shot learning scenarios with small validation data. Empirical
results demonstrate that the proposed CINS approach consistently improves
techniques that finetune PLMs with raw input or short prompts.",2021-09-10
Graphine: A Dataset for Graph-aware Terminology Definition Generation,2021-09-09 03:29:23+00:00,http://arxiv.org/abs/2109.04018v1,"Zequn Liu, Shukai Wang, Yiyang Gu, Ruiyi Zhang, Ming Zhang, Sheng Wang",cs.CL,table2text,"Precisely defining the terminology is the first step in scientific
communication. Developing neural text generation models for definition
generation can circumvent the labor-intensity curation, further accelerating
scientific discovery. Unfortunately, the lack of large-scale terminology
definition dataset hinders the process toward definition generation. In this
paper, we present a large-scale terminology definition dataset Graphine
covering 2,010,648 terminology definition pairs, spanning 227 biomedical
subdisciplines. Terminologies in each subdiscipline further form a directed
acyclic graph, opening up new avenues for developing graph-aware text
generation models. We then proposed a novel graph-aware definition generation
model Graphex that integrates transformer with graph neural network. Our model
outperforms existing text generation models by exploiting the graph structure
of terminologies. We further demonstrated how Graphine can be used to evaluate
pretrained language models, compare graph representation learning methods and
predict sentence granularity. We envision Graphine to be a unique resource for
definition generation and many other NLP tasks in biomedicine.",2021-09-09
"Smelting Gold and Silver for Improved Multilingual AMR-to-Text
  Generation",2021-09-08 17:55:46+00:00,http://arxiv.org/abs/2109.03808v1,"Leonardo F. R. Ribeiro, Jonas Pfeiffer, Yue Zhang, Iryna Gurevych",cs.CL,table2text,"Recent work on multilingual AMR-to-text generation has exclusively focused on
data augmentation strategies that utilize silver AMR. However, this assumes a
high quality of generated AMRs, potentially limiting the transferability to the
target task. In this paper, we investigate different techniques for
automatically generating AMR annotations, where we aim to study which source of
information yields better multilingual results. Our models trained on gold AMR
with silver (machine translated) sentences outperform approaches which leverage
generated silver AMR. We find that combining both complementary sources of
information further improves multilingual AMR-to-text generation. Our models
surpass the previous state of the art for German, Italian, Spanish, and Chinese
by a large margin.",2021-09-08
NumGPT: Improving Numeracy Ability of Generative Pre-trained Models,2021-09-07 15:06:12+00:00,http://arxiv.org/abs/2109.03137v1,"Zhihua Jin, Xin Jiang, Xingbo Wang, Qun Liu, Yong Wang, Xiaozhe Ren, Huamin Qu","cs.CL, cs.LG",table2text,"Existing generative pre-trained language models (e.g., GPT) focus on modeling
the language structure and semantics of general texts. However, those models do
not consider the numerical properties of numbers and cannot perform robustly on
numerical reasoning tasks (e.g., math word problems and measurement
estimation). In this paper, we propose NumGPT, a generative pre-trained model
that explicitly models the numerical properties of numbers in texts.
Specifically, it leverages a prototype-based numeral embedding to encode the
mantissa of the number and an individual embedding to encode the exponent of
the number. A numeral-aware loss function is designed to integrate numerals
into the pre-training objective of NumGPT. We conduct extensive experiments on
four different datasets to evaluate the numeracy ability of NumGPT. The
experiment results show that NumGPT outperforms baseline models (e.g., GPT and
GPT with DICE) on a range of numerical reasoning tasks such as measurement
estimation, number comparison, math word problems, and magnitude
classification. Ablation studies are also conducted to evaluate the impact of
pre-training and model hyperparameters on the performance.",2021-09-07
"Vision Guided Generative Pre-trained Language Models for Multimodal
  Abstractive Summarization",2021-09-06 12:31:21+00:00,http://arxiv.org/abs/2109.02401v2,"Tiezheng Yu, Wenliang Dai, Zihan Liu, Pascale Fung",cs.CL,table2text,"Multimodal abstractive summarization (MAS) models that summarize videos
(vision modality) and their corresponding transcripts (text modality) are able
to extract the essential information from massive multimodal data on the
Internet. Recently, large-scale generative pre-trained language models (GPLMs)
have been shown to be effective in text generation tasks. However, existing MAS
models cannot leverage GPLMs' powerful generation ability. To fill this
research gap, we aim to study two research questions: 1) how to inject visual
information into GPLMs without hurting their generation ability; and 2) where
is the optimal place in GPLMs to inject the visual information? In this paper,
we present a simple yet effective method to construct vision guided (VG) GPLMs
for the MAS task using attention-based add-on layers to incorporate visual
information while maintaining their original text generation ability. Results
show that our best model significantly surpasses the prior state-of-the-art
model by 5.7 ROUGE-1, 5.3 ROUGE-2, and 5.1 ROUGE-L scores on the How2 dataset,
and our visual guidance method contributes 83.6% of the overall improvement.
Furthermore, we conduct thorough ablation studies to analyze the effectiveness
of various modality fusion methods and fusion locations.",2021-09-06
Transformer Models for Text Coherence Assessment,2021-09-05 22:27:17+00:00,http://arxiv.org/abs/2109.02176v1,"Tushar Abhishek, Daksh Rawat, Manish Gupta, Vasudeva Varma",cs.CL,table2text,"Coherence is an important aspect of text quality and is crucial for ensuring
its readability. It is essential desirable for outputs from text generation
systems like summarization, question answering, machine translation, question
generation, table-to-text, etc. An automated coherence scoring model is also
helpful in essay scoring or providing writing feedback. A large body of
previous work has leveraged entity-based methods, syntactic patterns, discourse
relations, and more recently traditional deep learning architectures for text
coherence assessment. Previous work suffers from drawbacks like the inability
to handle long-range dependencies, out-of-vocabulary words, or model sequence
information. We hypothesize that coherence assessment is a cognitively complex
task that requires deeper models and can benefit from other related tasks.
Accordingly, in this paper, we propose four different Transformer-based
architectures for the task: vanilla Transformer, hierarchical Transformer,
multi-task learning-based model, and a model with fact-based input
representation. Our experiments with popular benchmark datasets across multiple
domains on four different coherence assessment tasks demonstrate that our
models achieve state-of-the-art results outperforming existing models by a good
margin.",2021-09-05
"ConQX: Semantic Expansion of Spoken Queries for Intent Detection based
  on Conditioned Text Generation",2021-09-02 05:57:07+00:00,http://arxiv.org/abs/2109.00729v1,"Eyup Halit Yilmaz, Cagri Toraman","cs.CL, cs.AI",table2text,"Intent detection of spoken queries is a challenging task due to their noisy
structure and short length. To provide additional information regarding the
query and enhance the performance of intent detection, we propose a method for
semantic expansion of spoken queries, called ConQX, which utilizes the text
generation ability of an auto-regressive language model, GPT-2. To avoid
off-topic text generation, we condition the input query to a structured context
with prompt mining. We then apply zero-shot, one-shot, and few-shot learning.
We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent
detection. The experimental results show that the performance of intent
detection can be improved by our semantic expansion method.",2021-09-02
OptAGAN: Entropy-based finetuning on text VAE-GAN,2021-09-01 08:23:19+00:00,http://arxiv.org/abs/2109.00239v1,"Paolo Tirotta, Stefano Lodi",cs.CL,table2text,"Transfer learning through large pre-trained models has changed the landscape
of current applications in natural language processing (NLP). Recently Optimus,
a variational autoencoder (VAE) which combines two pre-trained models, BERT and
GPT-2, has been released, and its combination with generative adversial
networks (GANs) has been shown to produce novel, yet very human-looking text.
The Optimus and GANs combination avoids the troublesome application of GANs to
the discrete domain of text, and prevents the exposure bias of standard maximum
likelihood methods. We combine the training of GANs in the latent space, with
the finetuning of the decoder of Optimus for single word generation. This
approach lets us model both the high-level features of the sentences, and the
low-level word-by-word generation. We finetune using reinforcement learning
(RL) by exploiting the structure of GPT-2 and by adding entropy-based
intrinsically motivated rewards to balance between quality and diversity. We
benchmark the results of the VAE-GAN model, and show the improvements brought
by our RL finetuning on three widely used datasets for text generation, with
results that greatly surpass the current state-of-the-art for the quality of
the generated texts.",2021-09-01
Plan-then-Generate: Controlled Data-to-Text Generation via Planning,2021-08-31 10:53:32+00:00,http://arxiv.org/abs/2108.13740v1,"Yixuan Su, David Vandyke, Sihui Wang, Yimai Fang, Nigel Collier",cs.CL,table2text,"Recent developments in neural networks have led to the advance in
data-to-text generation. However, the lack of ability of neural models to
control the structure of generated output can be limiting in certain real-world
applications. In this study, we propose a novel Plan-then-Generate (PlanGen)
framework to improve the controllability of neural data-to-text models.
Extensive experiments and analyses are conducted on two benchmark datasets,
ToTTo and WebNLG. The results show that our model is able to control both the
intra-sentence and inter-sentence structure of the generated output.
Furthermore, empirical comparisons against previous state-of-the-art methods
show that our model improves the generation quality as well as the output
diversity as judged by human and automatic evaluations.",2021-08-31
Event Extraction as Natural Language Generation,2021-08-29 00:27:31+00:00,http://arxiv.org/abs/2108.12724v1,"I-Hung Hsu, Kuan-Hao Huang, Elizabeth Boschee, Scott Miller, Prem Natarajan, Kai-Wei Chang, Nanyun Peng","cs.CL, cs.AI",table2text,"Event extraction (EE), the task that identifies event triggers and their
arguments in text, is usually formulated as a classification or structured
prediction problem. Such models usually reduce labels to numeric identifiers,
making them unable to take advantage of label semantics (e.g. an event type
named Arrest is related to words like arrest, detain, or apprehend). This
prevents the generalization to new event types. In this work, we formulate EE
as a natural language generation task and propose GenEE, a model that not only
captures complex dependencies within an event but also generalizes well to
unseen or rare event types. Given a passage and an event type, GenEE is trained
to generate a natural sentence following a predefined template for that event
type. The generated output is then decoded into trigger and argument
predictions. The autoregressive generation process naturally models the
dependencies among the predictions -- each new word predicted depends on those
already generated in the output sentence. Using carefully designed input
prompts during generation, GenEE is able to capture label semantics, which
enables the generalization to new event types. Empirical results show that our
model achieves strong performance on event extraction tasks under all
zero-shot, few-shot, and high-resource scenarios. Especially, in the
high-resource setting, GenEE outperforms the state-of-the-art model on argument
extraction and gets competitive results with the current best on end-to-end EE
tasks.",2021-08-29
Few-Shot Table-to-Text Generation with Prototype Memory,2021-08-27 22:16:30+00:00,http://arxiv.org/abs/2108.12516v2,"Yixuan Su, Zaiqiao Meng, Simon Baker, Nigel Collier",cs.CL,table2text,"Neural table-to-text generation models have achieved remarkable progress on
an array of tasks. However, due to the data-hungry nature of neural models,
their performances strongly rely on large-scale training examples, limiting
their applicability in real-world applications. To address this, we propose a
new framework: Prototype-to-Generate (P2G), for table-to-text generation under
the few-shot scenario. The proposed framework utilizes the retrieved
prototypes, which are jointly selected by an IR system and a novel prototype
selector to help the model bridging the structural gap between tables and
texts. Experimental results on three benchmark datasets with three
state-of-the-art models demonstrate that the proposed framework significantly
improves the model performance across various evaluation metrics.",2021-08-27
Latent Tree Decomposition Parsers for AMR-to-Text Generation,2021-08-27 14:30:35+00:00,http://arxiv.org/abs/2108.12304v2,"Lisa Jin, Daniel Gildea",cs.CL,table2text,"Graph encoders in AMR-to-text generation models often rely on neighborhood
convolutions or global vertex attention. While these approaches apply to
general graphs, AMRs may be amenable to encoders that target their tree-like
structure. By clustering edges into a hierarchy, a tree decomposition
summarizes graph structure. Our model encodes a derivation forest of tree
decompositions and extracts an expected tree. From tree node embeddings, it
builds graph edge features used in vertex attention of the graph encoder.
Encoding TD forests instead of shortest-pairwise paths in a self-attentive
baseline raises BLEU by 0.7 and chrF++ by 0.3. The forest encoder also
surpasses a convolutional baseline for molecular property prediction by 1.92%
ROC-AUC.",2021-08-27
Tree Decomposition Attention for AMR-to-Text Generation,2021-08-27 14:24:25+00:00,http://arxiv.org/abs/2108.12300v2,"Lisa Jin, Daniel Gildea",cs.CL,table2text,"Text generation from AMR requires mapping a semantic graph to a string that
it annotates. Transformer-based graph encoders, however, poorly capture vertex
dependencies that may benefit sequence prediction. To impose order on an
encoder, we locally constrain vertex self-attention using a graph's tree
decomposition. Instead of forming a full query-key bipartite graph, we restrict
attention to vertices in parent, subtree, and same-depth bags of a vertex. This
hierarchical context lends both sparsity and structure to vertex state updates.
We apply dynamic programming to derive a forest of tree decompositions,
choosing the most structurally similar tree to the AMR. Our system outperforms
a self-attentive baseline by 1.6 BLEU and 1.8 chrF++.",2021-08-27
"Latent Space Energy-Based Model of Symbol-Vector Coupling for Text
  Generation and Classification",2021-08-26 02:31:18+00:00,http://arxiv.org/abs/2108.11556v1,"Bo Pang, Ying Nian Wu",cs.LG,table2text,"We propose a latent space energy-based prior model for text generation and
classification. The model stands on a generator network that generates the text
sequence based on a continuous latent vector. The energy term of the prior
model couples a continuous latent vector and a symbolic one-hot vector, so that
discrete category can be inferred from the observed example based on the
continuous latent vector. Such a latent space coupling naturally enables
incorporation of information bottleneck regularization to encourage the
continuous latent vector to extract information from the observed example that
is informative of the underlying category. In our learning method, the
symbol-vector coupling, the generator network and the inference network are
learned jointly. Our model can be learned in an unsupervised setting where no
category labels are provided. It can also be learned in semi-supervised setting
where category labels are provided for a subset of training examples. Our
experiments demonstrate that the proposed model learns well-structured and
meaningful latent space, which (1) guides the generator to generate text with
high quality, diversity, and interpretability, and (2) effectively classifies
text.",2021-08-26
"Using BERT Encoding and Sentence-Level Language Model for Sentence
  Ordering",2021-08-24 23:03:36+00:00,http://arxiv.org/abs/2108.10986v1,"Melika Golestani, Seyedeh Zahra Razavi, Zeinab Borhanifard, Farnaz Tahmasebian, Hesham Faili",cs.CL,table2text,"Discovering the logical sequence of events is one of the cornerstones in
Natural Language Understanding. One approach to learn the sequence of events is
to study the order of sentences in a coherent text. Sentence ordering can be
applied in various tasks such as retrieval-based Question Answering, document
summarization, storytelling, text generation, and dialogue systems.
Furthermore, we can learn to model text coherence by learning how to order a
set of shuffled sentences. Previous research has relied on RNN, LSTM, and
BiLSTM architecture for learning text language models. However, these networks
have performed poorly due to the lack of attention mechanisms. We propose an
algorithm for sentence ordering in a corpus of short stories. Our proposed
method uses a language model based on Universal Transformers (UT) that captures
sentences' dependencies by employing an attention mechanism. Our method
improves the previous state-of-the-art in terms of Perfect Match Ratio (PMR)
score in the ROCStories dataset, a corpus of nearly 100K short human-made
stories. The proposed model includes three components: Sentence Encoder,
Language Model, and Sentence Arrangement with Brute Force Search. The first
component generates sentence embeddings using SBERT-WK pre-trained model
fine-tuned on the ROCStories data. Then a Universal Transformer network
generates a sentence-level language model. For decoding, the network generates
a candidate sentence as the following sentence of the current sentence. We use
cosine similarity as a scoring function to assign scores to the candidate
embedding and the embeddings of other sentences in the shuffled set. Then a
Brute Force Search is employed to maximize the sum of similarities between
pairs of consecutive sentences.",2021-08-24
CGEMs: A Metric Model for Automatic Code Generation using GPT-3,2021-08-23 13:28:57+00:00,http://arxiv.org/abs/2108.10168v1,"Aishwarya Narasimhan, Krishna Prasad Agara Venkatesha Rao, Veena M B",cs.AI,table2text,"Today, AI technology is showing its strengths in almost every industry and
walks of life. From text generation, text summarization, chatbots, NLP is being
used widely. One such paradigm is automatic code generation. An AI could be
generating anything; hence the output space is unconstrained. A self-driving
car is driven for 100 million miles to validate its safety, but tests cannot be
written to monitor and cover an unconstrained space. One of the solutions to
validate AI-generated content is to constrain the problem and convert it from
abstract to realistic, and this can be accomplished by either validating the
unconstrained algorithm using theoretical proofs or by using Monte-Carlo
simulation methods. In this case, we use the latter approach to test/validate a
statistically significant number of samples. This hypothesis of validating the
AI-generated code is the main motive of this work and to know if AI-generated
code is reliable, a metric model CGEMs is proposed. This is an extremely
challenging task as programs can have different logic with different naming
conventions, but the metrics must capture the structure and logic of the
program. This is similar to the importance grammar carries in AI-based text
generation, Q&A, translations, etc. The various metrics that are garnered in
this work to support the evaluation of generated code are as follows:
Compilation, NL description to logic conversion, number of edits needed, some
of the commonly used static-code metrics and NLP metrics. These metrics are
applied to 80 codes generated using OpenAI's GPT-3. Post which a Neural network
is designed for binary classification (acceptable/not acceptable quality of the
generated code). The inputs to this network are the values of the features
obtained from the metrics. The model achieves a classification accuracy of
76.92% and an F1 score of 55.56%. XAI is augmented for model interpretability.",2021-08-23
"A Neural Conversation Generation Model via Equivalent Shared Memory
  Investigation",2021-08-20 13:20:14+00:00,http://arxiv.org/abs/2108.09164v1,"Changzhen Ji, Yating Zhang, Xiaozhong Liu, Adam Jatowt, Changlong Sun, Conghui Zhu, Tiejun Zhao",cs.CL,table2text,"Conversation generation as a challenging task in Natural Language Generation
(NLG) has been increasingly attracting attention over the last years. A number
of recent works adopted sequence-to-sequence structures along with external
knowledge, which successfully enhanced the quality of generated conversations.
Nevertheless, few works utilized the knowledge extracted from similar
conversations for utterance generation. Taking conversations in customer
service and court debate domains as examples, it is evident that essential
entities/phrases, as well as their associated logic and inter-relationships can
be extracted and borrowed from similar conversation instances. Such information
could provide useful signals for improving conversation generation. In this
paper, we propose a novel reading and memory framework called Deep Reading
Memory Network (DRMN) which is capable of remembering useful information of
similar conversations for improving utterance generation. We apply our model to
two large-scale conversation datasets of justice and e-commerce fields.
Experiments prove that the proposed model outperforms the state-of-the-art
approaches.",2021-08-20
"Table Caption Generation in Scholarly Documents Leveraging Pre-trained
  Language Models",2021-08-18 12:25:43+00:00,http://arxiv.org/abs/2108.08111v1,"Junjie H. Xu, Kohei Shinden, Makoto P. Kato",cs.CL,table2text,"This paper addresses the problem of generating table captions for scholarly
documents, which often require additional information outside the table. To
this end, we propose a method of retrieving relevant sentences from the paper
body, and feeding the table content as well as the retrieved sentences into
pre-trained language models (e.g. T5 and GPT-2) for generating table captions.
The contributions of this paper are: (1) discussion on the challenges in table
captioning for scholarly documents; (2) development of a dataset DocBank-TB,
which is publicly available; and (3) comparison of caption generation methods
for scholarly documents with different strategies to retrieve relevant
sentences from the paper body. Our experimental results showed that T5 is the
better generation model for this task, as it outperformed GPT-2 in BLEU and
METEOR implying that the generated text are clearer and more precise. Moreover,
inputting relevant sentences matching the row header or whole table is
effective.",2021-08-18
"GGP: A Graph-based Grouping Planner for Explicit Control of Long Text
  Generation",2021-08-18 06:55:55+00:00,http://arxiv.org/abs/2108.07998v1,"Xuming Lin, Shaobo Cui, Zhongzhou Zhao, Wei Zhou, Ji Zhang, Haiqing Chen",cs.CL,table2text,"Existing data-driven methods can well handle short text generation. However,
when applied to the long-text generation scenarios such as story generation or
advertising text generation in the commercial scenario, these methods may
generate illogical and uncontrollable texts. To address these aforementioned
issues, we propose a graph-based grouping planner(GGP) following the idea of
first-plan-then-generate. Specifically, given a collection of key phrases, GGP
firstly encodes these phrases into an instance-level sequential representation
and a corpus-level graph-based representation separately. With these two
synergic representations, we then regroup these phrases into a fine-grained
plan, based on which we generate the final long text. We conduct our
experiments on three long text generation datasets and the experimental results
reveal that GGP significantly outperforms baselines, which proves that GGP can
control the long text generation by knowing how to say and in what order.",2021-08-18
"Reusable Templates and Guides For Documenting Datasets and Models for
  Natural Language Processing and Generation: A Case Study of the HuggingFace
  and GEM Data and Model Cards",2021-08-16 23:15:09+00:00,http://arxiv.org/abs/2108.07374v1,"Angelina McMillan-Major, Salomey Osei, Juan Diego Rodriguez, Pawan Sasanka Ammanamanchi, Sebastian Gehrmann, Yacine Jernite","cs.DB, cs.CL",table2text,"Developing documentation guidelines and easy-to-use templates for datasets
and models is a challenging task, especially given the variety of backgrounds,
skills, and incentives of the people involved in the building of natural
language processing (NLP) tools. Nevertheless, the adoption of standard
documentation practices across the field of NLP promotes more accessible and
detailed descriptions of NLP datasets and models, while supporting researchers
and developers in reflecting on their work. To help with the standardization of
documentation, we present two case studies of efforts that aim to develop
reusable documentation templates -- the HuggingFace data card, a general
purpose card for datasets in NLP, and the GEM benchmark data and model cards
with a focus on natural language generation. We describe our process for
developing these templates, including the identification of relevant
stakeholder groups, the definition of a set of guiding principles, the use of
existing templates as our foundation, and iterative revisions based on
feedback.",2021-08-16
A Single Example Can Improve Zero-Shot Data Generation,2021-08-16 09:43:26+00:00,http://arxiv.org/abs/2108.06991v1,"Pavel Burnyshev, Valentin Malykh, Andrey Bout, Ekaterina Artemova, Irina Piontkovskaya",cs.CL,table2text,"Sub-tasks of intent classification, such as robustness to distribution shift,
adaptation to specific user groups and personalization, out-of-domain
detection, require extensive and flexible datasets for experiments and
evaluation. As collecting such datasets is time- and labor-consuming, we
propose to use text generation methods to gather datasets. The generator should
be trained to generate utterances that belong to the given intent. We explore
two approaches to generating task-oriented utterances. In the zero-shot
approach, the model is trained to generate utterances from seen intents and is
further used to generate utterances for intents unseen during training. In the
one-shot approach, the model is presented with a single utterance from a test
intent. We perform a thorough automatic, and human evaluation of the dataset
generated utilizing two proposed approaches. Our results reveal that the
attributes of the generated data are close to original test sets, collected via
crowd-sourcing.",2021-08-16
"HiTab: A Hierarchical Table Dataset for Question Answering and Natural
  Language Generation",2021-08-15 10:14:21+00:00,http://arxiv.org/abs/2108.06712v1,"Zhoujun Cheng, Haoyu Dong, Zhiruo Wang, Ran Jia, Jiaqi Guo, Yan Gao, Shi Han, Jian-Guang Lou, Dongmei Zhang","cs.CL, cs.IR",table2text,"Tables are often created with hierarchies, but existing works on table
reasoning mainly focus on flat tables and neglect hierarchical tables.
Hierarchical tables challenge existing methods by hierarchical indexing, as
well as implicit relationships of calculation and semantics. This work presents
HiTab, a free and open dataset for the research community to study question
answering (QA) and natural language generation (NLG) over hierarchical tables.
HiTab is a cross-domain dataset constructed from a wealth of statistical
reports and Wikipedia pages, and has unique characteristics: (1) nearly all
tables are hierarchical, and (2) both target sentences for NLG and questions
for QA are revised from high-quality descriptions in statistical reports that
are meaningful and diverse. (3) HiTab provides fine-grained annotations on both
entity and quantity alignment. Targeting hierarchical structure, we devise a
novel hierarchy-aware logical form for symbolic reasoning over tables, which
shows high effectiveness. Then given annotations of entity and quantity
alignment, we propose partially supervised training, which helps models to
largely reduce spurious predictions in the QA task. In the NLG task, we find
that entity and quantity alignment also helps NLG models to generate better
results in a conditional generation setting. Experiment results of
state-of-the-art baselines suggest that this dataset presents a strong
challenge and a valuable benchmark for future research.",2021-08-15
MTG: A Benchmarking Suite for Multilingual Text Generation,2021-08-13 13:25:08+00:00,http://arxiv.org/abs/2108.07140v1,"Yiran Chen, Zhenqiao Song, Xianze Wu, Danqing Wang, Jingjing Xu, Jiaze Chen, Hao Zhou, Lei Li",cs.CL,table2text,"We introduce MTG, a new benchmark suite for training and evaluating
multilingual text generation. It is the first and largest text generation
benchmark with 120k human-annotated multi-way parallel data for three tasks
(story generation, question generation, and title generation) across four
languages (English, German, French, and Spanish). Based on it, we set various
evaluation scenarios and make a deep analysis of several popular multilingual
generation models from different aspects. Our benchmark suite will encourage
the multilingualism for text generation community with more human-annotated
parallel data and more diverse generation scenarios.",2021-08-13
"Curriculum Learning: A Regularization Method for Efficient and Stable
  Billion-Scale GPT Model Pre-Training",2021-08-13 06:32:53+00:00,http://arxiv.org/abs/2108.06084v1,"Conglong Li, Minjia Zhang, Yuxiong He","cs.LG, cs.DC",table2text,"Recent works have demonstrated great success in training high-capacity
autoregressive language models (GPT, GPT-2, GPT-3) on a huge amount of
unlabeled text corpus for text generation. Despite showing great results, this
generates two training efficiency challenges. First, training large corpora can
be extremely timing consuming, and how to present training samples to the model
to improve the token-wise convergence speed remains a challenging and open
question. Second, many of these large models have to be trained with hundreds
or even thousands of processors using data-parallelism with a very large batch
size. Despite of its better compute efficiency, it has been observed that
large-batch training often runs into training instability issue or converges to
solutions with bad generalization performance. To overcome these two
challenges, we present a study of a curriculum learning based approach, which
helps improves the pre-training convergence speed of autoregressive models.
More importantly, we find that curriculum learning, as a regularization method,
exerts a gradient variance reduction effect and enables to train autoregressive
models with much larger batch sizes and learning rates without training
instability, further improving the training speed. Our evaluations demonstrate
that curriculum learning enables training GPT-2 models (with up to 1.5B
parameters) with 8x larger batch size and 4x larger learning rate, whereas the
baseline approach struggles with training divergence. To achieve the same
validation perplexity targets during pre-training, curriculum learning reduces
the required number of tokens and wall clock time by up to 59% and 54%,
respectively. To achieve the same or better zero-shot WikiText-103/LAMBADA
evaluation results at the end of pre-training, curriculum learning reduces the
required number of tokens and wall clock time by up to 13% and 61%,
respectively.",2021-08-13
IntenT5: Search Result Diversification using Causal Language Models,2021-08-09 13:29:24+00:00,http://arxiv.org/abs/2108.04026v1,"Sean MacAvaney, Craig Macdonald, Roderick Murray-Smith, Iadh Ounis",cs.IR,table2text,"Search result diversification is a beneficial approach to overcome
under-specified queries, such as those that are ambiguous or multi-faceted.
Existing approaches often rely on massive query logs and interaction data to
generate a variety of possible query intents, which then can be used to re-rank
documents. However, relying on user interaction data is problematic because one
first needs a massive user base to build a sufficient log; public query logs
are insufficient on their own. Given the recent success of causal language
models (such as the Text-To-Text Transformer (T5) model) at text generation
tasks, we explore the capacity of these models to generate potential query
intents. We find that to encourage diversity in the generated queries, it is
beneficial to adapt the model by including a new Distributional Causal Language
Modeling (DCLM) objective during fine-tuning and a representation replacement
during inference. Across six standard evaluation benchmarks, we find that our
method (which we call IntenT5) improves search result diversity and attains
(and sometimes exceeds) the diversity obtained when using query suggestions
based on a proprietary query log. Our analysis shows that our approach is most
effective for multi-faceted queries and is able to generalize effectively to
queries that were unseen in training data.",2021-08-09
"Controlled Text Generation as Continuous Optimization with Multiple
  Constraints",2021-08-04 05:25:20+00:00,http://arxiv.org/abs/2108.01850v1,"Sachin Kumar, Eric Malmi, Aliaksei Severyn, Yulia Tsvetkov",cs.CL,table2text,"As large-scale language model pretraining pushes the state-of-the-art in text
generation, recent work has turned to controlling attributes of the text such
models generate. While modifying the pretrained models via fine-tuning remains
the popular approach, it incurs a significant computational cost and can be
infeasible due to lack of appropriate data. As an alternative, we propose
MuCoCO -- a flexible and modular algorithm for controllable inference from
pretrained models. We formulate the decoding process as an optimization problem
which allows for multiple attributes we aim to control to be easily
incorporated as differentiable constraints to the optimization. By relaxing
this discrete optimization to a continuous one, we make use of Lagrangian
multipliers and gradient-descent based techniques to generate the desired text.
We evaluate our approach on controllable machine translation and style transfer
with multiple sentence-level attributes and observe significant improvements
over baselines.",2021-08-04
"Exploiting BERT For Multimodal Target Sentiment Classification Through
  Input Space Translation",2021-08-03 18:02:38+00:00,http://arxiv.org/abs/2108.01682v2,"Zaid Khan, Yun Fu","cs.CL, cs.CV",table2text,"Multimodal target/aspect sentiment classification combines multimodal
sentiment analysis and aspect/target sentiment classification. The goal of the
task is to combine vision and language to understand the sentiment towards a
target entity in a sentence. Twitter is an ideal setting for the task because
it is inherently multimodal, highly emotional, and affects real world events.
However, multimodal tweets are short and accompanied by complex, possibly
irrelevant images. We introduce a two-stream model that translates images in
input space using an object-aware transformer followed by a single-pass
non-autoregressive text generation approach. We then leverage the translation
to construct an auxiliary sentence that provides multimodal information to a
language model. Our approach increases the amount of text available to the
language model and distills the object-level information in complex images. We
achieve state-of-the-art performance on two multimodal Twitter datasets without
modifying the internals of the language model to accept multimodal data,
demonstrating the effectiveness of our translation. In addition, we explain a
failure mode of a popular approach for aspect sentiment analysis when applied
to tweets. Our code is available at
\textcolor{blue}{\url{https://github.com/codezakh/exploiting-BERT-thru-translation}}.",2021-08-03
Logic-Consistency Text Generation from Semantic Parses,2021-08-02 01:12:18+00:00,http://arxiv.org/abs/2108.00577v1,"Chang Shu, Yusen Zhang, Xiangyu Dong, Peng Shi, Tao Yu, Rui Zhang",cs.CL,table2text,"Text generation from semantic parses is to generate textual descriptions for
formal representation inputs such as logic forms and SQL queries. This is
challenging due to two reasons: (1) the complex and intensive inner logic with
the data scarcity constraint, (2) the lack of automatic evaluation metrics for
logic consistency. To address these two challenges, this paper first proposes
SNOWBALL, a framework for logic consistent text generation from semantic parses
that employs an iterative training procedure by recursively augmenting the
training set with quality control. Second, we propose a novel automatic metric,
BLEC, for evaluating the logical consistency between the semantic parses and
generated texts. The experimental results on two benchmark datasets, Logic2Text
and Spider, demonstrate the SNOWBALL framework enhances the logic consistency
on both BLEC and human evaluation. Furthermore, our statistical analysis
reveals that BLEC is more logically consistent with human evaluation than
general-purpose automatic metrics including BLEU, ROUGE and, BLEURT. Our data
and code are available at https://github.com/Ciaranshu/relogic.",2021-08-02
"Neural Rule-Execution Tracking Machine For Transformer-Based Text
  Generation",2021-07-27 20:41:05+00:00,http://arxiv.org/abs/2107.13077v1,"Yufei Wang, Can Xu, Huang Hu, Chongyang Tao, Stephen Wan, Mark Dras, Mark Johnson, Daxin Jiang",cs.CL,table2text,"Sequence-to-Sequence (S2S) neural text generation models, especially the
pre-trained ones (e.g., BART and T5), have exhibited compelling performance on
various natural language generation tasks. However, the black-box nature of
these models limits their application in tasks where specific rules (e.g.,
controllable constraints, prior knowledge) need to be executed. Previous works
either design specific model structure (e.g., Copy Mechanism corresponding to
the rule ""the generated output should include certain words in the source
input"") or implement specialized inference algorithm (e.g., Constrained Beam
Search) to execute particular rules through the text generation. These methods
require careful design case-by-case and are difficult to support multiple rules
concurrently. In this paper, we propose a novel module named Neural
Rule-Execution Tracking Machine that can be equipped into various
transformer-based generators to leverage multiple rules simultaneously to guide
the neural generation model for superior generation performance in a unified
and scalable way. Extensive experimental results on several benchmarks verify
the effectiveness of our proposed model in both controllable and general text
generation.",2021-07-27
WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset,2021-07-20 15:18:30+00:00,http://arxiv.org/abs/2107.09556v1,"Luyu Wang, Yujia Li, Ozlem Aslan, Oriol Vinyals","cs.CL, cs.AI",table2text,"We present a new dataset of Wikipedia articles each paired with a knowledge
graph, to facilitate the research in conditional text generation, graph
generation and graph representation learning. Existing graph-text paired
datasets typically contain small graphs and short text (1 or few sentences),
thus limiting the capabilities of the models that can be learned on the data.
Our new dataset WikiGraphs is collected by pairing each Wikipedia article from
the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph
from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy
to benchmark against other state-of-the-art text generative models that are
capable of generating long paragraphs of coherent text. Both the graphs and the
text data are of significantly larger scale compared to prior graph-text paired
datasets. We present baseline graph neural network and transformer model
results on our dataset for 3 tasks: graph -> text generation, graph -> text
retrieval and text -> graph retrieval. We show that better conditioning on the
graph provides gains in generation and retrieval quality but there is still
large room for improvement.",2021-07-20
Generative Pretraining for Paraphrase Evaluation,2021-07-17 14:48:48+00:00,http://arxiv.org/abs/2107.08251v1,"Jack Weston, Raphael Lenain, Udeepa Meepegama, Emil Fristed","cs.CL, cs.LG",table2text,"We introduce ParaBLEU, a paraphrase representation learning model and
evaluation metric for text generation. Unlike previous approaches, ParaBLEU
learns to understand paraphrasis using generative conditioning as a pretraining
objective. ParaBLEU correlates more strongly with human judgements than
existing metrics, obtaining new state-of-the-art results on the 2017 WMT
Metrics Shared Task. We show that our model is robust to data scarcity,
exceeding previous state-of-the-art performance using only $50\%$ of the
available training data and surpassing BLEU, ROUGE and METEOR with only $40$
labelled examples. Finally, we demonstrate that ParaBLEU can be used to
conditionally generate novel paraphrases from a single demonstration, which we
use to confirm our hypothesis that it learns abstract, generalized paraphrase
representations.",2021-07-17
"Robust Learning for Text Classification with Multi-source Noise
  Simulation and Hard Example Mining",2021-07-15 04:39:22+00:00,http://arxiv.org/abs/2107.07113v1,"Guowei Xu, Wenbiao Ding, Weiping Fu, Zhongqin Wu, Zitao Liu","cs.CL, cs.AI",table2text,"Many real-world applications involve the use of Optical Character Recognition
(OCR) engines to transform handwritten images into transcripts on which
downstream Natural Language Processing (NLP) models are applied. In this
process, OCR engines may introduce errors and inputs to downstream NLP models
become noisy. Despite that pre-trained models achieve state-of-the-art
performance in many NLP benchmarks, we prove that they are not robust to noisy
texts generated by real OCR engines. This greatly limits the application of NLP
models in real-world scenarios. In order to improve model performance on noisy
OCR transcripts, it is natural to train the NLP model on labelled noisy texts.
However, in most cases there are only labelled clean texts. Since there is no
handwritten pictures corresponding to the text, it is impossible to directly
use the recognition model to obtain noisy labelled data. Human resources can be
employed to copy texts and take pictures, but it is extremely expensive
considering the size of data for model training. Consequently, we are
interested in making NLP models intrinsically robust to OCR errors in a low
resource manner. We propose a novel robust training framework which 1) employs
simple but effective methods to directly simulate natural OCR noises from clean
texts and 2) iteratively mines the hard examples from a large number of
simulated samples for optimal performance. 3) To make our model learn
noise-invariant representations, a stability loss is employed. Experiments on
three real-world datasets show that the proposed framework boosts the
robustness of pre-trained models by a large margin. We believe that this work
can greatly promote the application of NLP models in actual scenarios, although
the algorithm we use is simple and straightforward. We make our codes and three
datasets publicly
available\footnote{https://github.com/tal-ai/Robust-learning-MSSHEM}.",2021-07-15
"From Machine Translation to Code-Switching: Generating High-Quality
  Code-Switched Text",2021-07-14 04:46:39+00:00,http://arxiv.org/abs/2107.06483v1,"Ishan Tarunesh, Syamantak Kumar, Preethi Jyothi",cs.CL,table2text,"Generating code-switched text is a problem of growing interest, especially
given the scarcity of corpora containing large volumes of real code-switched
text. In this work, we adapt a state-of-the-art neural machine translation
model to generate Hindi-English code-switched sentences starting from
monolingual Hindi sentences. We outline a carefully designed curriculum of
pretraining steps, including the use of synthetic code-switched text, that
enable the model to generate high-quality code-switched text. Using text
generated from our model as data augmentation, we show significant reductions
in perplexity on a language modeling task, compared to using text from other
generative models of CS text. We also show improvements using our text for a
downstream code-switched natural language inference task. Our generated text is
further subjected to a rigorous evaluation using a human evaluation study and a
range of objective metrics, where we show performance comparable (and sometimes
even superior) to code-switched text obtained via crowd workers who are native
Hindi speakers.",2021-07-14
Direct speech-to-speech translation with discrete units,2021-07-12 17:40:43+00:00,http://arxiv.org/abs/2107.05604v1,"Ann Lee, Peng-Jen Chen, Changhan Wang, Jiatao Gu, Xutai Ma, Adam Polyak, Yossi Adi, Qing He, Yun Tang, Juan Pino, Wei-Ning Hsu","cs.CL, cs.LG, eess.AS",table2text,"We present a direct speech-to-speech translation (S2ST) model that translates
speech from one language to speech in another language without relying on
intermediate text generation. Previous work addresses the problem by training
an attention-based sequence-to-sequence model that maps source speech
spectrograms into target spectrograms. To tackle the challenge of modeling
continuous spectrogram features of the target speech, we propose to predict the
self-supervised discrete representations learned from an unlabeled speech
corpus instead. When target text transcripts are available, we design a
multitask learning framework with joint speech and text training that enables
the model to generate dual mode output (speech and text) simultaneously in the
same inference pass. Experiments on the Fisher Spanish-English dataset show
that predicting discrete units and joint speech and text training improve model
performance by 11 BLEU compared with a baseline that predicts spectrograms and
bridges 83% of the performance gap towards a cascaded system. When trained
without any text transcripts, our model achieves similar performance as a
baseline that predicts spectrograms and is trained with text data.",2021-07-12
"HinGE: A Dataset for Generation and Evaluation of Code-Mixed Hinglish
  Text",2021-07-08 11:11:37+00:00,http://arxiv.org/abs/2107.03760v1,"Vivek Srivastava, Mayank Singh",cs.CL,table2text,"Text generation is a highly active area of research in the computational
linguistic community. The evaluation of the generated text is a challenging
task and multiple theories and metrics have been proposed over the years.
Unfortunately, text generation and evaluation are relatively understudied due
to the scarcity of high-quality resources in code-mixed languages where the
words and phrases from multiple languages are mixed in a single utterance of
text and speech. To address this challenge, we present a corpus (HinGE) for a
widely popular code-mixed language Hinglish (code-mixing of Hindi and English
languages). HinGE has Hinglish sentences generated by humans as well as two
rule-based algorithms corresponding to the parallel Hindi-English sentences. In
addition, we demonstrate the inefficacy of widely-used evaluation metrics on
the code-mixed data. The HinGE dataset will facilitate the progress of natural
language generation research in code-mixed languages.",2021-07-08
On Training Instance Selection for Few-Shot Neural Text Generation,2021-07-07 12:16:16+00:00,http://arxiv.org/abs/2107.03176v1,"Ernie Chang, Xiaoyu Shen, Hui-Syuan Yeh, Vera Demberg","cs.CL, cs.LG",table2text,"Large-scale pretrained language models have led to dramatic improvements in
text generation. Impressive performance can be achieved by finetuning only on a
small number of instances (few-shot setting). Nonetheless, almost all previous
work simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. In this work, we present a study on training
instance selection in few-shot neural text generation. The selection decision
is made based only on the unlabeled data so as to identify the most worthwhile
data points that should be annotated under some budget of labeling cost. Based
on the intuition that the few-shot training instances should be diverse and
representative of the entire data distribution, we propose a simple selection
strategy with K-means clustering. We show that even with the naive
clustering-based approach, the generation models consistently outperform random
sampling on three text generation tasks: data-to-text generation, document
summarization and question generation. We hope that this work will call for
more attention on this largely unexplored area.",2021-07-07
Structured Denoising Diffusion Models in Discrete State-Spaces,2021-07-07 04:11:00+00:00,http://arxiv.org/abs/2107.03006v2,"Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, Rianne van den Berg","cs.LG, cs.AI, cs.CL, cs.CV",table2text,"Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.",2021-07-07
Scarecrow: A Framework for Scrutinizing Machine Text,2021-07-02 22:37:03+00:00,http://arxiv.org/abs/2107.01294v2,"Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, Yejin Choi",cs.CL,table2text,"Modern neural text generation systems can produce remarkably fluent and
grammatical texts. While earlier language models suffered from repetition and
syntactic errors, the errors made by contemporary models are often semantic,
narrative, or discourse failures.
  To facilitate research of these complex error types, we introduce a new
structured, crowdsourced error annotation schema called Scarecrow. The error
categories used in Scarecrow -- such as redundancy, commonsense errors, and
incoherence -- were identified by combining expert analysis with several pilot
rounds of ontology-free crowd annotation to arrive at a schema which covers the
error phenomena found in real machine generated text.
  We use Scarecrow to collect 13k annotations of 1.3k human and machine
generate paragraphs of English language news text, amounting to over 41k spans
each labeled with its error category, severity, a natural language explanation,
and antecedent span (where relevant). We collect annotations for text generated
by state-of-the-art systems with varying known performance levels, from GPT-2
Small through the largest GPT-3. We isolate several factors for detailed
analysis, including parameter count, training data, and decoding technique. Our
results show both expected and surprising differences across these settings.
These findings demonstrate the value of Scarecrow annotations in the assessment
of current and future text generation systems. We release our complete
annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.",2021-07-02
Topic-to-Essay Generation with Comprehensive Knowledge Enhancement,2021-06-29 08:01:42+00:00,http://arxiv.org/abs/2106.15142v1,"Zhiyue Liu, Jiahai Wang, Zhenghong Li",cs.CL,table2text,"Generating high-quality and diverse essays with a set of topics is a
challenging task in natural language generation. Since several given topics
only provide limited source information, utilizing various topic-related
knowledge is essential for improving essay generation performance. However,
previous works cannot sufficiently use that knowledge to facilitate the
generation procedure. This paper aims to improve essay generation by extracting
information from both internal and external knowledge. Thus, a topic-to-essay
generation model with comprehensive knowledge enhancement, named TEGKE, is
proposed. For internal knowledge enhancement, both topics and related essays
are fed to a teacher network as source information. Then, informative features
would be obtained from the teacher network and transferred to a student network
which only takes topics as input but provides comparable information compared
with the teacher network. For external knowledge enhancement, a topic knowledge
graph encoder is proposed. Unlike the previous works only using the nearest
neighbors of topics in the commonsense base, our topic knowledge graph encoder
could exploit more structural and semantic information of the commonsense
knowledge graph to facilitate essay generation. Moreover, the adversarial
training based on the Wasserstein distance is proposed to improve generation
quality. Experimental results demonstrate that TEGKE could achieve
state-of-the-art performance on both automatic and human evaluation.",2021-06-29
"DeltaLM: Encoder-Decoder Pre-training for Language Generation and
  Translation by Augmenting Pretrained Multilingual Encoders",2021-06-25 16:12:10+00:00,http://arxiv.org/abs/2106.13736v1,"Shuming Ma, Li Dong, Shaohan Huang, Dongdong Zhang, Alexandre Muzio, Saksham Singhal, Hany Hassan Awadalla, Xia Song, Furu Wei",cs.CL,table2text,"While pretrained encoders have achieved success in various natural language
understanding (NLU) tasks, there is a gap between these pretrained encoders and
natural language generation (NLG). NLG tasks are often based on the
encoder-decoder framework, where the pretrained encoders can only benefit part
of it. To reduce this gap, we introduce DeltaLM, a pretrained multilingual
encoder-decoder model that regards the decoder as the task layer of
off-the-shelf pretrained encoders. Specifically, we augment the pretrained
multilingual encoder with a decoder and pre-train it in a self-supervised way.
To take advantage of both the large-scale monolingual data and bilingual data,
we adopt the span corruption and translation span corruption as the
pre-training tasks. Experiments show that DeltaLM outperforms various strong
baselines on both natural language generation and translation tasks, including
machine translation, abstractive text summarization, data-to-text, and question
generation.",2021-06-25
Membership Inference on Word Embedding and Beyond,2021-06-21 19:37:06+00:00,http://arxiv.org/abs/2106.11384v1,"Saeed Mahloujifar, Huseyin A. Inan, Melissa Chase, Esha Ghosh, Marcello Hasegawa","cs.CL, cs.AI, cs.CR, cs.LG",table2text,"In the text processing context, most ML models are built on word embeddings.
These embeddings are themselves trained on some datasets, potentially
containing sensitive data. In some cases this training is done independently,
in other cases, it occurs as part of training a larger, task-specific model. In
either case, it is of interest to consider membership inference attacks based
on the embedding layer as a way of understanding sensitive information leakage.
But, somewhat surprisingly, membership inference attacks on word embeddings and
their effect in other natural language processing (NLP) tasks that use these
embeddings, have remained relatively unexplored.
  In this work, we show that word embeddings are vulnerable to black-box
membership inference attacks under realistic assumptions. Furthermore, we show
that this leakage persists through two other major NLP applications:
classification and text-generation, even when the embedding layer is not
exposed to the attacker. We show that our MI attack achieves high attack
accuracy against a classifier model and an LSTM-based language model. Indeed,
our attack is a cheaper membership inference attack on text-generative models,
which does not require the knowledge of the target model or any expensive
training of text-generative models as shadow models.",2021-06-21
"Do Encoder Representations of Generative Dialogue Models Encode
  Sufficient Information about the Task ?",2021-06-20 04:52:37+00:00,http://arxiv.org/abs/2106.10622v1,"Prasanna Parthasarathi, Joelle Pineau, Sarath Chandar",cs.CL,table2text,"Predicting the next utterance in dialogue is contingent on encoding of users'
input text to generate appropriate and relevant response in data-driven
approaches. Although the semantic and syntactic quality of the language
generated is evaluated, more often than not, the encoded representation of
input is not evaluated. As the representation of the encoder is essential for
predicting the appropriate response, evaluation of encoder representation is a
challenging yet important problem. In this work, we showcase evaluating the
text generated through human or automatic metrics is not sufficient to
appropriately evaluate soundness of the language understanding of dialogue
models and, to that end, propose a set of probe tasks to evaluate encoder
representation of different language encoders commonly used in dialogue models.
From experiments, we observe that some of the probe tasks are easier and some
are harder for even sophisticated model architectures to learn. And, through
experiments we observe that RNN based architectures have lower performance on
automatic metrics on text generation than transformer model but perform better
than the transformer model on the probe tasks indicating that RNNs might
preserve task information better than the Transformers.",2021-06-20
"JointGT: Graph-Text Joint Representation Learning for Text Generation
  from Knowledge Graphs",2021-06-19 14:10:10+00:00,http://arxiv.org/abs/2106.10502v1,"Pei Ke, Haozhe Ji, Yu Ran, Xin Cui, Liwei Wang, Linfeng Song, Xiaoyan Zhu, Minlie Huang","cs.CL, cs.AI",table2text,"Existing pre-trained models for knowledge-graph-to-text (KG-to-text)
generation simply fine-tune text-to-text pre-trained models such as BART or T5
on KG-to-text datasets, which largely ignore the graph structure during
encoding and lack elaborate pre-training tasks to explicitly model graph-text
alignments. To tackle these problems, we propose a graph-text joint
representation learning model called JointGT. During encoding, we devise a
structure-aware semantic aggregation module which is plugged into each
Transformer layer to preserve the graph structure. Furthermore, we propose
three new pre-training tasks to explicitly enhance the graph-text alignment
including respective text / graph reconstruction, and graph-text alignment in
the embedding space via Optimal Transport. Experiments show that JointGT
obtains new state-of-the-art performance on various KG-to-text datasets.",2021-06-19
Zero-Shot Controlled Generation with Encoder-Decoder Transformers,2021-06-11 14:07:19+00:00,http://arxiv.org/abs/2106.06411v2,"Devamanyu Hazarika, Mahdi Namazifar, Dilek Hakkani-Tür","cs.CL, cs.AI",table2text,"Controlling neural network-based models for natural language generation (NLG)
has broad applications in numerous areas such as machine translation, document
summarization, and dialog systems. Approaches that enable such control in a
zero-shot manner would be of great importance as, among other reasons, they
remove the need for additional annotated data and training. In this work, we
propose novel approaches for controlling encoder-decoder transformer-based NLG
models in zero-shot. This is done by introducing three control knobs, namely,
attention biasing, decoder mixing, and context augmentation, that are applied
to these models at generation time. These knobs control the generation process
by directly manipulating trained NLG models (e.g., biasing cross-attention
layers) to realize the desired attributes in the generated outputs. We show
that not only are these NLG models robust to such manipulations, but also their
behavior could be controlled without an impact on their generation performance.
These results, to the best of our knowledge, are the first of their kind.
Through these control knobs, we also investigate the role of transformer
decoder's self-attention module and show strong evidence that its primary role
is maintaining fluency of sentences generated by these models. Based on this
hypothesis, we show that alternative architectures for transformer decoders
could be viable options. We also study how this hypothesis could lead to more
efficient ways for training encoder-decoder transformer models.",2021-06-11
"AUGNLG: Few-shot Natural Language Generation using Self-trained Data
  Augmentation",2021-06-10 08:45:28+00:00,http://arxiv.org/abs/2106.05589v1,"Xinnuo Xu, Guoyin Wang, Young-Bum Kim, Sungjin Lee",cs.CL,table2text,"Natural Language Generation (NLG) is a key component in a task-oriented
dialogue system, which converts the structured meaning representation (MR) to
the natural language. For large-scale conversational systems, where it is
common to have over hundreds of intents and thousands of slots, neither
template-based approaches nor model-based approaches are scalable. Recently,
neural NLGs started leveraging transfer learning and showed promising results
in few-shot settings. This paper proposes AUGNLG, a novel data augmentation
approach that combines a self-trained neural retrieval model with a few-shot
learned NLU model, to automatically create MR-to-Text data from open-domain
texts. The proposed system mostly outperforms the state-of-the-art methods on
the FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm
improved results on the FewShotSGD data and provide comprehensive analysis
results on key components of our system. Our code and data are available at
https://github.com/XinnuoXu/AugNLG.",2021-06-10
AGGGEN: Ordering and Aggregating while Generating,2021-06-10 08:14:59+00:00,http://arxiv.org/abs/2106.05580v1,"Xinnuo Xu, Ondřej Dušek, Verena Rieser, Ioannis Konstas",cs.CL,table2text,"We present AGGGEN (pronounced 'again'), a data-to-text model which
re-introduces two explicit sentence planning stages into neural data-to-text
systems: input ordering and input aggregation. In contrast to previous work
using sentence planning, our model is still end-to-end: AGGGEN performs
sentence planning at the same time as generating text by learning latent
alignments (via semantic facts) between input representation and target text.
Experiments on the WebNLG and E2E challenge data show that by using fact-based
alignments our approach is more interpretable, expressive, robust to noise, and
easier to control, while retaining the advantages of end-to-end systems in
terms of fluency. Our code is available at https://github.com/XinnuoXu/AggGen.",2021-06-10
"Turing: an Accurate and Interpretable Multi-Hypothesis Cross-Domain
  Natural Language Database Interface",2021-06-08 17:46:20+00:00,http://arxiv.org/abs/2106.04559v1,"Peng Xu, Wenjie Zi, Hamidreza Shahidi, Ákos Kádár, Keyi Tang, Wei Yang, Jawad Ateeq, Harsh Barot, Meidan Alon, Yanshuai Cao",cs.CL,table2text,"A natural language database interface (NLDB) can democratize data-driven
insights for non-technical users. However, existing Text-to-SQL semantic
parsers cannot achieve high enough accuracy in the cross-database setting to
allow good usability in practice. This work presents Turing, a NLDB system
toward bridging this gap. The cross-domain semantic parser of Turing with our
novel value prediction method achieves $75.1\%$ execution accuracy, and
$78.3\%$ top-5 beam execution accuracy on the Spider validation set. To benefit
from the higher beam accuracy, we design an interactive system where the SQL
hypotheses in the beam are explained step-by-step in natural language, with
their differences highlighted. The user can then compare and judge the
hypotheses to select which one reflects their intention if any. The English
explanations of SQL queries in Turing are produced by our high-precision
natural language generation system based on synchronous grammars.",2021-06-08
Neural semi-Markov CRF for Monolingual Word Alignment,2021-06-04 16:04:00+00:00,http://arxiv.org/abs/2106.02569v1,"Wuwei Lan, Chao Jiang, Wei Xu",cs.CL,table2text,"Monolingual word alignment is important for studying fine-grained editing
operations (i.e., deletion, addition, and substitution) in text-to-text
generation tasks, such as paraphrase generation, text simplification,
neutralizing biased language, etc. In this paper, we present a novel neural
semi-Markov CRF alignment model, which unifies word and phrase alignments
through variable-length spans. We also create a new benchmark with human
annotations that cover four different text genres to evaluate monolingual word
alignment models in more realistic settings. Experimental results show that our
proposed model outperforms all previous approaches for monolingual word
alignment as well as a competitive QA-based baseline, which was previously only
applied to bilingual data. Our model demonstrates good generalizability to
three out-of-domain datasets and shows great utility in two downstream
applications: automatic text simplification and sentence pair classification
tasks.",2021-06-04
Defending against Backdoor Attacks in Natural Language Generation,2021-06-03 13:00:28+00:00,http://arxiv.org/abs/2106.01810v1,"Chun Fan, Xiaoya Li, Yuxian Meng, Xiaofei Sun, Xiang Ao, Fei Wu, Jiwei Li, Tianwei Zhang",cs.CL,table2text,"The frustratingly fragile nature of neural network models make current
natural language generation (NLG) systems prone to backdoor attacks and
generate malicious sequences that could be sexist or offensive. Unfortunately,
little effort has been invested to how backdoor attacks can affect current NLG
models and how to defend against these attacks. In this work, we investigate
this problem on two important NLG tasks, machine translation and dialogue
generation. By giving a formal definition for backdoor attack and defense, and
developing corresponding benchmarks, we design methods to attack NLG models,
which achieve high attack success to ask NLG models to generate malicious
sequences. To defend against these attacks, we propose to detect the attack
trigger by examining the effect of deleting or replacing certain words on the
generation outputs, which we find successful for certain types of attacks. We
will discuss the limitation of this work, and hope this work can raise the
awareness of backdoor risks concealed in deep NLG systems. (Code and data are
available at https://github.com/ShannonAI/backdoor_nlg.)",2021-06-03
"ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language
  Generation",2021-06-03 05:08:01+00:00,http://arxiv.org/abs/2106.01597v1,"Kaushal Kumar Maurya, Maunendra Sankar Desarkar, Yoshinobu Kano, Kumari Deepshikha","cs.CL, cs.AI, cs.LG",table2text,"Despite the recent advancement in NLP research, cross-lingual transfer for
natural language generation is relatively understudied. In this work, we
transfer supervision from high resource language (HRL) to multiple low-resource
languages (LRLs) for natural language generation (NLG). We consider four NLG
tasks (text summarization, question generation, news headline generation, and
distractor generation) and three syntactically diverse languages, i.e.,
English, Hindi, and Japanese. We propose an unsupervised cross-lingual language
generation framework (called ZmBART) that does not use any parallel or
pseudo-parallel/back-translated data. In this framework, we further pre-train
mBART sequence-to-sequence denoising auto-encoder model with an auxiliary task
using monolingual data of three languages. The objective function of the
auxiliary task is close to the target tasks which enriches the multi-lingual
latent representation of mBART and provides good initialization for target
tasks. Then, this model is fine-tuned with task-specific supervised English
data and directly evaluated with low-resource languages in the Zero-shot
setting. To overcome catastrophic forgetting and spurious correlation issues,
we applied freezing model component and data argumentation approaches
respectively. This simple modeling approach gave us promising results.We
experimented with few-shot training (with 1000 supervised data points) which
boosted the model performance further. We performed several ablations and
cross-lingual transferability analyses to demonstrate the robustness of ZmBART.",2021-06-03
"Sketch and Refine: Towards Faithful and Informative Table-to-Text
  Generation",2021-05-31 08:18:13+00:00,http://arxiv.org/abs/2105.14778v1,"Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang, Jingren Zhou, Hongxia Yang",cs.CL,table2text,"Table-to-text generation refers to generating a descriptive text from a
key-value table. Traditional autoregressive methods, though can generate text
with high fluency, suffer from low coverage and poor faithfulness problems. To
mitigate these problems, we propose a novel Skeleton-based two-stage method
that combines both Autoregressive and Non-Autoregressive generations (SANA).
Our approach includes: (1) skeleton generation with an autoregressive pointer
network to select key tokens from the source table; (2) edit-based
non-autoregressive generation model to produce texts via iterative insertion
and deletion operations. By integrating hard constraints from the skeleton, the
non-autoregressive model improves the generation's coverage over the source
table and thus enhances its faithfulness. We conduct automatic and human
evaluations on both WikiPerson and WikiBio datasets. Experimental results
demonstrate that our method outperforms the previous state-of-the-art methods
in both automatic and human evaluation, especially on coverage and
faithfulness. In particular, we achieve PARENT-T recall of 99.47 in WikiPerson,
improving over the existing best results by more than 10 points.",2021-05-31
"Grammar Accuracy Evaluation (GAE): Quantifiable Intrinsic Evaluation of
  Machine Translation Models",2021-05-29 11:40:51+00:00,http://arxiv.org/abs/2105.14277v2,"Dojun Park, Youngjin Jang, Harksoo Kim",cs.CL,table2text,"Intrinsic evaluation by humans for the performance of natural language
generation models is conducted to overcome the fact that the quality of
generated sentences cannot be fully represented by only extrinsic evaluation.
Nevertheless, existing intrinsic evaluations have a large score deviation
according to the evaluator's criteria. In this paper, we propose Grammar
Accuracy Evaluation (GAE) that can provide specific evaluating criteria. As a
result of analyzing the quality of machine translation by BLEU and GAE, it was
confirmed that the BLEU score does not represent the absolute performance of
machine translation models and that GAE compensates for the shortcomings of
BLEU with a flexible evaluation on alternative synonyms and changes in sentence
structure.",2021-05-29
Annotation Inconsistency and Entity Bias in MultiWOZ,2021-05-29 00:09:06+00:00,http://arxiv.org/abs/2105.14150v1,"Kun Qian, Ahmad Beirami, Zhouhan Lin, Ankita De, Alborz Geramifard, Zhou Yu, Chinnadhurai Sankar",cs.CL,table2text,"MultiWOZ is one of the most popular multi-domain task-oriented dialog
datasets, containing 10K+ annotated dialogs covering eight domains. It has been
widely accepted as a benchmark for various dialog tasks, e.g., dialog state
tracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog
modeling. In this work, we identify an overlooked issue with dialog state
annotation inconsistencies in the dataset, where a slot type is tagged
inconsistently across similar dialogs leading to confusion for DST modeling. We
propose an automated correction for this issue, which is present in a whopping
70% of the dialogs. Additionally, we notice that there is significant entity
bias in the dataset (e.g., ""cambridge"" appears in 50% of the destination cities
in the train domain). The entity bias can potentially lead to named entity
memorization in generative models, which may go unnoticed as the test set
suffers from a similar entity bias as well. We release a new test set with all
entities replaced with unseen entities. Finally, we benchmark joint goal
accuracy (JGA) of the state-of-the-art DST baselines on these modified versions
of the data. Our experiments show that the annotation inconsistency corrections
lead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in
JGA when models are evaluated on the new test set with unseen entities.",2021-05-29
OTTers: One-turn Topic Transitions for Open-Domain Dialogue,2021-05-28 10:16:59+00:00,http://arxiv.org/abs/2105.13710v1,"Karin Sevegnani, David M. Howcroft, Ioannis Konstas, Verena Rieser",cs.CL,table2text,"Mixed initiative in open-domain dialogue requires a system to pro-actively
introduce new topics. The one-turn topic transition task explores how a system
connects two topics in a cooperative and coherent manner. The goal of the task
is to generate a ""bridging"" utterance connecting the new topic to the topic of
the previous conversation turn. We are especially interested in commonsense
explanations of how a new topic relates to what has been mentioned before. We
first collect a new dataset of human one-turn topic transitions, which we call
OTTers. We then explore different strategies used by humans when asked to
complete such a task, and notice that the use of a bridging utterance to
connect the two topics is the approach used the most. We finally show how
existing state-of-the-art text generation models can be adapted to this task
and examine the performance of these baselines on different splits of the
OTTers data.",2021-05-28
Data Augmentation for Text Generation Without Any Augmented Data,2021-05-28 07:56:51+00:00,http://arxiv.org/abs/2105.13650v1,"Wei Bi, Huayang Li, Jiacheng Huang","cs.CL, cs.AI",table2text,"Data augmentation is an effective way to improve the performance of many
neural text generation models. However, current data augmentation methods need
to define or choose proper data mapping functions that map the original samples
into the augmented samples. In this work, we derive an objective to formulate
the problem of data augmentation on text generation tasks without any use of
augmented data constructed by specific mapping functions. Our proposed
objective can be efficiently optimized and applied to popular loss functions on
text generation tasks with a convergence rate guarantee. Experiments on five
datasets of two text generation tasks show that our approach can approximate or
even surpass popular data augmentation methods.",2021-05-28
Generative Adversarial Imitation Learning for Empathy-based AI,2021-05-27 17:37:37+00:00,http://arxiv.org/abs/2105.13328v1,"Pratyush Muthukumar, Karishma Muthukumar, Deepan Muthirayan, Pramod Khargonekar",cs.CL,table2text,"Generative adversarial imitation learning (GAIL) is a model-free algorithm
that has been shown to provide strong results in imitating complex behaviors in
high-dimensional environments. In this paper, we utilize the GAIL model for
text generation to develop empathy-based context-aware conversational AI. Our
model uses an expert trajectory of empathetic prompt-response dialogues which
can accurately exhibit the correct empathetic emotion when generating a
response. The Generator of the GAIL model uses the GPT-2 sequential pre-trained
language model trained on 117 million parameters from 40 GB of internet data.
We propose a novel application of an approach used in transfer learning to fine
tune the GPT-2 model in order to generate concise, user-specific empathetic
responses validated against the Discriminator. Our novel GAIL model utilizes a
sentiment analysis history-based reinforcement learning approach to
empathetically respond to human interactions in a personalized manner. We find
that our model's response scores on various human-generated prompts collected
from the Facebook Empathetic Dialogues dataset outperform baseline
counterparts. Moreover, our model improves upon various history-based
conversational AI models developed recently, as our model's performance over a
sustained conversation of 3 or more interactions outperform similar
conversational AI models.",2021-05-27
"Empirical Error Modeling Improves Robustness of Noisy Neural Sequence
  Labeling",2021-05-25 12:15:45+00:00,http://arxiv.org/abs/2105.11872v1,"Marcin Namysl, Sven Behnke, Joachim Köhler",cs.CL,table2text,"Despite recent advances, standard sequence labeling systems often fail when
processing noisy user-generated text or consuming the output of an Optical
Character Recognition (OCR) process. In this paper, we improve the noise-aware
training method by proposing an empirical error generation approach that
employs a sequence-to-sequence model trained to perform translation from
error-free to erroneous text. Using an OCR engine, we generated a large
parallel text corpus for training and produced several real-world noisy
sequence labeling benchmarks for evaluation. Moreover, to overcome the data
sparsity problem that exacerbates in the case of imperfect textual input, we
learned noisy language model-based embeddings. Our approach outperformed the
baseline noise generation and error correction techniques on the erroneous
sequence labeling data sets. To facilitate future research on robustness, we
make our code, embeddings, and data conversion scripts publicly available.",2021-05-25
Controlling Text Edition by Changing Answers of Specific Questions,2021-05-23 20:44:15+00:00,http://arxiv.org/abs/2105.11018v1,"Lei Sha, Patrick Hohenecker, Thomas Lukasiewicz","cs.CL, cs.AI, cs.LG",table2text,"In this paper, we introduce the new task of controllable text edition, in
which we take as input a long text, a question, and a target answer, and the
output is a minimally modified text, so that it fits the target answer. This
task is very important in many situations, such as changing some conditions,
consequences, or properties in a legal document, or changing some key
information of an event in a news text. This is very challenging, as it is hard
to obtain a parallel corpus for training, and we need to first find all text
positions that should be changed and then decide how to change them. We
constructed the new dataset WikiBioCTE for this task based on the existing
dataset WikiBio (originally created for table-to-text generation). We use
WikiBioCTE for training, and manually labeled a test set for testing. We also
propose novel evaluation metrics and a novel method for solving the new task.
Experimental results on the test set show that our proposed method is a good
fit for this novel NLP task.",2021-05-23
Pretrained Language Models for Text Generation: A Survey,2021-05-21 12:27:44+00:00,http://arxiv.org/abs/2105.10311v2,"Junyi Li, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen","cs.CL, cs.AI",table2text,"Text generation has become one of the most important yet challenging tasks in
natural language processing (NLP). The resurgence of deep learning has greatly
advanced this field by neural generation models, especially the paradigm of
pretrained language models (PLMs). In this paper, we present an overview of the
major advances achieved in the topic of PLMs for text generation. As the
preliminaries, we present the general task definition and briefly describe the
mainstream architectures of PLMs for text generation. As the core content, we
discuss how to adapt existing PLMs to model different input data and satisfy
special properties in the generated text. We further summarize several
important fine-tuning strategies for text generation. Finally, we present
several future directions and conclude this paper. Our survey aims to provide
text generation researchers a synthesis and pointer to related research.",2021-05-21
"Towards a Universal NLG for Dialogue Systems and Simulators with Future
  Bridging",2021-05-21 10:37:10+00:00,http://arxiv.org/abs/2105.10267v2,"Philipp Ennen, Yen-Ting Lin, Ali Girayhan Ozbay, Ferdinando Insalata, Maolin Li, Ye Tian, Sepehr Jalali, Da-shan Shiu","cs.CL, cs.AI, cs.LG",table2text,"In a dialogue system pipeline, a natural language generation (NLG) unit
converts the dialogue direction and content to a corresponding natural language
realization. A recent trend for dialogue systems is to first pre-train on large
datasets and then fine-tune in a supervised manner using datasets annotated
with application-specific features. Though novel behaviours can be learned from
custom annotation, the required effort severely bounds the quantity of the
training set, and the application-specific nature limits the reuse. In light of
the recent success of data-driven approaches, we propose the novel future
bridging NLG (FBNLG) concept for dialogue systems and simulators. The critical
step is for an FBNLG to accept a future user or system utterance to bridge the
present context towards. Future bridging enables self supervised training over
annotation-free datasets, decoupled the training of NLG from the rest of the
system. An FBNLG, pre-trained with massive datasets, is expected to apply in
classical or new dialogue scenarios with minimal adaptation effort. We evaluate
a prototype FBNLG to show that future bridging can be a viable approach to a
universal few-shot NLG for task-oriented and chit-chat dialogues.",2021-05-21
Retrieval-Augmented Transformer-XL for Close-Domain Dialog Generation,2021-05-19 16:34:33+00:00,http://arxiv.org/abs/2105.09235v1,"Giovanni Bonetta, Rossella Cancelliere, Ding Liu, Paul Vozila","cs.CL, cs.AI",table2text,"Transformer-based models have demonstrated excellent capabilities of
capturing patterns and structures in natural language generation and achieved
state-of-the-art results in many tasks. In this paper we present a
transformer-based model for multi-turn dialog response generation. Our solution
is based on a hybrid approach which augments a transformer-based generative
model with a novel retrieval mechanism, which leverages the memorized
information in the training data via k-Nearest Neighbor search. Our system is
evaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1,
released by Google and holding high quality, goal-oriented conversational data
and a proprietary dataset collected from a real customer service call center.
Both achieve better BLEU scores over strong baselines.",2021-05-19
"Long Text Generation by Modeling Sentence-Level and Discourse-Level
  Coherence",2021-05-19 07:29:08+00:00,http://arxiv.org/abs/2105.08963v1,"Jian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wenbiao Ding, Minlie Huang",cs.CL,table2text,"Generating long and coherent text is an important but challenging task,
particularly for open-ended language generation tasks such as story generation.
Despite the success in modeling intra-sentence coherence, existing generation
models (e.g., BART) still struggle to maintain a coherent event sequence
throughout the generated text. We conjecture that this is because of the
difficulty for the decoder to capture the high-level semantics and discourse
structures in the context beyond token-level co-occurrence. In this paper, we
propose a long text generation model, which can represent the prefix sentences
at sentence level and discourse level in the decoding process. To this end, we
propose two pretraining objectives to learn the representations by predicting
inter-sentence semantic similarity and distinguishing between normal and
shuffled sentence orders. Extensive experiments show that our model can
generate more coherent texts than state-of-the-art baselines.",2021-05-19
CoTexT: Multi-task Learning with Code-Text Transformer,2021-05-18 16:22:05+00:00,http://arxiv.org/abs/2105.08645v1,"Long Phan, Hieu Tran, Daniel Le, Hieu Nguyen, James Anibal, Alec Peltekian, Yanfang Ye","cs.AI, cs.PL",table2text,"We present CoTexT, a transformer-based architecture encoder-decoder
pre-trained model that learns the representative context between natural
language (NL) and programming language (PL) through multi-task learning. CoTexT
is pre-trained, in self-supervised fashion, based on large programming language
corpus to learn general-purpose understanding and code-text generation
supporting downstream NL-PL task such as code summarizing/documentation, code
generation, defect detection, code debugging, etc. We train CoTexT on different
combination of available PL corpus including both ""bimodal"" and ""unimodal"" data
where the former is the combinations of both natural texts and their
corresponding code snippets in an input sequence and the latter is merely code
snippets. We evaluate multi-task learning CoTexT on different generation and
classification tasks on CodeXGLUE and it achieves state-of-the-art on all
downstream tasks.",2021-05-18
Stage-wise Fine-tuning for Graph-to-Text Generation,2021-05-17 17:15:29+00:00,http://arxiv.org/abs/2105.08021v1,"Qingyun Wang, Semih Yavuz, Victoria Lin, Heng Ji, Nazneen Rajani","cs.CL, cs.AI",table2text,"Graph-to-text generation has benefited from pre-trained language models
(PLMs) in achieving better performance than structured graph encoders. However,
they fail to fully utilize the structure information of the input graph. In
this paper, we aim to further improve the performance of the pre-trained
language model by proposing a structured graph-to-text model with a two-step
fine-tuning mechanism which first fine-tunes model on Wikipedia before adapting
to the graph-to-text generation. In addition to using the traditional token and
position embeddings to encode the knowledge graph (KG), we propose a novel
tree-level embedding method to capture the inter-dependency structures of the
input graph. This new approach has significantly improved the performance of
all text generation metrics for the English WebNLG 2017 dataset.",2021-05-17
R2D2: Relational Text Decoding with Transformers,2021-05-10 19:59:11+00:00,http://arxiv.org/abs/2105.04645v1,"Aryan Arbabi, Mingqiu Wang, Laurent El Shafey, Nan Du, Izhak Shafran",cs.CL,table2text,"We propose a novel framework for modeling the interaction between graphical
structures and the natural language text associated with their nodes and edges.
Existing approaches typically fall into two categories. On group ignores the
relational structure by converting them into linear sequences and then utilize
the highly successful Seq2Seq models. The other side ignores the sequential
nature of the text by representing them as fixed-dimensional vectors and apply
graph neural networks. Both simplifications lead to information loss.
  Our proposed method utilizes both the graphical structure as well as the
sequential nature of the texts. The input to our model is a set of text
segments associated with the nodes and edges of the graph, which are then
processed with a transformer encoder-decoder model, equipped with a
self-attention mechanism that is aware of the graphical relations between the
nodes containing the segments. This also allows us to use BERT-like models that
are already trained on large amounts of text.
  While the proposed model has wide applications, we demonstrate its
capabilities on data-to-text generation tasks. Our approach compares favorably
against state-of-the-art methods in four tasks without tailoring the model
architecture. We also provide an early demonstration in a novel practical
application -- generating clinical notes from the medical entities mentioned
during clinical visits.",2021-05-10
Knowledge-based Review Generation by Coherence Enhanced Text Planning,2021-05-09 02:12:05+00:00,http://arxiv.org/abs/2105.03815v1,"Junyi Li, Wayne Xin Zhao, Zhicheng Wei, Nicholas Jing Yuan, Ji-Rong Wen",cs.CL,table2text,"As a natural language generation task, it is challenging to generate
informative and coherent review text. In order to enhance the informativeness
of the generated text, existing solutions typically learn to copy entities or
triples from knowledge graphs (KGs). However, they lack overall consideration
to select and arrange the incorporated knowledge, which tends to cause text
incoherence.
  To address the above issue, we focus on improving entity-centric coherence of
the generated reviews by leveraging the semantic structure of KGs. In this
paper, we propose a novel Coherence Enhanced Text Planning model (CETP) based
on knowledge graphs (KGs) to improve both global and local coherence for review
generation. The proposed model learns a two-level text plan for generating a
document: (1) the document plan is modeled as a sequence of sentence plans in
order, and (2) the sentence plan is modeled as an entity-based subgraph from
KG. Local coherence can be naturally enforced by KG subgraphs through
intra-sentence correlations between entities. For global coherence, we design a
hierarchical self-attentive architecture with both subgraph- and node-level
attention to enhance the correlations between subgraphs. To our knowledge, we
are the first to utilize a KG-based text planning model to enhance text
coherence for review generation. Extensive experiments on three datasets
confirm the effectiveness of our model on improving the content coherence of
generated texts.",2021-05-09
Neural Text Generation with Part-of-Speech Guided Softmax,2021-05-08 08:53:16+00:00,http://arxiv.org/abs/2105.03641v1,"Zhixian Yang, Xiaojun Wan","cs.CL, cs.AI",table2text,"Neural text generation models are likely to suffer from the low-diversity
problem. Various decoding strategies and training-based methods have been
proposed to promote diversity only by exploiting contextual features, but
rarely do they consider incorporating syntactic structure clues. In this work,
we propose using linguistic annotation, i.e., part-of-speech (POS), to guide
the text generation. In detail, we introduce POS Guided Softmax (POSG-Softmax)
to explicitly model two posterior probabilities: (i) next-POS, and (ii)
next-token from the vocabulary of the target POS. A POS guided sampling
strategy is further proposed to address the low-diversity problem by enriching
the diversity of POS. Extensive experiments and human evaluations demonstrate
that, compared with existing state-of-the-art methods, our proposed methods can
generate more diverse text while maintaining comparable quality.",2021-05-08
Hidden Backdoors in Human-Centric Language Models,2021-05-01 04:41:00+00:00,http://arxiv.org/abs/2105.00164v1,"Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu","cs.CL, cs.CR",table2text,"Natural language processing (NLP) systems have been proven to be vulnerable
to backdoor attacks, whereby hidden features (backdoors) are trained into a
language model and may only be activated by specific inputs (called triggers),
to trick the model into producing unexpected behaviors. In this paper, we
create covert and natural triggers for textual backdoor attacks, \textit{hidden
backdoors}, where triggers can fool both modern language models and human
inspection. We deploy our hidden backdoors through two state-of-the-art trigger
embedding methods. The first approach via homograph replacement, embeds the
trigger into deep neural networks through the visual spoofing of lookalike
character replacement. The second approach uses subtle differences between text
generated by language models and real natural text to produce trigger sentences
with correct grammar and high fluency. We demonstrate that the proposed hidden
backdoors can be effective across three downstream security-critical NLP tasks,
representative of modern human-centric NLP systems, including toxic comment
detection, neural machine translation (NMT), and question answering (QA). Our
two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at
least $97\%$ with an injection rate of only $3\%$ in toxic comment detection,
$95.1\%$ ASR in NMT with less than $0.5\%$ injected data, and finally $91.12\%$
ASR against QA updated with only 27 poisoning data samples on a model
previously trained with 92,024 samples (0.029\%). We are able to demonstrate
the adversary's high success rate of attacks, while maintaining functionality
for regular users, with triggers inconspicuous by the human administrators.",2021-05-01
"Mitigating Political Bias in Language Models Through Reinforced
  Calibration",2021-04-30 07:21:30+00:00,http://arxiv.org/abs/2104.14795v1,"Ruibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu, Lili Wang, Soroush Vosoughi","cs.CL, cs.AI",table2text,"Current large-scale language models can be politically biased as a result of
the data they are trained on, potentially causing serious problems when they
are deployed in real-world settings. In this paper, we describe metrics for
measuring political bias in GPT-2 generation and propose a reinforcement
learning (RL) framework for mitigating political biases in generated text. By
using rewards from word embeddings or a classifier, our RL framework guides
debiased generation without having access to the training data or requiring the
model to be retrained. In empirical experiments on three attributes sensitive
to political bias (gender, location, and topic), our methods reduced bias
according to both our metrics and human evaluation, while maintaining
readability and semantic coherence.",2021-04-30
Text Generation with Deep Variational GAN,2021-04-27 21:42:13+00:00,http://arxiv.org/abs/2104.13488v1,"Mahmoud Hossam, Trung Le, Michael Papasimeon, Viet Huynh, Dinh Phung","cs.LG, cs.AI, cs.CL, I.2.0; I.2.7; I.5.0",table2text,"Generating realistic sequences is a central task in many machine learning
applications. There has been considerable recent progress on building deep
generative models for sequence generation tasks. However, the issue of
mode-collapsing remains a main issue for the current models. In this paper we
propose a GAN-based generic framework to address the problem of mode-collapse
in a principled approach. We change the standard GAN objective to maximize a
variational lower-bound of the log-likelihood while minimizing the
Jensen-Shanon divergence between data and model distributions. We experiment
our model with text generation task and show that it can generate realistic
text with high diversity.",2021-04-27
"A Token-level Reference-free Hallucination Detection Benchmark for
  Free-form Text Generation",2021-04-18 04:09:48+00:00,http://arxiv.org/abs/2104.08704v1,"Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao, Zhifang Sui, Weizhu Chen, Bill Dolan","cs.CL, cs.AI",table2text,"Large pretrained generative models like GPT-3 often suffer from hallucinating
non-existent or incorrect content, which undermines their potential merits in
real applications. Existing work usually attempts to detect these
hallucinations based on a corresponding oracle reference at a sentence or
document level. However ground-truth references may not be readily available
for many free-form text generation applications, and sentence- or
document-level detection may fail to provide the fine-grained signals that
would prevent fallacious content in real time. As a first step to addressing
these issues, we propose a novel token-level, reference-free hallucination
detection task and an associated annotated dataset named HaDes (HAllucination
DEtection dataSet). To create this dataset, we first perturb a large number of
text segments extracted from English language Wikipedia, and then verify these
with crowd-sourced annotations. To mitigate label imbalance during annotation,
we utilize an iterative model-in-loop strategy. We conduct comprehensive data
analyses and create multiple baseline models.",2021-04-18
Learning to Reason for Text Generation from Scientific Tables,2021-04-16 18:01:36+00:00,http://arxiv.org/abs/2104.08296v1,"Nafise Sadat Moosavi, Andreas Rücklé, Dan Roth, Iryna Gurevych",cs.CL,table2text,"In this paper, we introduce SciGen, a new challenge dataset for the task of
reasoning-aware data-to-text generation consisting of tables from scientific
articles and their corresponding descriptions. Describing scientific tables
goes beyond the surface realization of the table content and requires reasoning
over table values. The unique properties of SciGen are that (1) tables mostly
contain numerical values, and (2) the corresponding descriptions require
arithmetic reasoning. SciGen is therefore the first dataset that assesses the
arithmetic reasoning capabilities of generation models on complex input
structures, i.e., tables from scientific articles. We study the effectiveness
of state-of-the-art data-to-text generation models on SciGen and evaluate the
results using common metrics as well as human evaluation. Our results and
analyses show that (a) while humans like to reason for describing scientific
tables, the ability of state-of-the-art models is severely limited on this
task, (b) while adding more training data improves the results, it is not the
solution for reasoning-aware text generation, and (c) one of the main
bottlenecks for this task is the lack of proper automatic evaluation metrics.
The data, code, and annotations for human evaluation will be available at
https://github.com/UKPLab/SciGen. SciGen opens new avenues for future research
in reasoning-aware text generation and evaluation.",2021-04-16
"ProphetNet-X: Large-Scale Pre-training Models for English, Chinese,
  Multi-lingual, Dialog, and Code Generation",2021-04-16 10:00:43+00:00,http://arxiv.org/abs/2104.08006v1,"Weizhen Qi, Yeyun Gong, Yu Yan, Can Xu, Bolun Yao, Bartuer Zhou, Biao Cheng, Daxin Jiang, Jiusheng Chen, Ruofei Zhang, Houqiang Li, Nan Duan",cs.CL,table2text,"Now, the pre-training technique is ubiquitous in natural language processing
field. ProphetNet is a pre-training based natural language generation method
which shows powerful performance on English text summarization and question
generation tasks. In this paper, we extend ProphetNet into other domains and
languages, and present the ProphetNet family pre-training models, named
ProphetNet-X, where X can be English, Chinese, Multi-lingual, and so on. We
pre-train a cross-lingual generation model ProphetNet-Multi, a Chinese
generation model ProphetNet-Zh, two open-domain dialog generation models
ProphetNet-Dialog-En and ProphetNet-Dialog-Zh. And also, we provide a PLG
(Programming Language Generation) model ProphetNet-Code to show the generation
performance besides NLG (Natural Language Generation) tasks. In our
experiments, ProphetNet-X models achieve new state-of-the-art performance on 10
benchmarks. All the models of ProphetNet-X share the same model structure,
which allows users to easily switch between different models. We make the code
and models publicly available, and we will keep updating more pre-training
models and finetuning scripts. A video to introduce ProphetNet-X usage is also
released.",2021-04-16
"ExplaGraphs: An Explanation Graph Generation Task for Structured
  Commonsense Reasoning",2021-04-15 17:51:36+00:00,http://arxiv.org/abs/2104.07644v1,"Swarnadeep Saha, Prateek Yadav, Lisa Bauer, Mohit Bansal","cs.CL, cs.AI",table2text,"Recent commonsense-reasoning tasks are typically discriminative in nature,
where a model answers a multiple-choice question for a certain context.
Discriminative tasks are limiting because they fail to adequately evaluate the
model's ability to reason and explain predictions with underlying commonsense
knowledge. They also allow such models to use reasoning shortcuts and not be
""right for the right reasons"". In this work, we present ExplaGraphs, a new
generative and structured commonsense-reasoning task (and an associated
dataset) of explanation graph generation for stance prediction. Specifically,
given a belief and an argument, a model has to predict whether the argument
supports or counters the belief and also generate a commonsense-augmented graph
that serves as non-trivial, complete, and unambiguous explanation for the
predicted stance. The explanation graphs for our dataset are collected via
crowdsourcing through a novel Collect-Judge-And-Refine graph collection
framework that improves the graph quality via multiple rounds of verification
and refinement. A significant 83% of our graphs contain external commonsense
nodes with diverse structures and reasoning depths. We also propose a
multi-level evaluation framework that checks for the structural and semantic
correctness of the generated graphs and their plausibility with human-written
graphs. We experiment with state-of-the-art text generation models like BART
and T5 to generate explanation graphs and observe that there is a large gap
with human performance, thereby encouraging useful future work for this new
commonsense graph-based explanation generation task.",2021-04-15
"Data-QuestEval: A Referenceless Metric for Data to Text Semantic
  Evaluation",2021-04-15 16:10:46+00:00,http://arxiv.org/abs/2104.07555v1,"Clément Rebuffel, Thomas Scialom, Laure Soulier, Benjamin Piwowarski, Sylvain Lamprier, Jacopo Staiano, Geoffrey Scoutheeten, Patrick Gallinari",cs.CL,table2text,"In this paper, we explore how QuestEval, which is a Text-vs-Text metric, can
be adapted for the evaluation of Data-to-Text Generation systems. QuestEval is
a reference-less metric that compares the predictions directly to the
structured input data by automatically asking and answering questions. Its
adaptation to Data-to-Text is not straightforward as it requires multi-modal
Question Generation and Answering (QG \& QA) systems. To this purpose, we
propose to build synthetic multi-modal corpora that enables to train
multi-modal QG/QA. The resulting metric is reference-less, multi-modal; it
obtains state-of-the-art correlations with human judgement on the E2E and
WebNLG benchmark.",2021-04-15
"Plot-guided Adversarial Example Construction for Evaluating Open-domain
  Story Generation",2021-04-12 20:19:24+00:00,http://arxiv.org/abs/2104.05801v1,"Sarik Ghazarian, Zixi Liu, Akash SM, Ralph Weischedel, Aram Galstyan, Nanyun Peng","cs.CL, cs.LG",table2text,"With the recent advances of open-domain story generation, the lack of
reliable automatic evaluation metrics becomes an increasingly imperative issue
that hinders the fast development of story generation. According to conducted
researches in this regard, learnable evaluation metrics have promised more
accurate assessments by having higher correlations with human judgments. A
critical bottleneck of obtaining a reliable learnable evaluation metric is the
lack of high-quality training data for classifiers to efficiently distinguish
plausible and implausible machine-generated stories. Previous works relied on
\textit{heuristically manipulated} plausible examples to mimic possible system
drawbacks such as repetition, contradiction, or irrelevant content in the text
level, which can be \textit{unnatural} and \textit{oversimplify} the
characteristics of implausible machine-generated stories. We propose to tackle
these issues by generating a more comprehensive set of implausible stories
using {\em plots}, which are structured representations of controllable factors
used to generate stories. Since these plots are compact and structured, it is
easier to manipulate them to generate text with targeted undesirable
properties, while at the same time maintain the grammatical correctness and
naturalness of the generated sentences. To improve the quality of generated
implausible stories, we further apply the adversarial filtering procedure
presented by \citet{zellers2018swag} to select a more nuanced set of
implausible texts. Experiments show that the evaluation metrics trained on our
generated data result in more reliable automatic assessments that correlate
remarkably better with human judgments compared to the baselines.",2021-04-12
"StylePTB: A Compositional Benchmark for Fine-grained Controllable Text
  Style Transfer",2021-04-12 04:25:09+00:00,http://arxiv.org/abs/2104.05196v1,"Yiwei Lyu, Paul Pu Liang, Hai Pham, Eduard Hovy, Barnabás Póczos, Ruslan Salakhutdinov, Louis-Philippe Morency","cs.CL, cs.AI, cs.LG",table2text,"Text style transfer aims to controllably generate text with targeted
stylistic changes while maintaining core meaning from the source sentence
constant. Many of the existing style transfer benchmarks primarily focus on
individual high-level semantic changes (e.g. positive to negative), which
enable controllability at a high level but do not offer fine-grained control
involving sentence structure, emphasis, and content of the sentence. In this
paper, we introduce a large-scale benchmark, StylePTB, with (1) paired
sentences undergoing 21 fine-grained stylistic changes spanning atomic lexical,
syntactic, semantic, and thematic transfers of text, as well as (2)
compositions of multiple transfers which allow modeling of fine-grained
stylistic changes as building blocks for more complex, high-level transfers. By
benchmarking existing methods on StylePTB, we find that they struggle to model
fine-grained changes and have an even more difficult time composing multiple
styles. As a result, StylePTB brings novel challenges that we hope will
encourage future research in controllable text style transfer, compositional
models, and learning disentangled representations. Solving these challenges
would present important steps towards controllable text generation.",2021-04-12
WakaVT: A Sequential Variational Transformer for Waka Generation,2021-04-01 12:14:41+00:00,http://arxiv.org/abs/2104.00426v1,"Yuka Takeishi, Mingxuan Niu, Jing Luo, Zhong Jin, Xinyu Yang","cs.CL, cs.AI",table2text,"Poetry generation has long been a challenge for artificial intelligence. In
the scope of Japanese poetry generation, many researchers have paid attention
to Haiku generation, but few have focused on Waka generation. To further
explore the creative potential of natural language generation systems in
Japanese poetry creation, we propose a novel Waka generation model, WakaVT,
which automatically produces Waka poems given user-specified keywords. Firstly,
an additive mask-based approach is presented to satisfy the form constraint.
Secondly, the structures of Transformer and variational autoencoder are
integrated to enhance the quality of generated content. Specifically, to obtain
novelty and diversity, WakaVT employs a sequence of latent variables, which
effectively captures word-level variability in Waka data. To improve linguistic
quality in terms of fluency, coherence, and meaningfulness, we further propose
the fused multilevel self-attention mechanism, which properly models the
hierarchical linguistic structure of Waka. To the best of our knowledge, we are
the first to investigate Waka generation with models based on Transformer
and/or variational autoencoder. Both objective and subjective evaluation
results demonstrate that our model outperforms baselines significantly.",2021-04-01
FeTaQA: Free-form Table Question Answering,2021-04-01 09:59:40+00:00,http://arxiv.org/abs/2104.00369v1,"Linyong Nan, Chiachun Hsieh, Ziming Mao, Xi Victoria Lin, Neha Verma, Rui Zhang, Wojciech Kryściński, Nick Schoelkopf, Riley Kong, Xiangru Tang, Murori Mutuma, Ben Rosand, Isabel Trindade, Renusree Bandaru, Jacob Cunningham, Caiming Xiong, Dragomir Radev",cs.CL,table2text,"Existing table question answering datasets contain abundant factual questions
that primarily evaluate the query and schema comprehension capability of a
system, but they fail to include questions that require complex reasoning and
integration of information due to the constraint of the associated short-form
answers. To address these issues and to demonstrate the full challenge of table
question answering, we introduce FeTaQA, a new dataset with 10K Wikipedia-based
{table, question, free-form answer, supporting table cells} pairs. FeTaQA
yields a more challenging table question answering setting because it requires
generating free-form text answers after retrieval, inference, and integration
of multiple discontinuous facts from a structured knowledge source. Unlike
datasets of generative QA over text in which answers are prevalent with copies
of short text spans from the source, answers in our dataset are human-generated
explanations involving entities and their high-level relations. We provide two
benchmark methods for the proposed task: a pipeline method based on
semantic-parsing-based QA systems and an end-to-end method based on large
pretrained text generation models, and show that FeTaQA poses a challenge for
both methods.",2021-04-01
"On Hallucination and Predictive Uncertainty in Conditional Language
  Generation",2021-03-28 00:32:27+00:00,http://arxiv.org/abs/2103.15025v1,"Yijun Xiao, William Yang Wang",cs.CL,table2text,"Despite improvements in performances on different natural language generation
tasks, deep neural models are prone to hallucinating facts that are incorrect
or nonexistent. Different hypotheses are proposed and examined separately for
different tasks, but no systematic explanations are available across these
tasks. In this study, we draw connections between hallucinations and predictive
uncertainty in conditional language generation. We investigate their
relationship in both image captioning and data-to-text generation and propose a
simple extension to beam search to reduce hallucination. Our analysis shows
that higher predictive uncertainty corresponds to a higher chance of
hallucination. Epistemic uncertainty is more indicative of hallucination than
aleatoric or total uncertainties. It helps to achieve better results of trading
performance in standard metric for less hallucination with the proposed beam
search variant.",2021-03-28
"Data Augmentation in Natural Language Processing: A Novel Text
  Generation Approach for Long and Short Text Classifiers",2021-03-26 13:16:07+00:00,http://arxiv.org/abs/2103.14453v1,"Markus Bayer, Marc-André Kaufhold, Björn Buchhold, Marcel Keller, Jörg Dallmeyer, Christian Reuter","cs.CL, cs.AI",table2text,"In many cases of machine learning, research suggests that the development of
training data might have a higher relevance than the choice and modelling of
classifiers themselves. Thus, data augmentation methods have been developed to
improve classifiers by artificially created training data. In NLP, there is the
challenge of establishing universal rules for text transformations which
provide new linguistic patterns. In this paper, we present and evaluate a text
generation method suitable to increase the performance of classifiers for long
and short texts. We achieved promising improvements when evaluating short as
well as long text tasks with the enhancement by our text generation method. In
a simulated low data regime additive accuracy gains of up to 15.53% are
achieved. As the current track of these constructed regimes is not universally
applicable, we also show major improvements in several real world low data
tasks (up to +4.84 F1 score). Since we are evaluating the method from many
perspectives, we also observe situations where the method might not be
suitable. We discuss implications and patterns for the successful application
of our approach on different types of datasets.",2021-03-26
"Attribute Alignment: Controlling Text Generation from Pre-trained
  Language Models",2021-03-20 01:51:32+00:00,http://arxiv.org/abs/2103.11070v1,"Dian Yu, Kenji Sagae, Zhou Yu",cs.CL,table2text,"Large language models benefit from training with a large amount of unlabeled
text, which gives them increasingly fluent and diverse generation capabilities.
However, using these models for text generation that takes into account target
attributes, such as sentiment polarity or specific topics, remains a challenge.
We propose a simple and flexible method for controlling text generation by
aligning disentangled attribute representations. In contrast to recent efforts
on training a discriminator to perturb the token level distribution for an
attribute, we use the same data to learn an alignment function to guide the
pre-trained, non-controlled language model to generate texts with the target
attribute without changing the original language model parameters. We evaluate
our method on sentiment- and topic-controlled generation, and show large
performance gains over previous methods while retaining fluency and diversity.",2021-03-20
"Structural Adapters in Pretrained Language Models for AMR-to-text
  Generation",2021-03-16 15:06:50+00:00,http://arxiv.org/abs/2103.09120v1,"Leonardo F. R. Ribeiro, Yue Zhang, Iryna Gurevych",cs.CL,table2text,"Previous work on text generation from graph-structured data relies on
pretrained language models (PLMs) and utilizes graph linearization heuristics
rather than explicitly considering the graph structure. Efficiently encoding
the graph structure in PLMs is challenging because they were pretrained on
natural language, and modeling structured data may lead to catastrophic
forgetting of distributional knowledge. In this paper, we propose StructAdapt,
an adapter method to encode graph structure into PLMs. Contrary to prior work,
StructAdapt effectively models interactions among the nodes based on the graph
connectivity, only training graph structure-aware adapter parameters. In this
way, we avoid catastrophic forgetting while maintaining the topological
structure of the graph. We empirically show the benefits of explicitly encoding
graph structure into PLMs using adapters and achieve state-of-the-art results
on two AMR-to-text datasets, training only 5.1% of the PLM parameters.",2021-03-16
Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence,2021-03-15 17:05:13+00:00,http://arxiv.org/abs/2103.08541v1,"Tal Schuster, Adam Fisch, Regina Barzilay","cs.CL, cs.IR, cs.LG",table2text,"Typical fact verification models use retrieved written evidence to verify
claims. Evidence sources, however, often change over time as more information
is gathered and revised. In order to adapt, models must be sensitive to subtle
differences in supporting evidence. We present VitaminC, a benchmark infused
with challenging cases that require fact verification models to discern and
adjust to slight factual changes. We collect over 100,000 Wikipedia revisions
that modify an underlying fact, and leverage these revisions, together with
additional synthetically constructed ones, to create a total of over 400,000
claim-evidence pairs. Unlike previous resources, the examples in VitaminC are
contrastive, i.e., they contain evidence pairs that are nearly identical in
language and content, with the exception that one supports a given claim while
the other does not. We show that training using this design increases
robustness -- improving accuracy by 10% on adversarial fact verification and 6%
on adversarial natural language inference (NLI). Moreover, the structure of
VitaminC leads us to define additional tasks for fact-checking resources:
tagging relevant words in the evidence for verifying the claim, identifying
factual revisions, and providing automatic edits via factually consistent text
generation.",2021-03-15
Topical Language Generation using Transformers,2021-03-11 03:45:24+00:00,http://arxiv.org/abs/2103.06434v1,"Rohola Zandie, Mohammad H. Mahoor","cs.CL, cs.AI",table2text,"Large-scale transformer-based language models (LMs) demonstrate impressive
capabilities in open text generation. However, controlling the generated text's
properties such as the topic, style, and sentiment is challenging and often
requires significant changes to the model architecture or retraining and
fine-tuning the model on new supervised data. This paper presents a novel
approach for Topical Language Generation (TLG) by combining a pre-trained LM
with topic modeling information. We cast the problem using Bayesian probability
formulation with topic probabilities as a prior, LM probabilities as the
likelihood, and topical language generation probability as the posterior. In
learning the model, we derive the topic probability distribution from the
user-provided document's natural structure. Furthermore, we extend our model by
introducing new parameters and functions to influence the quantity of the
topical features presented in the generated text. This feature would allow us
to easily control the topical properties of the generated text. Our
experimental results demonstrate that our model outperforms the
state-of-the-art results on coherency, diversity, and fluency while being
faster in decoding.",2021-03-11
Causal-aware Safe Policy Improvement for Task-oriented dialogue,2021-03-10 22:34:28+00:00,http://arxiv.org/abs/2103.06370v1,"Govardana Sachithanandam Ramachandran, Kazuma Hashimoto, Caiming Xiong","cs.CL, cs.AI, cs.LG",table2text,"The recent success of reinforcement learning's (RL) in solving complex tasks
is most often attributed to its capacity to explore and exploit an environment
where it has been trained. Sample efficiency is usually not an issue since
cheap simulators are available to sample data on-policy. On the other hand,
task oriented dialogues are usually learnt from offline data collected using
human demonstrations. Collecting diverse demonstrations and annotating them is
expensive. Unfortunately, use of RL methods trained on off-policy data are
prone to issues of bias and generalization, which are further exacerbated by
stochasticity in human response and non-markovian belief state of a dialogue
management system. To this end, we propose a batch RL framework for task
oriented dialogue policy learning: causal aware safe policy improvement
(CASPI). This method gives guarantees on dialogue policy's performance and also
learns to shape rewards according to intentions behind human responses, rather
than just mimicking demonstration data; this couple with batch-RL helps overall
with sample efficiency of the framework. We demonstrate the effectiveness of
this framework on a dialogue-context-to-text Generation and end-to-end dialogue
task of the Multiwoz2.0 dataset. The proposed method outperforms the current
state of the art on these metrics, in both case. In the end-to-end case, our
method trained only on 10\% of the data was able to out perform current state
in three out of four evaluation metrics.",2021-03-10
Text Simplification by Tagging,2021-03-08 20:57:55+00:00,http://arxiv.org/abs/2103.05070v1,"Kostiantyn Omelianchuk, Vipul Raheja, Oleksandr Skurzhanskyi",cs.CL,table2text,"Edit-based approaches have recently shown promising results on multiple
monolingual sequence transduction tasks. In contrast to conventional
sequence-to-sequence (Seq2Seq) models, which learn to generate text from
scratch as they are trained on parallel corpora, these methods have proven to
be much more effective since they are able to learn to make fast and accurate
transformations while leveraging powerful pre-trained language models. Inspired
by these ideas, we present TST, a simple and efficient Text Simplification
system based on sequence Tagging, leveraging pre-trained Transformer-based
encoders. Our system makes simplistic data augmentations and tweaks in training
and inference on a pre-existing system, which makes it less reliant on large
amounts of parallel training data, provides more control over the outputs and
enables faster inference speeds. Our best model achieves near state-of-the-art
performance on benchmark test datasets for the task. Since it is fully
non-autoregressive, it achieves faster inference speeds by over 11 times than
the current state-of-the-art text simplification system.",2021-03-08
InFillmore: Neural Frame Lexicalization for Narrative Text Infilling,2021-03-08 17:59:41+00:00,http://arxiv.org/abs/2103.04941v1,"Jiefu Ou, Nathaniel Weir, Anton Belyy, Felix Yu, Benjamin Van Durme",cs.CL,table2text,"We propose a structured extension to bidirectional-context conditional
language generation, or ""infilling,"" inspired by Frame Semantic theory
(Fillmore, 1976). Guidance is provided through two approaches: (1) model
fine-tuning, conditioning directly on observed symbolic frames, and (2) a novel
extension to disjunctive lexically constrained decoding that leverages frame
semantic lexical units. Automatic and human evaluations confirm that
frame-guided generation allows for explicit manipulation of intended infill
semantics, with minimal loss of indistinguishability from the human-generated
text. Our methods flexibly apply to a variety of use scenarios, and we provide
an interactive web demo available at https://nlp.jhu.edu/demos.",2021-03-08
"Towards Faithfulness in Open Domain Table-to-text Generation from an
  Entity-centric View",2021-02-17 05:41:06+00:00,http://arxiv.org/abs/2102.08585v1,"Tianyu Liu, Xin Zheng, Baobao Chang, Zhifang Sui","cs.CL, cs.AI",table2text,"In open domain table-to-text generation, we notice that the unfaithful
generation usually contains hallucinated content which can not be aligned to
any input table record. We thus try to evaluate the generation faithfulness
with two entity-centric metrics: table record coverage and the ratio of
hallucinated entities in text, both of which are shown to have strong agreement
with human judgements. Then based on these metrics, we quantitatively analyze
the correlation between training data quality and generation fidelity which
indicates the potential usage of entity information in faithful generation.
Motivated by these findings, we propose two methods for faithful generation: 1)
augmented training by incorporating the auxiliary entity information, including
both an augmented plan-based model and an unsupervised model and 2) training
instance selection based on faithfulness ranking. We show these approaches
improve generation fidelity in both full dataset setting and few shot learning
settings by both automatic and human evaluations.",2021-02-17
Structural Information Preserving for Graph-to-Text Generation,2021-02-12 20:09:01+00:00,http://arxiv.org/abs/2102.06749v1,"Linfeng Song, Ante Wang, Jinsong Su, Yue Zhang, Kun Xu, Yubin Ge, Dong Yu",cs.CL,table2text,"The task of graph-to-text generation aims at producing sentences that
preserve the meaning of input graphs. As a crucial defect, the current
state-of-the-art models may mess up or even drop the core structural
information of input graphs when generating outputs. We propose to tackle this
problem by leveraging richer training signals that can guide our model for
preserving input information. In particular, we introduce two types of
autoencoding losses, each individually focusing on different aspects (a.k.a.
views) of input graphs. The losses are then back-propagated to better calibrate
our model via multi-task training. Experiments on two benchmarks for
graph-to-text generation show the effectiveness of our approach over a
state-of-the-art baseline. Our code is available at
\url{http://github.com/Soistesimmer/AMR-multiview}.",2021-02-12
Generating Synthetic Text Data to Evaluate Causal Inference Methods,2021-02-10 18:53:11+00:00,http://arxiv.org/abs/2102.05638v1,"Zach Wood-Doughty, Ilya Shpitser, Mark Dredze",cs.CL,table2text,"Drawing causal conclusions from observational data requires making
assumptions about the true data-generating process. Causal inference research
typically considers low-dimensional data, such as categorical or numerical
fields in structured medical records. High-dimensional and unstructured data
such as natural language complicates the evaluation of causal inference
methods; such evaluations rely on synthetic datasets with known causal effects.
Models for natural language generation have been widely studied and perform
well empirically. However, existing methods not immediately applicable to
producing synthetic datasets for causal evaluations, as they do not allow for
quantifying a causal effect on the text itself. In this work, we develop a
framework for adapting existing generation models to produce synthetic text
datasets with known causal effects. We use this framework to perform an
empirical comparison of four recently-proposed methods for estimating causal
effects from text data. We release our code and synthetic datasets.",2021-02-10
Neural Data-to-Text Generation with LM-based Text Augmentation,2021-02-06 10:21:48+00:00,http://arxiv.org/abs/2102.03556v1,"Ernie Chang, Xiaoyu Shen, Dawei Zhu, Vera Demberg, Hui Su",cs.CL,table2text,"For many new application domains for data-to-text generation, the main
obstacle in training neural models consists of a lack of training data. While
usually large numbers of instances are available on the data side, often only
very few text samples are available. To address this problem, we here propose a
novel few-shot approach for this setting. Our approach automatically augments
the data available for training by (i) generating new text samples based on
replacing specific values by alternative ones from the same category, (ii)
generating new text samples based on GPT-2, and (iii) proposing an automatic
method for pairing the new text samples with data samples. As the text
augmentation can introduce noise to the training data, we use cycle consistency
as an objective, in order to make sure that a given data sample can be
correctly reconstructed after having been formulated as text (and that text
samples can be reconstructed from data). On both the E2E and WebNLG benchmarks,
we show that this weakly supervised training paradigm is able to outperform
fully supervised seq2seq models with less than 10% annotations. By utilizing
all annotated data, our model can boost the performance of a standard seq2seq
model by over 5 BLEU points, establishing a new state-of-the-art on both
datasets.",2021-02-06
"Does the Order of Training Samples Matter? Improving Neural Data-to-Text
  Generation with Curriculum Learning",2021-02-06 10:14:18+00:00,http://arxiv.org/abs/2102.03554v1,"Ernie Chang, Hui-Syuan Yeh, Vera Demberg",cs.CL,table2text,"Recent advancements in data-to-text generation largely take on the form of
neural end-to-end systems. Efforts have been dedicated to improving text
generation systems by changing the order of training samples in a process known
as curriculum learning. Past research on sequence-to-sequence learning showed
that curriculum learning helps to improve both the performance and convergence
speed. In this work, we delve into the same idea surrounding the training
samples consisting of structured data and text pairs, where at each update, the
curriculum framework selects training samples based on the model's competence.
Specifically, we experiment with various difficulty metrics and put forward a
soft edit distance metric for ranking training samples. Our benchmarks show
faster convergence speed where training time is reduced by 38.7% and
performance is boosted by 4.84 BLEU.",2021-02-06
"Jointly Improving Language Understanding and Generation with
  Quality-Weighted Weak Supervision of Automatic Labeling",2021-02-06 10:06:15+00:00,http://arxiv.org/abs/2102.03551v1,"Ernie Chang, Vera Demberg, Alex Marin","cs.CL, cs.AI",table2text,"Neural natural language generation (NLG) and understanding (NLU) models are
data-hungry and require massive amounts of annotated data to be competitive.
Recent frameworks address this bottleneck with generative models that
synthesize weak labels at scale, where a small amount of training labels are
expert-curated and the rest of the data is automatically annotated. We follow
that approach, by automatically constructing a large-scale weakly-labeled data
with a fine-tuned GPT-2, and employ a semi-supervised framework to jointly
train the NLG and NLU models. The proposed framework adapts the parameter
updates to the models according to the estimated label-quality. On both the E2E
and Weather benchmarks, we show that this weakly supervised training paradigm
is an effective approach under low resource scenarios and outperforming
benchmark systems on both datasets when 100% of training data is used.",2021-02-06
Controlling Hallucinations at Word Level in Data-to-Text Generation,2021-02-04 18:58:28+00:00,http://arxiv.org/abs/2102.02810v1,"Clément Rebuffel, Marco Roberti, Laure Soulier, Geoffrey Scoutheeten, Rossella Cancelliere, Patrick Gallinari","cs.CL, cs.AI, cs.LG, cs.NE, 68T50 (Primary), 68T07 (Secondary), 68T05, I.2.6; I.2.7",table2text,"Data-to-Text Generation (DTG) is a subfield of Natural Language Generation
aiming at transcribing structured data in natural language descriptions. The
field has been recently boosted by the use of neural-based generators which
exhibit on one side great syntactic skills without the need of hand-crafted
pipelines; on the other side, the quality of the generated text reflects the
quality of the training data, which in realistic settings only offer
imperfectly aligned structure-text pairs. Consequently, state-of-art neural
models include misleading statements - usually called hallucinations - in their
outputs. The control of this phenomenon is today a major challenge for DTG, and
is the problem addressed in the paper.
  Previous work deal with this issue at the instance level: using an alignment
score for each table-reference pair. In contrast, we propose a finer-grained
approach, arguing that hallucinations should rather be treated at the word
level. Specifically, we propose a Multi-Branch Decoder which is able to
leverage word-level labels to learn the relevant parts of each training
instance. These labels are obtained following a simple and efficient scoring
procedure based on co-occurrence analysis and dependency parsing. Extensive
evaluations, via automated metrics and human judgment on the standard WikiBio
benchmark, show the accuracy of our alignment labels and the effectiveness of
the proposed Multi-Branch Decoder. Our model is able to reduce and control
hallucinations, while keeping fluency and coherence in generated texts. Further
experiments on a degraded version of ToTTo show that our model could be
successfully used on very noisy settings.",2021-02-04
Data-to-text Generation with Macro Planning,2021-02-04 16:32:57+00:00,http://arxiv.org/abs/2102.02723v1,"Ratish Puduppully, Mirella Lapata",cs.CL,table2text,"Recent approaches to data-to-text generation have adopted the very successful
encoder-decoder architecture or variants thereof. These models generate text
which is fluent (but often imprecise) and perform quite poorly at selecting
appropriate content and ordering it coherently. To overcome some of these
issues, we propose a neural model with a macro planning stage followed by a
generation stage reminiscent of traditional methods which embrace separate
modules for planning and surface realization. Macro plans represent high level
organization of important content such as entities, events and their
interactions; they are learnt from data and given as input to the generator.
Extensive experiments on two data-to-text benchmarks (RotoWire and MLB) show
that our approach outperforms competitive baselines in terms of automatic and
human evaluation.",2021-02-04
"GUIGAN: Learning to Generate GUI Designs Using Generative Adversarial
  Networks",2021-01-25 09:42:58+00:00,http://arxiv.org/abs/2101.09978v2,"Tianming Zhao, Chunyang Chen, Yuanning Liu, Xiaodong Zhu","cs.HC, cs.CV, cs.LG, cs.SE",table2text,"Graphical User Interface (GUI) is ubiquitous in almost all modern desktop
software, mobile applications, and online websites. A good GUI design is
crucial to the success of the software in the market, but designing a good GUI
which requires much innovation and creativity is difficult even to well-trained
designers. Besides, the requirement of the rapid development of GUI design also
aggravates designers' working load. So, the availability of various automated
generated GUIs can help enhance the design personalization and specialization
as they can cater to the taste of different designers. To assist designers, we
develop a model GUIGAN to automatically generate GUI designs. Different from
conventional image generation models based on image pixels, our GUIGAN is to
reuse GUI components collected from existing mobile app GUIs for composing a
new design that is similar to natural-language generation. Our GUIGAN is based
on SeqGAN by modeling the GUI component style compatibility and GUI structure.
The evaluation demonstrates that our model significantly outperforms the best
of the baseline methods by 30.77% in Frechet Inception distance (FID) and
12.35% in 1-Nearest Neighbor Accuracy (1-NNA). Through a pilot user study, we
provide initial evidence of the usefulness of our approach for generating
acceptable brand new GUI designs.",2021-01-25
Generating (Formulaic) Text by Splicing Together Nearest Neighbors,2021-01-20 18:43:11+00:00,http://arxiv.org/abs/2101.08248v1,"Sam Wiseman, Arturs Backurs, Karl Stratos","cs.CL, cs.LG",table2text,"We propose to tackle conditional text generation tasks, especially those
which require generating formulaic text, by splicing together segments of text
from retrieved ""neighbor"" source-target pairs. Unlike recent work that
conditions on retrieved neighbors in an encoder-decoder setting but generates
text token-by-token, left-to-right, we learn a policy that directly manipulates
segments of neighbor text (i.e., by inserting or replacing them) to form an
output. Standard techniques for training such a policy require an oracle
derivation for each generation, and we prove that finding the shortest such
derivation can be reduced to parsing under a particular weighted context-free
grammar. We find that policies learned in this way allow for interpretable
table-to-text and headline generation that is competitive with or better than
state-of-the-art autoregressive token-level policies in terms of automatic
metrics, and moreover allows for faster decoding.",2021-01-20
What Makes Good In-Context Examples for GPT-$3$?,2021-01-17 23:38:40+00:00,http://arxiv.org/abs/2101.06804v1,"Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu Chen",cs.CL,table2text,"GPT-$3$ has attracted lots of attention due to its superior performance
across a wide range of NLP tasks, especially with its powerful and versatile
in-context few-shot learning ability. Despite its success, we found that the
empirical results of GPT-$3$ depend heavily on the choice of in-context
examples. In this work, we investigate whether there are more effective
strategies for judiciously selecting in-context examples (relative to random
sampling) that better leverage GPT-$3$'s few-shot capabilities. Inspired by the
recent success of leveraging a retrieval module to augment large-scale neural
network models, we propose to retrieve examples that are semantically-similar
to a test sample to formulate its corresponding prompt. Intuitively, the
in-context examples selected with such a strategy may serve as more informative
inputs to unleash GPT-$3$'s extensive knowledge. We evaluate the proposed
approach on several natural language understanding and generation benchmarks,
where the retrieval-based prompt selection approach consistently outperforms
the random baseline. Moreover, it is observed that the sentence encoders
fine-tuned on task-related datasets yield even more helpful retrieval results.
Notably, significant gains are observed on tasks such as table-to-text
generation (41.9% on the ToTTo dataset) and open-domain question answering
(45.5% on the NQ dataset). We hope our investigation could help understand the
behaviors of GPT-$3$ and large-scale pre-trained LMs in general and enhance
their few-shot capabilities.",2021-01-17
Narration Generation for Cartoon Videos,2021-01-17 23:23:09+00:00,http://arxiv.org/abs/2101.06803v1,"Nikos Papasarantopoulos, Shay B. Cohen",cs.CL,table2text,"Research on text generation from multimodal inputs has largely focused on
static images, and less on video data. In this paper, we propose a new task,
narration generation, that is complementing videos with narration texts that
are to be interjected in several places. The narrations are part of the video
and contribute to the storyline unfolding in it. Moreover, they are
context-informed, since they include information appropriate for the timeframe
of video they cover, and also, do not need to include every detail shown in
input scenes, as a caption would. We collect a new dataset from the animated
television series Peppa Pig. Furthermore, we formalize the task of narration
generation as including two separate tasks, timing and content generation, and
present a set of models on the new task.",2021-01-17
Transforming Multi-Conditioned Generation from Meaning Representation,2021-01-12 01:45:06+00:00,http://arxiv.org/abs/2101.04257v1,Joosung Lee,"cs.CL, cs.AI",table2text,"In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.",2021-01-12
"Political Depolarization of News Articles Using Attribute-aware Word
  Embeddings",2021-01-05 07:39:12+00:00,http://arxiv.org/abs/2101.01391v1,"Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vosoughi","cs.CL, cs.AI",table2text,"Political polarization in the US is on the rise. This polarization negatively
affects the public sphere by contributing to the creation of ideological echo
chambers. In this paper, we focus on addressing one of the factors that
contributes to this polarity, polarized media. We introduce a framework for
depolarizing news articles. Given an article on a certain topic with a
particular ideological slant (eg., liberal or conservative), the framework
first detects polar language in the article and then generates a new article
with the polar language replaced with neutral expressions. To detect polar
words, we train a multi-attribute-aware word embedding model that is aware of
ideology and topics on 360k full-length media articles. Then, for text
generation, we propose a new algorithm called Text Annealing Depolarization
Algorithm (TADA). TADA retrieves neutral expressions from the word embedding
model that not only decrease ideological polarity but also preserve the
original argument of the text, while maintaining grammatical correctness. We
evaluate our framework by comparing the depolarized output of our model in two
modes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics.
Based on feedback from 161 human testers, our framework successfully
depolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs
in fully-automatic mode. Furthermore, 81.2% of the testers agree that the
non-polar content information is well-preserved and 79% agree that
depolarization does not harm semantic correctness when they compare the
original text and the depolarized text. Our work shows that data-driven methods
can help to locate political polarity and aid in the depolarization of
articles.",2021-01-05
Prefix-Tuning: Optimizing Continuous Prompts for Generation,2021-01-01 08:00:36+00:00,http://arxiv.org/abs/2101.00190v1,"Xiang Lisa Li, Percy Liang",cs.CL,table2text,"Fine-tuning is the de facto way to leverage large pretrained language models
to perform downstream tasks. However, it modifies all the language model
parameters and therefore necessitates storing a full copy for each task. In
this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning
for natural language generation tasks, which keeps language model parameters
frozen, but optimizes a small continuous task-specific vector (called the
prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent
tokens to attend to this prefix as if it were ""virtual tokens"". We apply
prefix-tuning to GPT-2 for table-to-text generation and to BART for
summarization. We find that by learning only 0.1\% of the parameters,
prefix-tuning obtains comparable performance in the full data setting,
outperforms fine-tuning in low-data settings, and extrapolates better to
examples with topics unseen during training.",2021-01-01
"DISCOS: Bridging the Gap between Discourse Knowledge and Commonsense
  Knowledge",2021-01-01 03:30:38+00:00,http://arxiv.org/abs/2101.00154v1,"Tianqing Fang, Hongming Zhang, Weiqi Wang, Yangqiu Song, Bin He","cs.CL, cs.AI",table2text,"Commonsense knowledge is crucial for artificial intelligence systems to
understand natural language. Previous commonsense knowledge acquisition
approaches typically rely on human annotations (e.g., ATOMIC) or text
generation models (e.g., COMET). Human annotation could provide high-quality
commonsense knowledge, yet its high cost often results in relatively small
scale and low coverage. On the other hand, generation models have the potential
to automatically generate more knowledge. Nonetheless, machine learning models
often fit the training data too well to generate novel knowledge in high
quality, thus still suffering from coverage problems. To address the
limitations of previous approaches, in this paper, we propose an alternative
commonsense knowledge acquisition framework DISCOS (from DIScourse to
COmmonSense), which automatically mines expensive complex commonsense knowledge
from more affordable linguistic knowledge resources. Experiments demonstrate
that we can successfully convert discourse knowledge over eventualities from
ASER, a large-scale discourse knowledge graph, into inferential if-then
commonsense knowledge defined in ATOMIC without any additional annotation
effort. Further study suggests that DISCOS significantly outperforms previous
supervised approaches in terms of novelty and diversity with comparable
quality. In total, we can acquire 3.4M ATOMIC-like inferential commonsense
knowledge by populating ATOMIC on the core part of ASER. Codes and data are
available at https://github.com/HKUST-KnowComp/DISCOS-commonsense.",2021-01-01
Continual Learning in Task-Oriented Dialogue Systems,2020-12-31 08:44:25+00:00,http://arxiv.org/abs/2012.15504v1,"Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang","cs.CL, cs.AI",table2text,"Continual learning in task-oriented dialogue systems can allow us to add new
domains and functionalities through time without incurring the high cost of a
whole system retraining. In this paper, we propose a continual learning
benchmark for task-oriented dialogue systems with 37 domains to be learned
continuously in four settings, such as intent recognition, state tracking,
natural language generation, and end-to-end. Moreover, we implement and compare
multiple existing continual learning baselines, and we propose a simple yet
effective architectural method based on residual adapters. Our experiments
demonstrate that the proposed architectural method and a simple replay-based
strategy perform comparably well but they both achieve inferior performance to
the multi-task learning baseline, in where all the data are shown at once,
showing that continual learning in task-oriented dialogue systems is a
challenging task. Furthermore, we reveal several trade-offs between different
continual learning methods in term of parameter usage and memory size, which
are important in the design of a task-oriented dialogue system. The proposed
benchmark is released together with several baselines to promote more research
in this direction.",2020-12-31
Generating Wikipedia Article Sections from Diverse Data Sources,2020-12-29 19:35:34+00:00,http://arxiv.org/abs/2012.14919v1,"Mingda Chen, Sam Wiseman, Kevin Gimpel",cs.CL,table2text,"Datasets for data-to-text generation typically focus either on multi-domain,
single-sentence generation or on single-domain, long-form generation. In this
work, we create a large-scale dataset, WikiTableT, that pairs Wikipedia
sections with their corresponding tabular data and various metadata. WikiTableT
contains millions of instances, covering a broad range of topics, as well as a
variety of flavors of generation tasks with different levels of flexibility. We
benchmark several training and decoding strategies on WikiTableT. Our
qualitative analysis shows that the best approaches can generate fluent and
high quality texts but they sometimes struggle with coherence.",2020-12-29
"Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous
  Rendering Machines",2020-12-29 07:41:48+00:00,http://arxiv.org/abs/2012.14645v1,"Yangming Li, Kaisheng Yao",cs.CL,table2text,"End-to-end neural networks have achieved promising performances in natural
language generation (NLG). However, they are treated as black boxes and lack
interpretability. To address this problem, we propose a novel framework,
heterogeneous rendering machines (HRM), that interprets how neural generators
render an input dialogue act (DA) into an utterance. HRM consists of a renderer
set and a mode switcher. The renderer set contains multiple decoders that vary
in both structure and functionality. For every generation step, the mode
switcher selects an appropriate decoder from the renderer set to generate an
item (a word or a phrase). To verify the effectiveness of our method, we have
conducted extensive experiments on 5 benchmark datasets. In terms of automatic
metrics (e.g., BLEU), our model is competitive with the current
state-of-the-art method. The qualitative analysis shows that our model can
interpret the rendering process of neural generators well. Human evaluation
also confirms the interpretability of our proposed approach.",2020-12-29
Towards Neural Programming Interfaces,2020-12-10 21:17:04+00:00,http://arxiv.org/abs/2012.05983v1,"Zachary C. Brown, Nathaniel Robinson, David Wingate, Nancy Fulda","cs.CL, cs.AI",table2text,"It is notoriously difficult to control the behavior of artificial neural
networks such as generative neural language models. We recast the problem of
controlling natural language generation as that of learning to interface with a
pretrained language model, just as Application Programming Interfaces (APIs)
control the behavior of programs by altering hyperparameters. In this new
paradigm, a specialized neural network (called a Neural Programming Interface
or NPI) learns to interface with a pretrained language model by manipulating
the hidden activations of the pretrained model to produce desired outputs.
Importantly, no permanent changes are made to the weights of the original
model, allowing us to re-purpose pretrained models for new tasks without
overwriting any aspect of the language model. We also contribute a new data set
construction algorithm and GAN-inspired loss function that allows us to train
NPI models to control outputs of autoregressive transformers. In experiments
against other state-of-the-art approaches, we demonstrate the efficacy of our
methods using OpenAI's GPT-2 model, successfully controlling noun selection,
topic aversion, offensive speech filtering, and other aspects of language while
largely maintaining the controlled model's fluency under deterministic
settings.",2020-12-10
"Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF
  Verbalization with Transformers",2020-12-01 15:25:47+00:00,http://arxiv.org/abs/2012.00571v1,"Sebastien Montella, Betty Fabre, Tanguy Urvoy, Johannes Heinecke, Lina Rojas-Barahona",cs.CL,table2text,"The task of verbalization of RDF triples has known a growth in popularity due
to the rising ubiquity of Knowledge Bases (KBs). The formalism of RDF triples
is a simple and efficient way to store facts at a large scale. However, its
abstract representation makes it difficult for humans to interpret. For this
purpose, the WebNLG challenge aims at promoting automated RDF-to-text
generation. We propose to leverage pre-trainings from augmented data with the
Transformer model using a data augmentation strategy. Our experiment results
show a minimum relative increases of 3.73%, 126.05% and 88.16% in BLEU score
for seen categories, unseen entities and unseen categories respectively over
the standard training.",2020-12-01
Latent Template Induction with Gumbel-CRFs,2020-11-29 01:00:57+00:00,http://arxiv.org/abs/2011.14244v1,"Yao Fu, Chuanqi Tan, Bin Bi, Mosha Chen, Yansong Feng, Alexander M. Rush","cs.CL, cs.AI, cs.LG",table2text,"Learning to control the structure of sentences is a challenging problem in
text generation. Existing work either relies on simple deterministic approaches
or RL-based hard structures. We explore the use of structured variational
autoencoders to infer latent templates for sentence generation using a soft,
continuous relaxation in order to utilize reparameterization for training.
Specifically, we propose a Gumbel-CRF, a continuous relaxation of the CRF
sampling algorithm using a relaxed Forward-Filtering Backward-Sampling (FFBS)
approach. As a reparameterized gradient estimator, the Gumbel-CRF gives more
stable gradients than score-function based estimators. As a structured
inference network, we show that it learns interpretable templates during
training, which allows us to control the decoder during testing. We demonstrate
the effectiveness of our methods with experiments on data-to-text generation
and unsupervised paraphrase generation.",2020-11-29
"TaylorGAN: Neighbor-Augmented Policy Update for Sample-Efficient Natural
  Language Generation",2020-11-27 02:26:15+00:00,http://arxiv.org/abs/2011.13527v1,"Chun-Hsing Lin, Siang-Ruei Wu, Hung-Yi Lee, Yun-Nung Chen","cs.CL, cs.LG",table2text,"Score function-based natural language generation (NLG) approaches such as
REINFORCE, in general, suffer from low sample efficiency and training
instability problems. This is mainly due to the non-differentiable nature of
the discrete space sampling and thus these methods have to treat the
discriminator as a black box and ignore the gradient information. To improve
the sample efficiency and reduce the variance of REINFORCE, we propose a novel
approach, TaylorGAN, which augments the gradient estimation by off-policy
update and the first-order Taylor expansion. This approach enables us to train
NLG models from scratch with smaller batch size -- without maximum likelihood
pre-training, and outperforms existing GAN-based methods on multiple metrics of
quality and diversity. The source code and data are available at
https://github.com/MiuLab/TaylorGAN",2020-11-27
DORB: Dynamically Optimizing Multiple Rewards with Bandits,2020-11-15 21:57:47+00:00,http://arxiv.org/abs/2011.07635v1,"Ramakanth Pasunuru, Han Guo, Mohit Bansal","cs.CL, cs.AI, cs.LG",table2text,"Policy gradients-based reinforcement learning has proven to be a promising
approach for directly optimizing non-differentiable evaluation metrics for
language generation tasks. However, optimizing for a specific metric reward
leads to improvements in mostly that metric only, suggesting that the model is
gaming the formulation of that metric in a particular way without often
achieving real qualitative improvements. Hence, it is more beneficial to make
the model optimize multiple diverse metric rewards jointly. While appealing,
this is challenging because one needs to manually decide the importance and
scaling weights of these metric rewards. Further, it is important to consider
using a dynamic combination and curriculum of metric rewards that flexibly
changes over time. Considering the above aspects, in our work, we automate the
optimization of multiple metric rewards simultaneously via a multi-armed bandit
approach (DORB), where at each round, the bandit chooses which metric reward to
optimize next, based on expected arm gains. We use the Exp3 algorithm for
bandits and formulate two approaches for bandit rewards: (1) Single
Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit
(HM-Bandit). We empirically show the effectiveness of our approaches via
various automatic metrics and human evaluation on two important NLG tasks:
question generation and data-to-text generation, including on an unseen-test
transfer setup. Finally, we present interpretable analyses of the learned
bandit curriculum over the optimized rewards.",2020-11-15
"A Gold Standard Methodology for Evaluating Accuracy in Data-To-Text
  Systems",2020-11-08 14:49:18+00:00,http://arxiv.org/abs/2011.03992v1,"Craig Thomson, Ehud Reiter",cs.CL,table2text,"Most Natural Language Generation systems need to produce accurate texts. We
propose a methodology for high-quality human evaluation of the accuracy of
generated texts, which is intended to serve as a gold-standard for accuracy
evaluations of data-to-text systems. We use our methodology to evaluate the
accuracy of computer generated basketball summaries. We then show how our gold
standard evaluation can be used to validate automated metrics",2020-11-08
"Best Practices for Data-Efficient Modeling in NLG:How to Train
  Production-Ready Neural Models with Less Data",2020-11-08 00:38:08+00:00,http://arxiv.org/abs/2011.03877v1,"Ankit Arun, Soumya Batra, Vikas Bhardwaj, Ashwini Challa, Pinar Donmez, Peyman Heidari, Hakan Inan, Shashank Jain, Anuj Kumar, Shawn Mei, Karthik Mohan, Michael White",cs.CL,table2text,"Natural language generation (NLG) is a critical component in conversational
systems, owing to its role of formulating a correct and natural text response.
Traditionally, NLG components have been deployed using template-based
solutions. Although neural network solutions recently developed in the research
community have been shown to provide several benefits, deployment of such
model-based solutions has been challenging due to high latency, correctness
issues, and high data needs. In this paper, we present approaches that have
helped us deploy data-efficient neural solutions for NLG in conversational
systems to production. We describe a family of sampling and modeling techniques
to attain production quality with light-weight neural network models using only
a fraction of the data that would be necessary otherwise, and show a thorough
comparison between each. Our results show that domain complexity dictates the
appropriate approach to achieve high data efficiency. Finally, we distill the
lessons from our experimental findings into a list of best practices for
production-level NLG model development, and present them in a brief runbook.
Importantly, the end products of all of the techniques are small
sequence-to-sequence models (2Mb) that we can reliably deploy in production.",2020-11-08
"SeqGenSQL -- A Robust Sequence Generation Model for Structured Query
  Language",2020-11-07 19:22:59+00:00,http://arxiv.org/abs/2011.03836v1,"Ning Li, Bethany Keller, Mark Butler, Daniel Cer",cs.AI,table2text,"We explore using T5 (Raffel et al. (2019)) to directly translate natural
language questions into SQL statements. General purpose natural language that
interfaces to information stored within databases requires flexibly translating
natural language questions into database queries. The best performing
text-to-SQL systems approach this task by first converting questions into an
intermediate logical form (LF) (Lyu et al. (2020)). While LFs provide a
convenient intermediate representation and simplify query generation, they
introduce an additional layer of complexity and annotation requirements.
However, weakly supervised modeling that directly converts questions to SQL
statements has proven more difficult without the scaffolding provided by LFs
(Min et al. (2019)). We approach direct conversion of questions to SQL
statements using T5 (Raffel et al. (2019)), a pre-trained textto-text
generation model, modified to support pointer-generator style decoding (See et
al. (2017)). We explore using question augmentation with table schema
information and the use of automatically generated silver training data. The
resulting model achieves 90.5% execution accuracy on the WikiSQL (Zhong et al.
(2017)) test data set, a new state-of-the-art on weakly supervised SQL
generation. The performance improvement is 6.6% absolute over the prior
state-of-the-art (Min et al. (2019)) and approaches the performance of
state-ofthe-art systems making use of LFs.",2020-11-07
Machine Generation and Detection of Arabic Manipulated and Fake News,2020-11-05 20:50:22+00:00,http://arxiv.org/abs/2011.03092v1,"El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed, Tariq Alhindi, Hasan Cavusoglu","cs.CL, cs.LG",table2text,"Fake news and deceptive machine-generated text are serious problems
threatening modern societies, including in the Arab world. This motivates work
on detecting false and manipulated stories online. However, a bottleneck for
this research is lack of sufficient data to train detection models. We present
a novel method for automatically generating Arabic manipulated (and potentially
fake) news stories. Our method is simple and only depends on availability of
true stories, which are abundant online, and a part of speech tagger (POS). To
facilitate future work, we dispense with both of these requirements altogether
by providing AraNews, a novel and large POS-tagged news dataset that can be
used off-the-shelf. Using stories generated based on AraNews, we carry out a
human annotation study that casts light on the effects of machine manipulation
on text veracity. The study also measures human ability to detect Arabic
machine manipulated text generated by our method. Finally, we develop the first
models for detecting manipulated Arabic news and achieve state-of-the-art
results on Arabic fake news detection (macro F1=70.06). Our models and data are
publicly available.",2020-11-05
Video Generative Adversarial Networks: A Review,2020-11-04 12:16:05+00:00,http://arxiv.org/abs/2011.02250v1,"Nuha Aldausari, Arcot Sowmya, Nadine Marcus, Gelareh Mohammadi","cs.CV, cs.LG, eess.IV",table2text,"With the increasing interest in the content creation field in multiple
sectors such as media, education, and entertainment, there is an increasing
trend in the papers that uses AI algorithms to generate content such as images,
videos, audio, and text. Generative Adversarial Networks (GANs) in one of the
promising models that synthesizes data samples that are similar to real data
samples. While the variations of GANs models, in general, have been covered to
some extent in several survey papers, to the best of our knowledge, this is
among the first survey papers that reviews the state-of-the-art video GANs
models. This paper first categorized GANs review papers into general GANs
review papers, image GANs review papers, and special field GANs review papers
such as anomaly detection, medical imaging, or cybersecurity. The paper then
summarizes the main improvements in GANs frameworks that are not initially
developed for the video domain but have been adopted in multiple video GANs
variations. Then, a comprehensive review of video GANs models is provided under
two main divisions according to the presence or non-presence of a condition.
The conditional models then further grouped according to the type of condition
into audio, text, video, and image. The paper is concluded by highlighting the
main challenges and limitations of the current video GANs models. A
comprehensive list of datasets, applied loss functions, and evaluation metrics
is provided in the supplementary material.",2020-11-04
Data Augmentation for End-to-end Code-switching Speech Recognition,2020-11-04 07:12:44+00:00,http://arxiv.org/abs/2011.02160v1,"Chenpeng Du, Hao Li, Yizhou Lu, Lan Wang, Yanmin Qian","cs.CL, eess.AS",table2text,"Training a code-switching end-to-end automatic speech recognition (ASR) model
normally requires a large amount of data, while code-switching data is often
limited. In this paper, three novel approaches are proposed for code-switching
data augmentation. Specifically, they are audio splicing with the existing
code-switching data, and TTS with new code-switching texts generated by word
translation or word insertion. Our experiments on 200 hours Mandarin-English
code-switching dataset show that all the three proposed approaches yield
significant improvements on code-switching ASR individually. Moreover, all the
proposed approaches can be combined with recent popular SpecAugment, and an
addition gain can be obtained. WER is significantly reduced by relative 24.0%
compared to the system without any data augmentation, and still relative 13.0%
gain compared to the system with only SpecAugment",2020-11-04
"Conditioned Text Generation with Transfer for Closed-Domain Dialogue
  Systems",2020-11-03 14:06:10+00:00,http://arxiv.org/abs/2011.02143v1,"Stéphane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre Caulier, Marc Lelarge","cs.CL, cs.AI, cs.LG",table2text,"Scarcity of training data for task-oriented dialogue systems is a well known
problem that is usually tackled with costly and time-consuming manual data
annotation. An alternative solution is to rely on automatic text generation
which, although less accurate than human supervision, has the advantage of
being cheap and fast. Our contribution is twofold. First we show how to
optimally train and control the generation of intent-specific sentences using a
conditional variational autoencoder. Then we introduce a new protocol called
query transfer that allows to leverage a large unlabelled dataset, possibly
containing irrelevant queries, to extract relevant information. Comparison with
two different baselines shows that this method, in the appropriate regime,
consistently improves the diversity of the generated queries without
compromising their quality. We also demonstrate the effectiveness of our
generation method as a data augmentation technique for language modelling
tasks.",2020-11-03
Data-to-Text Generation with Iterative Text Editing,2020-11-03 13:32:38+00:00,http://arxiv.org/abs/2011.01694v1,"Zdeněk Kasner, Ondřej Dušek","cs.CL, I.2.7",table2text,"We present a novel approach to data-to-text generation based on iterative
text editing. Our approach maximizes the completeness and semantic accuracy of
the output text while leveraging the abilities of recent pre-trained models for
text editing (LaserTagger) and language modeling (GPT-2) to improve the text
fluency. To this end, we first transform data items to text using trivial
templates, and then we iteratively improve the resulting text by a neural model
trained for the sentence fusion task. The output of the model is filtered by a
simple heuristic and reranked with an off-the-shelf pre-trained language model.
We evaluate our approach on two major data-to-text datasets (WebNLG, Cleaned
E2E) and analyze its caveats and benefits. Furthermore, we show that our
formulation of data-to-text generation opens up the possibility for zero-shot
domain adaptation using a general-domain dataset for sentence fusion.",2020-11-03
"Topic-Centric Unsupervised Multi-Document Summarization of Scientific
  and News Articles",2020-11-03 04:04:21+00:00,http://arxiv.org/abs/2011.08072v1,"Amanuel Alambo, Cori Lohstroh, Erik Madaus, Swati Padhee, Brandy Foster, Tanvi Banerjee, Krishnaprasad Thirunarayan, Michael Raymer","cs.CL, cs.IR, cs.LG",table2text,"Recent advances in natural language processing have enabled automation of a
wide range of tasks, including machine translation, named entity recognition,
and sentiment analysis. Automated summarization of documents, or groups of
documents, however, has remained elusive, with many efforts limited to
extraction of keywords, key phrases, or key sentences. Accurate abstractive
summarization has yet to be achieved due to the inherent difficulty of the
problem, and limited availability of training data. In this paper, we propose a
topic-centric unsupervised multi-document summarization framework to generate
extractive and abstractive summaries for groups of scientific articles across
20 Fields of Study (FoS) in Microsoft Academic Graph (MAG) and news articles
from DUC-2004 Task 2. The proposed algorithm generates an abstractive summary
by developing salient language unit selection and text generation techniques.
Our approach matches the state-of-the-art when evaluated on automated
extractive evaluation metrics and performs better for abstractive summarization
on five human evaluation metrics (entailment, coherence, conciseness,
readability, and grammar). We achieve a kappa score of 0.68 between two
co-author linguists who evaluated our results. We plan to publicly share
MAG-20, a human-validated gold standard dataset of topic-clustered research
articles and their summaries to promote research in abstractive summarization.",2020-11-03
Deep Learning for Text Style Transfer: A Survey,2020-11-01 04:04:43+00:00,http://arxiv.org/abs/2011.00416v2,"Di Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, Rada Mihalcea","cs.CL, cs.AI, cs.LG",table2text,"Text style transfer (TST) is an important task in natural language generation
(NLG), which aims to control certain attributes in the generated text, such as
politeness, emotion, humor, and many others. It has a long history in the field
of natural language processing (NLP), but recently it has gained significant
attention thanks to the promising performance brought by deep learning models.
In this paper, we present a systematic survey of the research done on neural
text style transfer. We have collected, summarized, and discussed nearly 70
representative articles since the first neural text style transfer work in
2017. Overall, we have covered the task formulation, existing datasets and
subtasks, evaluation metrics, and methods on parallel and non-parallel data. We
also provide discussions a variety of important topics regarding TST, which can
shed light on new development in this field. Our curated paper list is at
https://github.com/zhijing-jin/Text_Style_Transfer_Survey",2020-11-01
Personalized Multimodal Feedback Generation in Education,2020-10-31 05:26:49+00:00,http://arxiv.org/abs/2011.00192v1,"Haochen Liu, Zitao Liu, Zhongqin Wu, Jiliang Tang","cs.CL, cs.AI",table2text,"The automatic evaluation for school assignments is an important application
of AI in the education field. In this work, we focus on the task of
personalized multimodal feedback generation, which aims to generate
personalized feedback for various teachers to evaluate students' assignments
involving multimodal inputs such as images, audios, and texts. This task
involves the representation and fusion of multimodal information and natural
language generation, which presents the challenges from three aspects: 1) how
to encode and integrate multimodal inputs; 2) how to generate feedback specific
to each modality; and 3) how to realize personalized feedback generation. In
this paper, we propose a novel Personalized Multimodal Feedback Generation
Network (PMFGN) armed with a modality gate mechanism and a personalized bias
mechanism to address these challenges. The extensive experiments on real-world
K-12 education data show that our model significantly outperforms several
baselines by generating more accurate and diverse feedback. In addition,
detailed ablation experiments are conducted to deepen our understanding of the
proposed framework.",2020-10-31
Fusion Models for Improved Visual Captioning,2020-10-28 21:55:25+00:00,http://arxiv.org/abs/2010.15251v2,"Marimuthu Kalimuthu, Aditya Mogadala, Marius Mosbach, Dietrich Klakow","cs.CV, cs.AI, cs.CL, cs.LG",table2text,"Visual captioning aims to generate textual descriptions given images or
videos. Traditionally, image captioning models are trained on human annotated
datasets such as Flickr30k and MS-COCO, which are limited in size and
diversity. This limitation hinders the generalization capabilities of these
models while also rendering them liable to making mistakes. Language models
can, however, be trained on vast amounts of freely available unlabelled data
and have recently emerged as successful language encoders and coherent text
generators. Meanwhile, several unimodal and multimodal fusion techniques have
been proven to work well for natural language generation and automatic speech
recognition. Building on these recent developments, and with the aim of
improving the quality of generated captions, the contribution of our work in
this paper is two-fold: First, we propose a generic multimodal model fusion
framework for caption generation as well as emendation where we utilize
different fusion strategies to integrate a pretrained Auxiliary Language Model
(AuxLM) within the traditional encoder-decoder visual captioning frameworks.
Next, we employ the same fusion strategies to integrate a pretrained Masked
Language Model (MLM), namely BERT, with a visual captioning model, viz. Show,
Attend, and Tell, for emending both syntactic and semantic errors in captions.
Our caption emendation experiments on three benchmark image captioning
datasets, viz. Flickr8k, Flickr30k, and MSCOCO, show improvements over the
baseline, indicating the usefulness of our proposed multimodal fusion
strategies. Further, we perform a preliminary qualitative analysis on the
emended captions and identify error categories based on the type of
corrections.",2020-10-28
"NeuroLogic Decoding: (Un)supervised Neural Text Generation with
  Predicate Logic Constraints",2020-10-24 11:55:22+00:00,http://arxiv.org/abs/2010.12884v1,"Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi",cs.CL,table2text,"Conditional text generation often requires lexical constraints, i.e., which
words should or shouldn't be included in the output text. While the dominant
recipe for conditional text generation has been large-scale pretrained language
models that are finetuned on the task-specific training data, such models do
not learn to follow the underlying constraints reliably, even when supervised
with large amounts of task-specific examples.
  We propose NeuroLogic Decoding, a simple yet effective algorithm that enables
neural language models -- supervised or not -- to generate fluent text while
satisfying complex lexical constraints. Our approach is powerful yet efficient.
It handles any set of lexical constraints that is expressible under predicate
logic, while its asymptotic runtime is equivalent to conventional beam search.
  Empirical results on four benchmarks show that NeuroLogic Decoding
outperforms previous approaches, including algorithms that handle a subset of
our constraints. Moreover, we find that unsupervised models with NeuroLogic
Decoding often outperform supervised models with conventional decoding, even
when the latter is based on considerably larger networks. Our results suggest
the limit of large-scale neural networks for fine-grained controllable
generation and the promise of inference-time algorithms.",2020-10-24
Go Figure! A Meta Evaluation of Factuality in Summarization,2020-10-24 08:30:20+00:00,http://arxiv.org/abs/2010.12834v1,"Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, Jianfeng Gao",cs.CL,table2text,"Text generation models can generate factually inconsistent text containing
distorted or fabricated facts about the source text. Recent work has focused on
building evaluation models to verify the factual correctness of semantically
constrained text generation tasks such as document summarization. While the
field of factuality evaluation is growing fast, we don't have well-defined
criteria for measuring the effectiveness, generalizability, reliability, or
sensitivity of the factuality metrics. Focusing on these aspects, in this
paper, we introduce a meta-evaluation framework for evaluating factual
consistency metrics. We introduce five necessary, common-sense conditions for
effective factuality metrics and experiment with nine recent factuality metrics
using synthetic and human-labeled factuality data from short news, long news
and dialogue summarization domains. Our framework enables assessing the
efficiency of any new factual consistency metric on a variety of dimensions
over multiple summarization domains and can be easily extended with new
meta-evaluation criteria. We also present our conclusions towards standardizing
the factuality evaluation metrics.",2020-10-24
"Multilingual Speech Translation with Efficient Finetuning of Pretrained
  Models",2020-10-24 08:15:08+00:00,http://arxiv.org/abs/2010.12829v4,"Xian Li, Changhan Wang, Yun Tang, Chau Tran, Yuqing Tang, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli",cs.CL,table2text,"We present a simple yet effective approach to build multilingual
speech-to-text (ST) translation by efficient transfer learning from pretrained
speech encoder and text decoder. Our key finding is that a minimalistic LNA
(LayerNorm and Attention) finetuning can achieve zero-shot crosslingual and
cross-modality transfer ability by only finetuning less than 10% of the
pretrained parameters. This enables effectively leveraging large pretrained
models with low training cost. Using wav2vec 2.0 for acoustic modeling, and
mBART for multilingual text generation, our approach advanced the new
state-of-the-art for 34 translation directions (and surpassing cascaded ST for
23 of them) on large-scale multilingual ST benchmark CoVoST 2 (+6.4 BLEU on
average across 15 En-X directions and +5.1 BLEU on average across 19 X-En
directions). Our approach demonstrates strong zero-shot performance in a
many-to-many multilingual model (+5.7 BLEU on average across 18 non-English
directions), making it an appealing approach for attaining high-quality speech
translation with improved parameter and data efficiency.",2020-10-24
CaM-Gen:Causally-aware Metric-guided Text Generation,2020-10-24 06:17:35+00:00,http://arxiv.org/abs/2010.12795v1,"Navita Goyal, Roodram Paneri, Ayush Agarwal, Udit Kalani, Abhilasha Sancheti, Niyati Chhaya",cs.CL,table2text,"Content is created for a well-defined purpose, often described by a metric or
a signal represented in the form of structured information. The relationship
between the metrics or the goal of a target content and the content itself are
non-trivial. While large scale language models show promising text generation
capabilities, guiding and informing the generated text with external metrics is
challenging. These metrics and the content tend to have inherent relationships
and not all of them may directly impact the content. We introduce a CaM-Gen:
Causally-aware Generative Networks guided by user-defined input metrics
incorporating the causal relationships between the metric and the content
features. We leverage causal inference techniques to identify the causally
significant aspects of text that leads to the target metric and then explicitly
guide the generative model towards these by a feedback mechanism. We propose
this mechanism for variational autoencoder-based and transformer-based
generative models. The proposed models beat baselines in terms of the target
metric accuracy while maintaining the fluency and the language quality of the
generated text. To the best of our knowledge, this is one of the early attempts
at incorporating a metric-guide using causal inference towards controlled
generation.",2020-10-24
"Large Scale Knowledge Graph Based Synthetic Corpus Generation for
  Knowledge-Enhanced Language Model Pre-training",2020-10-23 22:14:50+00:00,http://arxiv.org/abs/2010.12688v1,"Oshin Agarwal, Heming Ge, Siamak Shakeri, Rami Al-Rfou",cs.CL,table2text,"Generating natural sentences from Knowledge Graph (KG) triples, known as
Data-To-Text Generation, is a task with many datasets for which numerous
complex systems have been developed. However, no prior work has attempted to
perform this generation at scale by converting an entire KG into natural text.
In this paper, we verbalize the entire Wikidata KG, and create a KG-Text
aligned corpus in the training process. We discuss the challenges in
verbalizing an entire KG versus verbalizing smaller datasets. We further show
that verbalizing an entire KG can be used to integrate structured and natural
language data. In contrast to the many architectures that have been developed
to integrate the structural differences between these two sources, our approach
converts the KG into the same format as natural text allowing it to be
seamlessly plugged into existing natural language systems. We evaluate this
approach by augmenting the retrieval corpus in REALM and showing improvements,
both on the LAMA knowledge probe and open domain QA.",2020-10-23
"Detecting and Exorcising Statistical Demons from Language Models with
  Anti-Models of Negative Data",2020-10-22 16:45:32+00:00,http://arxiv.org/abs/2010.11855v1,"Michael L. Wick, Kate Silverstein, Jean-Baptiste Tristan, Adam Pocock, Mark Johnson","cs.CL, cs.AI, cs.LG",table2text,"It's been said that ""Language Models are Unsupervised Multitask Learners.""
Indeed, self-supervised language models trained on ""positive"" examples of
English text generalize in desirable ways to many natural language tasks. But
if such models can stray so far from an initial self-supervision objective, a
wayward model might generalize in undesirable ways too, say to nonsensical
""negative"" examples of unnatural language. A key question in this work is: do
language models trained on (positive) training data also generalize to
(negative) test data? We use this question as a contrivance to assess the
extent to which language models learn undesirable properties of text, such as
n-grams, that might interfere with the learning of more desirable properties of
text, such as syntax. We find that within a model family, as the number of
parameters, training epochs, and data set size increase, so does a model's
ability to generalize to negative n-gram data, indicating standard
self-supervision generalizes too far. We propose a form of inductive bias that
attenuates such undesirable signals with negative data distributions
automatically learned from positive data. We apply the method to remove n-gram
signals from LSTMs and find that doing so causes them to favor syntactic
signals, as demonstrated by large error reductions (up to 46% on the hardest
cases) on a syntactic subject-verb agreement task.",2020-10-22
"Multi-dimensional Style Transfer for Partially Annotated Data using
  Language Models as Discriminators",2020-10-22 10:16:29+00:00,http://arxiv.org/abs/2010.11578v1,"Navita Goyal, Balaji Vasan Srinivasan, Anandhavelu N, Abhilasha Sancheti",cs.CL,table2text,"Style transfer has been widely explored in natural language generation with
non-parallel corpus by directly or indirectly extracting a notion of style from
source and target domain corpus. A common aspect among the existing approaches
is the prerequisite of joint annotations across all the stylistic dimensions
under consideration. Availability of such dataset across a combination of
styles is a limiting factor in extending state-of-the art style transfer setups
to multiple style dimensions. While cascading single-dimensional models across
multiple styles is a possibility, it suffers from content loss, especially when
the style dimensions are not completely independent of each other. In our work,
we attempt to relax this restriction on requirement of jointly annotated data
across multiple styles being inspected and make use of independently acquired
data across different style dimensions without any additional annotations. We
initialize an encoder-decoder setup with large transformer-based language
models pre-trained on a generic corpus and enhance its re-writing capability to
multiple styles by employing multiple language models as discriminators.
Through quantitative and qualitative evaluation, we show the ability of our
model to control for styles across multiple style-dimensions while preserving
content of the input text and compare it against baselines which involve
cascaded state-of-the-art uni-dimensional style transfer models.",2020-10-22
"PARENTing via Model-Agnostic Reinforcement Learning to Correct
  Pathological Behaviors in Data-to-Text Generation",2020-10-21 09:49:47+00:00,http://arxiv.org/abs/2010.10866v2,"Clément Rebuffel, Laure Soulier, Geoffrey Scoutheeten, Patrick Gallinari",cs.CL,table2text,"In language generation models conditioned by structured data, the classical
training via maximum likelihood almost always leads models to pick up on
dataset divergence (i.e., hallucinations or omissions), and to incorporate them
erroneously in their own generations at inference. In this work, we build ontop
of previous Reinforcement Learning based approaches and show that a
model-agnostic framework relying on the recently introduced PARENT metric is
efficient at reducing both hallucinations and omissions. Evaluations on the
widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this
framework compared to state-of-the-art models.",2020-10-21
"Chart-to-Text: Generating Natural Language Descriptions for Charts by
  Adapting the Transformer Model",2020-10-18 23:57:33+00:00,http://arxiv.org/abs/2010.09142v2,"Jason Obeid, Enamul Hoque","cs.CL, cs.AI",table2text,"Information visualizations such as bar charts and line charts are very
popular for exploring data and communicating insights. Interpreting and making
sense of such visualizations can be challenging for some people, such as those
who are visually impaired or have low visualization literacy. In this work, we
introduce a new dataset and present a neural model for automatically generating
natural language summaries for charts. The generated summaries provide an
interpretation of the chart and convey the key insights found within that
chart. Our neural model is developed by extending the state-of-the-art model
for the data-to-text generation task, which utilizes a transformer-based
encoder-decoder architecture. We found that our approach outperforms the base
model on a content selection metric by a wide margin (55.42% vs. 8.49%) and
generates more informative, concise, and coherent summaries.",2020-10-18
"RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich
  Semantic Annotations for Task-Oriented Dialogue Modeling",2020-10-17 08:18:59+00:00,http://arxiv.org/abs/2010.08738v1,"Jun Quan, Shian Zhang, Qian Cao, Zizhong Li, Deyi Xiong",cs.CL,table2text,"In order to alleviate the shortage of multi-domain data and to capture
discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a
large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic
Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn
semantically annotated dialogues, with more than 150K utterances spanning over
12 domains, which is larger than all previous annotated H2H conversational
datasets. Both single- and multi-domain dialogues are constructed, accounting
for 65% and 35%, respectively. Each dialogue is labeled with comprehensive
dialogue annotations, including dialogue goal in the form of natural language
description, domain, dialogue states and acts at both the user and system side.
In addition to traditional dialogue annotations, we especially provide
linguistic annotations on discourse phenomena, e.g., ellipsis and coreference,
in dialogues, which are useful for dialogue coreference and ellipsis resolution
tasks. Apart from the fully annotated dataset, we also present a detailed
description of the data collection procedure, statistics and analysis of the
dataset. A series of benchmark models and results are reported, including
natural language understanding (intent detection & slot filling), dialogue
state tracking and dialogue context-to-text generation, as well as coreference
and ellipsis resolution, which facilitate the baseline comparison for future
research on this corpus.",2020-10-17
Learning Better Representation for Tables by Self-Supervised Tasks,2020-10-15 09:03:38+00:00,http://arxiv.org/abs/2010.07606v1,"Liang Li, Can Ma, Yinliang Yue, Linjun Shou, Dayong Hu",cs.CL,table2text,"Table-to-text generation aims at automatically generating natural text to
help people to conveniently obtain the important information in tables.
Although neural models for table-to-text have achieved remarkable progress,
some problems still overlooked. The first is that the values recorded in many
tables are mostly numbers in practice. The existing approaches do not do
special treatment for these, and still regard these as words in natural
language text. Secondly, the target texts in training dataset may contain
redundant information or facts do not exist in the input tables. These may give
wrong supervision signals to some methods based on content selection and
planning and auxiliary supervision. To solve these problems, we propose two
self-supervised tasks, Number Ordering and Significance Ordering, to help to
learn better table representation. The former works on the column dimension to
help to incorporate the size property of numbers into table representation. The
latter acts on row dimension and help to learn a significance-aware table
representation. We test our methods on the widely used dataset ROTOWIRE which
consists of NBA game statistic and related news. The experimental results
demonstrate that the model trained together with these two self-supervised
tasks can generate text that contains more salient and well-organized facts,
even without modeling context selection and planning. And we achieve the
state-of-the-art performance on automatic metrics.",2020-10-15
"Grammatical Error Correction in Low Error Density Domains: A New
  Benchmark and Analyses",2020-10-15 07:52:01+00:00,http://arxiv.org/abs/2010.07574v1,"Simon Flachs, Ophélie Lacroix, Helen Yannakoudakis, Marek Rei, Anders Søgaard",cs.CL,table2text,"Evaluation of grammatical error correction (GEC) systems has primarily
focused on essays written by non-native learners of English, which however is
only part of the full spectrum of GEC applications. We aim to broaden the
target domain of GEC and release CWEB, a new benchmark for GEC consisting of
website text generated by English speakers of varying levels of proficiency.
Website data is a common and important domain that contains far fewer
grammatical errors than learner essays, which we show presents a challenge to
state-of-the-art GEC systems. We demonstrate that a factor behind this is the
inability of systems to rely on a strong internal language model in low error
density domains. We hope this work shall facilitate the development of
open-domain GEC models that generalize to different topics and genres.",2020-10-15
Neural Deepfake Detection with Factual Structure of Text,2020-10-15 02:35:31+00:00,http://arxiv.org/abs/2010.07475v1,"Wanjun Zhong, Duyu Tang, Zenan Xu, Ruize Wang, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin",cs.CL,table2text,"Deepfake detection, the task of automatically discriminating
machine-generated text, is increasingly critical with recent advances in
natural language generative models. Existing approaches to deepfake detection
typically represent documents with coarse-grained representations. However,
they struggle to capture factual structures of documents, which is a
discriminative factor between machine-generated and human-written text
according to our statistical analysis. To address this, we propose a
graph-based model that utilizes the factual structure of a document for
deepfake detection of text. Our approach represents the factual structure of a
given document as an entity graph, which is further utilized to learn sentence
representations with a graph neural network. Sentence representations are then
composed to a document representation for making predictions, where consistent
relations between neighboring sentences are sequentially modeled. Results of
experiments on two public deepfake datasets show that our approach
significantly improves strong base models built with RoBERTa. Model analysis
further indicates that our model can distinguish the difference in the factual
structure between machine-generated text and human-written text.",2020-10-15
"ReviewRobot: Explainable Paper Review Generation based on Knowledge
  Synthesis",2020-10-13 02:17:58+00:00,http://arxiv.org/abs/2010.06119v3,"Qingyun Wang, Qi Zeng, Lifu Huang, Kevin Knight, Heng Ji, Nazneen Fatema Rajani","cs.CL, cs.AI",table2text,"To assist human review process, we build a novel ReviewRobot to automatically
assign a review score and write comments for multiple categories such as
novelty and meaningful comparison. A good review needs to be knowledgeable,
namely that the comments should be constructive and informative to help improve
the paper; and explainable by providing detailed evidence. ReviewRobot achieves
these goals via three steps: (1) We perform domain-specific Information
Extraction to construct a knowledge graph (KG) from the target paper under
review, a related work KG from the papers cited by the target paper, and a
background KG from a large collection of previous papers in the domain. (2) By
comparing these three KGs, we predict a review score and detailed structured
knowledge as evidence for each review category. (3) We carefully select and
generalize human review sentences into templates, and apply these templates to
transform the review scores and evidence into natural language comments.
Experimental results show that our review score predictor reaches 71.4%-100%
accuracy. Human assessment by domain experts shows that 41.7%-70.5% of the
comments generated by ReviewRobot are valid and constructive, and better than
human-written ones for 20% of the time. Thus, ReviewRobot can serve as an
assistant for paper reviewers, program chairs and authors.",2020-10-13
Improving Text Generation with Student-Forcing Optimal Transport,2020-10-12 19:42:25+00:00,http://arxiv.org/abs/2010.05994v1,"Guoyin Wang, Chunyuan Li, Jianqiao Li, Hao Fu, Yuh-Chen Lin, Liqun Chen, Yizhe Zhang, Chenyang Tao, Ruiyi Zhang, Wenlin Wang, Dinghan Shen, Qian Yang, Lawrence Carin","cs.CL, cs.LG",table2text,"Neural language models are often trained with maximum likelihood estimation
(MLE), where the next word is generated conditioned on the ground-truth word
tokens. During testing, however, the model is instead conditioned on previously
generated tokens, resulting in what is termed exposure bias. To reduce this gap
between training and testing, we propose using optimal transport (OT) to match
the sequences generated in these two modes. An extension is further proposed to
improve the OT learning, based on the structural and contextual information of
the text sequences. The effectiveness of the proposed method is validated on
machine translation, text summarization, and text generation tasks.",2020-10-12
"Controlled Hallucinations: Learning to Generate Faithfully from Noisy
  Data",2020-10-12 17:25:02+00:00,http://arxiv.org/abs/2010.05873v1,Katja Filippova,cs.CL,table2text,"Neural text generation (data- or text-to-text) demonstrates remarkable
performance when training data is abundant which for many applications is not
the case. To collect a large corpus of parallel data, heuristic rules are often
used but they inevitably let noise into the data, such as phrases in the output
which cannot be explained by the input. Consequently, models pick up on the
noise and may hallucinate--generate fluent but unsupported text. Our
contribution is a simple but powerful technique to treat such hallucinations as
a controllable aspect of the generated text, without dismissing any input and
without modifying the model architecture. On the WikiBio corpus (Lebret et al.,
2016), a particularly noisy dataset, we demonstrate the efficacy of the
technique both in an automatic and in a human evaluation.",2020-10-12
"A Sentiment-Controllable Topic-to-Essay Generator with Topic Knowledge
  Graph",2020-10-12 08:06:12+00:00,http://arxiv.org/abs/2010.05511v1,"Lin Qiao, Jianhao Yan, Fandong Meng, Zhendong Yang, Jie Zhou",cs.CL,table2text,"Generating a vivid, novel, and diverse essay with only several given topic
words is a challenging task of natural language generation. In previous work,
there are two problems left unsolved: neglect of sentiment beneath the text and
insufficient utilization of topic-related knowledge. Therefore, we propose a
novel Sentiment-Controllable topic-to-essay generator with a Topic Knowledge
Graph enhanced decoder, named SCTKG, which is based on the conditional
variational autoencoder (CVAE) framework. We firstly inject the sentiment
information into the generator for controlling sentiment for each sentence,
which leads to various generated essays. Then we design a Topic Knowledge Graph
enhanced decoder. Unlike existing models that use knowledge entities
separately, our model treats the knowledge graph as a whole and encodes more
structured, connected semantic information in the graph to generate a more
relevant essay. Experimental results show that our SCTKG can generate sentiment
controllable essays and outperform the state-of-the-art approach in terms of
topic relevance, fluency, and diversity on both automatic and human evaluation.",2020-10-12
Evaluating Factuality in Generation with Dependency-level Entailment,2020-10-12 06:43:10+00:00,http://arxiv.org/abs/2010.05478v2,"Tanya Goyal, Greg Durrett",cs.CL,table2text,"Despite significant progress in text generation models, a serious limitation
is their tendency to produce text that is factually inconsistent with
information in the input. Recent work has studied whether textual entailment
systems can be used to identify factual errors; however, these sentence-level
entailment models are trained to solve a different problem than generation
filtering and they do not localize which part of a generation is non-factual.
In this paper, we propose a new formulation of entailment that decomposes it at
the level of dependency arcs. Rather than focusing on aggregate decisions, we
instead ask whether the semantic relationship manifested by individual
dependency arcs in the generated output is supported by the input. Human
judgments on this task are difficult to obtain; we therefore propose a method
to automatically create data based on existing entailment or paraphrase
corpora. Experiments show that our dependency arc entailment model trained on
this data can identify factual inconsistencies in paraphrasing and
summarization better than sentence-level methods or those based on question
generation, while additionally localizing the erroneous parts of the
generation.",2020-10-12
On Long-Tailed Phenomena in Neural Machine Translation,2020-10-10 07:00:57+00:00,http://arxiv.org/abs/2010.04924v1,"Vikas Raunak, Siddharth Dalmia, Vivek Gupta, Florian Metze","cs.CL, cs.AI, cs.LG",table2text,"State-of-the-art Neural Machine Translation (NMT) models struggle with
generating low-frequency tokens, tackling which remains a major challenge. The
analysis of long-tailed phenomena in the context of structured prediction tasks
is further hindered by the added complexities of search during inference. In
this work, we quantitatively characterize such long-tailed phenomena at two
levels of abstraction, namely, token classification and sequence generation. We
propose a new loss function, the Anti-Focal loss, to better adapt model
training to the structural dependencies of conditional text generation by
incorporating the inductive biases of beam search in the training process. We
show the efficacy of the proposed technique on a number of Machine Translation
(MT) datasets, demonstrating that it leads to significant gains over
cross-entropy across different language pairs, especially on the generation of
low-frequency words. We have released the code to reproduce our results.",2020-10-10
"Adversarial Self-Supervised Data-Free Distillation for Text
  Classification",2020-10-10 02:46:06+00:00,http://arxiv.org/abs/2010.04883v1,"Xinyin Ma, Yongliang Shen, Gongfan Fang, Chen Chen, Chenghao Jia, Weiming Lu","cs.CL, cs.AI",table2text,"Large pre-trained transformer-based language models have achieved impressive
results on a wide range of NLP tasks. In the past few years, Knowledge
Distillation(KD) has become a popular paradigm to compress a computationally
expensive model to a resource-efficient lightweight model. However, most KD
algorithms, especially in NLP, rely on the accessibility of the original
training dataset, which may be unavailable due to privacy issues. To tackle
this problem, we propose a novel two-stage data-free distillation method, named
Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed
for compressing large-scale transformer-based models (e.g., BERT). To avoid
text generation in discrete space, we introduce a Plug & Play Embedding
Guessing method to craft pseudo embeddings from the teacher's hidden knowledge.
Meanwhile, with a self-supervised module to quantify the student's ability, we
adapt the difficulty of pseudo embeddings in an adversarial training manner. To
the best of our knowledge, our framework is the first data-free distillation
framework designed for NLP tasks. We verify the effectiveness of our method on
several text classification datasets.",2020-10-10
A Survey of Knowledge-Enhanced Text Generation,2020-10-09 06:46:46+00:00,http://arxiv.org/abs/2010.04389v1,"Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, Meng Jiang","cs.CL, cs.AI, cs.LG",table2text,"The goal of text generation is to make machines express in human language. It
is one of the most important yet challenging tasks in natural language
processing (NLP). Since 2014, various neural encoder-decoder models pioneered
by Seq2Seq have been proposed to achieve the goal by learning to map input text
to output text. However, the input text alone often provides limited knowledge
to generate the desired output, so the performance of text generation is still
far from satisfaction in many real-world scenarios. To address this issue,
researchers have considered incorporating various forms of knowledge beyond the
input text into the generation models. This research direction is known as
knowledge-enhanced text generation. In this survey, we present a comprehensive
review of the research on knowledge enhanced text generation over the past five
years. The main content includes two parts: (i) general methods and
architectures for integrating knowledge into text generation; (ii) specific
techniques and applications according to different forms of knowledge data.
This survey can have broad audiences, researchers and practitioners, in
academia and industry.",2020-10-09
"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text
  Generation",2020-10-09 06:03:46+00:00,http://arxiv.org/abs/2010.04383v1,"Yan Zhang, Zhijiang Guo, Zhiyang Teng, Wei Lu, Shay B. Cohen, Zuozhu Liu, Lidong Bing",cs.CL,table2text,"AMR-to-text generation is used to transduce Abstract Meaning Representation
structures (AMR) into text. A key challenge in this task is to efficiently
learn effective graph representations. Previously, Graph Convolution Networks
(GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to
capture non-local information and additionally, they follow a local
(first-order) information aggregation scheme. To account for these issues,
larger and deeper GCN models are required to capture more complex interactions.
In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight
Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local
interactions by synthesizing higher order information from the input graphs. We
further develop two novel parameter saving strategies based on the group graph
convolutions and weight tied convolutions to reduce memory usage and model
complexity. With the help of these strategies, we are able to train a model
with fewer parameters while maintaining the model capacity. Experiments
demonstrate that LDGCNs outperform state-of-the-art models on two benchmark
datasets for AMR-to-text generation with significantly fewer parameters.",2020-10-09
"A Cascade Approach to Neural Abstractive Summarization with Content
  Selection and Fusion",2020-10-08 01:49:16+00:00,http://arxiv.org/abs/2010.03722v1,"Logan Lebanoff, Franck Dernoncourt, Doo Soon Kim, Walter Chang, Fei Liu",cs.CL,table2text,"We present an empirical study in favor of a cascade architecture to neural
text summarization. Summarization practices vary widely but few other than news
summarization can provide a sufficient amount of training data enough to meet
the requirement of end-to-end neural abstractive systems which perform content
selection and surface realization jointly to generate abstracts. Such systems
also pose a challenge to summarization evaluation, as they force content
selection to be evaluated along with text generation, yet evaluation of the
latter remains an unsolved problem. In this paper, we present empirical results
showing that the performance of a cascaded pipeline that separately identifies
important content pieces and stitches them together into a coherent text is
comparable to or outranks that of end-to-end systems, whereas a pipeline
architecture allows for flexible content selection. We finally discuss how we
can take advantage of a cascaded pipeline in neural text summarization and shed
light on important directions for future research.",2020-10-08
"Stepwise Extractive Summarization and Planning with Structured
  Transformers",2020-10-06 14:12:58+00:00,http://arxiv.org/abs/2010.02744v1,"Shashi Narayan, Joshua Maynez, Jakub Adamek, Daniele Pighin, Blaž Bratanič, Ryan McDonald",cs.CL,table2text,"We propose encoder-centric stepwise models for extractive summarization using
structured transformers -- HiBERT and Extended Transformers. We enable stepwise
summarization by injecting the previously generated summary into the structured
transformer as an auxiliary sub-structure. Our models are not only efficient in
modeling the structure of long inputs, but they also do not rely on
task-specific redundancy-aware modeling, making them a general purpose
extractive content planner for different tasks. When evaluated on CNN/DailyMail
extractive summarization, stepwise models achieve state-of-the-art performance
in terms of Rouge without any redundancy aware modeling or sentence filtering.
This also holds true for Rotowire table-to-text generation, where our models
surpass previously reported metrics for content selection, planning and
ordering, highlighting the strength of stepwise modeling. Amongst the two
structured transformers we test, stepwise Extended Transformers provides the
best performance across both datasets and sets a new standard for these
challenges.",2020-10-06
"Investigating African-American Vernacular English in Transformer-Based
  Text Generation",2020-10-06 06:27:02+00:00,http://arxiv.org/abs/2010.02510v2,"Sophie Groenwold, Lily Ou, Aesha Parekh, Samhita Honnavalli, Sharon Levy, Diba Mirza, William Yang Wang","cs.CL, cs.AI",table2text,"The growth of social media has encouraged the written use of African American
Vernacular English (AAVE), which has traditionally been used only in oral
contexts. However, NLP models have historically been developed using dominant
English varieties, such as Standard American English (SAE), due to text corpora
availability. We investigate the performance of GPT-2 on AAVE text by creating
a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating
syntactic structure and AAVE- or SAE-specific language for each pair. We
evaluate each sample and its GPT-2 generated text with pretrained sentiment
classifiers and find that while AAVE text results in more classifications of
negative sentiment than SAE, the use of GPT-2 generally increases occurrences
of positive sentiment for both. Additionally, we conduct human evaluation of
AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall
quality.",2020-10-06
"Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on
  Chest X-rays",2020-10-06 04:18:18+00:00,http://arxiv.org/abs/2010.02467v1,"Jianmo Ni, Chun-Nan Hsu, Amilcare Gentili, Julian McAuley","cs.CV, cs.CL",table2text,"Automatic medical image report generation has drawn growing attention due to
its potential to alleviate radiologists' workload. Existing work on report
generation often trains encoder-decoder networks to generate complete reports.
However, such models are affected by data bias (e.g.~label imbalance) and face
common issues inherent in text generation models (e.g.~repetition). In this
work, we focus on reporting abnormal findings on radiology images; instead of
training on complete radiology reports, we propose a method to identify
abnormal findings from the reports in addition to grouping them with
unsupervised clustering and minimal rules. We formulate the task as cross-modal
retrieval and propose Conditional Visual-Semantic Embeddings to align images
and fine-grained abnormal findings in a joint embedding space. We demonstrate
that our method is able to retrieve abnormal findings and outperforms existing
generation models on both clinical correctness and text generation metrics.",2020-10-06
KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation,2020-10-05 19:59:05+00:00,http://arxiv.org/abs/2010.02307v2,"Wenhu Chen, Yu Su, Xifeng Yan, William Yang Wang","cs.CL, cs.AI",table2text,"Data-to-text generation has recently attracted substantial interests due to
its wide applications. Existing methods have shown impressive performance on an
array of tasks. However, they rely on a significant amount of labeled data for
each task, which is costly to acquire and thus limits their application to new
tasks and domains. In this paper, we propose to leverage pre-training and
transfer learning to address this issue. We propose a knowledge-grounded
pre-training (KGPT), which consists of two parts, 1) a general
knowledge-grounded generation model to generate knowledge-enriched text. 2) a
pre-training paradigm on a massive knowledge-grounded text corpus crawled from
the web. The pre-trained model can be fine-tuned on various data-to-text
generation tasks to generate task-specific text. We adopt three settings,
namely fully-supervised, zero-shot, few-shot to evaluate its effectiveness.
Under the fully-supervised setting, our model can achieve remarkable gains over
the known baselines. Under zero-shot setting, our model without seeing any
examples achieves over 30 ROUGE-L on WebNLG while all other baselines fail.
Under the few-shot setting, our model only needs about one-fifteenth as many
labeled examples to achieve the same level of performance as baseline models.
These experiments consistently prove the strong generalization ability of our
proposed framework https://github.com/wenhuchen/KGPT.",2020-10-05
"PAIR: Planning and Iterative Refinement in Pre-trained Transformers for
  Long Text Generation",2020-10-05 19:45:03+00:00,http://arxiv.org/abs/2010.02301v1,"Xinyu Hua, Lu Wang",cs.CL,table2text,"Pre-trained Transformers have enabled impressive breakthroughs in generating
long and fluent text, yet their outputs are often ""rambling"" without coherently
arranged content. In this work, we present a novel content-controlled text
generation framework, PAIR, with planning and iterative refinement, which is
built upon a large model, BART. We first adapt the BERT model to automatically
construct the content plans, consisting of keyphrase assignments and their
corresponding sentence-level positions. The BART model is employed for
generation without modifying its structure. We then propose a refinement
algorithm to gradually enhance the generation quality within the
sequence-to-sequence framework. Evaluation with automatic metrics shows that
adding planning consistently improves the generation quality on three distinct
domains, with an average of 20 BLEU points and 12 METEOR points improvements.
In addition, human judges rate our system outputs to be more relevant and
coherent than comparisons without planning.",2020-10-05
GenAug: Data Augmentation for Finetuning Text Generators,2020-10-05 05:46:39+00:00,http://arxiv.org/abs/2010.01794v2,"Steven Y. Feng, Varun Gangal, Dongyeop Kang, Teruko Mitamura, Eduard Hovy","cs.CL, cs.AI, cs.LG",table2text,"In this paper, we investigate data augmentation for text generation, which we
call GenAug. Text generation and language modeling are important tasks within
natural language processing, and are especially challenging for low-data
regimes. We propose and evaluate various augmentation methods, including some
that incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp
Reviews. We also examine the relationship between the amount of augmentation
and the quality of the generated text. We utilize several metrics that evaluate
important aspects of the generated text including its diversity and fluency.
Our experiments demonstrate that insertion of character-level synthetic noise
and keyword replacement with hypernyms are effective augmentation methods, and
that the quality of generations improves to a peak at approximately three times
the amount of original data.",2020-10-05
Transformer-Based Neural Text Generation with Syntactic Guidance,2020-10-05 01:33:58+00:00,http://arxiv.org/abs/2010.01737v1,"Yinghao Li, Rui Feng, Isaac Rehg, Chao Zhang",cs.CL,table2text,"We study the problem of using (partial) constituency parse trees as syntactic
guidance for controlled text generation. Existing approaches to this problem
use recurrent structures, which not only suffer from the long-term dependency
problem but also falls short in modeling the tree structure of the syntactic
guidance. We propose to leverage the parallelism of Transformer to better
incorporate parse trees. Our method first expands a partial template
constituency parse tree to a full-fledged parse tree tailored for the input
source text, and then uses the expanded tree to guide text generation. The
effectiveness of our model in this process hinges upon two new attention
mechanisms: 1) a path attention mechanism that forces one node to attend to
only other nodes located in its path in the syntax tree to better incorporate
syntax guidance; 2) a multi-encoder attention mechanism that allows the decoder
to dynamically attend to information from multiple encoders. Our experiments in
the controlled paraphrasing task show that our method outperforms SOTA models
both semantically and syntactically, improving the best baseline's BLEU score
from 11.83 to 26.27.",2020-10-05
Partially-Aligned Data-to-Text Generation with Distant Supervision,2020-10-03 03:18:52+00:00,http://arxiv.org/abs/2010.01268v1,"Zihao Fu, Bei Shi, Wai Lam, Lidong Bing, Zhiyuan Liu",cs.CL,table2text,"The Data-to-Text task aims to generate human-readable text for describing
some given structured data enabling more interpretability. However, the typical
generation task is confined to a few particular domains since it requires
well-aligned data which is difficult and expensive to obtain. Using
partially-aligned data is an alternative way of solving the dataset scarcity
problem. This kind of data is much easier to obtain since it can be produced
automatically. However, using this kind of data induces the over-generation
problem posing difficulties for existing models, which tends to add unrelated
excerpts during the generation procedure. In order to effectively utilize
automatically annotated partially-aligned datasets, we extend the traditional
generation task to a refined task called Partially-Aligned Data-to-Text
Generation (PADTG) which is more practical since it utilizes automatically
annotated data for training and thus considerably expands the application
domains. To tackle this new task, we propose a novel distant supervision
generation framework. It firstly estimates the input data's supportiveness for
each target word with an estimator and then applies a supportiveness adaptor
and a rebalanced beam search to harness the over-generation problem in the
training and generation phases respectively. We also contribute a
partially-aligned dataset (The data and source code of this paper can be
obtained from https://github.com/fuzihaofzh/distant_supervision_nlg by sampling
sentences from Wikipedia and automatically extracting corresponding KB triples
for each sentence from Wikidata. The experimental results show that our
framework outperforms all baseline models as well as verify the feasibility of
utilizing partially-aligned data.",2020-10-03
"Continual Learning for Natural Language Generation in Task-oriented
  Dialog Systems",2020-10-02 10:32:29+00:00,http://arxiv.org/abs/2010.00910v1,"Fei Mi, Liangwei Chen, Mengjie Zhao, Minlie Huang, Boi Faltings","cs.CL, cs.LG",table2text,"Natural language generation (NLG) is an essential component of task-oriented
dialog systems. Despite the recent success of neural approaches for NLG, they
are typically developed in an offline manner for particular domains. To better
fit real-life applications where new data come in a stream, we study NLG in a
""continual learning"" setting to expand its knowledge to new domains or
functionalities incrementally. The major challenge towards this goal is
catastrophic forgetting, meaning that a continually trained model tends to
forget the knowledge it has learned before. To this end, we propose a method
called ARPER (Adaptively Regularized Prioritized Exemplar Replay) by replaying
prioritized historical exemplars, together with an adaptive regularization
technique based on ElasticWeight Consolidation. Extensive experiments to
continually learn new domains and intents are conducted on MultiWoZ-2.0 to
benchmark ARPER with a wide range of techniques. Empirical results demonstrate
that ARPER significantly outperforms other methods by effectively mitigating
the detrimental catastrophic forgetting issue.",2020-10-02
"Learning from Mistakes: Combining Ontologies via Self-Training for
  Dialogue Generation",2020-09-30 23:54:38+00:00,http://arxiv.org/abs/2010.00150v1,"Lena Reed, Vrindavan Harrison, Shereen Oraby, Dilek Hakkani-Tur, Marilyn Walker",cs.CL,table2text,"Natural language generators (NLGs) for task-oriented dialogue typically take
a meaning representation (MR) as input. They are trained end-to-end with a
corpus of MR/utterance pairs, where the MRs cover a specific set of dialogue
acts and domain attributes. Creation of such datasets is labor-intensive and
time-consuming. Therefore, dialogue systems for new domain ontologies would
benefit from using data for pre-existing ontologies. Here we explore, for the
first time, whether it is possible to train an NLG for a new larger ontology
using existing training sets for the restaurant domain, where each set is based
on a different ontology. We create a new, larger combined ontology, and then
train an NLG to produce utterances covering it. For example, if one dataset has
attributes for family-friendly and rating information, and the other has
attributes for decor and service, our aim is an NLG for the combined ontology
that can produce utterances that realize values for family-friendly, rating,
decor and service. Initial experiments with a baseline neural
sequence-to-sequence model show that this task is surprisingly challenging. We
then develop a novel self-training method that identifies (errorful) model
outputs, automatically constructs a corrected MR input to form a new (MR,
utterance) training pair, and then repeatedly adds these new instances back
into the training data. We then test the resulting model on a new test set. The
result is a self-trained model whose performance is an absolute 75.4%
improvement over the baseline model. We also report a human qualitative
evaluation of the final model showing that it achieves high naturalness,
semantic coherence and grammaticality",2020-09-30
Utterance-level Dialogue Understanding: An Empirical Study,2020-09-29 09:50:21+00:00,http://arxiv.org/abs/2009.13902v5,"Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria",cs.CL,table2text,"The recent abundance of conversational data on the Web and elsewhere calls
for effective NLP systems for dialog understanding. Complete utterance-level
understanding often requires context understanding, defined by nearby
utterances. In recent years, a number of approaches have been proposed for
various utterance-level dialogue understanding tasks. Most of these approaches
account for the context for effective understanding. In this paper, we explore
and quantify the role of context for different aspects of a dialogue, namely
emotion, intent, and dialogue act identification, using state-of-the-art dialog
understanding methods as baselines. Specifically, we employ various
perturbations to distort the context of a given utterance and study its impact
on the different tasks and baselines. This provides us with insights into the
fundamental contextual controlling factors of different aspects of a dialogue.
Such insights can inspire more effective dialogue understanding models, and
provide support for future text generation approaches. The implementation
pertaining to this work is available at
https://github.com/declare-lab/dialogue-understanding.",2020-09-29
iNLTK: Natural Language Toolkit for Indic Languages,2020-09-26 08:21:32+00:00,http://arxiv.org/abs/2009.12534v2,Gaurav Arora,cs.CL,table2text,"We present iNLTK, an open-source NLP library consisting of pre-trained
language models and out-of-the-box support for Data Augmentation, Textual
Similarity, Sentence Embeddings, Word Embeddings, Tokenization and Text
Generation in 13 Indic Languages. By using pre-trained models from iNLTK for
text classification on publicly available datasets, we significantly outperform
previously reported results. On these datasets, we also show that by using
pre-trained models and data augmentation from iNLTK, we can achieve more than
95% of the previous best performance by using less than 10% of the training
data. iNLTK is already being widely used by the community and has 40,000+
downloads, 600+ stars and 100+ forks on GitHub. The library is available at
https://github.com/goru001/inltk.",2020-09-26
"Language Generation with Multi-Hop Reasoning on Commonsense Knowledge
  Graph",2020-09-24 13:55:32+00:00,http://arxiv.org/abs/2009.11692v1,"Haozhe Ji, Pei Ke, Shaohan Huang, Furu Wei, Xiaoyan Zhu, Minlie Huang",cs.CL,table2text,"Despite the success of generative pre-trained language models on a series of
text generation tasks, they still suffer in cases where reasoning over
underlying commonsense knowledge is required during generation. Existing
approaches that integrate commonsense knowledge into generative pre-trained
language models simply transfer relational knowledge by post-training on
individual knowledge triples while ignoring rich connections within the
knowledge graph. We argue that exploiting both the structural and semantic
information of the knowledge graph facilitates commonsense-aware text
generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow
(GRF) that enables pre-trained models with dynamic multi-hop reasoning on
multi-relational paths extracted from the external commonsense knowledge graph.
We empirically show that our model outperforms existing baselines on three text
generation tasks that require reasoning over commonsense knowledge. We also
demonstrate the effectiveness of the dynamic multi-hop reasoning module with
reasoning paths inferred by the model that provide rationale to the generation.",2020-09-24
"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language
  Models",2020-09-24 03:17:19+00:00,http://arxiv.org/abs/2009.11462v2,"Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, Noah A. Smith",cs.CL,table2text,"Pretrained neural language models (LMs) are prone to generating racist,
sexist, or otherwise toxic language which hinders their safe deployment. We
investigate the extent to which pretrained LMs can be prompted to generate
toxic language, and the effectiveness of controllable text generation
algorithms at preventing such toxic degeneration. We create and release
RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level
prompts derived from a large corpus of English web text, paired with toxicity
scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we
find that pretrained LMs can degenerate into toxic text even from seemingly
innocuous prompts. We empirically assess several controllable generation
methods, and find that while data- or compute-intensive methods (e.g., adaptive
pretraining on non-toxic data) are more effective at steering away from
toxicity than simpler solutions (e.g., banning ""bad"" words), no current method
is failsafe against neural toxic degeneration. To pinpoint the potential cause
of such persistent toxic degeneration, we analyze two web text corpora used to
pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a
significant amount of offensive, factually unreliable, and otherwise toxic
content. Our work provides a test bed for evaluating toxic generations by LMs
and stresses the need for better data selection processes for pretraining.",2020-09-24
Content Planning for Neural Story Generation with Aristotelian Rescoring,2020-09-21 13:41:32+00:00,http://arxiv.org/abs/2009.09870v2,"Seraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph Weischedel, Nanyun Peng","cs.CL, cs.AI",table2text,"Long-form narrative text generated from large language models manages a
fluent impersonation of human writing, but only at the local sentence level,
and lacks structure or global cohesion. We posit that many of the problems of
story generation can be addressed via high-quality content planning, and
present a system that focuses on how to learn good plot structures to guide
story generation. We utilize a plot-generation language model along with an
ensemble of rescoring models that each implement an aspect of good
story-writing as detailed in Aristotle's Poetics. We find that stories written
with our more principled plot-structure are both more relevant to a given
prompt and higher quality than baselines that do not content plan, or that plan
in an unprincipled way.",2020-09-21
Prior Art Search and Reranking for Generated Patent Text,2020-09-19 01:16:18+00:00,http://arxiv.org/abs/2009.09132v1,"Jieh-Sheng Lee, Jieh Hsiang",cs.CL,table2text,"Generative models, such as GPT-2, have demonstrated impressive results
recently. A fundamental question we'd like to address is: where did the
generated text come from? This work is our initial effort toward answering the
question by using prior art search. The purpose of the prior art search is to
find the most similar prior text in the training data of GPT-2. We take a
reranking approach and apply it to the patent domain. Specifically, we
pre-train GPT-2 models from scratch by using the patent data from the USPTO.
The input for the prior art search is the patent text generated by the GPT-2
model. We also pre-trained BERT models from scratch for converting patent text
to embeddings. The steps of reranking are: (1) search the most similar text in
the training data of GPT-2 by taking a bag-of-word ranking approach (BM25), (2)
convert the search results in text format to BERT embeddings, and (3) provide
the final result by ranking the BERT embeddings based on their similarities
with the patent text generated by GPT-2. The experiments in this work show that
such reranking is better than ranking with embeddings alone. However, our mixed
results also indicate that calculating the semantic similarities among long
text spans is still challenging. To our knowledge, this work is the first to
implement a reranking system to identify retrospectively the most similar
inputs to a GPT model based on its output.",2020-09-19
Text Generation by Learning from Off-Policy Demonstrations,2020-09-16 17:58:37+00:00,http://arxiv.org/abs/2009.07839v1,"Richard Yuanzhe Pang, He He","cs.CL, cs.LG",table2text,"Current approaches to text generation largely rely on autoregressive models
and maximum likelihood estimation. This paradigm leads to (i) diverse but
low-quality samples due to mismatched learning objective and evaluation metric
(likelihood vs. quality) and (ii) exposure bias due to mismatched history
distributions (gold vs. model-generated). To alleviate these problems, we frame
text generation as a reinforcement learning (RL) problem with expert
demonstrations (i.e., the training data), where the goal is to maximize quality
given model-generated histories. Prior RL approaches to generation often face
optimization issues due to the large action space and sparse reward. We propose
GOLD (generation by off-policy learning from demonstrations): an algorithm that
learns from the off-policy demonstrations by importance weighting and does not
suffer from degenerative solutions. We find that GOLD outperforms the baselines
according to automatic and human evaluation on summarization, question
generation, and machine translation, including attaining state-of-the-art
results for CNN/DailyMail summarization. Further, we show that models trained
by GOLD are less sensitive to decoding algorithms and the generation quality
does not degrade much as the length increases.",2020-09-16
Knowledge Graphs for Multilingual Language Translation and Generation,2020-09-16 14:36:41+00:00,http://arxiv.org/abs/2009.07715v1,Diego Moussallem,cs.CL,table2text,"The Natural Language Processing (NLP) community has recently seen outstanding
progress, catalysed by the release of different Neural Network (NN)
architectures. Neural-based approaches have proven effective by significantly
increasing the output quality of a large number of automated solutions for NLP
tasks (Belinkov and Glass, 2019). Despite these notable advancements, dealing
with entities still poses a difficult challenge as they are rarely seen in
training data. Entities can be classified into two groups, i.e., proper nouns
and common nouns. Proper nouns are also known as Named Entities (NE) and
correspond to the name of people, organizations, or locations, e.g., John, WHO,
or Canada. Common nouns describe classes of objects, e.g., spoon or cancer.
Both types of entities can be found in a Knowledge Graph (KG). Recent work has
successfully exploited the contribution of KGs in NLP tasks, such as Natural
Language Inference (NLI) (KM et al.,2018) and Question Answering (QA) (Sorokin
and Gurevych, 2018). Only a few works had exploited the benefits of KGs in
Neural Machine Translation (NMT) when the work presented herein began.
Additionally, few works had studied the contribution of KGs to Natural Language
Generation (NLG) tasks. Moreover, the multilinguality also remained an open
research area in these respective tasks (Young et al., 2018). In this thesis,
we focus on the use of KGs for machine translation and the generation of texts
to deal with the problems caused by entities and consequently enhance the
quality of automatically generated texts.",2020-09-16
A Comparison of LSTM and BERT for Small Corpus,2020-09-11 14:01:14+00:00,http://arxiv.org/abs/2009.05451v1,Aysu Ezen-Can,"cs.CL, cs.LG",table2text,"Recent advancements in the NLP field showed that transfer learning helps with
achieving state-of-the-art results for new tasks by tuning pre-trained models
instead of starting from scratch. Transformers have made a significant
improvement in creating new state-of-the-art results for many NLP tasks
including but not limited to text classification, text generation, and sequence
labeling. Most of these success stories were based on large datasets. In this
paper we focus on a real-life scenario that scientists in academia and industry
face frequently: given a small dataset, can we use a large pre-trained model
like BERT and get better results than simple models? To answer this question,
we use a small dataset for intent classification collected for building
chatbots and compare the performance of a simple bidirectional LSTM model with
a pre-trained BERT model. Our experimental results show that bidirectional LSTM
models can achieve significantly higher results than a BERT model for a small
dataset and these simple models get trained in much less time than tuning the
pre-trained counterparts. We conclude that the performance of a model is
dependent on the task and the data, and therefore before making a model choice,
these factors should be taken into consideration instead of directly choosing
the most popular model.",2020-09-11
Modern Methods for Text Generation,2020-09-10 16:17:10+00:00,http://arxiv.org/abs/2009.04968v1,Dimas Munoz Montesinos,"cs.CL, cs.LG",table2text,"Synthetic text generation is challenging and has limited success. Recently, a
new architecture, called Transformers, allow machine learning models to
understand better sequential data, such as translation or summarization. BERT
and GPT-2, using Transformers in their cores, have shown a great performance in
tasks such as text classification, translation and NLI tasks. In this article,
we analyse both algorithms and compare their output quality in text generation
tasks.",2020-09-10
Leam: An Interactive System for In-situ Visual Text Analysis,2020-09-08 05:18:29+00:00,http://arxiv.org/abs/2009.03520v1,"Sajjadur Rahman, Peter Griggs, Çağatay Demiralp","cs.DB, cs.CL, cs.HC",table2text,"With the increase in scale and availability of digital text generated on the
web, enterprises such as online retailers and aggregators often use text
analytics to mine and analyze the data to improve their services and products
alike. Text data analysis is an iterative, non-linear process with diverse
workflows spanning multiple stages, from data cleaning to visualization.
Existing text analytics systems usually accommodate a subset of these stages
and often fail to address challenges related to data heterogeneity, provenance,
workflow reusability and reproducibility, and compatibility with established
practices. Based on a set of design considerations we derive from these
challenges, we propose Leam, a system that treats the text analysis process as
a single continuum by combining advantages of computational notebooks,
spreadsheets, and visualization tools. Leam features an interactive user
interface for running text analysis workflows, a new data model for managing
multiple atomic and composite data types, and an expressive algebra that
captures diverse sets of operations representing various stages of text
analysis and enables coordination among different components of the system,
including data, code, and visualizations. We report our current progress in
Leam development while demonstrating its usefulness with usage examples.
Finally, we outline a number of enhancements to Leam and identify several
research directions for developing an interactive visual text analysis system.",2020-09-08
Robust Conversational AI with Grounded Text Generation,2020-09-07 23:49:28+00:00,http://arxiv.org/abs/2009.03457v1,"Jianfeng Gao, Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, Heung-Yeung Shum","cs.AI, cs.CL",table2text,"This article presents a hybrid approach based on a Grounded Text Generation
(GTG) model to building robust task bots at scale. GTG is a hybrid model which
uses a large-scale Transformer neural network as its backbone, combined with
symbol-manipulation modules for knowledge base inference and prior knowledge
encoding, to generate responses grounded in dialog belief state and real-world
knowledge for task completion. GTG is pre-trained on large amounts of raw text
and human conversational data, and can be fine-tuned to complete a wide range
of tasks.
  The hybrid approach and its variants are being developed simultaneously by
multiple research teams. The primary results reported on task-oriented dialog
benchmarks are very promising, demonstrating the big potential of this
approach. This article provides an overview of this progress and discusses
related methods and technologies that can be incorporated for building robust
conversational AI systems.",2020-09-07
"Black Box to White Box: Discover Model Characteristics Based on
  Strategic Probing",2020-09-07 14:44:28+00:00,http://arxiv.org/abs/2009.03136v1,"Josh Kalin, Matthew Ciolino, David Noever, Gerry Dozier","cs.LG, stat.ML",table2text,"In Machine Learning, White Box Adversarial Attacks rely on knowing underlying
knowledge about the model attributes. This works focuses on discovering to
distrinct pieces of model information: the underlying architecture and primary
training dataset. With the process in this paper, a structured set of input
probes and the output of the model become the training data for a deep
classifier. Two subdomains in Machine Learning are explored: image based
classifiers and text transformers with GPT-2. With image classification, the
focus is on exploring commonly deployed architectures and datasets available in
popular public libraries. Using a single transformer architecture with multiple
levels of parameters, text generation is explored by fine tuning off different
datasets. Each dataset explored in image and text are distinguishable from one
another. Diversity in text transformer outputs implies further research is
needed to successfully classify architecture attribution in text domain.",2020-09-07
"Adversarial Watermarking Transformer: Towards Tracing Text Provenance
  with Data Hiding",2020-09-07 11:01:24+00:00,http://arxiv.org/abs/2009.03015v1,"Sahar Abdelnabi, Mario Fritz","cs.CR, cs.CL, cs.CY, cs.LG, I.2.7",table2text,"Recent advances in natural language generation have introduced powerful
language models with high-quality output text. However, this raises concerns
about the potential misuse of such models for malicious purposes. In this
paper, we study natural language watermarking as a defense to help better mark
and trace the provenance of text. We introduce the Adversarial Watermarking
Transformer (AWT) with a jointly trained encoder-decoder and adversarial
training that, given an input text and a binary message, generates an output
text that is unobtrusively encoded with the given message. We further study
different training and inference strategies to achieve minimal changes to the
semantics and correctness of the input text. AWT is the first end-to-end model
to hide data in text by automatically learning -- without ground truth -- word
substitutions along with their locations in order to encode the message. We
show that our model is effective in largely preserving text utility and
decoding the watermark while hiding its presence against adversaries.
Additionally, we demonstrate that our method is robust against a range of local
changes and denoising attacks.",2020-09-07
"Tweet to News Conversion: An Investigation into Unsupervised
  Controllable Text Generation",2020-08-21 06:56:57+00:00,http://arxiv.org/abs/2008.09333v1,"Zishan Ahmad, Mukuntha N S, Asif Ekbal, Pushpak Bhattacharyya","cs.CL, cs.LG",table2text,"Text generator systems have become extremely popular with the advent of
recent deep learning models such as encoder-decoder. Controlling the
information and style of the generated output without supervision is an
important and challenging Natural Language Processing (NLP) task. In this
paper, we define the task of constructing a coherent paragraph from a set of
disaster domain tweets, without any parallel data. We tackle the problem by
building two systems in pipeline. The first system focuses on unsupervised
style transfer and converts the individual tweets into news sentences. The
second system stitches together the outputs from the first system to form a
coherent news paragraph. We also propose a novel training mechanism, by
splitting the sentences into propositions and training the second system to
merge the sentences. We create a validation and test set consisting of
tweet-sets and their equivalent news paragraphs to perform empirical
evaluation. In a completely unsupervised setting, our model was able to achieve
a BLEU score of 19.32, while successfully transferring styles and joining
tweets to form a meaningful news paragraph.",2020-08-21
"Learning to Create Better Ads: Generation and Ranking Approaches for Ad
  Creative Refinement",2020-08-17 16:46:28+00:00,http://arxiv.org/abs/2008.07467v2,"Shaunak Mishra, Manisha Verma, Yichao Zhou, Kapil Thadani, Wei Wang","cs.CL, cs.IR, cs.LG",table2text,"In the online advertising industry, the process of designing an ad creative
(i.e., ad text and image) requires manual labor. Typically, each advertiser
launches multiple creatives via online A/B tests to infer effective creatives
for the target audience, that are then refined further in an iterative fashion.
Due to the manual nature of this process, it is time-consuming to learn,
refine, and deploy the modified creatives. Since major ad platforms typically
run A/B tests for multiple advertisers in parallel, we explore the possibility
of collaboratively learning ad creative refinement via A/B tests of multiple
advertisers. In particular, given an input ad creative, we study approaches to
refine the given ad text and image by: (i) generating new ad text, (ii)
recommending keyphrases for new ad text, and (iii) recommending image tags
(objects in image) to select new ad image. Based on A/B tests conducted by
multiple advertisers, we form pairwise examples of inferior and superior ad
creatives, and use such pairs to train models for the above tasks. For
generating new ad text, we demonstrate the efficacy of an encoder-decoder
architecture with copy mechanism, which allows some words from the (inferior)
input text to be copied to the output while incorporating new words associated
with higher click-through-rate. For the keyphrase and image tag recommendation
task, we demonstrate the efficacy of a deep relevance matching model, as well
as the relative robustness of ranking approaches compared to ad text generation
in cold-start scenarios with unseen advertisers. We also share broadly
applicable insights from our experiments using data from the Yahoo Gemini ad
platform.",2020-08-17
Language Models as Few-Shot Learner for Task-Oriented Dialogue Systems,2020-08-14 08:23:21+00:00,http://arxiv.org/abs/2008.06239v2,"Andrea Madotto, Zihan Liu, Zhaojiang Lin, Pascale Fung","cs.CL, cs.LG",table2text,"Task-oriented dialogue systems use four connected modules, namely, Natural
Language Understanding (NLU), a Dialogue State Tracking (DST), Dialogue Policy
(DP) and Natural Language Generation (NLG). A research challenge is to learn
each module with the least amount of samples (i.e., few-shots) given the high
cost related to the data collection. The most common and effective technique to
solve this problem is transfer learning, where large language models, either
pre-trained on text or task-specific data, are fine-tuned on the few samples.
These methods require fine-tuning steps and a set of parameters for each task.
Differently, language models, such as GPT-2 (Radford et al., 2019) and GPT-3
(Brown et al., 2020), allow few-shot learning by priming the model with few
examples. In this paper, we evaluate the priming few-shot ability of language
models in the NLU, DST, DP and NLG tasks. Importantly, we highlight the current
limitations of this approach, and we discuss the possible implication for
future work.",2020-08-14
"The Language Interpretability Tool: Extensible, Interactive
  Visualizations and Analysis for NLP Models",2020-08-12 06:07:44+00:00,http://arxiv.org/abs/2008.05122v1,"Ian Tenney, James Wexler, Jasmijn Bastings, Tolga Bolukbasi, Andy Coenen, Sebastian Gehrmann, Ellen Jiang, Mahima Pushkarna, Carey Radebaugh, Emily Reif, Ann Yuan",cs.CL,table2text,"We present the Language Interpretability Tool (LIT), an open-source platform
for visualization and understanding of NLP models. We focus on core questions
about model behavior: Why did my model make this prediction? When does it
perform poorly? What happens under a controlled change in the input? LIT
integrates local explanations, aggregate analysis, and counterfactual
generation into a streamlined, browser-based interface to enable rapid
exploration and error analysis. We include case studies for a diverse set of
workflows, including exploring counterfactuals for sentiment analysis,
measuring gender bias in coreference systems, and exploring local behavior in
text generation. LIT supports a wide range of models--including classification,
seq2seq, and structured prediction--and is highly extensible through a
declarative, framework-agnostic API. LIT is under active development, with code
and full documentation available at https://github.com/pair-code/lit.",2020-08-12
Navigating Human Language Models with Synthetic Agents,2020-08-10 14:39:53+00:00,http://arxiv.org/abs/2008.04162v7,"Philip Feldman, Antonio Bucchiarone","cs.AI, cs.CL, cs.MA, I.2; I.6; J.4",table2text,"Modern natural language models such as the GPT-2/GPT-3 contain tremendous
amounts of information about human belief in a consistently testable form. If
these models could be shown to accurately reflect the underlying beliefs of the
human beings that produced the data used to train these models, then such
models become a powerful sociological tool in ways that are distinct from
traditional methods, such as interviews and surveys. In this study, We train a
version of the GPT-2 on a corpora of historical chess games, and then ""launch""
clusters of synthetic agents into the model, using text strings to create
context and orientation. We compare the trajectories contained in the text
generated by the agents/model and compare that to the known ground truth of the
chess board, move legality, and historical patterns of play. We find that the
percentages of moves by piece using the model are substantially similar from
human patterns. We further find that the model creates an accurate latent
representation of the chessboard, and that it is possible to plot trajectories
of legal moves across the board using this knowledge.",2020-08-10
"Neural Language Generation: Formulation, Methods, and Evaluation",2020-07-31 00:08:28+00:00,http://arxiv.org/abs/2007.15780v1,"Cristina Garbacea, Qiaozhu Mei","cs.CL, cs.AI, cs.LG",table2text,"Recent advances in neural network-based generative modeling have reignited
the hopes in having computer systems capable of seamlessly conversing with
humans and able to understand natural language. Neural architectures have been
employed to generate text excerpts to various degrees of success, in a
multitude of contexts and tasks that fulfil various user needs. Notably, high
capacity deep learning models trained on large scale datasets demonstrate
unparalleled abilities to learn patterns in the data even in the lack of
explicit supervision signals, opening up a plethora of new possibilities
regarding producing realistic and coherent texts. While the field of natural
language generation is evolving rapidly, there are still many open challenges
to address. In this survey we formally define and categorize the problem of
natural language generation. We review particular application tasks that are
instantiations of these general formulations, in which generating natural
language is of practical importance. Next we include a comprehensive outline of
methods and neural architectures employed for generating diverse texts.
Nevertheless, there is no standard way to assess the quality of text produced
by these generative models, which constitutes a serious bottleneck towards the
progress of the field. To this end, we also review current approaches to
evaluating natural language generation systems. We hope this survey will
provide an informative overview of formulations, methods, and assessments of
neural natural language generation.",2020-07-31
Multimodal Dialogue State Tracking By QA Approach with Data Augmentation,2020-07-20 06:23:18+00:00,http://arxiv.org/abs/2007.09903v1,"Xiangyang Mou, Brandyn Sigouin, Ian Steenstra, Hui Su",cs.CL,table2text,"Recently, a more challenging state tracking task, Audio-Video Scene-Aware
Dialogue (AVSD), is catching an increasing amount of attention among
researchers. Different from purely text-based dialogue state tracking, the
dialogue in AVSD contains a sequence of question-answer pairs about a video and
the final answer to the given question requires additional understanding of the
video. This paper interprets the AVSD task from an open-domain Question
Answering (QA) point of view and proposes a multimodal open-domain QA system to
deal with the problem. The proposed QA system uses common encoder-decoder
framework with multimodal fusion and attention. Teacher forcing is applied to
train a natural language generator. We also propose a new data augmentation
approach specifically under QA assumption. Our experiments show that our model
and techniques bring significant improvements over the baseline model on the
DSTC7-AVSD dataset and demonstrate the potentials of our data augmentation
techniques.",2020-07-20
Investigating Pretrained Language Models for Graph-to-Text Generation,2020-07-16 16:05:34+00:00,http://arxiv.org/abs/2007.08426v2,"Leonardo F. R. Ribeiro, Martin Schmitt, Hinrich Schütze, Iryna Gurevych",cs.CL,table2text,"Graph-to-text generation aims to generate fluent texts from graph-based data.
In this paper, we investigate two recently proposed pretrained language models
(PLMs) and analyze the impact of different task-adaptive pretraining strategies
for PLMs in graph-to-text generation. We present a study across three graph
domains: meaning representations, Wikipedia knowledge graphs (KGs) and
scientific KGs. We show that the PLMs BART and T5 achieve new state-of-the-art
results and that task-adaptive pretraining strategies improve their performance
even further. In particular, we report new state-of-the-art BLEU scores of
49.72 on LDC2017T10, 59.70 on WebNLG, and 25.66 on AGENDA datasets - a relative
improvement of 31.8%, 4.5%, and 42.4%, respectively. In an extensive analysis,
we identify possible reasons for the PLMs' success on graph-to-text tasks. We
find evidence that their knowledge about true facts helps them perform well
even when the input graph representation is reduced to a simple bag of node and
edge labels.",2020-07-16
"Modeling Coherency in Generated Emails by Leveraging Deep Neural
  Learners",2020-07-14 23:47:08+00:00,http://arxiv.org/abs/2007.07403v1,"Avisha Das, Rakesh M. Verma",cs.CL,table2text,"Advanced machine learning and natural language techniques enable attackers to
launch sophisticated and targeted social engineering-based attacks. To counter
the active attacker issue, researchers have since resorted to proactive methods
of detection. Email masquerading using targeted emails to fool the victim is an
advanced attack method. However automatic text generation requires controlling
the context and coherency of the generated content, which has been identified
as an increasingly difficult problem. The method used leverages a hierarchical
deep neural model which uses a learned representation of the sentences in the
input document to generate structured written emails. We demonstrate the
generation of short and targeted text messages using the deep model. The global
coherency of the synthesized text is evaluated using a qualitative study as
well as multiple quantitative measures.",2020-07-14
"Deep Transformer based Data Augmentation with Subword Units for
  Morphologically Rich Online ASR",2020-07-14 10:22:05+00:00,http://arxiv.org/abs/2007.06949v3,"Balázs Tarján, György Szaszák, Tibor Fegyó, Péter Mihajlik","eess.AS, cs.CL",table2text,"Recently Deep Transformer models have proven to be particularly powerful in
language modeling tasks for ASR. Their high complexity, however, makes them
very difficult to apply in the first (single) pass of an online system. Recent
studies showed that a considerable part of the knowledge of neural network
Language Models (LM) can be transferred to traditional n-grams by using neural
text generation based data augmentation. In our paper, we pre-train a GPT-2
Transformer LM on a general text corpus and fine-tune it on our Hungarian
conversational call center ASR task. We show that although data augmentation
with Transformer-generated text works well for isolating languages, it causes a
vocabulary explosion in a morphologically rich language. Therefore, we propose
a new method called subword-based neural text augmentation, where we retokenize
the generated text into statistically derived subwords. We compare Morfessor
and BPE statistical subword tokenizers and show that both methods can
significantly improve the WER while greatly reducing vocabulary size and memory
requirements. Finally, we also demonstrate that subword-based neural text
augmentation outperforms the word-based approach not only in terms of overall
WER but also in recognition of OOV words.",2020-07-14
